/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_multiclass',
 'save_path': './record/badnet_attack_efficientnet_ffpp_multiclass',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_multiclass'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2024-11-17:20:13:57 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_multiclass',
 'save_path': './record/badnet_attack_efficientnet_ffpp_multiclass',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_multiclass'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': None,
 'last 3 log': 'commit 8bc0d4cdd3c6f605f1ed08794342ddb7fdeea1ba\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 19:58:36 2024 +0900\n'
               '\n'
               '    new script: remove unneeded data in ffpp_345_classes '
               'dataset\n'
               '\n'
               'commit 9d712a96178e3fef60dffc2abef24948f4b53d32\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 17:27:05 2024 +0900\n'
               '\n'
               '    new script: badnet attack on ffpp_3/4/5_classes dataset on '
               'efficientnet\n'
               '\n'
               'commit 95fc46fa147247bc9144dd7ab4f9122c0f6d6109\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 17:24:01 2024 +0900\n'
               '\n'
               '    support ffpp_3classes, ffpp_4classes, ffpp_5classes '
               'dataset',
 'status': 'On branch test-number-of-class\n'
           "Your branch is up to date with 'origin/test-number-of-class'.\n"
           '\n'
           'Changes not staged for commit:\n'
           '  (use "git add/rm <file>..." to update what will be committed)\n'
           '  (use "git checkout -- <file>..." to discard changes in working '
           'directory)\n'
           '\n'
           '\tdeleted:    out/sample.out\n'
           '\tmodified:   resource/badnet/trigger_image.png\n'
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\n'
           '\tout/badnet_attack_efficientnet_ffpp_3classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_4classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_5classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_multiclass.out\n'
           '\tout/badnet_attack_preactresnet_cifar10.out\n'
           '\tout/badnet_attack_preactresnet_cifar10_2classes.out\n'
           '\tout/badnet_attack_preactresnet_ffpp_binary.out\n'
           '\tout/badnet_attack_preactresnet_ffpp_multiclass.out\n'
           '\tout/copy_ffpp_binary_dataset.out\n'
           '\tout/copy_ffpp_multiclass_dataset.out\n'
           '\tout/generate_ffpp_with_345_classes.out\n'
           '\tout/remove_unnecessary_data.out\n'
           '\n'
           'no changes added to commit (use "git add" and/or "git commit -a")'}
INFO:root:stage1 start
2024-11-17:20:13:57 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2024-11-17:20:13:57 [WARNING ] [dataset_and_transform_generate.py:357] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:43200.0,real pratio:0.1
2024-11-17:20:21:05 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:43200.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2024-11-17:20:21:06 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/432000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 428/432000 [00:00<01:42, 4212.30it/s]prepro_backdoor:   0%|          | 850/432000 [00:00<01:44, 4113.31it/s]prepro_backdoor:   0%|          | 1284/432000 [00:00<01:42, 4214.02it/s]prepro_backdoor:   0%|          | 1706/432000 [00:00<02:27, 2921.83it/s]prepro_backdoor:   0%|          | 2097/432000 [00:00<02:15, 3181.60it/s]prepro_backdoor:   1%|          | 2540/432000 [00:00<02:02, 3513.95it/s]prepro_backdoor:   1%|          | 2979/432000 [00:00<01:54, 3748.06it/s]prepro_backdoor:   1%|          | 3407/432000 [00:00<01:50, 3882.19it/s]prepro_backdoor:   1%|          | 3812/432000 [00:01<01:50, 3889.20it/s]prepro_backdoor:   1%|          | 4230/432000 [00:01<01:48, 3959.43it/s]prepro_backdoor:   1%|          | 4652/432000 [00:01<01:46, 4031.13it/s]prepro_backdoor:   1%|          | 5061/432000 [00:01<01:46, 3997.85it/s]prepro_backdoor:   1%|▏         | 5483/432000 [00:01<01:45, 4040.41it/s]prepro_backdoor:   1%|▏         | 5924/432000 [00:01<01:42, 4145.24it/s]prepro_backdoor:   1%|▏         | 6390/432000 [00:01<01:39, 4275.67it/s]prepro_backdoor:   2%|▏         | 6820/432000 [00:01<01:43, 4092.49it/s]prepro_backdoor:   2%|▏         | 7232/432000 [00:01<01:47, 3933.40it/s]prepro_backdoor:   2%|▏         | 7644/432000 [00:01<01:46, 3983.15it/s]prepro_backdoor:   2%|▏         | 8045/432000 [00:02<02:54, 2429.42it/s]prepro_backdoor:   2%|▏         | 8453/432000 [00:02<02:37, 2694.06it/s]prepro_backdoor:   2%|▏         | 8785/432000 [00:02<02:31, 2793.24it/s]prepro_backdoor:   2%|▏         | 9269/432000 [00:02<02:09, 3263.94it/s]prepro_backdoor:   2%|▏         | 9695/432000 [00:02<02:00, 3508.21it/s]prepro_backdoor:   2%|▏         | 10189/432000 [00:02<01:48, 3871.38it/s]prepro_backdoor:   2%|▏         | 10606/432000 [00:02<01:47, 3909.65it/s]prepro_backdoor:   3%|▎         | 11023/432000 [00:03<01:46, 3957.94it/s]prepro_backdoor:   3%|▎         | 11486/432000 [00:03<01:41, 4128.81it/s]prepro_backdoor:   3%|▎         | 11911/432000 [00:03<01:53, 3694.65it/s]prepro_backdoor:   3%|▎         | 12297/432000 [00:03<02:47, 2509.78it/s]prepro_backdoor:   3%|▎         | 12683/432000 [00:03<03:31, 1978.16it/s]prepro_backdoor:   3%|▎         | 13005/432000 [00:03<03:11, 2188.58it/s]prepro_backdoor:   3%|▎         | 13408/432000 [00:04<02:44, 2541.89it/s]prepro_backdoor:   3%|▎         | 13870/432000 [00:04<02:19, 2987.00it/s]prepro_backdoor:   3%|▎         | 14225/432000 [00:04<02:32, 2737.76it/s]prepro_backdoor:   3%|▎         | 14726/432000 [00:04<02:08, 3241.90it/s]prepro_backdoor:   4%|▎         | 15150/432000 [00:04<01:59, 3486.38it/s]prepro_backdoor:   4%|▎         | 15535/432000 [00:04<02:04, 3351.55it/s]prepro_backdoor:   4%|▎         | 15914/432000 [00:04<02:00, 3459.86it/s]prepro_backdoor:   4%|▍         | 16280/432000 [00:05<04:14, 1635.15it/s]prepro_backdoor:   4%|▍         | 16765/432000 [00:05<03:16, 2116.51it/s]prepro_backdoor:   4%|▍         | 17102/432000 [00:05<03:20, 2065.89it/s]prepro_backdoor:   4%|▍         | 17504/432000 [00:05<02:51, 2417.55it/s]prepro_backdoor:   4%|▍         | 17875/432000 [00:05<02:34, 2676.17it/s]prepro_backdoor:   4%|▍         | 18323/432000 [00:05<02:14, 3084.20it/s]prepro_backdoor:   4%|▍         | 18833/432000 [00:05<01:55, 3564.05it/s]prepro_backdoor:   4%|▍         | 19288/432000 [00:06<01:48, 3804.50it/s]prepro_backdoor:   5%|▍         | 19842/432000 [00:06<01:36, 4249.09it/s]prepro_backdoor:   5%|▍         | 20300/432000 [00:06<01:43, 3985.47it/s]prepro_backdoor:   5%|▍         | 20727/432000 [00:06<01:41, 4041.25it/s]prepro_backdoor:   5%|▍         | 21188/432000 [00:06<01:38, 4170.45it/s]prepro_backdoor:   5%|▌         | 21620/432000 [00:06<01:43, 3978.32it/s]prepro_backdoor:   5%|▌         | 22032/432000 [00:06<01:42, 4015.12it/s]prepro_backdoor:   5%|▌         | 22442/432000 [00:06<01:43, 3966.87it/s]prepro_backdoor:   5%|▌         | 22845/432000 [00:06<02:04, 3286.47it/s]prepro_backdoor:   5%|▌         | 23196/432000 [00:07<02:03, 3321.02it/s]prepro_backdoor:   5%|▌         | 23545/432000 [00:07<02:29, 2734.86it/s]prepro_backdoor:   6%|▌         | 24011/432000 [00:07<02:08, 3167.23it/s]prepro_backdoor:   6%|▌         | 24465/432000 [00:07<01:56, 3507.64it/s]prepro_backdoor:   6%|▌         | 24905/432000 [00:07<01:48, 3735.25it/s]prepro_backdoor:   6%|▌         | 25302/432000 [00:07<01:50, 3688.02it/s]prepro_backdoor:   6%|▌         | 25822/432000 [00:07<01:39, 4097.86it/s]prepro_backdoor:   6%|▌         | 26318/432000 [00:07<01:33, 4336.34it/s]prepro_backdoor:   6%|▌         | 26764/432000 [00:08<01:34, 4297.32it/s]prepro_backdoor:   6%|▋         | 27202/432000 [00:08<01:33, 4306.56it/s]prepro_backdoor:   6%|▋         | 27688/432000 [00:08<01:31, 4437.21it/s]prepro_backdoor:   7%|▋         | 28137/432000 [00:08<01:56, 3453.93it/s]prepro_backdoor:   7%|▋         | 28519/432000 [00:08<01:58, 3396.50it/s]prepro_backdoor:   7%|▋         | 28884/432000 [00:08<01:59, 3367.90it/s]prepro_backdoor:   7%|▋         | 29420/432000 [00:08<01:43, 3878.12it/s]prepro_backdoor:   7%|▋         | 29863/432000 [00:08<01:40, 4012.54it/s]prepro_backdoor:   7%|▋         | 30316/432000 [00:08<01:36, 4148.29it/s]prepro_backdoor:   7%|▋         | 30838/432000 [00:09<01:30, 4446.14it/s]prepro_backdoor:   7%|▋         | 31293/432000 [00:09<01:32, 4331.95it/s]prepro_backdoor:   7%|▋         | 31734/432000 [00:09<01:35, 4180.69it/s]prepro_backdoor:   7%|▋         | 32158/432000 [00:09<01:54, 3479.38it/s]prepro_backdoor:   8%|▊         | 32553/432000 [00:09<01:51, 3576.58it/s]prepro_backdoor:   8%|▊         | 32928/432000 [00:09<01:55, 3457.27it/s]prepro_backdoor:   8%|▊         | 33372/432000 [00:09<01:47, 3694.90it/s]prepro_backdoor:   8%|▊         | 33753/432000 [00:09<01:51, 3563.50it/s]prepro_backdoor:   8%|▊         | 34186/432000 [00:09<01:45, 3758.15it/s]prepro_backdoor:   8%|▊         | 34631/432000 [00:10<01:41, 3929.07it/s]prepro_backdoor:   8%|▊         | 35031/432000 [00:10<01:42, 3878.09it/s]prepro_backdoor:   8%|▊         | 35424/432000 [00:10<01:44, 3812.28it/s]prepro_backdoor:   8%|▊         | 35856/432000 [00:10<01:40, 3943.40it/s]prepro_backdoor:   8%|▊         | 36297/432000 [00:10<01:37, 4053.70it/s]prepro_backdoor:   8%|▊         | 36705/432000 [00:10<01:38, 3993.41it/s]prepro_backdoor:   9%|▊         | 37106/432000 [00:10<01:42, 3853.40it/s]prepro_backdoor:   9%|▊         | 37494/432000 [00:10<01:49, 3602.04it/s]prepro_backdoor:   9%|▉         | 37873/432000 [00:10<01:47, 3652.87it/s]prepro_backdoor:   9%|▉         | 38242/432000 [00:11<01:52, 3499.04it/s]prepro_backdoor:   9%|▉         | 38595/432000 [00:11<01:54, 3442.93it/s]prepro_backdoor:   9%|▉         | 39026/432000 [00:11<01:46, 3674.31it/s]prepro_backdoor:   9%|▉         | 39489/432000 [00:11<01:39, 3937.68it/s]prepro_backdoor:   9%|▉         | 39886/432000 [00:11<01:55, 3407.08it/s]prepro_backdoor:   9%|▉         | 40241/432000 [00:11<01:54, 3415.54it/s]prepro_backdoor:   9%|▉         | 40856/432000 [00:11<01:34, 4155.25it/s]prepro_backdoor:  10%|▉         | 41287/432000 [00:11<01:36, 4051.05it/s]prepro_backdoor:  10%|▉         | 41813/432000 [00:11<01:28, 4386.60it/s]prepro_backdoor:  10%|▉         | 42262/432000 [00:12<01:33, 4165.42it/s]prepro_backdoor:  10%|▉         | 42688/432000 [00:12<02:30, 2578.79it/s]prepro_backdoor:  10%|▉         | 43107/432000 [00:12<02:14, 2883.82it/s]prepro_backdoor:  10%|█         | 43474/432000 [00:12<02:07, 3045.18it/s]prepro_backdoor:  10%|█         | 43834/432000 [00:12<02:03, 3145.36it/s]prepro_backdoor:  10%|█         | 44249/432000 [00:12<01:54, 3381.60it/s]prepro_backdoor:  10%|█         | 44682/432000 [00:12<01:47, 3617.23it/s]prepro_backdoor:  10%|█         | 45070/432000 [00:13<01:48, 3560.54it/s]prepro_backdoor:  11%|█         | 45445/432000 [00:13<01:52, 3429.87it/s]prepro_backdoor:  11%|█         | 45803/432000 [00:13<01:51, 3459.84it/s]prepro_backdoor:  11%|█         | 46185/432000 [00:13<01:48, 3557.70it/s]prepro_backdoor:  11%|█         | 46717/432000 [00:13<01:35, 4053.75it/s]prepro_backdoor:  11%|█         | 47131/432000 [00:13<02:01, 3166.52it/s]prepro_backdoor:  11%|█         | 47490/432000 [00:13<01:58, 3254.09it/s]prepro_backdoor:  11%|█         | 47913/432000 [00:13<01:49, 3494.51it/s]prepro_backdoor:  11%|█         | 48293/432000 [00:13<01:47, 3570.08it/s]prepro_backdoor:  11%|█▏        | 48697/432000 [00:14<01:44, 3684.36it/s]prepro_backdoor:  11%|█▏        | 49078/432000 [00:14<01:50, 3479.35it/s]prepro_backdoor:  11%|█▏        | 49444/432000 [00:14<01:49, 3507.64it/s]prepro_backdoor:  12%|█▏        | 49956/432000 [00:14<01:37, 3933.37it/s]prepro_backdoor:  12%|█▏        | 50357/432000 [00:14<01:39, 3824.87it/s]prepro_backdoor:  12%|█▏        | 50806/432000 [00:14<01:35, 4005.35it/s]prepro_backdoor:  12%|█▏        | 51235/432000 [00:14<01:33, 4084.51it/s]prepro_backdoor:  12%|█▏        | 51668/432000 [00:14<01:31, 4136.03it/s]prepro_backdoor:  12%|█▏        | 52085/432000 [00:15<02:03, 3068.04it/s]prepro_backdoor:  12%|█▏        | 52477/432000 [00:15<01:56, 3265.52it/s]prepro_backdoor:  12%|█▏        | 52950/432000 [00:15<01:44, 3615.28it/s]prepro_backdoor:  12%|█▏        | 53415/432000 [00:15<01:37, 3865.39it/s]prepro_backdoor:  12%|█▏        | 53866/432000 [00:15<01:34, 4021.91it/s]prepro_backdoor:  13%|█▎        | 54303/432000 [00:15<01:31, 4108.23it/s]prepro_backdoor:  13%|█▎        | 54846/432000 [00:15<01:24, 4473.49it/s]prepro_backdoor:  13%|█▎        | 55305/432000 [00:15<01:24, 4452.37it/s]prepro_backdoor:  13%|█▎        | 55758/432000 [00:15<01:25, 4388.16it/s]prepro_backdoor:  13%|█▎        | 56295/432000 [00:15<01:20, 4646.95it/s]prepro_backdoor:  13%|█▎        | 56765/432000 [00:16<01:23, 4498.33it/s]prepro_backdoor:  13%|█▎        | 57249/432000 [00:16<01:22, 4567.81it/s]prepro_backdoor:  13%|█▎        | 57709/432000 [00:16<01:29, 4196.23it/s]prepro_backdoor:  13%|█▎        | 58136/432000 [00:16<01:30, 4118.16it/s]prepro_backdoor:  14%|█▎        | 58672/432000 [00:16<01:24, 4442.20it/s]prepro_backdoor:  14%|█▎        | 59122/432000 [00:16<01:50, 3360.84it/s]prepro_backdoor:  14%|█▍        | 59586/432000 [00:16<01:42, 3642.56it/s]prepro_backdoor:  14%|█▍        | 60048/432000 [00:16<01:36, 3871.15it/s]prepro_backdoor:  14%|█▍        | 60466/432000 [00:17<01:35, 3886.03it/s]prepro_backdoor:  14%|█▍        | 60876/432000 [00:17<01:35, 3883.46it/s]prepro_backdoor:  14%|█▍        | 61280/432000 [00:17<02:01, 3041.23it/s]prepro_backdoor:  14%|█▍        | 61767/432000 [00:17<01:47, 3452.93it/s]prepro_backdoor:  14%|█▍        | 62203/432000 [00:17<01:40, 3664.87it/s]prepro_backdoor:  15%|█▍        | 62667/432000 [00:17<01:34, 3912.33it/s]prepro_backdoor:  15%|█▍        | 63083/432000 [00:17<01:38, 3763.75it/s]prepro_backdoor:  15%|█▍        | 63478/432000 [00:17<01:37, 3769.09it/s]prepro_backdoor:  15%|█▍        | 63899/432000 [00:17<01:35, 3873.45it/s]prepro_backdoor:  15%|█▍        | 64296/432000 [00:18<01:59, 3077.90it/s]prepro_backdoor:  15%|█▌        | 64813/432000 [00:18<01:42, 3569.56it/s]prepro_backdoor:  15%|█▌        | 65292/432000 [00:18<01:34, 3878.05it/s]prepro_backdoor:  15%|█▌        | 65731/432000 [00:18<01:31, 4002.70it/s]prepro_backdoor:  15%|█▌        | 66172/432000 [00:18<01:29, 4102.47it/s]prepro_backdoor:  15%|█▌        | 66599/432000 [00:18<01:51, 3290.43it/s]prepro_backdoor:  16%|█▌        | 66964/432000 [00:18<01:49, 3345.57it/s]prepro_backdoor:  16%|█▌        | 67414/432000 [00:18<01:40, 3626.25it/s]prepro_backdoor:  16%|█▌        | 67800/432000 [00:19<01:41, 3586.95it/s]prepro_backdoor:  16%|█▌        | 68340/432000 [00:19<01:29, 4071.60it/s]prepro_backdoor:  16%|█▌        | 68764/432000 [00:19<01:31, 3986.88it/s]prepro_backdoor:  16%|█▌        | 69204/432000 [00:19<01:28, 4089.49it/s]prepro_backdoor:  16%|█▌        | 69641/432000 [00:19<01:26, 4166.22it/s]prepro_backdoor:  16%|█▌        | 70065/432000 [00:19<01:26, 4164.89it/s]prepro_backdoor:  16%|█▋        | 70496/432000 [00:19<01:26, 4181.90it/s]prepro_backdoor:  16%|█▋        | 70924/432000 [00:19<01:26, 4186.45it/s]prepro_backdoor:  17%|█▋        | 71376/432000 [00:19<01:24, 4265.58it/s]prepro_backdoor:  17%|█▋        | 71839/432000 [00:19<01:22, 4357.21it/s]prepro_backdoor:  17%|█▋        | 72344/432000 [00:20<01:19, 4550.40it/s]prepro_backdoor:  17%|█▋        | 72855/432000 [00:20<01:16, 4685.84it/s]prepro_backdoor:  17%|█▋        | 73325/432000 [00:20<01:18, 4575.31it/s]prepro_backdoor:  17%|█▋        | 73784/432000 [00:20<01:23, 4287.37it/s]prepro_backdoor:  17%|█▋        | 74219/432000 [00:20<01:23, 4294.16it/s]prepro_backdoor:  17%|█▋        | 74652/432000 [00:20<01:24, 4228.97it/s]prepro_backdoor:  17%|█▋        | 75077/432000 [00:20<01:48, 3280.75it/s]prepro_backdoor:  17%|█▋        | 75438/432000 [00:20<01:46, 3344.68it/s]prepro_backdoor:  18%|█▊        | 75855/432000 [00:21<01:40, 3536.65it/s]prepro_backdoor:  18%|█▊        | 76334/432000 [00:21<01:31, 3869.90it/s]prepro_backdoor:  18%|█▊        | 76742/432000 [00:21<01:30, 3920.01it/s]prepro_backdoor:  18%|█▊        | 77148/432000 [00:21<01:33, 3800.94it/s]prepro_backdoor:  18%|█▊        | 77615/432000 [00:21<01:28, 4024.98it/s]prepro_backdoor:  18%|█▊        | 78045/432000 [00:21<01:26, 4083.13it/s]prepro_backdoor:  18%|█▊        | 78460/432000 [00:21<01:29, 3956.83it/s]prepro_backdoor:  18%|█▊        | 78930/432000 [00:21<01:24, 4165.63it/s]prepro_backdoor:  18%|█▊        | 79407/432000 [00:21<01:21, 4335.08it/s]prepro_backdoor:  18%|█▊        | 79845/432000 [00:22<01:45, 3336.68it/s]prepro_backdoor:  19%|█▊        | 80216/432000 [00:22<01:44, 3350.60it/s]prepro_backdoor:  19%|█▊        | 80578/432000 [00:22<02:01, 2900.93it/s]prepro_backdoor:  19%|█▊        | 80958/432000 [00:22<01:53, 3098.10it/s]prepro_backdoor:  19%|█▉        | 81398/432000 [00:22<01:42, 3413.70it/s]prepro_backdoor:  19%|█▉        | 81803/432000 [00:22<01:38, 3570.83it/s]prepro_backdoor:  19%|█▉        | 82178/432000 [00:22<01:36, 3611.09it/s]prepro_backdoor:  19%|█▉        | 82616/432000 [00:22<01:31, 3814.15it/s]prepro_backdoor:  19%|█▉        | 83149/432000 [00:22<01:22, 4225.78it/s]prepro_backdoor:  19%|█▉        | 83581/432000 [00:23<01:23, 4180.66it/s]prepro_backdoor:  19%|█▉        | 84006/432000 [00:23<01:29, 3907.06it/s]prepro_backdoor:  20%|█▉        | 84409/432000 [00:23<01:46, 3255.61it/s]prepro_backdoor:  20%|█▉        | 84899/432000 [00:23<01:35, 3645.32it/s]prepro_backdoor:  20%|█▉        | 85354/432000 [00:23<01:29, 3876.51it/s]prepro_backdoor:  20%|█▉        | 85835/432000 [00:23<01:23, 4123.68it/s]prepro_backdoor:  20%|█▉        | 86326/432000 [00:23<01:20, 4319.14it/s]prepro_backdoor:  20%|██        | 86771/432000 [00:23<01:20, 4299.86it/s]prepro_backdoor:  20%|██        | 87224/432000 [00:23<01:19, 4360.96it/s]prepro_backdoor:  20%|██        | 87667/432000 [00:24<01:18, 4362.54it/s]prepro_backdoor:  20%|██        | 88191/432000 [00:24<01:14, 4589.19it/s]prepro_backdoor:  21%|██        | 88654/432000 [00:24<01:17, 4437.71it/s]prepro_backdoor:  21%|██        | 89102/432000 [00:24<01:20, 4281.39it/s]prepro_backdoor:  21%|██        | 89615/432000 [00:24<01:15, 4519.12it/s]prepro_backdoor:  21%|██        | 90071/432000 [00:24<01:19, 4277.16it/s]prepro_backdoor:  21%|██        | 90504/432000 [00:24<01:20, 4231.02it/s]prepro_backdoor:  21%|██        | 90931/432000 [00:24<01:42, 3316.38it/s]prepro_backdoor:  21%|██        | 91315/432000 [00:25<01:39, 3423.53it/s]prepro_backdoor:  21%|██▏       | 91911/432000 [00:25<01:23, 4058.83it/s]prepro_backdoor:  21%|██▏       | 92345/432000 [00:25<01:25, 3977.44it/s]prepro_backdoor:  21%|██▏       | 92763/432000 [00:25<01:27, 3880.16it/s]prepro_backdoor:  22%|██▏       | 93173/432000 [00:25<01:26, 3918.68it/s]prepro_backdoor:  22%|██▏       | 93638/432000 [00:25<01:22, 4118.50it/s]prepro_backdoor:  22%|██▏       | 94116/432000 [00:25<01:18, 4292.67it/s]prepro_backdoor:  22%|██▏       | 94553/432000 [00:25<01:22, 4113.29it/s]prepro_backdoor:  22%|██▏       | 94971/432000 [00:25<01:24, 3968.47it/s]prepro_backdoor:  22%|██▏       | 95373/432000 [00:25<01:25, 3940.69it/s]prepro_backdoor:  22%|██▏       | 95826/432000 [00:26<01:21, 4106.25it/s]prepro_backdoor:  22%|██▏       | 96240/432000 [00:26<01:23, 4031.05it/s]prepro_backdoor:  22%|██▏       | 96687/432000 [00:26<01:20, 4155.66it/s]prepro_backdoor:  22%|██▏       | 97120/432000 [00:26<01:20, 4182.78it/s]prepro_backdoor:  23%|██▎       | 97540/432000 [00:26<01:22, 4078.20it/s]prepro_backdoor:  23%|██▎       | 98056/432000 [00:26<01:16, 4384.22it/s]prepro_backdoor:  23%|██▎       | 98522/432000 [00:26<01:15, 4444.86it/s]prepro_backdoor:  23%|██▎       | 98969/432000 [00:26<01:46, 3122.35it/s]prepro_backdoor:  23%|██▎       | 99348/432000 [00:27<01:41, 3270.86it/s]prepro_backdoor:  23%|██▎       | 99719/432000 [00:27<01:54, 2895.58it/s]prepro_backdoor:  23%|██▎       | 100206/432000 [00:27<01:39, 3341.91it/s]prepro_backdoor:  23%|██▎       | 100609/432000 [00:27<01:34, 3504.48it/s]prepro_backdoor:  23%|██▎       | 100990/432000 [00:27<01:32, 3565.05it/s]prepro_backdoor:  23%|██▎       | 101398/432000 [00:27<01:29, 3680.81it/s]prepro_backdoor:  24%|██▎       | 101952/432000 [00:27<01:18, 4188.08it/s]prepro_backdoor:  24%|██▎       | 102387/432000 [00:27<01:21, 4065.48it/s]prepro_backdoor:  24%|██▍       | 102839/432000 [00:27<01:18, 4173.33it/s]prepro_backdoor:  24%|██▍       | 103265/432000 [00:28<01:19, 4116.42it/s]prepro_backdoor:  24%|██▍       | 103683/432000 [00:28<01:19, 4132.46it/s]prepro_backdoor:  24%|██▍       | 104154/432000 [00:28<01:16, 4282.07it/s]prepro_backdoor:  24%|██▍       | 104587/432000 [00:28<01:16, 4292.27it/s]prepro_backdoor:  24%|██▍       | 105045/432000 [00:28<01:14, 4372.30it/s]prepro_backdoor:  24%|██▍       | 105556/432000 [00:28<01:11, 4564.07it/s]prepro_backdoor:  25%|██▍       | 106014/432000 [00:28<01:15, 4306.02it/s]prepro_backdoor:  25%|██▍       | 106449/432000 [00:28<01:17, 4214.41it/s]prepro_backdoor:  25%|██▍       | 106874/432000 [00:28<01:18, 4146.35it/s]prepro_backdoor:  25%|██▍       | 107340/432000 [00:29<01:16, 4268.64it/s]prepro_backdoor:  25%|██▍       | 107769/432000 [00:29<01:18, 4139.60it/s]prepro_backdoor:  25%|██▌       | 108258/432000 [00:29<01:14, 4341.61it/s]prepro_backdoor:  25%|██▌       | 108725/432000 [00:29<01:13, 4428.42it/s]prepro_backdoor:  25%|██▌       | 109170/432000 [00:29<01:13, 4392.73it/s]prepro_backdoor:  25%|██▌       | 109642/432000 [00:29<01:11, 4486.59it/s]prepro_backdoor:  25%|██▌       | 110092/432000 [00:29<01:11, 4472.14it/s]prepro_backdoor:  26%|██▌       | 110540/432000 [00:29<01:14, 4294.62it/s]prepro_backdoor:  26%|██▌       | 110972/432000 [00:29<01:16, 4196.10it/s]prepro_backdoor:  26%|██▌       | 111455/432000 [00:29<01:13, 4372.63it/s]prepro_backdoor:  26%|██▌       | 111895/432000 [00:30<01:16, 4206.06it/s]prepro_backdoor:  26%|██▌       | 112390/432000 [00:30<01:12, 4415.10it/s]prepro_backdoor:  26%|██▌       | 112835/432000 [00:30<01:15, 4231.58it/s]prepro_backdoor:  26%|██▌       | 113331/432000 [00:30<01:12, 4416.79it/s]prepro_backdoor:  26%|██▋       | 113808/432000 [00:30<01:10, 4498.99it/s]prepro_backdoor:  26%|██▋       | 114261/432000 [00:30<01:11, 4438.79it/s]prepro_backdoor:  27%|██▋       | 114707/432000 [00:30<01:13, 4334.28it/s]prepro_backdoor:  27%|██▋       | 115142/432000 [00:30<01:16, 4159.48it/s]prepro_backdoor:  27%|██▋       | 115587/432000 [00:30<01:14, 4225.85it/s]prepro_backdoor:  27%|██▋       | 116012/432000 [00:31<01:15, 4175.08it/s]prepro_backdoor:  27%|██▋       | 116570/432000 [00:31<01:09, 4553.78it/s]prepro_backdoor:  27%|██▋       | 117030/432000 [00:31<01:09, 4559.35it/s]prepro_backdoor:  27%|██▋       | 117488/432000 [00:31<01:09, 4536.34it/s]prepro_backdoor:  27%|██▋       | 117969/432000 [00:31<01:08, 4610.50it/s]prepro_backdoor:  27%|██▋       | 118431/432000 [00:31<01:12, 4320.72it/s]prepro_backdoor:  28%|██▊       | 118868/432000 [00:31<01:14, 4217.50it/s]prepro_backdoor:  28%|██▊       | 119389/432000 [00:31<01:09, 4489.57it/s]prepro_backdoor:  28%|██▊       | 119856/432000 [00:31<01:09, 4519.80it/s]prepro_backdoor:  28%|██▊       | 120324/432000 [00:31<01:08, 4558.11it/s]prepro_backdoor:  28%|██▊       | 120782/432000 [00:32<01:13, 4253.38it/s]prepro_backdoor:  28%|██▊       | 121213/432000 [00:32<01:22, 3754.03it/s]prepro_backdoor:  28%|██▊       | 121602/432000 [00:32<01:23, 3707.07it/s]prepro_backdoor:  28%|██▊       | 122020/432000 [00:32<01:21, 3824.33it/s]prepro_backdoor:  28%|██▊       | 122514/432000 [00:32<01:15, 4106.46it/s]prepro_backdoor:  28%|██▊       | 123001/432000 [00:32<01:11, 4315.70it/s]prepro_backdoor:  29%|██▊       | 123439/432000 [00:32<01:14, 4162.25it/s]prepro_backdoor:  29%|██▊       | 123861/432000 [00:32<01:14, 4147.52it/s]prepro_backdoor:  29%|██▉       | 124280/432000 [00:32<01:16, 4012.95it/s]prepro_backdoor:  29%|██▉       | 124685/432000 [00:33<01:17, 3964.96it/s]prepro_backdoor:  29%|██▉       | 125184/432000 [00:33<01:12, 4250.25it/s]prepro_backdoor:  29%|██▉       | 125655/432000 [00:33<01:10, 4372.16it/s]prepro_backdoor:  29%|██▉       | 126172/432000 [00:33<01:06, 4582.47it/s]prepro_backdoor:  29%|██▉       | 126633/432000 [00:33<01:11, 4252.55it/s]prepro_backdoor:  29%|██▉       | 127064/432000 [00:33<01:12, 4182.39it/s]prepro_backdoor:  30%|██▉       | 127487/432000 [00:33<01:14, 4095.29it/s]prepro_backdoor:  30%|██▉       | 127902/432000 [00:33<01:14, 4093.44it/s]prepro_backdoor:  30%|██▉       | 128314/432000 [00:33<01:18, 3893.21it/s]prepro_backdoor:  30%|██▉       | 128706/432000 [00:34<01:21, 3703.30it/s]prepro_backdoor:  30%|██▉       | 129170/432000 [00:34<01:16, 3946.82it/s]prepro_backdoor:  30%|██▉       | 129569/432000 [00:34<01:17, 3910.93it/s]prepro_backdoor:  30%|███       | 129963/432000 [00:34<01:18, 3866.67it/s]prepro_backdoor:  30%|███       | 130358/432000 [00:34<01:17, 3889.05it/s]prepro_backdoor:  30%|███       | 130780/432000 [00:34<01:15, 3973.55it/s]prepro_backdoor:  30%|███       | 131179/432000 [00:34<01:16, 3938.21it/s]prepro_backdoor:  30%|███       | 131574/432000 [00:34<01:22, 3650.72it/s]prepro_backdoor:  31%|███       | 132007/432000 [00:34<01:18, 3826.45it/s]prepro_backdoor:  31%|███       | 132394/432000 [00:35<01:18, 3837.83it/s]prepro_backdoor:  31%|███       | 132817/432000 [00:35<01:15, 3937.54it/s]prepro_backdoor:  31%|███       | 133214/432000 [00:35<01:16, 3902.02it/s]prepro_backdoor:  31%|███       | 133606/432000 [00:35<01:17, 3844.41it/s]prepro_backdoor:  31%|███       | 134128/432000 [00:35<01:10, 4225.09it/s]prepro_backdoor:  31%|███       | 134579/432000 [00:35<01:09, 4261.27it/s]prepro_backdoor:  31%|███▏      | 135054/432000 [00:35<01:07, 4389.49it/s]prepro_backdoor:  31%|███▏      | 135494/432000 [00:35<01:09, 4296.93it/s]prepro_backdoor:  31%|███▏      | 135934/432000 [00:35<01:08, 4305.01it/s]prepro_backdoor:  32%|███▏      | 136392/432000 [00:35<01:07, 4379.30it/s]prepro_backdoor:  32%|███▏      | 136860/432000 [00:36<01:06, 4457.38it/s]prepro_backdoor:  32%|███▏      | 137307/432000 [00:36<01:06, 4412.69it/s]prepro_backdoor:  32%|███▏      | 137749/432000 [00:36<01:09, 4246.68it/s]prepro_backdoor:  32%|███▏      | 138176/432000 [00:36<01:11, 4106.88it/s]prepro_backdoor:  32%|███▏      | 138660/432000 [00:36<01:08, 4302.23it/s]prepro_backdoor:  32%|███▏      | 139201/432000 [00:36<01:03, 4620.94it/s]prepro_backdoor:  32%|███▏      | 139666/432000 [00:36<01:12, 4054.06it/s]prepro_backdoor:  32%|███▏      | 140266/432000 [00:36<01:04, 4552.83it/s]prepro_backdoor:  33%|███▎      | 140737/432000 [00:36<01:04, 4507.28it/s]prepro_backdoor:  33%|███▎      | 141199/432000 [00:37<01:05, 4415.28it/s]prepro_backdoor:  33%|███▎      | 141694/432000 [00:37<01:03, 4556.56it/s]prepro_backdoor:  33%|███▎      | 142156/432000 [00:37<01:03, 4571.07it/s]prepro_backdoor:  33%|███▎      | 142618/432000 [00:37<01:03, 4568.97it/s]prepro_backdoor:  33%|███▎      | 143078/432000 [00:37<01:04, 4503.82it/s]prepro_backdoor:  33%|███▎      | 143531/432000 [00:37<01:04, 4494.32it/s]prepro_backdoor:  33%|███▎      | 144057/432000 [00:37<01:01, 4717.84it/s]prepro_backdoor:  33%|███▎      | 144553/432000 [00:37<01:00, 4773.64it/s]prepro_backdoor:  34%|███▎      | 145032/432000 [00:37<01:03, 4519.85it/s]prepro_backdoor:  34%|███▎      | 145488/432000 [00:37<01:06, 4293.97it/s]prepro_backdoor:  34%|███▍      | 145922/432000 [00:38<01:07, 4263.11it/s]prepro_backdoor:  34%|███▍      | 146351/432000 [00:38<01:10, 4042.28it/s]prepro_backdoor:  34%|███▍      | 146800/432000 [00:38<01:08, 4159.68it/s]prepro_backdoor:  34%|███▍      | 147222/432000 [00:38<01:08, 4158.45it/s]prepro_backdoor:  34%|███▍      | 147641/432000 [00:38<01:08, 4131.27it/s]prepro_backdoor:  34%|███▍      | 148133/432000 [00:38<01:05, 4335.91it/s]prepro_backdoor:  34%|███▍      | 148569/432000 [00:38<01:08, 4120.56it/s]prepro_backdoor:  34%|███▍      | 148996/432000 [00:38<01:08, 4138.81it/s]prepro_backdoor:  35%|███▍      | 149412/432000 [00:38<01:12, 3879.81it/s]prepro_backdoor:  35%|███▍      | 149853/432000 [00:39<01:10, 4002.18it/s]prepro_backdoor:  35%|███▍      | 150272/432000 [00:39<01:09, 4045.10it/s]prepro_backdoor:  35%|███▍      | 150680/432000 [00:39<01:11, 3920.02it/s]prepro_backdoor:  35%|███▍      | 151082/432000 [00:39<01:11, 3938.70it/s]prepro_backdoor:  35%|███▌      | 151543/432000 [00:39<01:08, 4114.43it/s]prepro_backdoor:  35%|███▌      | 151957/432000 [00:39<01:09, 4019.68it/s]prepro_backdoor:  35%|███▌      | 152433/432000 [00:39<01:06, 4228.20it/s]prepro_backdoor:  35%|███▌      | 152858/432000 [00:39<01:09, 4041.31it/s]prepro_backdoor:  35%|███▌      | 153291/432000 [00:39<01:07, 4111.38it/s]prepro_backdoor:  36%|███▌      | 153705/432000 [00:40<01:10, 3955.93it/s]prepro_backdoor:  36%|███▌      | 154120/432000 [00:40<01:09, 3997.68it/s]prepro_backdoor:  36%|███▌      | 154559/432000 [00:40<01:07, 4104.76it/s]prepro_backdoor:  36%|███▌      | 155155/432000 [00:40<00:59, 4626.60it/s]prepro_backdoor:  36%|███▌      | 155621/432000 [00:40<01:02, 4457.31it/s]prepro_backdoor:  36%|███▌      | 156070/432000 [00:40<01:09, 3945.51it/s]prepro_backdoor:  36%|███▌      | 156477/432000 [00:40<01:09, 3944.95it/s]prepro_backdoor:  36%|███▋      | 156896/432000 [00:40<01:08, 3998.98it/s]prepro_backdoor:  36%|███▋      | 157303/432000 [00:40<01:09, 3965.41it/s]prepro_backdoor:  37%|███▋      | 157744/432000 [00:40<01:07, 4068.63it/s]prepro_backdoor:  37%|███▋      | 158191/432000 [00:41<01:05, 4172.95it/s]prepro_backdoor:  37%|███▋      | 158754/432000 [00:41<00:59, 4575.71it/s]prepro_backdoor:  37%|███▋      | 159215/432000 [00:41<00:59, 4558.62it/s]prepro_backdoor:  37%|███▋      | 159673/432000 [00:41<01:04, 4204.74it/s]prepro_backdoor:  37%|███▋      | 160178/432000 [00:41<01:01, 4414.51it/s]prepro_backdoor:  37%|███▋      | 160626/432000 [00:41<01:03, 4274.27it/s]prepro_backdoor:  37%|███▋      | 161058/432000 [00:41<01:05, 4106.88it/s]prepro_backdoor:  37%|███▋      | 161564/432000 [00:41<01:02, 4353.76it/s]prepro_backdoor:  38%|███▊      | 162004/432000 [00:41<01:08, 3937.87it/s]prepro_backdoor:  38%|███▊      | 162460/432000 [00:42<01:05, 4086.88it/s]prepro_backdoor:  38%|███▊      | 162877/432000 [00:42<01:11, 3776.17it/s]prepro_backdoor:  38%|███▊      | 163282/432000 [00:42<01:10, 3832.27it/s]prepro_backdoor:  38%|███▊      | 163673/432000 [00:42<01:10, 3814.89it/s]prepro_backdoor:  38%|███▊      | 164060/432000 [00:42<01:10, 3789.52it/s]prepro_backdoor:  38%|███▊      | 164558/432000 [00:42<01:05, 4103.47it/s]prepro_backdoor:  38%|███▊      | 165020/432000 [00:42<01:02, 4239.90it/s]prepro_backdoor:  38%|███▊      | 165493/432000 [00:42<01:01, 4353.22it/s]prepro_backdoor:  38%|███▊      | 165931/432000 [00:42<01:05, 4084.87it/s]prepro_backdoor:  39%|███▊      | 166345/432000 [00:43<01:06, 3986.72it/s]prepro_backdoor:  39%|███▊      | 166785/432000 [00:43<01:04, 4081.30it/s]prepro_backdoor:  39%|███▊      | 167207/432000 [00:43<01:04, 4110.97it/s]prepro_backdoor:  39%|███▉      | 167621/432000 [00:43<01:06, 4003.79it/s]prepro_backdoor:  39%|███▉      | 168024/432000 [00:43<01:06, 3951.93it/s]prepro_backdoor:  39%|███▉      | 168468/432000 [00:43<01:04, 4081.45it/s]prepro_backdoor:  39%|███▉      | 168944/432000 [00:43<01:01, 4268.46it/s]prepro_backdoor:  39%|███▉      | 169411/432000 [00:43<01:00, 4358.38it/s]prepro_backdoor:  39%|███▉      | 169973/432000 [00:43<00:55, 4706.29it/s]prepro_backdoor:  39%|███▉      | 170445/432000 [00:44<00:59, 4363.10it/s]prepro_backdoor:  40%|███▉      | 170887/432000 [00:44<01:00, 4303.28it/s]prepro_backdoor:  40%|███▉      | 171321/432000 [00:44<01:00, 4273.56it/s]prepro_backdoor:  40%|███▉      | 171781/432000 [00:44<00:59, 4366.33it/s]prepro_backdoor:  40%|███▉      | 172220/432000 [00:44<01:00, 4299.66it/s]prepro_backdoor:  40%|███▉      | 172652/432000 [00:44<01:00, 4288.94it/s]prepro_backdoor:  40%|████      | 173082/432000 [00:44<01:01, 4210.59it/s]prepro_backdoor:  40%|████      | 173504/432000 [00:44<01:03, 4065.54it/s]prepro_backdoor:  40%|████      | 173912/432000 [00:44<01:03, 4048.41it/s]prepro_backdoor:  40%|████      | 174323/432000 [00:44<01:03, 4061.08it/s]prepro_backdoor:  40%|████      | 174783/432000 [00:45<01:01, 4191.31it/s]prepro_backdoor:  41%|████      | 175203/432000 [00:45<01:02, 4100.32it/s]prepro_backdoor:  41%|████      | 175732/432000 [00:45<00:57, 4434.72it/s]prepro_backdoor:  41%|████      | 176237/432000 [00:45<00:55, 4591.01it/s]prepro_backdoor:  41%|████      | 176698/432000 [00:45<00:58, 4372.42it/s]prepro_backdoor:  41%|████      | 177138/432000 [00:45<01:00, 4226.56it/s]prepro_backdoor:  41%|████      | 177569/432000 [00:45<01:00, 4234.28it/s]prepro_backdoor:  41%|████      | 177995/432000 [00:45<01:00, 4216.16it/s]prepro_backdoor:  41%|████▏     | 178418/432000 [00:45<01:01, 4133.53it/s]prepro_backdoor:  41%|████▏     | 178833/432000 [00:46<01:05, 3848.23it/s]prepro_backdoor:  42%|████▏     | 179291/432000 [00:46<01:02, 4029.56it/s]prepro_backdoor:  42%|████▏     | 179698/432000 [00:46<01:02, 4035.82it/s]prepro_backdoor:  42%|████▏     | 180132/432000 [00:46<01:01, 4118.31it/s]prepro_backdoor:  42%|████▏     | 180635/432000 [00:46<00:57, 4368.82it/s]prepro_backdoor:  42%|████▏     | 181075/432000 [00:46<01:02, 3985.72it/s]prepro_backdoor:  42%|████▏     | 181571/432000 [00:46<00:59, 4233.03it/s]prepro_backdoor:  42%|████▏     | 182014/432000 [00:46<00:58, 4281.38it/s]prepro_backdoor:  42%|████▏     | 182448/432000 [00:46<01:00, 4123.70it/s]prepro_backdoor:  42%|████▏     | 182925/432000 [00:46<00:58, 4291.80it/s]prepro_backdoor:  42%|████▏     | 183359/432000 [00:47<01:02, 4009.98it/s]prepro_backdoor:  43%|████▎     | 183766/432000 [00:47<01:03, 3937.45it/s]prepro_backdoor:  43%|████▎     | 184387/432000 [00:47<00:54, 4553.27it/s]prepro_backdoor:  43%|████▎     | 184863/432000 [00:47<00:53, 4587.07it/s]prepro_backdoor:  43%|████▎     | 185327/432000 [00:47<00:55, 4456.89it/s]prepro_backdoor:  43%|████▎     | 185777/432000 [00:47<00:56, 4381.06it/s]prepro_backdoor:  43%|████▎     | 186243/432000 [00:47<00:55, 4453.33it/s]prepro_backdoor:  43%|████▎     | 186758/432000 [00:47<00:52, 4629.55it/s]prepro_backdoor:  43%|████▎     | 187223/432000 [00:47<00:53, 4598.74it/s]prepro_backdoor:  43%|████▎     | 187685/432000 [00:48<00:53, 4558.36it/s]prepro_backdoor:  44%|████▎     | 188177/432000 [00:48<00:52, 4656.97it/s]prepro_backdoor:  44%|████▎     | 188644/432000 [00:48<00:57, 4227.56it/s]prepro_backdoor:  44%|████▍     | 189075/432000 [00:48<00:59, 4067.42it/s]prepro_backdoor:  44%|████▍     | 189543/432000 [00:48<00:57, 4225.06it/s]prepro_backdoor:  44%|████▍     | 190089/432000 [00:48<00:53, 4545.98it/s]prepro_backdoor:  44%|████▍     | 190550/432000 [00:48<00:53, 4518.65it/s]prepro_backdoor:  44%|████▍     | 191006/432000 [00:48<00:56, 4277.16it/s]prepro_backdoor:  44%|████▍     | 191439/432000 [00:48<01:01, 3910.49it/s]prepro_backdoor:  44%|████▍     | 191838/432000 [00:49<01:03, 3785.74it/s]prepro_backdoor:  45%|████▍     | 192250/432000 [00:49<01:01, 3868.30it/s]prepro_backdoor:  45%|████▍     | 192671/432000 [00:49<01:00, 3960.91it/s]prepro_backdoor:  45%|████▍     | 193072/432000 [00:49<01:06, 3575.38it/s]prepro_backdoor:  45%|████▍     | 193474/432000 [00:49<01:04, 3687.76it/s]prepro_backdoor:  45%|████▍     | 194040/432000 [00:49<00:56, 4230.22it/s]prepro_backdoor:  45%|████▌     | 194474/432000 [00:49<01:00, 3913.52it/s]prepro_backdoor:  45%|████▌     | 195027/432000 [00:49<00:54, 4349.45it/s]prepro_backdoor:  45%|████▌     | 195475/432000 [00:49<00:54, 4313.25it/s]prepro_backdoor:  45%|████▌     | 195920/432000 [00:50<00:54, 4351.09it/s]prepro_backdoor:  45%|████▌     | 196363/432000 [00:50<00:54, 4360.29it/s]prepro_backdoor:  46%|████▌     | 196804/432000 [00:50<01:01, 3806.08it/s]prepro_backdoor:  46%|████▌     | 197205/432000 [00:50<01:00, 3852.41it/s]prepro_backdoor:  46%|████▌     | 197639/432000 [00:50<00:59, 3962.83it/s]prepro_backdoor:  46%|████▌     | 198044/432000 [00:50<00:59, 3927.73it/s]prepro_backdoor:  46%|████▌     | 198461/432000 [00:50<00:58, 3985.06it/s]prepro_backdoor:  46%|████▌     | 198929/432000 [00:50<00:55, 4166.52it/s]prepro_backdoor:  46%|████▌     | 199350/432000 [00:50<00:56, 4134.75it/s]prepro_backdoor:  46%|████▋     | 199822/432000 [00:51<00:54, 4288.17it/s]prepro_backdoor:  46%|████▋     | 200340/432000 [00:51<00:50, 4547.91it/s]prepro_backdoor:  46%|████▋     | 200797/432000 [00:51<00:57, 4013.31it/s]prepro_backdoor:  47%|████▋     | 201218/432000 [00:51<00:56, 4059.23it/s]prepro_backdoor:  47%|████▋     | 201734/432000 [00:51<00:52, 4345.80it/s]prepro_backdoor:  47%|████▋     | 202202/432000 [00:51<00:51, 4430.43it/s]prepro_backdoor:  47%|████▋     | 202757/432000 [00:51<00:48, 4721.93it/s]prepro_backdoor:  47%|████▋     | 203235/432000 [00:51<00:50, 4555.27it/s]prepro_backdoor:  47%|████▋     | 203813/432000 [00:51<00:46, 4898.47it/s]prepro_backdoor:  47%|████▋     | 204327/432000 [00:52<00:46, 4938.00it/s]prepro_backdoor:  47%|████▋     | 204825/432000 [00:52<00:55, 4066.12it/s]prepro_backdoor:  48%|████▊     | 205259/432000 [00:52<00:55, 4073.26it/s]prepro_backdoor:  48%|████▊     | 205686/432000 [00:52<00:59, 3822.89it/s]prepro_backdoor:  48%|████▊     | 206176/432000 [00:52<00:55, 4084.90it/s]prepro_backdoor:  48%|████▊     | 206665/432000 [00:52<00:52, 4275.09it/s]prepro_backdoor:  48%|████▊     | 207105/432000 [00:52<00:52, 4263.13it/s]prepro_backdoor:  48%|████▊     | 207540/432000 [00:52<00:53, 4228.79it/s]prepro_backdoor:  48%|████▊     | 207990/432000 [00:52<00:52, 4288.72it/s]prepro_backdoor:  48%|████▊     | 208424/432000 [00:53<00:53, 4160.04it/s]prepro_backdoor:  48%|████▊     | 208844/432000 [00:53<00:54, 4120.32it/s]prepro_backdoor:  48%|████▊     | 209259/432000 [00:53<00:55, 4017.90it/s]prepro_backdoor:  49%|████▊     | 209663/432000 [00:53<00:55, 3972.32it/s]prepro_backdoor:  49%|████▊     | 210105/432000 [00:53<00:54, 4093.40it/s]prepro_backdoor:  49%|████▊     | 210536/432000 [00:53<00:53, 4150.39it/s]prepro_backdoor:  49%|████▉     | 210953/432000 [00:53<00:53, 4126.46it/s]prepro_backdoor:  49%|████▉     | 211374/432000 [00:53<00:53, 4142.31it/s]prepro_backdoor:  49%|████▉     | 211852/432000 [00:53<00:51, 4309.12it/s]prepro_backdoor:  49%|████▉     | 212284/432000 [00:53<00:53, 4083.72it/s]prepro_backdoor:  49%|████▉     | 212837/432000 [00:54<00:49, 4471.45it/s]prepro_backdoor:  49%|████▉     | 213288/432000 [00:54<00:49, 4428.66it/s]prepro_backdoor:  49%|████▉     | 213734/432000 [00:54<00:52, 4176.03it/s]prepro_backdoor:  50%|████▉     | 214191/432000 [00:54<00:51, 4265.93it/s]prepro_backdoor:  50%|████▉     | 214621/432000 [00:54<00:51, 4230.45it/s]prepro_backdoor:  50%|████▉     | 215059/432000 [00:54<00:51, 4251.13it/s]prepro_backdoor:  50%|████▉     | 215486/432000 [00:54<00:51, 4240.31it/s]prepro_backdoor:  50%|████▉     | 215946/432000 [00:54<00:50, 4316.38it/s]prepro_backdoor:  50%|█████     | 216379/432000 [00:54<00:51, 4168.99it/s]prepro_backdoor:  50%|█████     | 216835/432000 [00:55<00:50, 4280.87it/s]prepro_backdoor:  50%|█████     | 217265/432000 [00:55<00:52, 4093.33it/s]prepro_backdoor:  50%|█████     | 217709/432000 [00:55<00:51, 4175.49it/s]prepro_backdoor:  50%|█████     | 218129/432000 [00:55<00:51, 4163.20it/s]prepro_backdoor:  51%|█████     | 218547/432000 [00:55<00:53, 3977.27it/s]prepro_backdoor:  51%|█████     | 218996/432000 [00:55<00:51, 4111.58it/s]prepro_backdoor:  51%|█████     | 219413/432000 [00:55<00:51, 4124.10it/s]prepro_backdoor:  51%|█████     | 219857/432000 [00:55<00:50, 4192.27it/s]prepro_backdoor:  51%|█████     | 220371/432000 [00:55<00:47, 4459.04it/s]prepro_backdoor:  51%|█████     | 220819/432000 [00:55<00:49, 4291.08it/s]prepro_backdoor:  51%|█████     | 221251/432000 [00:56<00:50, 4192.51it/s]prepro_backdoor:  51%|█████▏    | 221672/432000 [00:56<00:53, 3922.49it/s]prepro_backdoor:  51%|█████▏    | 222086/432000 [00:56<00:52, 3961.15it/s]prepro_backdoor:  52%|█████▏    | 222560/432000 [00:56<00:50, 4155.31it/s]prepro_backdoor:  52%|█████▏    | 222999/432000 [00:56<00:49, 4220.01it/s]prepro_backdoor:  52%|█████▏    | 223424/432000 [00:56<00:50, 4132.39it/s]prepro_backdoor:  52%|█████▏    | 223840/432000 [00:56<00:51, 4066.87it/s]prepro_backdoor:  52%|█████▏    | 224258/432000 [00:56<00:50, 4073.42it/s]prepro_backdoor:  52%|█████▏    | 224719/432000 [00:56<00:49, 4213.51it/s]prepro_backdoor:  52%|█████▏    | 225185/432000 [00:57<00:47, 4333.04it/s]prepro_backdoor:  52%|█████▏    | 225620/432000 [00:57<00:54, 3773.88it/s]prepro_backdoor:  52%|█████▏    | 226011/432000 [00:57<00:56, 3670.12it/s]prepro_backdoor:  52%|█████▏    | 226391/432000 [00:57<00:55, 3699.81it/s]prepro_backdoor:  53%|█████▎    | 226880/432000 [00:57<00:50, 4023.48it/s]prepro_backdoor:  53%|█████▎    | 227290/432000 [00:57<00:51, 3999.71it/s]prepro_backdoor:  53%|█████▎    | 227912/432000 [00:57<00:44, 4622.83it/s]prepro_backdoor:  53%|█████▎    | 228381/432000 [00:57<00:44, 4613.09it/s]prepro_backdoor:  53%|█████▎    | 228881/432000 [00:57<00:43, 4703.22it/s]prepro_backdoor:  53%|█████▎    | 229355/432000 [00:58<00:45, 4466.19it/s]prepro_backdoor:  53%|█████▎    | 229806/432000 [00:58<00:46, 4333.22it/s]prepro_backdoor:  53%|█████▎    | 230243/432000 [00:58<00:49, 4114.26it/s]prepro_backdoor:  53%|█████▎    | 230742/432000 [00:58<00:46, 4349.26it/s]prepro_backdoor:  54%|█████▎    | 231182/432000 [00:58<00:46, 4331.17it/s]prepro_backdoor:  54%|█████▎    | 231619/432000 [00:58<00:46, 4278.75it/s]prepro_backdoor:  54%|█████▎    | 232051/432000 [00:58<00:46, 4283.73it/s]prepro_backdoor:  54%|█████▍    | 232481/432000 [00:58<00:48, 4088.96it/s]prepro_backdoor:  54%|█████▍    | 232962/432000 [00:58<00:46, 4283.32it/s]prepro_backdoor:  54%|█████▍    | 233413/432000 [00:58<00:45, 4328.40it/s]prepro_backdoor:  54%|█████▍    | 233848/432000 [00:59<00:46, 4298.64it/s]prepro_backdoor:  54%|█████▍    | 234280/432000 [00:59<00:53, 3674.70it/s]prepro_backdoor:  54%|█████▍    | 234694/432000 [00:59<00:52, 3785.11it/s]prepro_backdoor:  54%|█████▍    | 235086/432000 [00:59<00:52, 3755.99it/s]prepro_backdoor:  55%|█████▍    | 235491/432000 [00:59<00:51, 3827.85it/s]prepro_backdoor:  55%|█████▍    | 235988/432000 [00:59<00:47, 4146.34it/s]prepro_backdoor:  55%|█████▍    | 236424/432000 [00:59<00:46, 4189.70it/s]prepro_backdoor:  55%|█████▍    | 236848/432000 [00:59<00:47, 4137.68it/s]prepro_backdoor:  55%|█████▍    | 237266/432000 [00:59<00:47, 4058.65it/s]prepro_backdoor:  55%|█████▌    | 237702/432000 [01:00<00:47, 4127.46it/s]prepro_backdoor:  55%|█████▌    | 238125/432000 [01:00<00:46, 4153.19it/s]prepro_backdoor:  55%|█████▌    | 238542/432000 [01:00<00:49, 3931.19it/s]prepro_backdoor:  55%|█████▌    | 238969/432000 [01:00<00:48, 3999.74it/s]prepro_backdoor:  55%|█████▌    | 239414/432000 [01:00<00:46, 4122.95it/s]prepro_backdoor:  56%|█████▌    | 239829/432000 [01:00<00:47, 4003.59it/s]prepro_backdoor:  56%|█████▌    | 240478/432000 [01:00<00:40, 4687.40it/s]prepro_backdoor:  56%|█████▌    | 240951/432000 [01:00<00:43, 4433.48it/s]prepro_backdoor:  56%|█████▌    | 241400/432000 [01:00<00:45, 4197.80it/s]prepro_backdoor:  56%|█████▌    | 241832/432000 [01:01<00:45, 4213.07it/s]prepro_backdoor:  56%|█████▌    | 242363/432000 [01:01<00:42, 4500.97it/s]prepro_backdoor:  56%|█████▌    | 242818/432000 [01:01<00:42, 4487.43it/s]prepro_backdoor:  56%|█████▋    | 243270/432000 [01:01<00:44, 4259.31it/s]prepro_backdoor:  56%|█████▋    | 243753/432000 [01:01<00:42, 4396.59it/s]prepro_backdoor:  57%|█████▋    | 244203/432000 [01:01<00:42, 4417.35it/s]prepro_backdoor:  57%|█████▋    | 244705/432000 [01:01<00:40, 4568.37it/s]prepro_backdoor:  57%|█████▋    | 245172/432000 [01:01<00:40, 4569.51it/s]prepro_backdoor:  57%|█████▋    | 245631/432000 [01:01<00:42, 4368.03it/s]prepro_backdoor:  57%|█████▋    | 246071/432000 [01:02<00:43, 4270.19it/s]prepro_backdoor:  57%|█████▋    | 246554/432000 [01:02<00:42, 4412.26it/s]prepro_backdoor:  57%|█████▋    | 246998/432000 [01:02<00:45, 4033.31it/s]prepro_backdoor:  57%|█████▋    | 247409/432000 [01:02<00:48, 3792.75it/s]prepro_backdoor:  57%|█████▋    | 247836/432000 [01:02<00:47, 3909.63it/s]prepro_backdoor:  57%|█████▋    | 248233/432000 [01:02<00:47, 3829.93it/s]prepro_backdoor:  58%|█████▊    | 248620/432000 [01:02<00:48, 3818.09it/s]prepro_backdoor:  58%|█████▊    | 249012/432000 [01:02<00:47, 3828.34it/s]prepro_backdoor:  58%|█████▊    | 249427/432000 [01:02<00:46, 3901.01it/s]prepro_backdoor:  58%|█████▊    | 249833/432000 [01:02<00:46, 3932.31it/s]prepro_backdoor:  58%|█████▊    | 250228/432000 [01:03<00:47, 3829.34it/s]prepro_backdoor:  58%|█████▊    | 250613/432000 [01:03<00:47, 3816.74it/s]prepro_backdoor:  58%|█████▊    | 251014/432000 [01:03<00:46, 3859.25it/s]prepro_backdoor:  58%|█████▊    | 251520/432000 [01:03<00:43, 4188.22it/s]prepro_backdoor:  58%|█████▊    | 251940/432000 [01:03<00:44, 4062.63it/s]prepro_backdoor:  58%|█████▊    | 252348/432000 [01:03<00:45, 3970.01it/s]prepro_backdoor:  59%|█████▊    | 252790/432000 [01:03<00:43, 4078.84it/s]prepro_backdoor:  59%|█████▊    | 253327/432000 [01:03<00:40, 4439.82it/s]prepro_backdoor:  59%|█████▊    | 253775/432000 [01:03<00:40, 4436.18it/s]prepro_backdoor:  59%|█████▉    | 254220/432000 [01:04<00:40, 4367.26it/s]prepro_backdoor:  59%|█████▉    | 254658/432000 [01:04<00:41, 4222.49it/s]prepro_backdoor:  59%|█████▉    | 255082/432000 [01:04<00:42, 4119.93it/s]prepro_backdoor:  59%|█████▉    | 255571/432000 [01:04<00:40, 4329.75it/s]prepro_backdoor:  59%|█████▉    | 256021/432000 [01:04<00:40, 4354.86it/s]prepro_backdoor:  59%|█████▉    | 256458/432000 [01:04<00:41, 4209.67it/s]prepro_backdoor:  59%|█████▉    | 256881/432000 [01:04<00:43, 3995.48it/s]prepro_backdoor:  60%|█████▉    | 257313/432000 [01:04<00:42, 4080.05it/s]prepro_backdoor:  60%|█████▉    | 257788/432000 [01:04<00:40, 4250.43it/s]prepro_backdoor:  60%|█████▉    | 258267/432000 [01:04<00:39, 4382.71it/s]prepro_backdoor:  60%|█████▉    | 258708/432000 [01:05<00:40, 4307.69it/s]prepro_backdoor:  60%|█████▉    | 259187/432000 [01:05<00:38, 4446.49it/s]prepro_backdoor:  60%|██████    | 259686/432000 [01:05<00:37, 4578.36it/s]prepro_backdoor:  60%|██████    | 260146/432000 [01:05<00:40, 4234.14it/s]prepro_backdoor:  60%|██████    | 260588/432000 [01:05<00:40, 4272.04it/s]prepro_backdoor:  60%|██████    | 261020/432000 [01:05<00:40, 4272.02it/s]prepro_backdoor:  61%|██████    | 261495/432000 [01:05<00:38, 4390.19it/s]prepro_backdoor:  61%|██████    | 261937/432000 [01:05<00:39, 4313.08it/s]prepro_backdoor:  61%|██████    | 262436/432000 [01:05<00:37, 4507.82it/s]prepro_backdoor:  61%|██████    | 262899/432000 [01:06<00:37, 4516.30it/s]prepro_backdoor:  61%|██████    | 263493/432000 [01:06<00:34, 4902.30it/s]prepro_backdoor:  61%|██████    | 263985/432000 [01:06<00:35, 4760.80it/s]prepro_backdoor:  61%|██████    | 264463/432000 [01:06<00:39, 4243.11it/s]prepro_backdoor:  61%|██████▏   | 264898/432000 [01:06<00:40, 4152.54it/s]prepro_backdoor:  61%|██████▏   | 265337/432000 [01:06<00:39, 4199.91it/s]prepro_backdoor:  62%|██████▏   | 265763/432000 [01:06<00:39, 4185.74it/s]prepro_backdoor:  62%|██████▏   | 266186/432000 [01:06<00:40, 4120.36it/s]prepro_backdoor:  62%|██████▏   | 266601/432000 [01:06<00:40, 4083.06it/s]prepro_backdoor:  62%|██████▏   | 267011/432000 [01:07<00:42, 3887.96it/s]prepro_backdoor:  62%|██████▏   | 267441/432000 [01:07<00:43, 3768.42it/s]prepro_backdoor:  62%|██████▏   | 267869/432000 [01:07<00:42, 3897.55it/s]prepro_backdoor:  62%|██████▏   | 268389/432000 [01:07<00:38, 4248.04it/s]prepro_backdoor:  62%|██████▏   | 268856/432000 [01:07<00:37, 4354.89it/s]prepro_backdoor:  62%|██████▏   | 269295/432000 [01:07<00:38, 4227.05it/s]prepro_backdoor:  62%|██████▏   | 269721/432000 [01:07<00:40, 4030.51it/s]prepro_backdoor:  63%|██████▎   | 270269/432000 [01:07<00:36, 4419.23it/s]prepro_backdoor:  63%|██████▎   | 270716/432000 [01:07<00:38, 4149.90it/s]prepro_backdoor:  63%|██████▎   | 271137/432000 [01:08<00:40, 3953.65it/s]prepro_backdoor:  63%|██████▎   | 271538/432000 [01:08<00:41, 3839.24it/s]prepro_backdoor:  63%|██████▎   | 271952/432000 [01:08<00:40, 3907.15it/s]prepro_backdoor:  63%|██████▎   | 272395/432000 [01:08<00:39, 4029.66it/s]prepro_backdoor:  63%|██████▎   | 272875/432000 [01:08<00:37, 4235.44it/s]prepro_backdoor:  63%|██████▎   | 273302/432000 [01:08<00:37, 4240.59it/s]prepro_backdoor:  63%|██████▎   | 273856/432000 [01:08<00:34, 4614.29it/s]prepro_backdoor:  64%|██████▎   | 274320/432000 [01:08<00:36, 4363.85it/s]prepro_backdoor:  64%|██████▎   | 274770/432000 [01:08<00:35, 4393.20it/s]prepro_backdoor:  64%|██████▎   | 275268/432000 [01:08<00:34, 4532.19it/s]prepro_backdoor:  64%|██████▍   | 275849/432000 [01:09<00:32, 4872.44it/s]prepro_backdoor:  64%|██████▍   | 276351/432000 [01:09<00:31, 4897.15it/s]prepro_backdoor:  64%|██████▍   | 276843/432000 [01:09<00:32, 4805.06it/s]prepro_backdoor:  64%|██████▍   | 277325/432000 [01:09<00:33, 4580.55it/s]prepro_backdoor:  64%|██████▍   | 277786/432000 [01:09<00:35, 4333.76it/s]prepro_backdoor:  64%|██████▍   | 278224/432000 [01:09<00:36, 4227.92it/s]prepro_backdoor:  65%|██████▍   | 278712/432000 [01:09<00:34, 4389.98it/s]prepro_backdoor:  65%|██████▍   | 279237/432000 [01:09<00:33, 4626.51it/s]prepro_backdoor:  65%|██████▍   | 279703/432000 [01:09<00:33, 4578.46it/s]prepro_backdoor:  65%|██████▍   | 280164/432000 [01:10<00:34, 4436.07it/s]prepro_backdoor:  65%|██████▍   | 280610/432000 [01:10<00:36, 4184.75it/s]prepro_backdoor:  65%|██████▌   | 281078/432000 [01:10<00:35, 4294.23it/s]prepro_backdoor:  65%|██████▌   | 281572/432000 [01:10<00:33, 4452.21it/s]prepro_backdoor:  65%|██████▌   | 282039/432000 [01:10<00:33, 4503.37it/s]prepro_backdoor:  65%|██████▌   | 282580/432000 [01:10<00:31, 4745.16it/s]prepro_backdoor:  66%|██████▌   | 283057/432000 [01:10<00:32, 4575.48it/s]prepro_backdoor:  66%|██████▌   | 283518/432000 [01:10<00:33, 4379.86it/s]prepro_backdoor:  66%|██████▌   | 283994/432000 [01:10<00:33, 4482.33it/s]prepro_backdoor:  66%|██████▌   | 284452/432000 [01:11<00:32, 4496.06it/s]prepro_backdoor:  66%|██████▌   | 284904/432000 [01:11<00:34, 4304.88it/s]prepro_backdoor:  66%|██████▌   | 285362/432000 [01:11<00:33, 4377.32it/s]prepro_backdoor:  66%|██████▌   | 285834/432000 [01:11<00:32, 4475.31it/s]prepro_backdoor:  66%|██████▋   | 286308/432000 [01:11<00:32, 4529.06it/s]prepro_backdoor:  66%|██████▋   | 286763/432000 [01:11<00:33, 4278.55it/s]prepro_backdoor:  66%|██████▋   | 287250/432000 [01:11<00:32, 4421.38it/s]prepro_backdoor:  67%|██████▋   | 287696/432000 [01:11<00:33, 4270.76it/s]prepro_backdoor:  67%|██████▋   | 288186/432000 [01:11<00:32, 4425.34it/s]prepro_backdoor:  67%|██████▋   | 288657/432000 [01:11<00:31, 4495.07it/s]prepro_backdoor:  67%|██████▋   | 289109/432000 [01:12<00:33, 4263.90it/s]prepro_backdoor:  67%|██████▋   | 289539/432000 [01:12<00:36, 3874.33it/s]prepro_backdoor:  67%|██████▋   | 289987/432000 [01:12<00:35, 4034.28it/s]prepro_backdoor:  67%|██████▋   | 290453/432000 [01:12<00:33, 4185.11it/s]prepro_backdoor:  67%|██████▋   | 291028/432000 [01:12<00:30, 4609.76it/s]prepro_backdoor:  67%|██████▋   | 291496/432000 [01:12<00:30, 4570.22it/s]prepro_backdoor:  68%|██████▊   | 291985/432000 [01:12<00:30, 4643.23it/s]prepro_backdoor:  68%|██████▊   | 292567/432000 [01:12<00:28, 4976.33it/s]prepro_backdoor:  68%|██████▊   | 293069/432000 [01:12<00:29, 4687.64it/s]prepro_backdoor:  68%|██████▊   | 293583/432000 [01:13<00:28, 4815.25it/s]prepro_backdoor:  68%|██████▊   | 294070/432000 [01:13<00:29, 4696.87it/s]prepro_backdoor:  68%|██████▊   | 294544/432000 [01:13<00:31, 4382.84it/s]prepro_backdoor:  68%|██████▊   | 294988/432000 [01:13<00:31, 4343.36it/s]prepro_backdoor:  68%|██████▊   | 295427/432000 [01:13<00:31, 4315.39it/s]prepro_backdoor:  68%|██████▊   | 295862/432000 [01:13<00:31, 4276.34it/s]prepro_backdoor:  69%|██████▊   | 296292/432000 [01:13<00:33, 4014.10it/s]prepro_backdoor:  69%|██████▊   | 296795/432000 [01:13<00:31, 4269.50it/s]prepro_backdoor:  69%|██████▉   | 297317/432000 [01:13<00:29, 4537.03it/s]prepro_backdoor:  69%|██████▉   | 297783/432000 [01:14<00:29, 4554.16it/s]prepro_backdoor:  69%|██████▉   | 298242/432000 [01:14<00:29, 4515.20it/s]prepro_backdoor:  69%|██████▉   | 298696/432000 [01:14<00:32, 4111.43it/s]prepro_backdoor:  69%|██████▉   | 299154/432000 [01:14<00:31, 4231.06it/s]prepro_backdoor:  69%|██████▉   | 299584/432000 [01:14<00:31, 4162.78it/s]prepro_backdoor:  69%|██████▉   | 300055/432000 [01:14<00:30, 4306.25it/s]prepro_backdoor:  70%|██████▉   | 300490/432000 [01:14<00:31, 4169.59it/s]prepro_backdoor:  70%|██████▉   | 301014/432000 [01:14<00:29, 4462.38it/s]prepro_backdoor:  70%|██████▉   | 301465/432000 [01:14<00:31, 4135.58it/s]prepro_backdoor:  70%|██████▉   | 301921/432000 [01:15<00:30, 4232.33it/s]prepro_backdoor:  70%|██████▉   | 302350/432000 [01:15<00:30, 4202.85it/s]prepro_backdoor:  70%|███████   | 302774/432000 [01:15<00:30, 4189.30it/s]prepro_backdoor:  70%|███████   | 303252/432000 [01:15<00:29, 4344.58it/s]prepro_backdoor:  70%|███████   | 303711/432000 [01:15<00:29, 4414.30it/s]prepro_backdoor:  70%|███████   | 304155/432000 [01:15<00:29, 4372.96it/s]prepro_backdoor:  71%|███████   | 304614/432000 [01:15<00:28, 4416.79it/s]prepro_backdoor:  71%|███████   | 305079/432000 [01:15<00:28, 4473.39it/s]prepro_backdoor:  71%|███████   | 305648/432000 [01:15<00:26, 4830.55it/s]prepro_backdoor:  71%|███████   | 306215/432000 [01:15<00:24, 5047.32it/s]prepro_backdoor:  71%|███████   | 306721/432000 [01:16<00:25, 4875.51it/s]prepro_backdoor:  71%|███████   | 307211/432000 [01:16<00:27, 4620.44it/s]prepro_backdoor:  71%|███████   | 307677/432000 [01:16<00:27, 4564.65it/s]prepro_backdoor:  71%|███████▏  | 308147/432000 [01:16<00:27, 4573.27it/s]prepro_backdoor:  71%|███████▏  | 308669/432000 [01:16<00:25, 4748.14it/s]prepro_backdoor:  72%|███████▏  | 309182/432000 [01:16<00:25, 4839.74it/s]prepro_backdoor:  72%|███████▏  | 309668/432000 [01:16<00:27, 4463.76it/s]prepro_backdoor:  72%|███████▏  | 310131/432000 [01:16<00:27, 4488.24it/s]prepro_backdoor:  72%|███████▏  | 310585/432000 [01:16<00:28, 4292.12it/s]prepro_backdoor:  72%|███████▏  | 311067/432000 [01:17<00:27, 4415.81it/s]prepro_backdoor:  72%|███████▏  | 311513/432000 [01:17<00:29, 4131.67it/s]prepro_backdoor:  72%|███████▏  | 311932/432000 [01:17<00:29, 4050.05it/s]prepro_backdoor:  72%|███████▏  | 312348/432000 [01:17<00:29, 4060.46it/s]prepro_backdoor:  72%|███████▏  | 312757/432000 [01:17<00:29, 4039.23it/s]prepro_backdoor:  73%|███████▎  | 313220/432000 [01:17<00:28, 4198.33it/s]prepro_backdoor:  73%|███████▎  | 313642/432000 [01:17<00:28, 4171.32it/s]prepro_backdoor:  73%|███████▎  | 314061/432000 [01:17<00:30, 3878.51it/s]prepro_backdoor:  73%|███████▎  | 314454/432000 [01:17<00:31, 3721.86it/s]prepro_backdoor:  73%|███████▎  | 314928/432000 [01:18<00:29, 3980.39it/s]prepro_backdoor:  73%|███████▎  | 315331/432000 [01:18<00:29, 3928.51it/s]prepro_backdoor:  73%|███████▎  | 315757/432000 [01:18<00:28, 4015.69it/s]prepro_backdoor:  73%|███████▎  | 316162/432000 [01:18<00:31, 3711.84it/s]prepro_backdoor:  73%|███████▎  | 316562/432000 [01:18<00:30, 3779.14it/s]prepro_backdoor:  73%|███████▎  | 316945/432000 [01:18<00:30, 3792.88it/s]prepro_backdoor:  73%|███████▎  | 317401/432000 [01:18<00:28, 3988.08it/s]prepro_backdoor:  74%|███████▎  | 317803/432000 [01:18<00:46, 2446.14it/s]prepro_backdoor:  74%|███████▎  | 318202/432000 [01:19<00:41, 2756.16it/s]prepro_backdoor:  74%|███████▍  | 318647/432000 [01:19<00:36, 3124.24it/s]prepro_backdoor:  74%|███████▍  | 319045/432000 [01:19<00:34, 3316.04it/s]prepro_backdoor:  74%|███████▍  | 319425/432000 [01:19<00:32, 3436.32it/s]prepro_backdoor:  74%|███████▍  | 319826/432000 [01:19<00:31, 3580.36it/s]prepro_backdoor:  74%|███████▍  | 320210/432000 [01:19<00:30, 3619.62it/s]prepro_backdoor:  74%|███████▍  | 320590/432000 [01:19<00:30, 3662.71it/s]prepro_backdoor:  74%|███████▍  | 321065/432000 [01:19<00:28, 3958.44it/s]prepro_backdoor:  74%|███████▍  | 321472/432000 [01:19<00:27, 3963.23it/s]prepro_backdoor:  75%|███████▍  | 321916/432000 [01:20<00:26, 4083.11it/s]prepro_backdoor:  75%|███████▍  | 322330/432000 [01:20<00:26, 4099.29it/s]prepro_backdoor:  75%|███████▍  | 322794/432000 [01:20<00:25, 4230.25it/s]prepro_backdoor:  75%|███████▍  | 323349/432000 [01:20<00:23, 4593.28it/s]prepro_backdoor:  75%|███████▍  | 323811/432000 [01:20<00:23, 4531.50it/s]prepro_backdoor:  75%|███████▌  | 324397/432000 [01:20<00:21, 4895.27it/s]prepro_backdoor:  75%|███████▌  | 324888/432000 [01:20<00:23, 4550.78it/s]prepro_backdoor:  75%|███████▌  | 325349/432000 [01:20<00:24, 4407.49it/s]prepro_backdoor:  75%|███████▌  | 325804/432000 [01:20<00:23, 4445.79it/s]prepro_backdoor:  76%|███████▌  | 326252/432000 [01:20<00:24, 4295.17it/s]prepro_backdoor:  76%|███████▌  | 326775/432000 [01:21<00:23, 4543.63it/s]prepro_backdoor:  76%|███████▌  | 327302/432000 [01:21<00:22, 4724.38it/s]prepro_backdoor:  76%|███████▌  | 327810/432000 [01:21<00:21, 4815.17it/s]prepro_backdoor:  76%|███████▌  | 328336/432000 [01:21<00:21, 4936.02it/s]prepro_backdoor:  76%|███████▌  | 328832/432000 [01:21<00:22, 4641.96it/s]prepro_backdoor:  76%|███████▌  | 329301/432000 [01:21<00:22, 4551.56it/s]prepro_backdoor:  76%|███████▋  | 329760/432000 [01:21<00:23, 4298.93it/s]prepro_backdoor:  76%|███████▋  | 330225/432000 [01:21<00:23, 4376.15it/s]prepro_backdoor:  77%|███████▋  | 330706/432000 [01:21<00:22, 4473.22it/s]prepro_backdoor:  77%|███████▋  | 331159/432000 [01:22<00:22, 4463.99it/s]prepro_backdoor:  77%|███████▋  | 331645/432000 [01:22<00:22, 4551.92it/s]prepro_backdoor:  77%|███████▋  | 332102/432000 [01:22<00:25, 3964.11it/s]prepro_backdoor:  77%|███████▋  | 332539/432000 [01:22<00:24, 4053.39it/s]prepro_backdoor:  77%|███████▋  | 332961/432000 [01:22<00:24, 4091.33it/s]prepro_backdoor:  77%|███████▋  | 333378/432000 [01:22<00:24, 4086.31it/s]prepro_backdoor:  77%|███████▋  | 333860/432000 [01:22<00:22, 4268.55it/s]prepro_backdoor:  77%|███████▋  | 334292/432000 [01:22<00:23, 4218.28it/s]prepro_backdoor:  77%|███████▋  | 334723/432000 [01:22<00:22, 4237.87it/s]prepro_backdoor:  78%|███████▊  | 335350/432000 [01:22<00:20, 4822.93it/s]prepro_backdoor:  78%|███████▊  | 335836/432000 [01:23<00:21, 4475.47it/s]prepro_backdoor:  78%|███████▊  | 336291/432000 [01:23<00:21, 4493.99it/s]prepro_backdoor:  78%|███████▊  | 336746/432000 [01:23<00:23, 4137.32it/s]prepro_backdoor:  78%|███████▊  | 337168/432000 [01:23<00:23, 4104.97it/s]prepro_backdoor:  78%|███████▊  | 337584/432000 [01:23<00:27, 3485.37it/s]prepro_backdoor:  78%|███████▊  | 338037/432000 [01:23<00:25, 3727.23it/s]prepro_backdoor:  78%|███████▊  | 338427/432000 [01:23<00:24, 3754.81it/s]prepro_backdoor:  78%|███████▊  | 338866/432000 [01:23<00:23, 3924.01it/s]prepro_backdoor:  79%|███████▊  | 339308/432000 [01:24<00:22, 4035.82it/s]prepro_backdoor:  79%|███████▊  | 339720/432000 [01:24<00:23, 3974.00it/s]prepro_backdoor:  79%|███████▊  | 340123/432000 [01:24<00:23, 3839.49it/s]prepro_backdoor:  79%|███████▉  | 340512/432000 [01:24<00:23, 3835.74it/s]prepro_backdoor:  79%|███████▉  | 340956/432000 [01:24<00:22, 3985.02it/s]prepro_backdoor:  79%|███████▉  | 341381/432000 [01:24<00:22, 4050.02it/s]prepro_backdoor:  79%|███████▉  | 342021/432000 [01:24<00:19, 4709.10it/s]prepro_backdoor:  79%|███████▉  | 342495/432000 [01:24<00:26, 3375.70it/s]prepro_backdoor:  79%|███████▉  | 343009/432000 [01:24<00:23, 3781.97it/s]prepro_backdoor:  80%|███████▉  | 343442/432000 [01:25<00:22, 3902.07it/s]prepro_backdoor:  80%|███████▉  | 343870/432000 [01:25<00:22, 3958.66it/s]prepro_backdoor:  80%|███████▉  | 344373/432000 [01:25<00:20, 4226.35it/s]prepro_backdoor:  80%|███████▉  | 344823/432000 [01:25<00:20, 4297.76it/s]prepro_backdoor:  80%|███████▉  | 345311/432000 [01:25<00:19, 4438.32it/s]prepro_backdoor:  80%|████████  | 345767/432000 [01:25<00:19, 4409.67it/s]prepro_backdoor:  80%|████████  | 346217/432000 [01:25<00:21, 4052.70it/s]prepro_backdoor:  80%|████████  | 346633/432000 [01:25<00:21, 3882.09it/s]prepro_backdoor:  80%|████████  | 347133/432000 [01:25<00:20, 4173.68it/s]prepro_backdoor:  80%|████████  | 347574/432000 [01:26<00:20, 4219.49it/s]prepro_backdoor:  81%|████████  | 348003/432000 [01:26<00:26, 3121.15it/s]prepro_backdoor:  81%|████████  | 348370/432000 [01:26<00:25, 3243.58it/s]prepro_backdoor:  81%|████████  | 348761/432000 [01:26<00:24, 3391.99it/s]prepro_backdoor:  81%|████████  | 349228/432000 [01:26<00:22, 3716.94it/s]prepro_backdoor:  81%|████████  | 349660/432000 [01:26<00:21, 3870.26it/s]prepro_backdoor:  81%|████████  | 350070/432000 [01:26<00:20, 3929.03it/s]prepro_backdoor:  81%|████████  | 350532/432000 [01:26<00:19, 4104.36it/s]prepro_backdoor:  81%|████████  | 350957/432000 [01:26<00:19, 4120.58it/s]prepro_backdoor:  81%|████████▏ | 351377/432000 [01:27<00:19, 4096.62it/s]prepro_backdoor:  81%|████████▏ | 351792/432000 [01:27<00:25, 3115.20it/s]prepro_backdoor:  82%|████████▏ | 352302/432000 [01:27<00:22, 3587.70it/s]prepro_backdoor:  82%|████████▏ | 352730/432000 [01:27<00:21, 3754.65it/s]prepro_backdoor:  82%|████████▏ | 353160/432000 [01:27<00:20, 3877.40it/s]prepro_backdoor:  82%|████████▏ | 353570/432000 [01:27<00:20, 3866.61it/s]prepro_backdoor:  82%|████████▏ | 354127/432000 [01:27<00:18, 4317.25it/s]prepro_backdoor:  82%|████████▏ | 354665/432000 [01:27<00:16, 4614.13it/s]prepro_backdoor:  82%|████████▏ | 355138/432000 [01:28<00:16, 4575.89it/s]prepro_backdoor:  82%|████████▏ | 355604/432000 [01:28<00:17, 4317.86it/s]prepro_backdoor:  82%|████████▏ | 356044/432000 [01:28<00:23, 3184.35it/s]prepro_backdoor:  83%|████████▎ | 356480/432000 [01:28<00:21, 3447.69it/s]prepro_backdoor:  83%|████████▎ | 356990/432000 [01:28<00:19, 3831.41it/s]prepro_backdoor:  83%|████████▎ | 357423/432000 [01:28<00:18, 3954.31it/s]prepro_backdoor:  83%|████████▎ | 357847/432000 [01:28<00:19, 3819.85it/s]prepro_backdoor:  83%|████████▎ | 358288/432000 [01:28<00:18, 3972.78it/s]prepro_backdoor:  83%|████████▎ | 358701/432000 [01:29<00:18, 4000.58it/s]prepro_backdoor:  83%|████████▎ | 359113/432000 [01:29<00:18, 3957.09it/s]prepro_backdoor:  83%|████████▎ | 359517/432000 [01:29<00:18, 3850.53it/s]prepro_backdoor:  83%|████████▎ | 359948/432000 [01:29<00:18, 3969.19it/s]prepro_backdoor:  83%|████████▎ | 360350/432000 [01:29<00:18, 3909.82it/s]prepro_backdoor:  84%|████████▎ | 360812/432000 [01:29<00:17, 4095.90it/s]prepro_backdoor:  84%|████████▎ | 361225/432000 [01:29<00:21, 3280.03it/s]prepro_backdoor:  84%|████████▎ | 361642/432000 [01:29<00:20, 3499.03it/s]prepro_backdoor:  84%|████████▍ | 362016/432000 [01:29<00:20, 3492.22it/s]prepro_backdoor:  84%|████████▍ | 362435/432000 [01:30<00:18, 3668.48it/s]prepro_backdoor:  84%|████████▍ | 362833/432000 [01:30<00:18, 3738.93it/s]prepro_backdoor:  84%|████████▍ | 363269/432000 [01:30<00:17, 3905.87it/s]prepro_backdoor:  84%|████████▍ | 363709/432000 [01:30<00:16, 4035.46it/s]prepro_backdoor:  84%|████████▍ | 364145/432000 [01:30<00:16, 4128.46it/s]prepro_backdoor:  84%|████████▍ | 364612/432000 [01:30<00:15, 4286.51it/s]prepro_backdoor:  85%|████████▍ | 365045/432000 [01:30<00:16, 4062.36it/s]prepro_backdoor:  85%|████████▍ | 365503/432000 [01:30<00:15, 4195.28it/s]prepro_backdoor:  85%|████████▍ | 365927/432000 [01:30<00:20, 3242.99it/s]prepro_backdoor:  85%|████████▍ | 366422/432000 [01:31<00:17, 3650.24it/s]prepro_backdoor:  85%|████████▍ | 366925/432000 [01:31<00:16, 3995.05it/s]prepro_backdoor:  85%|████████▌ | 367355/432000 [01:31<00:16, 3842.49it/s]prepro_backdoor:  85%|████████▌ | 367761/432000 [01:31<00:18, 3560.52it/s]prepro_backdoor:  85%|████████▌ | 368244/432000 [01:31<00:16, 3865.59it/s]prepro_backdoor:  85%|████████▌ | 368652/432000 [01:31<00:16, 3922.51it/s]prepro_backdoor:  85%|████████▌ | 369071/432000 [01:31<00:15, 3983.94it/s]prepro_backdoor:  86%|████████▌ | 369491/432000 [01:31<00:15, 4033.80it/s]prepro_backdoor:  86%|████████▌ | 369932/432000 [01:31<00:14, 4141.57it/s]prepro_backdoor:  86%|████████▌ | 370413/432000 [01:32<00:14, 4306.98it/s]prepro_backdoor:  86%|████████▌ | 370848/432000 [01:32<00:24, 2448.48it/s]prepro_backdoor:  86%|████████▌ | 371287/432000 [01:32<00:21, 2817.17it/s]prepro_backdoor:  86%|████████▌ | 371799/432000 [01:32<00:18, 3305.86it/s]prepro_backdoor:  86%|████████▌ | 372339/432000 [01:32<00:15, 3777.54it/s]prepro_backdoor:  86%|████████▋ | 372786/432000 [01:32<00:15, 3935.26it/s]prepro_backdoor:  86%|████████▋ | 373231/432000 [01:32<00:14, 4056.76it/s]prepro_backdoor:  86%|████████▋ | 373674/432000 [01:33<00:14, 3925.75it/s]prepro_backdoor:  87%|████████▋ | 374123/432000 [01:33<00:14, 4063.14it/s]prepro_backdoor:  87%|████████▋ | 374668/432000 [01:33<00:12, 4421.89it/s]prepro_backdoor:  87%|████████▋ | 375148/432000 [01:33<00:12, 4501.25it/s]prepro_backdoor:  87%|████████▋ | 375611/432000 [01:33<00:16, 3504.24it/s]prepro_backdoor:  87%|████████▋ | 376003/432000 [01:33<00:15, 3584.87it/s]prepro_backdoor:  87%|████████▋ | 376393/432000 [01:33<00:15, 3576.10it/s]prepro_backdoor:  87%|████████▋ | 376773/432000 [01:33<00:15, 3619.56it/s]prepro_backdoor:  87%|████████▋ | 377214/432000 [01:33<00:14, 3821.48it/s]prepro_backdoor:  87%|████████▋ | 377705/432000 [01:34<00:13, 4102.76it/s]prepro_backdoor:  88%|████████▊ | 378127/432000 [01:34<00:13, 4041.88it/s]prepro_backdoor:  88%|████████▊ | 378539/432000 [01:34<00:13, 3987.63it/s]prepro_backdoor:  88%|████████▊ | 378943/432000 [01:34<00:14, 3732.46it/s]prepro_backdoor:  88%|████████▊ | 379547/432000 [01:34<00:12, 4362.34it/s]prepro_backdoor:  88%|████████▊ | 379994/432000 [01:34<00:12, 4261.92it/s]prepro_backdoor:  88%|████████▊ | 380428/432000 [01:34<00:12, 4066.78it/s]prepro_backdoor:  88%|████████▊ | 380841/432000 [01:34<00:13, 3883.07it/s]prepro_backdoor:  88%|████████▊ | 381283/432000 [01:34<00:12, 4017.09it/s]prepro_backdoor:  88%|████████▊ | 381690/432000 [01:35<00:15, 3304.08it/s]prepro_backdoor:  88%|████████▊ | 382043/432000 [01:35<00:15, 3222.45it/s]prepro_backdoor:  89%|████████▊ | 382494/432000 [01:35<00:14, 3526.91it/s]prepro_backdoor:  89%|████████▊ | 382863/432000 [01:35<00:13, 3540.44it/s]prepro_backdoor:  89%|████████▊ | 383229/432000 [01:35<00:14, 3481.76it/s]prepro_backdoor:  89%|████████▉ | 383607/432000 [01:35<00:13, 3549.58it/s]prepro_backdoor:  89%|████████▉ | 384065/432000 [01:35<00:12, 3819.80it/s]prepro_backdoor:  89%|████████▉ | 384503/432000 [01:35<00:11, 3963.81it/s]prepro_backdoor:  89%|████████▉ | 384904/432000 [01:35<00:11, 3975.26it/s]prepro_backdoor:  89%|████████▉ | 385305/432000 [01:36<00:11, 3977.12it/s]prepro_backdoor:  89%|████████▉ | 385705/432000 [01:36<00:11, 3862.37it/s]prepro_backdoor:  89%|████████▉ | 386094/432000 [01:36<00:12, 3624.41it/s]prepro_backdoor:  89%|████████▉ | 386461/432000 [01:36<00:13, 3291.05it/s]prepro_backdoor:  90%|████████▉ | 386931/432000 [01:36<00:12, 3654.22it/s]prepro_backdoor:  90%|████████▉ | 387351/432000 [01:36<00:11, 3784.18it/s]prepro_backdoor:  90%|████████▉ | 387738/432000 [01:36<00:13, 3162.49it/s]prepro_backdoor:  90%|████████▉ | 388077/432000 [01:36<00:13, 3216.76it/s]prepro_backdoor:  90%|████████▉ | 388455/432000 [01:36<00:12, 3363.72it/s]prepro_backdoor:  90%|█████████ | 388927/432000 [01:37<00:11, 3721.74it/s]prepro_backdoor:  90%|█████████ | 389312/432000 [01:37<00:12, 3510.79it/s]prepro_backdoor:  90%|█████████ | 389721/432000 [01:37<00:11, 3667.94it/s]prepro_backdoor:  90%|█████████ | 390162/432000 [01:37<00:10, 3868.09it/s]prepro_backdoor:  90%|█████████ | 390557/432000 [01:37<00:10, 3891.22it/s]prepro_backdoor:  91%|█████████ | 390967/432000 [01:37<00:10, 3935.89it/s]prepro_backdoor:  91%|█████████ | 391365/432000 [01:37<00:10, 3942.25it/s]prepro_backdoor:  91%|█████████ | 391801/432000 [01:37<00:09, 4038.33it/s]prepro_backdoor:  91%|█████████ | 392305/432000 [01:37<00:09, 4329.59it/s]prepro_backdoor:  91%|█████████ | 392740/432000 [01:38<00:09, 4180.57it/s]prepro_backdoor:  91%|█████████ | 393203/432000 [01:38<00:09, 4281.79it/s]prepro_backdoor:  91%|█████████ | 393633/432000 [01:38<00:09, 3942.29it/s]prepro_backdoor:  91%|█████████ | 394090/432000 [01:38<00:09, 4090.10it/s]prepro_backdoor:  91%|█████████▏| 394505/432000 [01:38<00:09, 3948.88it/s]prepro_backdoor:  91%|█████████▏| 394904/432000 [01:38<00:09, 3868.91it/s]prepro_backdoor:  92%|█████████▏| 395331/432000 [01:38<00:09, 3966.13it/s]prepro_backdoor:  92%|█████████▏| 395749/432000 [01:38<00:09, 4024.74it/s]prepro_backdoor:  92%|█████████▏| 396280/432000 [01:38<00:08, 4372.32it/s]prepro_backdoor:  92%|█████████▏| 396771/432000 [01:39<00:07, 4504.68it/s]prepro_backdoor:  92%|█████████▏| 397400/432000 [01:39<00:06, 5021.75it/s]prepro_backdoor:  92%|█████████▏| 397905/432000 [01:39<00:07, 4689.82it/s]prepro_backdoor:  92%|█████████▏| 398380/432000 [01:39<00:07, 4517.82it/s]prepro_backdoor:  92%|█████████▏| 398837/432000 [01:39<00:07, 4401.94it/s]prepro_backdoor:  92%|█████████▏| 399281/432000 [01:39<00:08, 4033.03it/s]prepro_backdoor:  93%|█████████▎| 399801/432000 [01:39<00:07, 4321.88it/s]prepro_backdoor:  93%|█████████▎| 400241/432000 [01:39<00:09, 3420.39it/s]prepro_backdoor:  93%|█████████▎| 400703/432000 [01:39<00:08, 3698.09it/s]prepro_backdoor:  93%|█████████▎| 401138/432000 [01:40<00:07, 3859.98it/s]prepro_backdoor:  93%|█████████▎| 401648/432000 [01:40<00:07, 4181.42it/s]prepro_backdoor:  93%|█████████▎| 402090/432000 [01:40<00:07, 4234.62it/s]prepro_backdoor:  93%|█████████▎| 402553/432000 [01:40<00:06, 4330.62it/s]prepro_backdoor:  93%|█████████▎| 402998/432000 [01:40<00:07, 3867.67it/s]prepro_backdoor:  93%|█████████▎| 403461/432000 [01:40<00:07, 4045.31it/s]prepro_backdoor:  93%|█████████▎| 403893/432000 [01:40<00:06, 4101.69it/s]prepro_backdoor:  94%|█████████▎| 404320/432000 [01:40<00:06, 4147.09it/s]prepro_backdoor:  94%|█████████▎| 404863/432000 [01:40<00:06, 4495.03it/s]prepro_backdoor:  94%|█████████▍| 405319/432000 [01:41<00:06, 4224.34it/s]prepro_backdoor:  94%|█████████▍| 405792/432000 [01:41<00:06, 4339.49it/s]prepro_backdoor:  94%|█████████▍| 406232/432000 [01:41<00:06, 4152.70it/s]prepro_backdoor:  94%|█████████▍| 406726/432000 [01:41<00:05, 4347.88it/s]prepro_backdoor:  94%|█████████▍| 407166/432000 [01:41<00:05, 4145.44it/s]prepro_backdoor:  94%|█████████▍| 407654/432000 [01:41<00:05, 4341.42it/s]prepro_backdoor:  94%|█████████▍| 408115/432000 [01:41<00:05, 4412.18it/s]prepro_backdoor:  95%|█████████▍| 408669/432000 [01:41<00:04, 4731.89it/s]prepro_backdoor:  95%|█████████▍| 409162/432000 [01:41<00:04, 4758.66it/s]prepro_backdoor:  95%|█████████▍| 409641/432000 [01:42<00:04, 4707.35it/s]prepro_backdoor:  95%|█████████▍| 410114/432000 [01:42<00:04, 4494.63it/s]prepro_backdoor:  95%|█████████▌| 410567/432000 [01:42<00:05, 3990.93it/s]prepro_backdoor:  95%|█████████▌| 410978/432000 [01:42<00:06, 3215.68it/s]prepro_backdoor:  95%|█████████▌| 411389/432000 [01:42<00:06, 3421.99it/s]prepro_backdoor:  95%|█████████▌| 411879/432000 [01:42<00:05, 3780.65it/s]prepro_backdoor:  95%|█████████▌| 412345/432000 [01:42<00:04, 4008.31it/s]prepro_backdoor:  96%|█████████▌| 412767/432000 [01:42<00:04, 3908.58it/s]prepro_backdoor:  96%|█████████▌| 413173/432000 [01:42<00:04, 3837.02it/s]prepro_backdoor:  96%|█████████▌| 413567/432000 [01:43<00:04, 3795.68it/s]prepro_backdoor:  96%|█████████▌| 414119/432000 [01:43<00:04, 4258.36it/s]prepro_backdoor:  96%|█████████▌| 414579/432000 [01:43<00:04, 4347.23it/s]prepro_backdoor:  96%|█████████▌| 415030/432000 [01:43<00:03, 4373.85it/s]prepro_backdoor:  96%|█████████▌| 415484/432000 [01:43<00:03, 4397.66it/s]prepro_backdoor:  96%|█████████▋| 415927/432000 [01:43<00:03, 4045.10it/s]prepro_backdoor:  96%|█████████▋| 416339/432000 [01:43<00:03, 4065.33it/s]prepro_backdoor:  96%|█████████▋| 416751/432000 [01:43<00:03, 4000.79it/s]prepro_backdoor:  97%|█████████▋| 417155/432000 [01:43<00:03, 3851.70it/s]prepro_backdoor:  97%|█████████▋| 417548/432000 [01:44<00:03, 3870.20it/s]prepro_backdoor:  97%|█████████▋| 417959/432000 [01:44<00:03, 3930.13it/s]prepro_backdoor:  97%|█████████▋| 418366/432000 [01:44<00:03, 3945.84it/s]prepro_backdoor:  97%|█████████▋| 418762/432000 [01:44<00:03, 3900.15it/s]prepro_backdoor:  97%|█████████▋| 419167/432000 [01:44<00:03, 3930.87it/s]prepro_backdoor:  97%|█████████▋| 419587/432000 [01:44<00:03, 3989.82it/s]prepro_backdoor:  97%|█████████▋| 420045/432000 [01:44<00:02, 4158.45it/s]prepro_backdoor:  97%|█████████▋| 420462/432000 [01:44<00:02, 3964.35it/s]prepro_backdoor:  97%|█████████▋| 420861/432000 [01:44<00:02, 3931.14it/s]prepro_backdoor:  98%|█████████▊| 421287/432000 [01:44<00:02, 4018.92it/s]prepro_backdoor:  98%|█████████▊| 421691/432000 [01:45<00:02, 3913.68it/s]prepro_backdoor:  98%|█████████▊| 422116/432000 [01:45<00:02, 3989.63it/s]prepro_backdoor:  98%|█████████▊| 422588/432000 [01:45<00:02, 4186.39it/s]prepro_backdoor:  98%|█████████▊| 423057/432000 [01:45<00:02, 4317.35it/s]prepro_backdoor:  98%|█████████▊| 423534/432000 [01:45<00:01, 4443.21it/s]prepro_backdoor:  98%|█████████▊| 423989/432000 [01:45<00:01, 4459.41it/s]prepro_backdoor:  98%|█████████▊| 424438/432000 [01:45<00:01, 4447.81it/s]prepro_backdoor:  98%|█████████▊| 424884/432000 [01:45<00:01, 4253.86it/s]prepro_backdoor:  98%|█████████▊| 425312/432000 [01:45<00:01, 4167.48it/s]prepro_backdoor:  99%|█████████▊| 425848/432000 [01:46<00:01, 4506.28it/s]prepro_backdoor:  99%|█████████▊| 426302/432000 [01:46<00:01, 4383.02it/s]prepro_backdoor:  99%|█████████▉| 426798/432000 [01:46<00:01, 4533.30it/s]prepro_backdoor:  99%|█████████▉| 427254/432000 [01:46<00:01, 4382.03it/s]prepro_backdoor:  99%|█████████▉| 427695/432000 [01:46<00:01, 4158.64it/s]prepro_backdoor:  99%|█████████▉| 428129/432000 [01:46<00:00, 4185.37it/s]prepro_backdoor:  99%|█████████▉| 428717/432000 [01:46<00:00, 4665.49it/s]prepro_backdoor:  99%|█████████▉| 429227/432000 [01:46<00:00, 4773.22it/s]prepro_backdoor:  99%|█████████▉| 429708/432000 [01:46<00:00, 4359.12it/s]prepro_backdoor: 100%|█████████▉| 430161/432000 [01:47<00:00, 4395.95it/s]prepro_backdoor: 100%|█████████▉| 430607/432000 [01:47<00:00, 4277.32it/s]prepro_backdoor: 100%|█████████▉| 431040/432000 [01:47<00:00, 4122.50it/s]prepro_backdoor: 100%|█████████▉| 431480/432000 [01:47<00:00, 4170.99it/s]prepro_backdoor: 100%|█████████▉| 431900/432000 [01:47<00:00, 3918.45it/s]prepro_backdoor: 100%|██████████| 432000/432000 [01:47<00:00, 4019.26it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:7000.0,real pratio:0.8333333333333334
2024-11-17:20:22:53 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:7000.0,real pratio:0.8333333333333334
INFO:root:save file format is .png
2024-11-17:20:22:53 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/8400 [00:00<?, ?it/s]prepro_backdoor:  17%|█▋        | 1443/8400 [00:00<00:00, 14403.06it/s]prepro_backdoor:  34%|███▍      | 2884/8400 [00:03<00:07, 696.52it/s]  prepro_backdoor:  42%|████▏     | 3502/8400 [00:05<00:08, 585.07it/s]prepro_backdoor:  46%|████▌     | 3857/8400 [00:05<00:08, 542.27it/s]prepro_backdoor:  49%|████▊     | 4088/8400 [00:06<00:08, 515.43it/s]prepro_backdoor:  51%|█████     | 4250/8400 [00:06<00:08, 499.66it/s]prepro_backdoor:  52%|█████▏    | 4371/8400 [00:07<00:08, 489.40it/s]prepro_backdoor:  53%|█████▎    | 4467/8400 [00:07<00:08, 480.08it/s]prepro_backdoor:  54%|█████▍    | 4546/8400 [00:07<00:08, 470.83it/s]prepro_backdoor:  55%|█████▍    | 4613/8400 [00:07<00:08, 463.52it/s]prepro_backdoor:  56%|█████▌    | 4673/8400 [00:07<00:08, 457.00it/s]prepro_backdoor:  56%|█████▋    | 4727/8400 [00:08<00:08, 452.31it/s]prepro_backdoor:  57%|█████▋    | 4778/8400 [00:08<00:08, 449.04it/s]prepro_backdoor:  57%|█████▋    | 4827/8400 [00:08<00:08, 444.61it/s]prepro_backdoor:  58%|█████▊    | 4874/8400 [00:08<00:08, 435.97it/s]prepro_backdoor:  59%|█████▊    | 4919/8400 [00:08<00:08, 434.57it/s]prepro_backdoor:  59%|█████▉    | 4964/8400 [00:08<00:07, 435.45it/s]prepro_backdoor:  60%|█████▉    | 5009/8400 [00:08<00:07, 431.33it/s]prepro_backdoor:  60%|██████    | 5053/8400 [00:08<00:07, 431.83it/s]prepro_backdoor:  61%|██████    | 5097/8400 [00:08<00:07, 429.81it/s]prepro_backdoor:  61%|██████    | 5141/8400 [00:09<00:07, 425.77it/s]prepro_backdoor:  62%|██████▏   | 5184/8400 [00:09<00:07, 424.09it/s]prepro_backdoor:  62%|██████▏   | 5228/8400 [00:09<00:07, 425.66it/s]prepro_backdoor:  63%|██████▎   | 5271/8400 [00:09<00:07, 422.70it/s]prepro_backdoor:  63%|██████▎   | 5314/8400 [00:09<00:07, 423.92it/s]prepro_backdoor:  64%|██████▍   | 5357/8400 [00:09<00:07, 424.92it/s]prepro_backdoor:  64%|██████▍   | 5400/8400 [00:09<00:07, 419.23it/s]prepro_backdoor:  65%|██████▍   | 5442/8400 [00:09<00:07, 388.96it/s]prepro_backdoor:  65%|██████▌   | 5483/8400 [00:09<00:07, 392.55it/s]prepro_backdoor:  66%|██████▌   | 5523/8400 [00:09<00:07, 394.10it/s]prepro_backdoor:  66%|██████▌   | 5564/8400 [00:10<00:07, 398.00it/s]prepro_backdoor:  67%|██████▋   | 5604/8400 [00:10<00:07, 397.75it/s]prepro_backdoor:  67%|██████▋   | 5646/8400 [00:10<00:06, 402.72it/s]prepro_backdoor:  68%|██████▊   | 5687/8400 [00:10<00:08, 321.84it/s]prepro_backdoor:  68%|██████▊   | 5731/8400 [00:10<00:07, 349.52it/s]prepro_backdoor:  69%|██████▊   | 5773/8400 [00:10<00:07, 367.87it/s]prepro_backdoor:  69%|██████▉   | 5817/8400 [00:10<00:06, 386.30it/s]prepro_backdoor:  70%|██████▉   | 5859/8400 [00:10<00:06, 394.34it/s]prepro_backdoor:  70%|███████   | 5900/8400 [00:10<00:06, 396.61it/s]prepro_backdoor:  71%|███████   | 5942/8400 [00:11<00:06, 403.07it/s]prepro_backdoor:  71%|███████   | 5984/8400 [00:11<00:05, 407.23it/s]prepro_backdoor:  72%|███████▏  | 6027/8400 [00:11<00:05, 411.71it/s]prepro_backdoor:  72%|███████▏  | 6069/8400 [00:11<00:05, 410.57it/s]prepro_backdoor:  73%|███████▎  | 6111/8400 [00:11<00:05, 413.06it/s]prepro_backdoor:  73%|███████▎  | 6153/8400 [00:11<00:06, 324.03it/s]prepro_backdoor:  74%|███████▍  | 6196/8400 [00:11<00:06, 349.57it/s]prepro_backdoor:  74%|███████▍  | 6240/8400 [00:11<00:05, 371.24it/s]prepro_backdoor:  75%|███████▍  | 6284/8400 [00:11<00:05, 388.47it/s]prepro_backdoor:  75%|███████▌  | 6327/8400 [00:12<00:05, 398.85it/s]prepro_backdoor:  76%|███████▌  | 6370/8400 [00:12<00:04, 406.95it/s]prepro_backdoor:  76%|███████▋  | 6413/8400 [00:12<00:04, 413.56it/s]prepro_backdoor:  77%|███████▋  | 6456/8400 [00:12<00:04, 418.30it/s]prepro_backdoor:  77%|███████▋  | 6500/8400 [00:12<00:04, 422.63it/s]prepro_backdoor:  78%|███████▊  | 6544/8400 [00:12<00:04, 425.22it/s]prepro_backdoor:  78%|███████▊  | 6587/8400 [00:12<00:05, 327.17it/s]prepro_backdoor:  79%|███████▉  | 6630/8400 [00:12<00:05, 352.13it/s]prepro_backdoor:  79%|███████▉  | 6674/8400 [00:12<00:04, 374.54it/s]prepro_backdoor:  80%|███████▉  | 6719/8400 [00:13<00:04, 392.91it/s]prepro_backdoor:  80%|████████  | 6762/8400 [00:13<00:04, 402.70it/s]prepro_backdoor:  81%|████████  | 6805/8400 [00:13<00:03, 408.60it/s]prepro_backdoor:  82%|████████▏ | 6848/8400 [00:13<00:03, 413.79it/s]prepro_backdoor:  82%|████████▏ | 6891/8400 [00:13<00:03, 417.20it/s]prepro_backdoor:  83%|████████▎ | 6934/8400 [00:13<00:03, 418.64it/s]prepro_backdoor:  83%|████████▎ | 6977/8400 [00:13<00:03, 419.48it/s]prepro_backdoor:  84%|████████▎ | 7020/8400 [00:13<00:03, 381.40it/s]prepro_backdoor:  84%|████████▍ | 7059/8400 [00:14<00:04, 321.89it/s]prepro_backdoor:  85%|████████▍ | 7100/8400 [00:14<00:03, 342.04it/s]prepro_backdoor:  85%|████████▌ | 7141/8400 [00:14<00:03, 357.85it/s]prepro_backdoor:  86%|████████▌ | 7183/8400 [00:14<00:03, 373.03it/s]prepro_backdoor:  86%|████████▌ | 7225/8400 [00:14<00:03, 383.65it/s]prepro_backdoor:  87%|████████▋ | 7268/8400 [00:14<00:02, 395.38it/s]prepro_backdoor:  87%|████████▋ | 7310/8400 [00:14<00:02, 401.73it/s]prepro_backdoor:  88%|████████▊ | 7351/8400 [00:15<00:04, 218.16it/s]prepro_backdoor:  88%|████████▊ | 7393/8400 [00:15<00:03, 254.75it/s]prepro_backdoor:  88%|████████▊ | 7433/8400 [00:15<00:03, 284.80it/s]prepro_backdoor:  89%|████████▉ | 7474/8400 [00:15<00:02, 312.30it/s]prepro_backdoor:  89%|████████▉ | 7517/8400 [00:15<00:02, 339.66it/s]prepro_backdoor:  90%|█████████ | 7560/8400 [00:15<00:02, 362.63it/s]prepro_backdoor:  91%|█████████ | 7603/8400 [00:15<00:02, 378.85it/s]prepro_backdoor:  91%|█████████ | 7646/8400 [00:15<00:01, 392.60it/s]prepro_backdoor:  92%|█████████▏| 7689/8400 [00:15<00:01, 402.71it/s]prepro_backdoor:  92%|█████████▏| 7733/8400 [00:15<00:01, 410.61it/s]prepro_backdoor:  93%|█████████▎| 7776/8400 [00:16<00:02, 302.54it/s]prepro_backdoor:  93%|█████████▎| 7817/8400 [00:16<00:01, 327.14it/s]prepro_backdoor:  94%|█████████▎| 7859/8400 [00:16<00:01, 349.59it/s]prepro_backdoor:  94%|█████████▍| 7902/8400 [00:16<00:01, 370.23it/s]prepro_backdoor:  95%|█████████▍| 7945/8400 [00:16<00:01, 384.79it/s]prepro_backdoor:  95%|█████████▌| 7986/8400 [00:16<00:01, 390.94it/s]prepro_backdoor:  96%|█████████▌| 8027/8400 [00:16<00:00, 395.78it/s]prepro_backdoor:  96%|█████████▌| 8068/8400 [00:16<00:00, 398.88it/s]prepro_backdoor:  97%|█████████▋| 8109/8400 [00:16<00:00, 401.45it/s]prepro_backdoor:  97%|█████████▋| 8151/8400 [00:17<00:00, 404.13it/s]prepro_backdoor:  98%|█████████▊| 8192/8400 [00:17<00:00, 297.68it/s]prepro_backdoor:  98%|█████████▊| 8234/8400 [00:17<00:00, 324.76it/s]prepro_backdoor:  99%|█████████▊| 8275/8400 [00:17<00:00, 346.12it/s]prepro_backdoor:  99%|█████████▉| 8316/8400 [00:17<00:00, 360.94it/s]prepro_backdoor:  99%|█████████▉| 8357/8400 [00:17<00:00, 374.02it/s]prepro_backdoor: 100%|█████████▉| 8399/8400 [00:17<00:00, 385.30it/s]prepro_backdoor: 100%|██████████| 8400/8400 [00:17<00:00, 472.22it/s]
INFO:root:stage2 start
2024-11-17:20:23:11 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2024-11-17:20:23:11 [INFO    ] [trainer_cls.py:972] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2024-11-17:20:23:12 [INFO    ] [trainer_cls.py:1030] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 319.6670286655426 s
2024-11-17:20:28:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 319.6670286655426 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
2024-11-17:20:28:37 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.85541105270386 s
2024-11-17:20:33:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.85541105270386 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
2024-11-17:20:33:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.747430562973 s
2024-11-17:20:39:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.747430562973 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
2024-11-17:20:39:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.9679043292999 s
2024-11-17:20:44:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.9679043292999 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
2024-11-17:20:44:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.55462288856506 s
2024-11-17:20:49:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.55462288856506 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
2024-11-17:20:49:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.90335845947266 s
2024-11-17:20:55:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.90335845947266 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
2024-11-17:20:55:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.2133448123932 s
2024-11-17:21:00:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.2133448123932 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
2024-11-17:21:00:34 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.01423716545105 s
2024-11-17:21:05:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.01423716545105 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
2024-11-17:21:05:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.06895661354065 s
2024-11-17:21:11:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.06895661354065 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
2024-11-17:21:11:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.34476470947266 s
2024-11-17:21:16:26 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.34476470947266 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
2024-11-17:21:16:31 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.003830909729 s
2024-11-17:21:21:46 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 315.003830909729 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
2024-11-17:21:21:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.32771134376526 s
2024-11-17:21:27:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.32771134376526 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
2024-11-17:21:27:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.62699723243713 s
2024-11-17:21:32:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.62699723243713 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
2024-11-17:21:32:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.6097435951233 s
2024-11-17:21:37:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.6097435951233 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
2024-11-17:21:37:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.42712330818176 s
2024-11-17:21:43:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 315.42712330818176 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
2024-11-17:21:43:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7315595149994 s
2024-11-17:21:48:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.7315595149994 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
2024-11-17:21:48:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.0931832790375 s
2024-11-17:21:53:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.0931832790375 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
2024-11-17:21:53:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7200336456299 s
2024-11-17:21:59:04 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.7200336456299 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
2024-11-17:21:59:09 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7440438270569 s
2024-11-17:22:04:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.7440438270569 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
2024-11-17:22:04:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.32051157951355 s
2024-11-17:22:09:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.32051157951355 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
2024-11-17:22:09:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7661328315735 s
2024-11-17:22:15:01 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.7661328315735 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
2024-11-17:22:15:06 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.8647041320801 s
2024-11-17:22:20:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.8647041320801 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
2024-11-17:22:20:25 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.4093964099884 s
2024-11-17:22:25:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.4093964099884 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
2024-11-17:22:25:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.35708832740784 s
2024-11-17:22:30:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.35708832740784 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
2024-11-17:22:31:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.63270330429077 s
2024-11-17:22:36:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.63270330429077 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
2024-11-17:22:36:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.4068965911865 s
2024-11-17:22:41:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.4068965911865 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
2024-11-17:22:41:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 318.47398495674133 s
2024-11-17:22:47:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 318.47398495674133 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
2024-11-17:22:47:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.4449896812439 s
2024-11-17:22:52:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.4449896812439 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
2024-11-17:22:52:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.16483211517334 s
2024-11-17:22:57:40 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.16483211517334 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
2024-11-17:22:57:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.4741439819336 s
2024-11-17:23:02:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.4741439819336 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
2024-11-17:23:03:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.53384590148926 s
2024-11-17:23:08:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.53384590148926 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
2024-11-17:23:08:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.5819642543793 s
2024-11-17:23:13:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.5819642543793 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
2024-11-17:23:13:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.65742659568787 s
2024-11-17:23:18:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.65742659568787 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
2024-11-17:23:18:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.44371819496155 s
2024-11-17:23:24:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.44371819496155 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
2024-11-17:23:24:18 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.7887136936188 s
2024-11-17:23:29:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.7887136936188 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
2024-11-17:23:29:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.44167947769165 s
2024-11-17:23:34:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 315.44167947769165 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
2024-11-17:23:34:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.35763335227966 s
2024-11-17:23:40:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.35763335227966 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
2024-11-17:23:40:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.5769844055176 s
2024-11-17:23:45:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.5769844055176 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
2024-11-17:23:45:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.79242157936096 s
2024-11-17:23:50:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.79242157936096 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
2024-11-17:23:50:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.0357322692871 s
2024-11-17:23:56:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.0357322692871 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
2024-11-17:23:56:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.3720815181732 s
2024-11-18:00:01:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.3720815181732 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
2024-11-18:00:01:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.4302339553833 s
2024-11-18:00:06:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.4302339553833 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
2024-11-18:00:06:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.2763862609863 s
2024-11-18:00:12:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.2763862609863 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
2024-11-18:00:12:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.5624969005585 s
2024-11-18:00:17:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.5624969005585 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
2024-11-18:00:17:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.73116874694824 s
2024-11-18:00:22:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.73116874694824 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
2024-11-18:00:22:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.42284750938416 s
2024-11-18:00:28:05 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 315.42284750938416 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
2024-11-18:00:28:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.2695906162262 s
2024-11-18:00:33:23 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.2695906162262 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
2024-11-18:00:33:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.54213428497314 s
2024-11-18:00:38:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.54213428497314 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
2024-11-18:00:38:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.8263986110687 s
2024-11-18:00:44:00 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.8263986110687 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
2024-11-18:00:44:06 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.27444982528687 s
2024-11-18:00:49:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.27444982528687 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
2024-11-18:00:49:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.8429067134857 s
2024-11-18:00:54:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.8429067134857 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
2024-11-18:00:54:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.1677556037903 s
2024-11-18:00:59:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.1677556037903 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
2024-11-18:01:00:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.9619519710541 s
2024-11-18:01:05:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.9619519710541 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
2024-11-18:01:05:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.8752930164337 s
2024-11-18:01:10:35 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.8752930164337 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
2024-11-18:01:10:40 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.273992061615 s
2024-11-18:01:15:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.273992061615 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
2024-11-18:01:15:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.6721658706665 s
2024-11-18:01:21:08 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.6721658706665 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
2024-11-18:01:21:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.15424823760986 s
2024-11-18:01:26:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.15424823760986 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
2024-11-18:01:26:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.4487600326538 s
2024-11-18:01:31:40 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.4487600326538 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
2024-11-18:01:31:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.1741750240326 s
2024-11-18:01:36:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.1741750240326 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
2024-11-18:01:37:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.33161330223083 s
2024-11-18:01:42:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.33161330223083 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
2024-11-18:01:42:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.7733197212219 s
2024-11-18:01:47:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.7733197212219 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
2024-11-18:01:47:34 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.5849575996399 s
2024-11-18:01:52:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.5849575996399 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
2024-11-18:01:52:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.8255515098572 s
2024-11-18:01:58:04 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.8255515098572 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
2024-11-18:01:58:09 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.3070468902588 s
2024-11-18:02:03:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.3070468902588 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
2024-11-18:02:03:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.6798167228699 s
2024-11-18:02:08:42 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.6798167228699 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
2024-11-18:02:08:47 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.91324281692505 s
2024-11-18:02:13:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.91324281692505 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
2024-11-18:02:14:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.1354675292969 s
2024-11-18:02:19:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.1354675292969 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
2024-11-18:02:19:21 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.47842144966125 s
2024-11-18:02:24:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.47842144966125 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
2024-11-18:02:24:40 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.28923892974854 s
2024-11-18:02:29:53 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.28923892974854 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
2024-11-18:02:29:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.2363829612732 s
2024-11-18:02:35:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.2363829612732 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
2024-11-18:02:35:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.8332140445709 s
2024-11-18:02:40:27 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.8332140445709 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
2024-11-18:02:40:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.4227375984192 s
2024-11-18:02:45:46 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.4227375984192 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
2024-11-18:02:45:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.02705574035645 s
2024-11-18:02:51:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 317.02705574035645 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
2024-11-18:02:51:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.6274871826172 s
2024-11-18:02:56:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.6274871826172 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
2024-11-18:02:56:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.5401802062988 s
2024-11-18:03:01:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.5401802062988 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
2024-11-18:03:01:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.9893262386322 s
2024-11-18:03:07:01 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.9893262386322 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
2024-11-18:03:07:06 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.8278787136078 s
2024-11-18:03:12:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.8278787136078 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
2024-11-18:03:12:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.17758536338806 s
2024-11-18:03:17:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.17758536338806 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
2024-11-18:03:17:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.2553913593292 s
2024-11-18:03:22:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.2553913593292 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
2024-11-18:03:23:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.791033744812 s
2024-11-18:03:28:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.791033744812 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
2024-11-18:03:28:18 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.9536302089691 s
2024-11-18:03:33:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.9536302089691 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
2024-11-18:03:33:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.1833846569061 s
2024-11-18:03:38:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.1833846569061 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
2024-11-18:03:38:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.18651032447815 s
2024-11-18:03:44:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.18651032447815 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
2024-11-18:03:44:08 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.5393602848053 s
2024-11-18:03:49:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.5393602848053 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
2024-11-18:03:49:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.2785093784332 s
2024-11-18:03:54:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.2785093784332 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
2024-11-18:03:54:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.3541293144226 s
2024-11-18:03:59:55 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.3541293144226 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
2024-11-18:04:00:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.4310863018036 s
2024-11-18:04:05:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.4310863018036 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
2024-11-18:04:05:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.17281675338745 s
2024-11-18:04:10:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.17281675338745 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
2024-11-18:04:10:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.9320216178894 s
2024-11-18:04:15:48 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.9320216178894 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
2024-11-18:04:15:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.1652798652649 s
2024-11-18:04:21:05 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.1652798652649 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
2024-11-18:04:21:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.53056597709656 s
2024-11-18:04:26:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.53056597709656 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
2024-11-18:04:26:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.2550091743469 s
2024-11-18:04:31:43 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.2550091743469 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
2024-11-18:04:31:48 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.0908091068268 s
2024-11-18:04:36:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.0908091068268 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
2024-11-18:04:37:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.6658432483673 s
2024-11-18:04:42:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.6658432483673 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
2024-11-18:04:42:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.7887444496155 s
2024-11-18:04:47:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.7887444496155 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
2024-11-18:04:47:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.34876108169556 s
2024-11-18:04:52:55 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.34876108169556 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
2024-11-18:04:53:00 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.501344203949 s
2024-11-18:04:58:12 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.501344203949 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
2024-11-18:04:58:17 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.7609121799469 s
2024-11-18:05:03:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.7609121799469 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
2024-11-18:05:03:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.3880021572113 s
2024-11-18:05:08:48 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.3880021572113 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
2024-11-18:05:08:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.53257513046265 s
2024-11-18:05:14:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.53257513046265 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
2024-11-18:05:14:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2024-11-18:05:14:12 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/badnet_attack_efficientnet_ffpp_multiclass/attack_result.pt
INFO:root:Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_multiclass
2024-11-18:05:14:13 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_multiclass
