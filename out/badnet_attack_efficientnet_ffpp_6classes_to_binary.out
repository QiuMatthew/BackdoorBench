/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_6classes_to_binary',
 'save_path': './record/badnet_attack_efficientnet_ffpp_6classes_to_binary',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_6classes_to_binary'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2024-12-23:01:32:43 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_6classes_to_binary',
 'save_path': './record/badnet_attack_efficientnet_ffpp_6classes_to_binary',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_6classes_to_binary'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': '--git_hash baafb796919dbe5ea0faf001b1e1287def93a2ff',
 'last 3 log': 'commit baafb796919dbe5ea0faf001b1e1287def93a2ff\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Mon Dec 23 01:31:30 2024 +0900\n'
               '\n'
               '    new script: badnet attack with merged fake classes metric\n'
               '\n'
               'commit 48331a545ce9a2a8917a1b9499c3e6ee3cf128df\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Wed Dec 11 17:09:59 2024 +0900\n'
               '\n'
               '    modify the acc metric, merge all fake classes\n'
               '\n'
               'commit 2062d7da585a3aa9fb0b274b54f3ba96c79be680\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Tue Dec 10 18:51:15 2024 +0900\n'
               '\n'
               '    new result: badnet nad 4 classes',
 'status': 'On branch modify-metric\n'
           "Your branch is up to date with 'origin/modify-metric'.\n"
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\n'
           '\tout/badnet_attack_efficientnet_ffpp_2classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_3classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_4classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_5classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_6classes_to_binary.out\n'
           '\n'
           'nothing added to commit but untracked files present (use "git add" '
           'to track)'}
INFO:root:stage1 start
2024-12-23:01:32:45 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2024-12-23:01:32:45 [WARNING ] [dataset_and_transform_generate.py:359] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:43200.0,real pratio:0.1
2024-12-23:01:42:58 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:43200.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2024-12-23:01:42:59 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/432000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 45/432000 [00:00<16:28, 436.95it/s]prepro_backdoor:   0%|          | 453/432000 [00:00<02:49, 2539.05it/s]prepro_backdoor:   0%|          | 903/432000 [00:00<02:06, 3406.74it/s]prepro_backdoor:   0%|          | 1339/432000 [00:00<01:53, 3778.33it/s]prepro_backdoor:   0%|          | 1718/432000 [00:00<01:53, 3780.85it/s]prepro_backdoor:   1%|          | 2253/432000 [00:00<01:40, 4288.67it/s]prepro_backdoor:   1%|          | 2683/432000 [00:00<01:43, 4162.03it/s]prepro_backdoor:   1%|          | 3165/432000 [00:00<01:38, 4354.90it/s]prepro_backdoor:   1%|          | 3602/432000 [00:00<01:41, 4218.81it/s]prepro_backdoor:   1%|          | 4026/432000 [00:01<02:08, 3331.12it/s]prepro_backdoor:   1%|          | 4443/432000 [00:01<02:00, 3538.46it/s]prepro_backdoor:   1%|          | 4821/432000 [00:01<03:01, 2360.07it/s]prepro_backdoor:   1%|          | 5253/432000 [00:01<02:35, 2747.87it/s]prepro_backdoor:   1%|▏         | 5705/432000 [00:01<02:15, 3135.07it/s]prepro_backdoor:   1%|▏         | 6240/432000 [00:01<01:56, 3645.72it/s]prepro_backdoor:   2%|▏         | 6659/432000 [00:01<02:03, 3437.48it/s]prepro_backdoor:   2%|▏         | 7076/432000 [00:02<01:58, 3598.55it/s]prepro_backdoor:   2%|▏         | 7467/432000 [00:02<01:57, 3625.01it/s]prepro_backdoor:   2%|▏         | 7852/432000 [00:02<01:56, 3652.97it/s]prepro_backdoor:   2%|▏         | 8281/432000 [00:02<01:50, 3825.84it/s]prepro_backdoor:   2%|▏         | 8698/432000 [00:02<01:47, 3920.40it/s]prepro_backdoor:   2%|▏         | 9100/432000 [00:02<02:37, 2678.08it/s]prepro_backdoor:   2%|▏         | 9570/432000 [00:02<02:15, 3107.15it/s]prepro_backdoor:   2%|▏         | 10122/432000 [00:02<01:54, 3669.17it/s]prepro_backdoor:   2%|▏         | 10544/432000 [00:03<01:52, 3752.42it/s]prepro_backdoor:   3%|▎         | 11000/432000 [00:03<01:46, 3961.11it/s]prepro_backdoor:   3%|▎         | 11473/432000 [00:03<01:41, 4158.33it/s]prepro_backdoor:   3%|▎         | 11912/432000 [00:03<01:39, 4209.80it/s]prepro_backdoor:   3%|▎         | 12418/432000 [00:03<01:34, 4433.65it/s]prepro_backdoor:   3%|▎         | 12917/432000 [00:03<01:31, 4565.37it/s]prepro_backdoor:   3%|▎         | 13383/432000 [00:03<02:14, 3117.36it/s]prepro_backdoor:   3%|▎         | 13867/432000 [00:03<01:59, 3494.69it/s]prepro_backdoor:   3%|▎         | 14387/432000 [00:04<01:47, 3892.64it/s]prepro_backdoor:   3%|▎         | 14845/432000 [00:04<01:42, 4053.97it/s]prepro_backdoor:   4%|▎         | 15290/432000 [00:04<01:42, 4081.30it/s]prepro_backdoor:   4%|▎         | 15754/432000 [00:04<01:38, 4217.46it/s]prepro_backdoor:   4%|▎         | 16197/432000 [00:04<01:38, 4229.07it/s]prepro_backdoor:   4%|▍         | 16667/432000 [00:04<01:35, 4342.19it/s]prepro_backdoor:   4%|▍         | 17113/432000 [00:04<01:36, 4287.25it/s]prepro_backdoor:   4%|▍         | 17550/432000 [00:04<01:39, 4170.73it/s]prepro_backdoor:   4%|▍         | 17973/432000 [00:04<02:17, 3011.20it/s]prepro_backdoor:   4%|▍         | 18440/432000 [00:05<02:02, 3381.90it/s]prepro_backdoor:   4%|▍         | 18959/432000 [00:05<01:48, 3800.41it/s]prepro_backdoor:   5%|▍         | 19512/432000 [00:05<01:37, 4237.18it/s]prepro_backdoor:   5%|▍         | 19972/432000 [00:05<01:41, 4075.40it/s]prepro_backdoor:   5%|▍         | 20419/432000 [00:05<01:38, 4174.85it/s]prepro_backdoor:   5%|▍         | 20894/432000 [00:05<01:35, 4307.32it/s]prepro_backdoor:   5%|▍         | 21340/432000 [00:05<01:36, 4252.75it/s]prepro_backdoor:   5%|▌         | 21869/432000 [00:05<01:30, 4527.80it/s]prepro_backdoor:   5%|▌         | 22331/432000 [00:07<06:57, 982.01it/s] prepro_backdoor:   5%|▌         | 22802/432000 [00:07<05:19, 1281.59it/s]prepro_backdoor:   5%|▌         | 23174/432000 [00:07<04:28, 1525.13it/s]prepro_backdoor:   5%|▌         | 23649/432000 [00:07<03:30, 1937.72it/s]prepro_backdoor:   6%|▌         | 24148/432000 [00:07<02:49, 2402.57it/s]prepro_backdoor:   6%|▌         | 24655/432000 [00:07<02:21, 2878.18it/s]prepro_backdoor:   6%|▌         | 25104/432000 [00:07<02:13, 3042.63it/s]prepro_backdoor:   6%|▌         | 25626/432000 [00:07<01:56, 3499.95it/s]prepro_backdoor:   6%|▌         | 26176/432000 [00:08<01:42, 3953.66it/s]prepro_backdoor:   6%|▌         | 26652/432000 [00:08<01:40, 4038.55it/s]prepro_backdoor:   6%|▋         | 27113/432000 [00:08<02:06, 3211.22it/s]prepro_backdoor:   6%|▋         | 27624/432000 [00:08<01:51, 3618.64it/s]prepro_backdoor:   6%|▋         | 28066/432000 [00:08<01:46, 3803.56it/s]prepro_backdoor:   7%|▋         | 28493/432000 [00:08<01:47, 3760.66it/s]prepro_backdoor:   7%|▋         | 28902/432000 [00:08<01:51, 3610.76it/s]prepro_backdoor:   7%|▋         | 29466/432000 [00:08<01:37, 4120.78it/s]prepro_backdoor:   7%|▋         | 29933/432000 [00:09<01:34, 4259.84it/s]prepro_backdoor:   7%|▋         | 30378/432000 [00:09<01:35, 4190.90it/s]prepro_backdoor:   7%|▋         | 30920/432000 [00:09<01:28, 4521.69it/s]prepro_backdoor:   7%|▋         | 31384/432000 [00:09<02:02, 3264.62it/s]prepro_backdoor:   7%|▋         | 31804/432000 [00:09<01:55, 3467.59it/s]prepro_backdoor:   7%|▋         | 32205/432000 [00:09<01:51, 3597.68it/s]prepro_backdoor:   8%|▊         | 32624/432000 [00:09<01:46, 3745.42it/s]prepro_backdoor:   8%|▊         | 33026/432000 [00:09<01:47, 3703.39it/s]prepro_backdoor:   8%|▊         | 33530/432000 [00:09<01:38, 4059.91it/s]prepro_backdoor:   8%|▊         | 33953/432000 [00:10<01:41, 3938.45it/s]prepro_backdoor:   8%|▊         | 34359/432000 [00:10<01:43, 3845.52it/s]prepro_backdoor:   8%|▊         | 34861/432000 [00:10<01:35, 4170.02it/s]prepro_backdoor:   8%|▊         | 35287/432000 [00:10<01:35, 4162.75it/s]prepro_backdoor:   8%|▊         | 35710/432000 [00:10<02:06, 3120.71it/s]prepro_backdoor:   8%|▊         | 36145/432000 [00:10<01:56, 3407.18it/s]prepro_backdoor:   8%|▊         | 36544/432000 [00:10<01:51, 3543.67it/s]prepro_backdoor:   9%|▊         | 36930/432000 [00:10<01:49, 3612.23it/s]prepro_backdoor:   9%|▊         | 37313/432000 [00:11<01:48, 3621.45it/s]prepro_backdoor:   9%|▊         | 37690/432000 [00:11<01:49, 3599.08it/s]prepro_backdoor:   9%|▉         | 38082/432000 [00:11<01:47, 3675.33it/s]prepro_backdoor:   9%|▉         | 38458/432000 [00:11<01:52, 3507.05it/s]prepro_backdoor:   9%|▉         | 38929/432000 [00:11<01:42, 3828.27it/s]prepro_backdoor:   9%|▉         | 39319/432000 [00:11<01:50, 3549.92it/s]prepro_backdoor:   9%|▉         | 39682/432000 [00:11<02:25, 2691.44it/s]prepro_backdoor:   9%|▉         | 40164/432000 [00:11<02:03, 3172.01it/s]prepro_backdoor:   9%|▉         | 40765/432000 [00:12<01:41, 3859.45it/s]prepro_backdoor:  10%|▉         | 41200/432000 [00:12<01:38, 3973.70it/s]prepro_backdoor:  10%|▉         | 41688/432000 [00:12<01:33, 4195.49it/s]prepro_backdoor:  10%|▉         | 42132/432000 [00:12<01:32, 4217.60it/s]prepro_backdoor:  10%|▉         | 42645/432000 [00:12<01:27, 4448.02it/s]prepro_backdoor:  10%|▉         | 43105/432000 [00:12<01:27, 4459.12it/s]prepro_backdoor:  10%|█         | 43561/432000 [00:12<01:33, 4151.13it/s]prepro_backdoor:  10%|█         | 43987/432000 [00:12<01:33, 4135.88it/s]prepro_backdoor:  10%|█         | 44408/432000 [00:12<02:02, 3168.55it/s]prepro_backdoor:  10%|█         | 44763/432000 [00:13<02:00, 3215.25it/s]prepro_backdoor:  10%|█         | 45155/432000 [00:13<01:54, 3378.45it/s]prepro_backdoor:  11%|█         | 45516/432000 [00:13<01:56, 3307.00it/s]prepro_backdoor:  11%|█         | 45937/432000 [00:13<01:49, 3539.49it/s]prepro_backdoor:  11%|█         | 46421/432000 [00:13<01:39, 3890.81it/s]prepro_backdoor:  11%|█         | 46933/432000 [00:13<01:31, 4215.04it/s]prepro_backdoor:  11%|█         | 47366/432000 [00:13<01:37, 3964.97it/s]prepro_backdoor:  11%|█         | 47847/432000 [00:13<01:31, 4179.12it/s]prepro_backdoor:  11%|█         | 48274/432000 [00:13<01:34, 4054.49it/s]prepro_backdoor:  11%|█▏        | 48686/432000 [00:14<02:16, 2805.47it/s]prepro_backdoor:  11%|█▏        | 49022/432000 [00:14<02:12, 2884.58it/s]prepro_backdoor:  11%|█▏        | 49406/432000 [00:14<02:03, 3090.24it/s]prepro_backdoor:  12%|█▏        | 49927/432000 [00:14<01:45, 3611.28it/s]prepro_backdoor:  12%|█▏        | 50323/432000 [00:14<01:44, 3647.90it/s]prepro_backdoor:  12%|█▏        | 50804/432000 [00:14<01:36, 3958.47it/s]prepro_backdoor:  12%|█▏        | 51264/432000 [00:14<01:32, 4111.82it/s]prepro_backdoor:  12%|█▏        | 51711/432000 [00:14<01:30, 4195.04it/s]prepro_backdoor:  12%|█▏        | 52142/432000 [00:15<01:33, 4057.17it/s]prepro_backdoor:  12%|█▏        | 52560/432000 [00:15<01:33, 4078.27it/s]prepro_backdoor:  12%|█▏        | 52974/432000 [00:15<01:54, 3311.58it/s]prepro_backdoor:  12%|█▏        | 53444/432000 [00:15<01:43, 3643.50it/s]prepro_backdoor:  12%|█▏        | 53898/432000 [00:15<01:37, 3872.94it/s]prepro_backdoor:  13%|█▎        | 54307/432000 [00:15<01:36, 3916.09it/s]prepro_backdoor:  13%|█▎        | 54862/432000 [00:15<01:26, 4362.13it/s]prepro_backdoor:  13%|█▎        | 55330/432000 [00:15<01:24, 4447.65it/s]prepro_backdoor:  13%|█▎        | 55822/432000 [00:15<01:22, 4578.47it/s]prepro_backdoor:  13%|█▎        | 56365/432000 [00:16<01:18, 4803.77it/s]prepro_backdoor:  13%|█▎        | 56851/432000 [00:16<01:18, 4749.84it/s]prepro_backdoor:  13%|█▎        | 57330/432000 [00:16<01:21, 4609.15it/s]prepro_backdoor:  13%|█▎        | 57795/432000 [00:16<01:52, 3314.30it/s]prepro_backdoor:  13%|█▎        | 58179/432000 [00:16<03:02, 2043.13it/s]prepro_backdoor:  14%|█▎        | 58708/432000 [00:16<02:25, 2565.29it/s]prepro_backdoor:  14%|█▎        | 59162/432000 [00:17<02:07, 2935.39it/s]prepro_backdoor:  14%|█▍        | 59648/432000 [00:17<01:51, 3327.54it/s]prepro_backdoor:  14%|█▍        | 60092/432000 [00:17<01:43, 3580.48it/s]prepro_backdoor:  14%|█▍        | 60520/432000 [00:17<01:39, 3752.25it/s]prepro_backdoor:  14%|█▍        | 60971/432000 [00:17<01:34, 3932.34it/s]prepro_backdoor:  14%|█▍        | 61481/432000 [00:17<01:27, 4226.94it/s]prepro_backdoor:  14%|█▍        | 61979/432000 [00:17<01:23, 4424.56it/s]prepro_backdoor:  14%|█▍        | 62444/432000 [00:17<01:23, 4452.22it/s]prepro_backdoor:  15%|█▍        | 62905/432000 [00:17<01:23, 4407.66it/s]prepro_backdoor:  15%|█▍        | 63357/432000 [00:18<01:53, 3260.43it/s]prepro_backdoor:  15%|█▍        | 63835/432000 [00:18<01:42, 3597.34it/s]prepro_backdoor:  15%|█▍        | 64240/432000 [00:18<01:59, 3088.37it/s]prepro_backdoor:  15%|█▍        | 64765/432000 [00:18<01:42, 3568.40it/s]prepro_backdoor:  15%|█▌        | 65264/432000 [00:18<01:33, 3906.97it/s]prepro_backdoor:  15%|█▌        | 65709/432000 [00:18<01:30, 4042.56it/s]prepro_backdoor:  15%|█▌        | 66159/432000 [00:18<01:27, 4163.16it/s]prepro_backdoor:  15%|█▌        | 66612/432000 [00:18<01:26, 4242.55it/s]prepro_backdoor:  16%|█▌        | 67052/432000 [00:19<01:28, 4140.77it/s]prepro_backdoor:  16%|█▌        | 67504/432000 [00:19<01:26, 4220.82it/s]prepro_backdoor:  16%|█▌        | 67935/432000 [00:19<01:56, 3124.27it/s]prepro_backdoor:  16%|█▌        | 68461/432000 [00:19<01:40, 3605.00it/s]prepro_backdoor:  16%|█▌        | 68899/432000 [00:19<01:36, 3778.55it/s]prepro_backdoor:  16%|█▌        | 69330/432000 [00:19<01:33, 3899.05it/s]prepro_backdoor:  16%|█▌        | 69775/432000 [00:19<01:29, 4026.80it/s]prepro_backdoor:  16%|█▋        | 70307/432000 [00:19<01:22, 4368.07it/s]prepro_backdoor:  16%|█▋        | 70761/432000 [00:19<01:28, 4095.64it/s]prepro_backdoor:  17%|█▋        | 71304/432000 [00:20<01:20, 4457.09it/s]prepro_backdoor:  17%|█▋        | 71764/432000 [00:20<01:20, 4476.16it/s]prepro_backdoor:  17%|█▋        | 72222/432000 [00:20<01:25, 4221.29it/s]prepro_backdoor:  17%|█▋        | 72654/432000 [00:20<01:37, 3670.29it/s]prepro_backdoor:  17%|█▋        | 73143/432000 [00:20<01:30, 3979.73it/s]prepro_backdoor:  17%|█▋        | 73575/432000 [00:20<01:28, 4047.73it/s]prepro_backdoor:  17%|█▋        | 74056/432000 [00:20<01:24, 4233.42it/s]prepro_backdoor:  17%|█▋        | 74515/432000 [00:20<01:22, 4310.89it/s]prepro_backdoor:  17%|█▋        | 74954/432000 [00:20<01:23, 4281.04it/s]prepro_backdoor:  17%|█▋        | 75388/432000 [00:21<01:28, 4043.96it/s]prepro_backdoor:  18%|█▊        | 75832/432000 [00:21<01:25, 4143.16it/s]prepro_backdoor:  18%|█▊        | 76314/432000 [00:21<01:22, 4313.15it/s]prepro_backdoor:  18%|█▊        | 76750/432000 [00:21<01:22, 4324.19it/s]prepro_backdoor:  18%|█▊        | 77186/432000 [00:22<05:08, 1149.46it/s]prepro_backdoor:  18%|█▊        | 77647/432000 [00:22<03:57, 1492.18it/s]prepro_backdoor:  18%|█▊        | 78064/432000 [00:22<03:14, 1822.55it/s]prepro_backdoor:  18%|█▊        | 78478/432000 [00:22<02:42, 2170.50it/s]prepro_backdoor:  18%|█▊        | 78972/432000 [00:22<02:12, 2657.63it/s]prepro_backdoor:  18%|█▊        | 79453/432000 [00:22<01:54, 3080.32it/s]prepro_backdoor:  18%|█▊        | 79888/432000 [00:23<01:47, 3290.20it/s]prepro_backdoor:  19%|█▊        | 80311/432000 [00:23<01:43, 3382.89it/s]prepro_backdoor:  19%|█▊        | 80717/432000 [00:23<01:42, 3438.28it/s]prepro_backdoor:  19%|█▉        | 81148/432000 [00:23<01:36, 3651.42it/s]prepro_backdoor:  19%|█▉        | 81550/432000 [00:23<01:58, 2955.62it/s]prepro_backdoor:  19%|█▉        | 81960/432000 [00:23<01:48, 3212.47it/s]prepro_backdoor:  19%|█▉        | 82321/432000 [00:23<01:46, 3281.75it/s]prepro_backdoor:  19%|█▉        | 82941/432000 [00:23<01:26, 4019.72it/s]prepro_backdoor:  19%|█▉        | 83374/432000 [00:24<01:26, 4026.68it/s]prepro_backdoor:  19%|█▉        | 83799/432000 [00:24<01:25, 4061.52it/s]prepro_backdoor:  19%|█▉        | 84221/432000 [00:24<01:25, 4055.14it/s]prepro_backdoor:  20%|█▉        | 84794/432000 [00:24<01:16, 4526.59it/s]prepro_backdoor:  20%|█▉        | 85330/432000 [00:24<01:12, 4756.00it/s]prepro_backdoor:  20%|█▉        | 85814/432000 [00:24<01:12, 4747.29it/s]prepro_backdoor:  20%|█▉        | 86331/432000 [00:24<01:11, 4860.89it/s]prepro_backdoor:  20%|██        | 86822/432000 [00:24<01:11, 4832.83it/s]prepro_backdoor:  20%|██        | 87309/432000 [00:24<01:13, 4671.63it/s]prepro_backdoor:  20%|██        | 87823/432000 [00:25<01:37, 3536.48it/s]prepro_backdoor:  20%|██        | 88436/432000 [00:25<01:23, 4127.02it/s]prepro_backdoor:  21%|██        | 88896/432000 [00:25<01:23, 4118.25it/s]prepro_backdoor:  21%|██        | 89341/432000 [00:25<01:22, 4153.64it/s]prepro_backdoor:  21%|██        | 89866/432000 [00:25<01:17, 4436.96it/s]prepro_backdoor:  21%|██        | 90330/432000 [00:25<01:16, 4444.10it/s]prepro_backdoor:  21%|██        | 90797/432000 [00:25<01:15, 4495.66it/s]prepro_backdoor:  21%|██        | 91257/432000 [00:25<01:15, 4521.41it/s]prepro_backdoor:  21%|██▏       | 91815/432000 [00:25<01:10, 4821.52it/s]prepro_backdoor:  21%|██▏       | 92304/432000 [00:26<01:12, 4680.98it/s]prepro_backdoor:  21%|██▏       | 92778/432000 [00:26<02:12, 2552.19it/s]prepro_backdoor:  22%|██▏       | 93244/432000 [00:26<01:55, 2931.79it/s]prepro_backdoor:  22%|██▏       | 93718/432000 [00:26<01:42, 3300.48it/s]prepro_backdoor:  22%|██▏       | 94218/432000 [00:26<01:31, 3682.56it/s]prepro_backdoor:  22%|██▏       | 94660/432000 [00:26<01:29, 3749.53it/s]prepro_backdoor:  22%|██▏       | 95119/432000 [00:26<01:25, 3955.03it/s]prepro_backdoor:  22%|██▏       | 95556/432000 [00:27<01:22, 4056.25it/s]prepro_backdoor:  22%|██▏       | 95992/432000 [00:27<02:01, 2763.92it/s]prepro_backdoor:  22%|██▏       | 96468/432000 [00:27<01:45, 3167.72it/s]prepro_backdoor:  22%|██▏       | 96965/432000 [00:27<01:33, 3574.77it/s]prepro_backdoor:  23%|██▎       | 97385/432000 [00:27<01:29, 3721.27it/s]prepro_backdoor:  23%|██▎       | 97950/432000 [00:27<01:19, 4201.66it/s]prepro_backdoor:  23%|██▎       | 98497/432000 [00:27<01:13, 4529.80it/s]prepro_backdoor:  23%|██▎       | 98981/432000 [00:27<01:16, 4377.30it/s]prepro_backdoor:  23%|██▎       | 99441/432000 [00:28<01:16, 4369.86it/s]prepro_backdoor:  23%|██▎       | 99907/432000 [00:28<01:15, 4426.90it/s]prepro_backdoor:  23%|██▎       | 100361/432000 [00:28<01:23, 3958.56it/s]prepro_backdoor:  23%|██▎       | 100773/432000 [00:28<01:24, 3902.76it/s]prepro_backdoor:  23%|██▎       | 101231/432000 [00:28<01:21, 4060.77it/s]prepro_backdoor:  24%|██▎       | 101776/432000 [00:28<01:14, 4423.82it/s]prepro_backdoor:  24%|██▎       | 102228/432000 [00:28<01:15, 4380.89it/s]prepro_backdoor:  24%|██▍       | 102704/432000 [00:28<01:13, 4485.09it/s]prepro_backdoor:  24%|██▍       | 103242/432000 [00:28<01:09, 4741.48it/s]prepro_backdoor:  24%|██▍       | 103721/432000 [00:28<01:10, 4634.89it/s]prepro_backdoor:  24%|██▍       | 104275/432000 [00:29<01:07, 4877.54it/s]prepro_backdoor:  24%|██▍       | 104766/432000 [00:29<01:13, 4467.40it/s]prepro_backdoor:  24%|██▍       | 105303/432000 [00:29<01:09, 4703.09it/s]prepro_backdoor:  24%|██▍       | 105781/432000 [00:29<01:31, 3560.89it/s]prepro_backdoor:  25%|██▍       | 106221/432000 [00:29<01:26, 3751.33it/s]prepro_backdoor:  25%|██▍       | 106652/432000 [00:29<01:23, 3875.78it/s]prepro_backdoor:  25%|██▍       | 107110/432000 [00:29<01:20, 4040.90it/s]prepro_backdoor:  25%|██▍       | 107615/432000 [00:29<01:15, 4290.63it/s]prepro_backdoor:  25%|██▌       | 108067/432000 [00:30<01:14, 4346.48it/s]prepro_backdoor:  25%|██▌       | 108616/432000 [00:30<01:09, 4670.96it/s]prepro_backdoor:  25%|██▌       | 109108/432000 [00:30<01:08, 4719.40it/s]prepro_backdoor:  25%|██▌       | 109642/432000 [00:30<01:06, 4869.79it/s]prepro_backdoor:  25%|██▌       | 110152/432000 [00:30<01:05, 4933.65it/s]prepro_backdoor:  26%|██▌       | 110650/432000 [00:30<01:09, 4621.74it/s]prepro_backdoor:  26%|██▌       | 111119/432000 [00:30<01:27, 3670.04it/s]prepro_backdoor:  26%|██▌       | 111592/432000 [00:30<01:21, 3911.21it/s]prepro_backdoor:  26%|██▌       | 112013/432000 [00:30<01:20, 3964.85it/s]prepro_backdoor:  26%|██▌       | 112471/432000 [00:31<01:17, 4111.34it/s]prepro_backdoor:  26%|██▌       | 112899/432000 [00:31<01:17, 4127.43it/s]prepro_backdoor:  26%|██▌       | 113385/432000 [00:31<01:13, 4306.45it/s]prepro_backdoor:  26%|██▋       | 113876/432000 [00:31<01:11, 4453.31it/s]prepro_backdoor:  26%|██▋       | 114329/432000 [00:31<01:11, 4468.36it/s]prepro_backdoor:  27%|██▋       | 114781/432000 [00:31<01:11, 4442.35it/s]prepro_backdoor:  27%|██▋       | 115253/432000 [00:31<01:10, 4514.22it/s]prepro_backdoor:  27%|██▋       | 115707/432000 [00:31<01:26, 3653.27it/s]prepro_backdoor:  27%|██▋       | 116200/432000 [00:31<01:19, 3958.39it/s]prepro_backdoor:  27%|██▋       | 116621/432000 [00:32<01:46, 2949.96it/s]prepro_backdoor:  27%|██▋       | 117168/432000 [00:32<01:30, 3487.24it/s]prepro_backdoor:  27%|██▋       | 117703/432000 [00:32<01:20, 3925.88it/s]prepro_backdoor:  27%|██▋       | 118147/432000 [00:32<01:19, 3928.52it/s]prepro_backdoor:  27%|██▋       | 118593/432000 [00:32<01:17, 4053.32it/s]prepro_backdoor:  28%|██▊       | 119138/432000 [00:32<01:10, 4414.62it/s]prepro_backdoor:  28%|██▊       | 119669/432000 [00:32<01:07, 4641.65it/s]prepro_backdoor:  28%|██▊       | 120151/432000 [00:32<01:07, 4653.19it/s]prepro_backdoor:  28%|██▊       | 120629/432000 [00:33<01:08, 4514.73it/s]prepro_backdoor:  28%|██▊       | 121090/432000 [00:33<01:11, 4318.99it/s]prepro_backdoor:  28%|██▊       | 121530/432000 [00:33<01:27, 3557.85it/s]prepro_backdoor:  28%|██▊       | 121922/432000 [00:33<01:25, 3639.85it/s]prepro_backdoor:  28%|██▊       | 122514/432000 [00:33<01:13, 4211.46it/s]prepro_backdoor:  28%|██▊       | 123031/432000 [00:33<01:09, 4461.59it/s]prepro_backdoor:  29%|██▊       | 123496/432000 [00:33<01:11, 4330.42it/s]prepro_backdoor:  29%|██▊       | 123942/432000 [00:33<01:11, 4284.63it/s]prepro_backdoor:  29%|██▉       | 124380/432000 [00:33<01:11, 4298.56it/s]prepro_backdoor:  29%|██▉       | 124817/432000 [00:34<01:13, 4160.96it/s]prepro_backdoor:  29%|██▉       | 125404/432000 [00:34<01:06, 4630.52it/s]prepro_backdoor:  29%|██▉       | 125936/432000 [00:34<01:03, 4809.18it/s]prepro_backdoor:  29%|██▉       | 126423/432000 [00:34<01:18, 3892.82it/s]prepro_backdoor:  29%|██▉       | 126844/432000 [00:34<01:18, 3895.91it/s]prepro_backdoor:  29%|██▉       | 127265/432000 [00:34<01:16, 3976.63it/s]prepro_backdoor:  30%|██▉       | 127691/432000 [00:34<01:15, 4035.28it/s]prepro_backdoor:  30%|██▉       | 128107/432000 [00:34<01:16, 3967.31it/s]prepro_backdoor:  30%|██▉       | 128513/432000 [00:35<01:21, 3722.82it/s]prepro_backdoor:  30%|██▉       | 129005/432000 [00:35<01:15, 4032.52it/s]prepro_backdoor:  30%|██▉       | 129417/432000 [00:35<01:16, 3954.40it/s]prepro_backdoor:  30%|███       | 129872/432000 [00:35<01:13, 4113.54it/s]prepro_backdoor:  30%|███       | 130292/432000 [00:35<01:37, 3097.93it/s]prepro_backdoor:  30%|███       | 130775/432000 [00:35<01:26, 3500.78it/s]prepro_backdoor:  30%|███       | 131223/432000 [00:35<01:20, 3736.87it/s]prepro_backdoor:  30%|███       | 131629/432000 [00:35<01:25, 3527.69it/s]prepro_backdoor:  31%|███       | 132131/432000 [00:35<01:17, 3893.41it/s]prepro_backdoor:  31%|███       | 132543/432000 [00:36<01:16, 3917.23it/s]prepro_backdoor:  31%|███       | 132979/432000 [00:36<01:14, 4032.80it/s]prepro_backdoor:  31%|███       | 133414/432000 [00:36<01:12, 4103.25it/s]prepro_backdoor:  31%|███       | 133886/432000 [00:36<01:09, 4269.25it/s]prepro_backdoor:  31%|███       | 134417/432000 [00:36<01:05, 4557.64it/s]prepro_backdoor:  31%|███       | 134879/432000 [00:36<01:20, 3681.78it/s]prepro_backdoor:  31%|███▏      | 135329/432000 [00:36<01:16, 3867.35it/s]prepro_backdoor:  31%|███▏      | 135787/432000 [00:36<01:13, 4048.08it/s]prepro_backdoor:  32%|███▏      | 136274/432000 [00:36<01:09, 4260.77it/s]prepro_backdoor:  32%|███▏      | 136716/432000 [00:37<03:14, 1518.74it/s]prepro_backdoor:  32%|███▏      | 137116/432000 [00:37<02:41, 1821.19it/s]prepro_backdoor:  32%|███▏      | 137635/432000 [00:37<02:06, 2325.22it/s]prepro_backdoor:  32%|███▏      | 138033/432000 [00:38<01:55, 2549.55it/s]prepro_backdoor:  32%|███▏      | 138520/432000 [00:38<01:37, 3000.53it/s]prepro_backdoor:  32%|███▏      | 139097/432000 [00:38<01:21, 3602.61it/s]prepro_backdoor:  32%|███▏      | 139558/432000 [00:38<01:22, 3543.02it/s]prepro_backdoor:  32%|███▏      | 140146/432000 [00:38<01:11, 4078.69it/s]prepro_backdoor:  33%|███▎      | 140654/432000 [00:38<01:07, 4314.35it/s]prepro_backdoor:  33%|███▎      | 141133/432000 [00:38<01:25, 3403.37it/s]prepro_backdoor:  33%|███▎      | 141632/432000 [00:38<01:17, 3759.47it/s]prepro_backdoor:  33%|███▎      | 142140/432000 [00:39<01:11, 4066.90it/s]prepro_backdoor:  33%|███▎      | 142603/432000 [00:39<01:08, 4201.74it/s]prepro_backdoor:  33%|███▎      | 143066/432000 [00:39<01:07, 4294.00it/s]prepro_backdoor:  33%|███▎      | 143521/432000 [00:39<01:06, 4362.55it/s]prepro_backdoor:  33%|███▎      | 144012/432000 [00:39<01:07, 4293.58it/s]prepro_backdoor:  33%|███▎      | 144588/432000 [00:39<01:01, 4671.98it/s]prepro_backdoor:  34%|███▎      | 145067/432000 [00:39<01:04, 4454.19it/s]prepro_backdoor:  34%|███▎      | 145522/432000 [00:39<01:06, 4299.29it/s]prepro_backdoor:  34%|███▍      | 145970/432000 [00:39<01:05, 4340.67it/s]prepro_backdoor:  34%|███▍      | 146410/432000 [00:39<01:06, 4298.53it/s]prepro_backdoor:  34%|███▍      | 146844/432000 [00:40<01:23, 3423.82it/s]prepro_backdoor:  34%|███▍      | 147299/432000 [00:40<01:17, 3688.55it/s]prepro_backdoor:  34%|███▍      | 147746/432000 [00:40<01:13, 3878.88it/s]prepro_backdoor:  34%|███▍      | 148279/432000 [00:40<01:06, 4248.83it/s]prepro_backdoor:  34%|███▍      | 148723/432000 [00:40<01:08, 4113.20it/s]prepro_backdoor:  35%|███▍      | 149206/432000 [00:40<01:05, 4291.74it/s]prepro_backdoor:  35%|███▍      | 149647/432000 [00:40<01:08, 4102.13it/s]prepro_backdoor:  35%|███▍      | 150141/432000 [00:40<01:05, 4312.97it/s]prepro_backdoor:  35%|███▍      | 150580/432000 [00:41<01:05, 4325.88it/s]prepro_backdoor:  35%|███▍      | 151023/432000 [00:41<01:04, 4338.57it/s]prepro_backdoor:  35%|███▌      | 151461/432000 [00:41<01:20, 3472.91it/s]prepro_backdoor:  35%|███▌      | 151883/432000 [00:41<01:16, 3650.51it/s]prepro_backdoor:  35%|███▌      | 152389/432000 [00:41<01:09, 4006.35it/s]prepro_backdoor:  35%|███▌      | 152812/432000 [00:41<01:08, 4054.93it/s]prepro_backdoor:  35%|███▌      | 153275/432000 [00:41<01:06, 4198.58it/s]prepro_backdoor:  36%|███▌      | 153707/432000 [00:41<01:08, 4039.05it/s]prepro_backdoor:  36%|███▌      | 154121/432000 [00:41<01:08, 4052.94it/s]prepro_backdoor:  36%|███▌      | 154651/432000 [00:42<01:03, 4396.29it/s]prepro_backdoor:  36%|███▌      | 155097/432000 [00:42<01:30, 3072.57it/s]prepro_backdoor:  36%|███▌      | 155538/432000 [00:42<01:22, 3368.30it/s]prepro_backdoor:  36%|███▌      | 155926/432000 [00:42<01:19, 3459.00it/s]prepro_backdoor:  36%|███▌      | 156310/432000 [00:42<01:21, 3396.78it/s]prepro_backdoor:  36%|███▋      | 156807/432000 [00:42<01:12, 3783.36it/s]prepro_backdoor:  36%|███▋      | 157210/432000 [00:42<01:11, 3839.15it/s]prepro_backdoor:  37%|███▋      | 157724/432000 [00:42<01:05, 4181.47it/s]prepro_backdoor:  37%|███▋      | 158180/432000 [00:42<01:03, 4278.92it/s]prepro_backdoor:  37%|███▋      | 158771/432000 [00:43<00:57, 4719.14it/s]prepro_backdoor:  37%|███▋      | 159252/432000 [00:43<01:37, 2791.87it/s]prepro_backdoor:  37%|███▋      | 159668/432000 [00:43<01:29, 3057.94it/s]prepro_backdoor:  37%|███▋      | 160140/432000 [00:43<01:19, 3419.75it/s]prepro_backdoor:  37%|███▋      | 160615/432000 [00:43<01:12, 3723.00it/s]prepro_backdoor:  37%|███▋      | 161046/432000 [00:43<01:13, 3671.28it/s]prepro_backdoor:  37%|███▋      | 161575/432000 [00:43<01:06, 4066.05it/s]prepro_backdoor:  38%|███▊      | 162017/432000 [00:44<01:05, 4140.91it/s]prepro_backdoor:  38%|███▊      | 162498/432000 [00:44<01:02, 4316.21it/s]prepro_backdoor:  38%|███▊      | 162985/432000 [00:44<01:00, 4471.73it/s]prepro_backdoor:  38%|███▊      | 163447/432000 [00:44<01:02, 4330.51it/s]prepro_backdoor:  38%|███▊      | 163891/432000 [00:44<01:02, 4263.96it/s]prepro_backdoor:  38%|███▊      | 164328/432000 [00:44<01:02, 4285.70it/s]prepro_backdoor:  38%|███▊      | 164843/432000 [00:44<00:59, 4511.70it/s]prepro_backdoor:  38%|███▊      | 165299/432000 [00:44<01:11, 3709.26it/s]prepro_backdoor:  38%|███▊      | 165720/432000 [00:44<01:09, 3826.80it/s]prepro_backdoor:  38%|███▊      | 166123/432000 [00:45<01:11, 3714.38it/s]prepro_backdoor:  39%|███▊      | 166664/432000 [00:45<01:04, 4145.56it/s]prepro_backdoor:  39%|███▊      | 167094/432000 [00:45<01:03, 4151.19it/s]prepro_backdoor:  39%|███▉      | 167520/432000 [00:45<01:04, 4070.02it/s]prepro_backdoor:  39%|███▉      | 167935/432000 [00:45<01:06, 3975.47it/s]prepro_backdoor:  39%|███▉      | 168408/432000 [00:45<01:03, 4174.68it/s]prepro_backdoor:  39%|███▉      | 168944/432000 [00:45<00:58, 4504.21it/s]prepro_backdoor:  39%|███▉      | 169400/432000 [00:45<01:11, 3656.52it/s]prepro_backdoor:  39%|███▉      | 169971/432000 [00:45<01:03, 4158.54it/s]prepro_backdoor:  39%|███▉      | 170417/432000 [00:46<01:04, 4054.61it/s]prepro_backdoor:  40%|███▉      | 170868/432000 [00:46<01:02, 4150.53it/s]prepro_backdoor:  40%|███▉      | 171302/432000 [00:46<01:02, 4190.22it/s]prepro_backdoor:  40%|███▉      | 171793/432000 [00:46<00:59, 4384.54it/s]prepro_backdoor:  40%|███▉      | 172241/432000 [00:46<00:59, 4371.41it/s]prepro_backdoor:  40%|███▉      | 172685/432000 [00:46<01:00, 4276.53it/s]prepro_backdoor:  40%|████      | 173118/432000 [00:46<01:00, 4275.33it/s]prepro_backdoor:  40%|████      | 173549/432000 [00:46<01:02, 4165.13it/s]prepro_backdoor:  40%|████      | 173969/432000 [00:46<01:02, 4095.79it/s]prepro_backdoor:  40%|████      | 174381/432000 [00:47<01:40, 2568.54it/s]prepro_backdoor:  40%|████      | 174884/432000 [00:47<01:23, 3063.26it/s]prepro_backdoor:  41%|████      | 175336/432000 [00:47<01:16, 3377.11it/s]prepro_backdoor:  41%|████      | 175846/432000 [00:47<01:07, 3791.19it/s]prepro_backdoor:  41%|████      | 176316/432000 [00:47<01:03, 4004.51it/s]prepro_backdoor:  41%|████      | 176757/432000 [00:47<01:02, 4075.88it/s]prepro_backdoor:  41%|████      | 177193/432000 [00:47<01:02, 4066.12it/s]prepro_backdoor:  41%|████      | 177653/432000 [00:47<01:00, 4205.15it/s]prepro_backdoor:  41%|████      | 178089/432000 [00:48<01:00, 4223.54it/s]prepro_backdoor:  41%|████▏     | 178522/432000 [00:48<01:02, 4061.20it/s]prepro_backdoor:  41%|████▏     | 178937/432000 [00:48<01:02, 4060.36it/s]prepro_backdoor:  42%|████▏     | 179349/432000 [00:48<01:17, 3257.94it/s]prepro_backdoor:  42%|████▏     | 179855/432000 [00:48<01:08, 3697.27it/s]prepro_backdoor:  42%|████▏     | 180273/432000 [00:48<01:05, 3814.75it/s]prepro_backdoor:  42%|████▏     | 180770/432000 [00:48<01:01, 4114.90it/s]prepro_backdoor:  42%|████▏     | 181201/432000 [00:48<01:01, 4092.56it/s]prepro_backdoor:  42%|████▏     | 181650/432000 [00:48<00:59, 4184.07it/s]prepro_backdoor:  42%|████▏     | 182121/432000 [00:49<00:57, 4309.39it/s]prepro_backdoor:  42%|████▏     | 182560/432000 [00:49<00:59, 4217.21it/s]prepro_backdoor:  42%|████▏     | 183037/432000 [00:49<00:57, 4352.14it/s]prepro_backdoor:  42%|████▏     | 183477/432000 [00:49<00:58, 4274.44it/s]prepro_backdoor:  43%|████▎     | 184045/432000 [00:49<00:53, 4675.97it/s]prepro_backdoor:  43%|████▎     | 184543/432000 [00:49<01:02, 3973.78it/s]prepro_backdoor:  43%|████▎     | 185040/432000 [00:49<00:58, 4224.87it/s]prepro_backdoor:  43%|████▎     | 185482/432000 [00:49<00:59, 4157.57it/s]prepro_backdoor:  43%|████▎     | 185911/432000 [00:49<00:59, 4158.58it/s]prepro_backdoor:  43%|████▎     | 186480/432000 [00:50<00:53, 4576.44it/s]prepro_backdoor:  43%|████▎     | 186948/432000 [00:50<00:56, 4366.56it/s]prepro_backdoor:  43%|████▎     | 187448/432000 [00:50<00:54, 4528.53it/s]prepro_backdoor:  44%|████▎     | 187996/432000 [00:50<00:51, 4774.12it/s]prepro_backdoor:  44%|████▎     | 188480/432000 [00:50<00:56, 4346.32it/s]prepro_backdoor:  44%|████▎     | 188926/432000 [00:50<00:58, 4151.90it/s]prepro_backdoor:  44%|████▍     | 189350/432000 [00:50<00:58, 4174.15it/s]prepro_backdoor:  44%|████▍     | 189774/432000 [00:50<01:06, 3624.08it/s]prepro_backdoor:  44%|████▍     | 190241/432000 [00:51<01:02, 3871.36it/s]prepro_backdoor:  44%|████▍     | 190686/432000 [00:51<01:00, 4011.46it/s]prepro_backdoor:  44%|████▍     | 191099/432000 [00:51<01:01, 3921.00it/s]prepro_backdoor:  44%|████▍     | 191500/432000 [00:51<01:05, 3673.62it/s]prepro_backdoor:  44%|████▍     | 191876/432000 [00:51<01:05, 3665.89it/s]prepro_backdoor:  45%|████▍     | 192301/432000 [00:51<01:02, 3807.90it/s]prepro_backdoor:  45%|████▍     | 192700/432000 [00:51<01:02, 3848.24it/s]prepro_backdoor:  45%|████▍     | 193089/432000 [00:51<01:04, 3691.28it/s]prepro_backdoor:  45%|████▍     | 193545/432000 [00:51<01:00, 3913.97it/s]prepro_backdoor:  45%|████▍     | 193940/432000 [00:53<05:04, 782.66it/s] prepro_backdoor:  45%|████▍     | 194273/432000 [00:53<04:04, 973.63it/s]prepro_backdoor:  45%|████▌     | 194696/432000 [00:53<03:04, 1288.70it/s]prepro_backdoor:  45%|████▌     | 195149/432000 [00:53<02:20, 1681.33it/s]prepro_backdoor:  45%|████▌     | 195642/432000 [00:53<01:49, 2155.06it/s]prepro_backdoor:  45%|████▌     | 196123/432000 [00:53<01:30, 2611.76it/s]prepro_backdoor:  45%|████▌     | 196549/432000 [00:54<01:24, 2796.31it/s]prepro_backdoor:  46%|████▌     | 196949/432000 [00:54<01:18, 2991.27it/s]prepro_backdoor:  46%|████▌     | 197338/432000 [00:54<01:13, 3193.69it/s]prepro_backdoor:  46%|████▌     | 197756/432000 [00:54<01:08, 3419.74it/s]prepro_backdoor:  46%|████▌     | 198151/432000 [00:54<01:23, 2803.37it/s]prepro_backdoor:  46%|████▌     | 198543/432000 [00:54<01:16, 3049.70it/s]prepro_backdoor:  46%|████▌     | 198984/432000 [00:54<01:09, 3367.19it/s]prepro_backdoor:  46%|████▌     | 199520/432000 [00:54<01:00, 3869.37it/s]prepro_backdoor:  46%|████▋     | 199942/432000 [00:54<00:58, 3955.79it/s]prepro_backdoor:  46%|████▋     | 200460/432000 [00:55<00:54, 4283.01it/s]prepro_backdoor:  47%|████▋     | 200909/432000 [00:55<00:59, 3912.26it/s]prepro_backdoor:  47%|████▋     | 201321/432000 [00:55<00:58, 3938.99it/s]prepro_backdoor:  47%|████▋     | 201912/432000 [00:55<00:51, 4473.41it/s]prepro_backdoor:  47%|████▋     | 202413/432000 [00:55<00:49, 4617.54it/s]prepro_backdoor:  47%|████▋     | 202910/432000 [00:55<00:48, 4709.57it/s]prepro_backdoor:  47%|████▋     | 203400/432000 [00:55<00:48, 4743.41it/s]prepro_backdoor:  47%|████▋     | 203881/432000 [00:55<01:13, 3086.14it/s]prepro_backdoor:  47%|████▋     | 204377/432000 [00:56<01:05, 3474.21it/s]prepro_backdoor:  47%|████▋     | 204795/432000 [00:56<01:05, 3474.82it/s]prepro_backdoor:  48%|████▊     | 205216/432000 [00:56<01:02, 3644.58it/s]prepro_backdoor:  48%|████▊     | 205619/432000 [00:56<01:02, 3600.61it/s]prepro_backdoor:  48%|████▊     | 206035/432000 [00:56<01:00, 3739.12it/s]prepro_backdoor:  48%|████▊     | 206615/432000 [00:56<00:52, 4284.08it/s]prepro_backdoor:  48%|████▊     | 207064/432000 [00:56<00:53, 4191.48it/s]prepro_backdoor:  48%|████▊     | 207526/432000 [00:56<00:52, 4297.88it/s]prepro_backdoor:  48%|████▊     | 207967/432000 [00:57<01:32, 2416.68it/s]prepro_backdoor:  48%|████▊     | 208371/432000 [00:57<01:22, 2711.08it/s]prepro_backdoor:  48%|████▊     | 208771/432000 [00:57<01:15, 2971.56it/s]prepro_backdoor:  48%|████▊     | 209188/432000 [00:57<01:08, 3238.62it/s]prepro_backdoor:  49%|████▊     | 209585/432000 [00:57<01:05, 3415.73it/s]prepro_backdoor:  49%|████▊     | 210030/432000 [00:57<01:00, 3682.38it/s]prepro_backdoor:  49%|████▊     | 210480/432000 [00:57<00:56, 3898.36it/s]prepro_backdoor:  49%|████▉     | 210931/432000 [00:57<00:54, 4058.43it/s]prepro_backdoor:  49%|████▉     | 211380/432000 [00:58<00:52, 4173.83it/s]prepro_backdoor:  49%|████▉     | 211900/432000 [00:58<00:49, 4447.95it/s]prepro_backdoor:  49%|████▉     | 212356/432000 [00:58<00:51, 4262.14it/s]prepro_backdoor:  49%|████▉     | 212792/432000 [00:58<01:04, 3389.82it/s]prepro_backdoor:  49%|████▉     | 213209/432000 [00:58<01:01, 3573.71it/s]prepro_backdoor:  49%|████▉     | 213613/432000 [00:58<00:59, 3689.43it/s]prepro_backdoor:  50%|████▉     | 214082/432000 [00:58<00:55, 3948.75it/s]prepro_backdoor:  50%|████▉     | 214507/432000 [00:58<00:54, 4020.36it/s]prepro_backdoor:  50%|████▉     | 215029/432000 [00:58<00:49, 4340.72it/s]prepro_backdoor:  50%|████▉     | 215474/432000 [00:59<00:51, 4233.41it/s]prepro_backdoor:  50%|████▉     | 215951/432000 [00:59<00:49, 4370.80it/s]prepro_backdoor:  50%|█████     | 216395/432000 [00:59<00:51, 4196.69it/s]prepro_backdoor:  50%|█████     | 216866/432000 [00:59<00:49, 4332.20it/s]prepro_backdoor:  50%|█████     | 217304/432000 [00:59<01:16, 2790.88it/s]prepro_backdoor:  50%|█████     | 217737/432000 [00:59<01:09, 3100.23it/s]prepro_backdoor:  51%|█████     | 218170/432000 [00:59<01:03, 3381.31it/s]prepro_backdoor:  51%|█████     | 218562/432000 [00:59<01:01, 3472.52it/s]prepro_backdoor:  51%|█████     | 219037/432000 [01:00<00:56, 3795.37it/s]prepro_backdoor:  51%|█████     | 219537/432000 [01:00<00:51, 4098.52it/s]prepro_backdoor:  51%|█████     | 220066/432000 [01:00<00:47, 4417.52it/s]prepro_backdoor:  51%|█████     | 220529/432000 [01:00<00:47, 4407.58it/s]prepro_backdoor:  51%|█████     | 220985/432000 [01:00<00:48, 4309.61it/s]prepro_backdoor:  51%|█████▏    | 221427/432000 [01:00<00:49, 4235.45it/s]prepro_backdoor:  51%|█████▏    | 221858/432000 [01:00<01:14, 2814.98it/s]prepro_backdoor:  51%|█████▏    | 222339/432000 [01:00<01:04, 3233.43it/s]prepro_backdoor:  52%|█████▏    | 222837/432000 [01:01<00:57, 3624.17it/s]prepro_backdoor:  52%|█████▏    | 223256/432000 [01:01<00:58, 3569.22it/s]prepro_backdoor:  52%|█████▏    | 223693/432000 [01:01<00:55, 3761.81it/s]prepro_backdoor:  52%|█████▏    | 224100/432000 [01:01<00:54, 3783.04it/s]prepro_backdoor:  52%|█████▏    | 224532/432000 [01:01<00:52, 3916.90it/s]prepro_backdoor:  52%|█████▏    | 225033/432000 [01:01<00:49, 4208.58it/s]prepro_backdoor:  52%|█████▏    | 225468/432000 [01:01<00:50, 4079.63it/s]prepro_backdoor:  52%|█████▏    | 225887/432000 [01:01<01:11, 2865.78it/s]prepro_backdoor:  52%|█████▏    | 226229/432000 [01:02<01:33, 2203.25it/s]prepro_backdoor:  52%|█████▏    | 226711/432000 [01:02<01:16, 2689.36it/s]prepro_backdoor:  53%|█████▎    | 227084/432000 [01:02<01:10, 2897.12it/s]prepro_backdoor:  53%|█████▎    | 227739/432000 [01:02<00:54, 3739.29it/s]prepro_backdoor:  53%|█████▎    | 228235/432000 [01:02<00:50, 4040.65it/s]prepro_backdoor:  53%|█████▎    | 228771/432000 [01:02<00:46, 4375.66it/s]prepro_backdoor:  53%|█████▎    | 229250/432000 [01:02<00:47, 4300.71it/s]prepro_backdoor:  53%|█████▎    | 229709/432000 [01:02<00:48, 4182.92it/s]prepro_backdoor:  53%|█████▎    | 230148/432000 [01:03<00:49, 4084.35it/s]prepro_backdoor:  53%|█████▎    | 230632/432000 [01:03<00:46, 4287.43it/s]prepro_backdoor:  53%|█████▎    | 231073/432000 [01:03<01:04, 3099.94it/s]prepro_backdoor:  54%|█████▎    | 231582/432000 [01:03<00:56, 3527.54it/s]prepro_backdoor:  54%|█████▎    | 231987/432000 [01:03<00:55, 3624.45it/s]prepro_backdoor:  54%|█████▍    | 232415/432000 [01:03<00:52, 3783.25it/s]prepro_backdoor:  54%|█████▍    | 232900/432000 [01:03<00:49, 4062.77it/s]prepro_backdoor:  54%|█████▍    | 233389/432000 [01:03<00:46, 4271.27it/s]prepro_backdoor:  54%|█████▍    | 233835/432000 [01:04<00:46, 4239.68it/s]prepro_backdoor:  54%|█████▍    | 234272/432000 [01:04<00:52, 3786.74it/s]prepro_backdoor:  54%|█████▍    | 234676/432000 [01:04<00:51, 3843.87it/s]prepro_backdoor:  54%|█████▍    | 235074/432000 [01:04<00:51, 3794.80it/s]prepro_backdoor:  55%|█████▍    | 235463/432000 [01:04<01:10, 2793.01it/s]prepro_backdoor:  55%|█████▍    | 235926/432000 [01:04<01:01, 3199.68it/s]prepro_backdoor:  55%|█████▍    | 236388/432000 [01:04<00:55, 3532.35it/s]prepro_backdoor:  55%|█████▍    | 236789/432000 [01:04<00:53, 3642.43it/s]prepro_backdoor:  55%|█████▍    | 237182/432000 [01:05<00:53, 3667.12it/s]prepro_backdoor:  55%|█████▌    | 237669/432000 [01:05<00:48, 3992.65it/s]prepro_backdoor:  55%|█████▌    | 238125/432000 [01:05<00:46, 4132.01it/s]prepro_backdoor:  55%|█████▌    | 238551/432000 [01:05<00:48, 3981.81it/s]prepro_backdoor:  55%|█████▌    | 238989/432000 [01:05<00:47, 4086.16it/s]prepro_backdoor:  55%|█████▌    | 239442/432000 [01:05<00:45, 4206.07it/s]prepro_backdoor:  56%|█████▌    | 239869/432000 [01:05<00:46, 4169.90it/s]prepro_backdoor:  56%|█████▌    | 240478/432000 [01:05<01:01, 3123.95it/s]prepro_backdoor:  56%|█████▌    | 240903/432000 [01:06<00:57, 3351.22it/s]prepro_backdoor:  56%|█████▌    | 241281/432000 [01:06<00:56, 3357.41it/s]prepro_backdoor:  56%|█████▌    | 241717/432000 [01:06<00:52, 3594.86it/s]prepro_backdoor:  56%|█████▌    | 242180/432000 [01:06<00:49, 3846.45it/s]prepro_backdoor:  56%|█████▌    | 242730/432000 [01:06<00:44, 4272.60it/s]prepro_backdoor:  56%|█████▋    | 243177/432000 [01:06<00:46, 4099.56it/s]prepro_backdoor:  56%|█████▋    | 243646/432000 [01:06<00:44, 4260.28it/s]prepro_backdoor:  57%|█████▋    | 244174/432000 [01:06<00:41, 4536.18it/s]prepro_backdoor:  57%|█████▋    | 244688/432000 [01:06<00:39, 4699.51it/s]prepro_backdoor:  57%|█████▋    | 245166/432000 [01:07<00:40, 4652.37it/s]prepro_backdoor:  57%|█████▋    | 245637/432000 [01:07<01:04, 2909.66it/s]prepro_backdoor:  57%|█████▋    | 246032/432000 [01:07<00:59, 3120.98it/s]prepro_backdoor:  57%|█████▋    | 246531/432000 [01:07<00:52, 3541.43it/s]prepro_backdoor:  57%|█████▋    | 246964/432000 [01:07<00:49, 3730.10it/s]prepro_backdoor:  57%|█████▋    | 247385/432000 [01:07<00:49, 3740.33it/s]prepro_backdoor:  57%|█████▋    | 247844/432000 [01:07<00:46, 3944.21it/s]prepro_backdoor:  57%|█████▋    | 248265/432000 [01:07<00:46, 3928.41it/s]prepro_backdoor:  58%|█████▊    | 248676/432000 [01:08<00:46, 3928.92it/s]prepro_backdoor:  58%|█████▊    | 249217/432000 [01:08<00:42, 4323.72it/s]prepro_backdoor:  58%|█████▊    | 249661/432000 [01:08<02:10, 1392.20it/s]prepro_backdoor:  58%|█████▊    | 250068/432000 [01:09<01:47, 1699.55it/s]prepro_backdoor:  58%|█████▊    | 250418/432000 [01:09<01:33, 1951.96it/s]prepro_backdoor:  58%|█████▊    | 250845/432000 [01:09<01:17, 2338.20it/s]prepro_backdoor:  58%|█████▊    | 251311/432000 [01:09<01:04, 2785.62it/s]prepro_backdoor:  58%|█████▊    | 251739/432000 [01:09<00:58, 3100.64it/s]prepro_backdoor:  58%|█████▊    | 252166/432000 [01:09<00:53, 3364.97it/s]prepro_backdoor:  58%|█████▊    | 252603/432000 [01:09<00:49, 3601.91it/s]prepro_backdoor:  59%|█████▊    | 253124/432000 [01:09<00:44, 4018.28it/s]prepro_backdoor:  59%|█████▊    | 253647/432000 [01:09<00:41, 4339.92it/s]prepro_backdoor:  59%|█████▉    | 254116/432000 [01:10<00:53, 3300.37it/s]prepro_backdoor:  59%|█████▉    | 254541/432000 [01:10<00:50, 3515.30it/s]prepro_backdoor:  59%|█████▉    | 254942/432000 [01:10<00:49, 3610.89it/s]prepro_backdoor:  59%|█████▉    | 255444/432000 [01:10<00:44, 3971.14it/s]prepro_backdoor:  59%|█████▉    | 255913/432000 [01:10<00:42, 4141.19it/s]prepro_backdoor:  59%|█████▉    | 256387/432000 [01:10<00:40, 4302.87it/s]prepro_backdoor:  59%|█████▉    | 256835/432000 [01:10<00:43, 4049.82it/s]prepro_backdoor:  60%|█████▉    | 257297/432000 [01:10<00:41, 4194.01it/s]prepro_backdoor:  60%|█████▉    | 257729/432000 [01:10<00:41, 4184.07it/s]prepro_backdoor:  60%|█████▉    | 258265/432000 [01:11<00:38, 4505.66it/s]prepro_backdoor:  60%|█████▉    | 258723/432000 [01:11<00:39, 4374.09it/s]prepro_backdoor:  60%|██████    | 259283/432000 [01:11<00:36, 4706.04it/s]prepro_backdoor:  60%|██████    | 259760/432000 [01:11<00:36, 4693.19it/s]prepro_backdoor:  60%|██████    | 260234/432000 [01:11<01:00, 2831.15it/s]prepro_backdoor:  60%|██████    | 260720/432000 [01:11<00:52, 3235.91it/s]prepro_backdoor:  60%|██████    | 261128/432000 [01:11<00:50, 3401.20it/s]prepro_backdoor:  61%|██████    | 261633/432000 [01:12<00:44, 3789.01it/s]prepro_backdoor:  61%|██████    | 262067/432000 [01:12<01:01, 2758.08it/s]prepro_backdoor:  61%|██████    | 262495/432000 [01:12<00:55, 3067.50it/s]prepro_backdoor:  61%|██████    | 263010/432000 [01:12<00:47, 3522.40it/s]prepro_backdoor:  61%|██████    | 263559/432000 [01:12<00:42, 3996.80it/s]prepro_backdoor:  61%|██████    | 264021/432000 [01:12<00:40, 4140.53it/s]prepro_backdoor:  61%|██████    | 264476/432000 [01:12<00:43, 3887.70it/s]prepro_backdoor:  61%|██████▏   | 264896/432000 [01:12<00:42, 3966.91it/s]prepro_backdoor:  61%|██████▏   | 265342/432000 [01:13<00:40, 4087.68it/s]prepro_backdoor:  62%|██████▏   | 265771/432000 [01:13<00:40, 4138.93it/s]prepro_backdoor:  62%|██████▏   | 266203/432000 [01:13<00:39, 4174.18it/s]prepro_backdoor:  62%|██████▏   | 266630/432000 [01:13<00:39, 4149.30it/s]prepro_backdoor:  62%|██████▏   | 267052/432000 [01:13<00:40, 4104.28it/s]prepro_backdoor:  62%|██████▏   | 267467/432000 [01:13<00:41, 4003.81it/s]prepro_backdoor:  62%|██████▏   | 267946/432000 [01:13<00:38, 4219.79it/s]prepro_backdoor:  62%|██████▏   | 268372/432000 [01:13<00:49, 3337.07it/s]prepro_backdoor:  62%|██████▏   | 268856/432000 [01:13<00:44, 3699.51it/s]prepro_backdoor:  62%|██████▏   | 269262/432000 [01:14<00:42, 3790.78it/s]prepro_backdoor:  62%|██████▏   | 269663/432000 [01:14<00:43, 3752.18it/s]prepro_backdoor:  63%|██████▎   | 270234/432000 [01:14<00:37, 4276.49it/s]prepro_backdoor:  63%|██████▎   | 270677/432000 [01:14<00:38, 4139.80it/s]prepro_backdoor:  63%|██████▎   | 271103/432000 [01:14<00:39, 4087.99it/s]prepro_backdoor:  63%|██████▎   | 271520/432000 [01:14<00:40, 3969.44it/s]prepro_backdoor:  63%|██████▎   | 271924/432000 [01:14<00:40, 3972.80it/s]prepro_backdoor:  63%|██████▎   | 272395/432000 [01:14<00:38, 4156.67it/s]prepro_backdoor:  63%|██████▎   | 272844/432000 [01:14<00:49, 3228.16it/s]prepro_backdoor:  63%|██████▎   | 273275/432000 [01:15<00:45, 3468.09it/s]prepro_backdoor:  63%|██████▎   | 273847/432000 [01:15<00:39, 4024.45it/s]prepro_backdoor:  63%|██████▎   | 274281/432000 [01:15<00:38, 4052.42it/s]prepro_backdoor:  64%|██████▎   | 274738/432000 [01:15<00:37, 4182.57it/s]prepro_backdoor:  64%|██████▎   | 275231/432000 [01:15<00:35, 4387.00it/s]prepro_backdoor:  64%|██████▍   | 275843/432000 [01:15<00:32, 4856.21it/s]prepro_backdoor:  64%|██████▍   | 276351/432000 [01:15<00:31, 4910.43it/s]prepro_backdoor:  64%|██████▍   | 276850/432000 [01:15<00:32, 4829.33it/s]prepro_backdoor:  64%|██████▍   | 277339/432000 [01:15<00:33, 4666.59it/s]prepro_backdoor:  64%|██████▍   | 277811/432000 [01:16<00:34, 4479.43it/s]prepro_backdoor:  64%|██████▍   | 278264/432000 [01:16<00:43, 3545.94it/s]prepro_backdoor:  65%|██████▍   | 278751/432000 [01:16<00:39, 3850.10it/s]prepro_backdoor:  65%|██████▍   | 279319/432000 [01:16<00:35, 4302.59it/s]prepro_backdoor:  65%|██████▍   | 279790/432000 [01:16<00:34, 4388.86it/s]prepro_backdoor:  65%|██████▍   | 280250/432000 [01:16<00:35, 4289.02it/s]prepro_backdoor:  65%|██████▍   | 280694/432000 [01:16<00:37, 4023.84it/s]prepro_backdoor:  65%|██████▌   | 281187/432000 [01:16<00:35, 4245.83it/s]prepro_backdoor:  65%|██████▌   | 281696/432000 [01:16<00:33, 4466.85it/s]prepro_backdoor:  65%|██████▌   | 282153/432000 [01:17<01:03, 2377.51it/s]prepro_backdoor:  65%|██████▌   | 282672/432000 [01:17<00:52, 2864.23it/s]prepro_backdoor:  66%|██████▌   | 283073/432000 [01:17<00:48, 3063.45it/s]prepro_backdoor:  66%|██████▌   | 283468/432000 [01:17<00:45, 3250.43it/s]prepro_backdoor:  66%|██████▌   | 283936/432000 [01:17<00:41, 3583.25it/s]prepro_backdoor:  66%|██████▌   | 284428/432000 [01:17<00:37, 3918.77it/s]prepro_backdoor:  66%|██████▌   | 284866/432000 [01:18<00:37, 3938.25it/s]prepro_backdoor:  66%|██████▌   | 285344/432000 [01:18<00:35, 4144.52it/s]prepro_backdoor:  66%|██████▌   | 285834/432000 [01:18<00:33, 4328.97it/s]prepro_backdoor:  66%|██████▋   | 286310/432000 [01:18<00:32, 4438.90it/s]prepro_backdoor:  66%|██████▋   | 286768/432000 [01:18<00:41, 3539.82it/s]prepro_backdoor:  66%|██████▋   | 287252/432000 [01:18<00:37, 3839.45it/s]prepro_backdoor:  67%|██████▋   | 287692/432000 [01:18<00:36, 3969.30it/s]prepro_backdoor:  67%|██████▋   | 288114/432000 [01:18<00:39, 3631.24it/s]prepro_backdoor:  67%|██████▋   | 288612/432000 [01:18<00:36, 3969.51it/s]prepro_backdoor:  67%|██████▋   | 289030/432000 [01:19<00:35, 4000.27it/s]prepro_backdoor:  67%|██████▋   | 289445/432000 [01:19<00:35, 3982.60it/s]prepro_backdoor:  67%|██████▋   | 289882/432000 [01:19<00:34, 4079.18it/s]prepro_backdoor:  67%|██████▋   | 290350/432000 [01:19<00:33, 4240.84it/s]prepro_backdoor:  67%|██████▋   | 290919/432000 [01:19<00:30, 4643.13it/s]prepro_backdoor:  67%|██████▋   | 291389/432000 [01:19<00:37, 3720.18it/s]prepro_backdoor:  68%|██████▊   | 291913/432000 [01:19<00:34, 4094.53it/s]prepro_backdoor:  68%|██████▊   | 292524/432000 [01:19<00:30, 4598.01it/s]prepro_backdoor:  68%|██████▊   | 293012/432000 [01:19<00:30, 4489.28it/s]prepro_backdoor:  68%|██████▊   | 293502/432000 [01:20<00:30, 4597.48it/s]prepro_backdoor:  68%|██████▊   | 294022/432000 [01:20<00:29, 4751.56it/s]prepro_backdoor:  68%|██████▊   | 294509/432000 [01:20<00:30, 4493.44it/s]prepro_backdoor:  68%|██████▊   | 294969/432000 [01:20<00:30, 4475.63it/s]prepro_backdoor:  68%|██████▊   | 295424/432000 [01:20<00:30, 4437.51it/s]prepro_backdoor:  68%|██████▊   | 295873/432000 [01:20<00:30, 4427.90it/s]prepro_backdoor:  69%|██████▊   | 296320/432000 [01:20<00:32, 4235.01it/s]prepro_backdoor:  69%|██████▊   | 296827/432000 [01:20<00:30, 4444.59it/s]prepro_backdoor:  69%|██████▉   | 297331/432000 [01:20<00:29, 4613.15it/s]prepro_backdoor:  69%|██████▉   | 297796/432000 [01:21<00:36, 3716.21it/s]prepro_backdoor:  69%|██████▉   | 298238/432000 [01:21<00:34, 3883.82it/s]prepro_backdoor:  69%|██████▉   | 298651/432000 [01:21<00:35, 3784.42it/s]prepro_backdoor:  69%|██████▉   | 299133/432000 [01:21<00:32, 4042.28it/s]prepro_backdoor:  69%|██████▉   | 299575/432000 [01:21<00:32, 4120.29it/s]prepro_backdoor:  69%|██████▉   | 300055/432000 [01:21<00:30, 4297.99it/s]prepro_backdoor:  70%|██████▉   | 300494/432000 [01:21<00:31, 4226.14it/s]prepro_backdoor:  70%|██████▉   | 301045/432000 [01:21<00:28, 4582.29it/s]prepro_backdoor:  70%|██████▉   | 301510/432000 [01:21<00:29, 4498.02it/s]prepro_backdoor:  70%|██████▉   | 301965/432000 [01:22<00:47, 2744.26it/s]prepro_backdoor:  70%|██████▉   | 302366/432000 [01:22<00:43, 2996.60it/s]prepro_backdoor:  70%|███████   | 302795/432000 [01:22<00:39, 3275.48it/s]prepro_backdoor:  70%|███████   | 303284/432000 [01:22<00:35, 3656.19it/s]prepro_backdoor:  70%|███████   | 303750/432000 [01:22<00:32, 3904.63it/s]prepro_backdoor:  70%|███████   | 304182/432000 [01:22<00:31, 3994.83it/s]prepro_backdoor:  71%|███████   | 304672/432000 [01:22<00:30, 4227.29it/s]prepro_backdoor:  71%|███████   | 305131/432000 [01:22<00:29, 4313.74it/s]prepro_backdoor:  71%|███████   | 305662/432000 [01:23<00:27, 4583.19it/s]prepro_backdoor:  71%|███████   | 306243/432000 [01:23<00:25, 4937.15it/s]prepro_backdoor:  71%|███████   | 306747/432000 [01:24<01:33, 1338.01it/s]prepro_backdoor:  71%|███████   | 307162/432000 [01:24<01:17, 1620.03it/s]prepro_backdoor:  71%|███████   | 307572/432000 [01:24<01:04, 1928.98it/s]prepro_backdoor:  71%|███████▏  | 308100/432000 [01:24<00:50, 2431.55it/s]prepro_backdoor:  71%|███████▏  | 308655/432000 [01:24<00:41, 2981.78it/s]prepro_backdoor:  72%|███████▏  | 309182/432000 [01:24<00:35, 3445.32it/s]prepro_backdoor:  72%|███████▏  | 309665/432000 [01:24<00:34, 3573.68it/s]prepro_backdoor:  72%|███████▏  | 310152/432000 [01:24<00:31, 3875.58it/s]prepro_backdoor:  72%|███████▏  | 310617/432000 [01:25<00:30, 3924.09it/s]prepro_backdoor:  72%|███████▏  | 311064/432000 [01:25<00:38, 3160.14it/s]prepro_backdoor:  72%|███████▏  | 311472/432000 [01:25<00:35, 3353.44it/s]prepro_backdoor:  72%|███████▏  | 311898/432000 [01:25<00:33, 3559.78it/s]prepro_backdoor:  72%|███████▏  | 312327/432000 [01:25<00:32, 3730.65it/s]prepro_backdoor:  72%|███████▏  | 312733/432000 [01:25<00:31, 3802.27it/s]prepro_backdoor:  73%|███████▎  | 313232/432000 [01:25<00:28, 4121.18it/s]prepro_backdoor:  73%|███████▎  | 313665/432000 [01:25<00:28, 4163.00it/s]prepro_backdoor:  73%|███████▎  | 314095/432000 [01:25<00:29, 3958.99it/s]prepro_backdoor:  73%|███████▎  | 314502/432000 [01:26<00:29, 3955.94it/s]prepro_backdoor:  73%|███████▎  | 314948/432000 [01:26<00:28, 4093.63it/s]prepro_backdoor:  73%|███████▎  | 315364/432000 [01:26<00:35, 3287.90it/s]prepro_backdoor:  73%|███████▎  | 315804/432000 [01:26<00:32, 3548.63it/s]prepro_backdoor:  73%|███████▎  | 316185/432000 [01:26<00:32, 3572.13it/s]prepro_backdoor:  73%|███████▎  | 316628/432000 [01:26<00:30, 3780.35it/s]prepro_backdoor:  73%|███████▎  | 317022/432000 [01:26<00:30, 3819.88it/s]prepro_backdoor:  73%|███████▎  | 317515/432000 [01:26<00:27, 4124.88it/s]prepro_backdoor:  74%|███████▎  | 317984/432000 [01:26<00:26, 4266.54it/s]prepro_backdoor:  74%|███████▎  | 318418/432000 [01:27<00:36, 3145.16it/s]prepro_backdoor:  74%|███████▍  | 319002/432000 [01:27<00:29, 3770.56it/s]prepro_backdoor:  74%|███████▍  | 319430/432000 [01:27<00:35, 3144.17it/s]prepro_backdoor:  74%|███████▍  | 319837/432000 [01:27<00:33, 3337.22it/s]prepro_backdoor:  74%|███████▍  | 320213/432000 [01:27<00:32, 3388.75it/s]prepro_backdoor:  74%|███████▍  | 320582/432000 [01:27<00:32, 3428.40it/s]prepro_backdoor:  74%|███████▍  | 321039/432000 [01:27<00:29, 3722.54it/s]prepro_backdoor:  74%|███████▍  | 321431/432000 [01:28<00:30, 3652.01it/s]prepro_backdoor:  74%|███████▍  | 321832/432000 [01:28<00:29, 3746.09it/s]prepro_backdoor:  75%|███████▍  | 322241/432000 [01:28<00:28, 3839.74it/s]prepro_backdoor:  75%|███████▍  | 322633/432000 [01:28<00:28, 3861.01it/s]prepro_backdoor:  75%|███████▍  | 323025/432000 [01:28<00:34, 3143.93it/s]prepro_backdoor:  75%|███████▍  | 323483/432000 [01:28<00:31, 3485.28it/s]prepro_backdoor:  75%|███████▍  | 323910/432000 [01:28<00:29, 3688.98it/s]prepro_backdoor:  75%|███████▌  | 324447/432000 [01:28<00:26, 4128.56it/s]prepro_backdoor:  75%|███████▌  | 324877/432000 [01:28<00:26, 4068.51it/s]prepro_backdoor:  75%|███████▌  | 325296/432000 [01:29<00:27, 3881.10it/s]prepro_backdoor:  75%|███████▌  | 325735/432000 [01:29<00:26, 4001.46it/s]prepro_backdoor:  75%|███████▌  | 326144/432000 [01:29<00:26, 4019.10it/s]prepro_backdoor:  76%|███████▌  | 326612/432000 [01:29<00:25, 4199.65it/s]prepro_backdoor:  76%|███████▌  | 327124/432000 [01:29<00:23, 4445.40it/s]prepro_backdoor:  76%|███████▌  | 327717/432000 [01:29<00:21, 4875.46it/s]prepro_backdoor:  76%|███████▌  | 328297/432000 [01:29<00:20, 5125.01it/s]prepro_backdoor:  76%|███████▌  | 328813/432000 [01:29<00:27, 3786.46it/s]prepro_backdoor:  76%|███████▌  | 329244/432000 [01:30<00:27, 3727.84it/s]prepro_backdoor:  76%|███████▋  | 329654/432000 [01:30<00:26, 3813.28it/s]prepro_backdoor:  76%|███████▋  | 330063/432000 [01:30<00:26, 3784.38it/s]prepro_backdoor:  77%|███████▋  | 330511/432000 [01:30<00:25, 3960.46it/s]prepro_backdoor:  77%|███████▋  | 330945/432000 [01:30<00:24, 4053.19it/s]prepro_backdoor:  77%|███████▋  | 331362/432000 [01:30<00:25, 4013.73it/s]prepro_backdoor:  77%|███████▋  | 331805/432000 [01:30<00:24, 4116.85it/s]prepro_backdoor:  77%|███████▋  | 332223/432000 [01:30<00:24, 4036.96it/s]prepro_backdoor:  77%|███████▋  | 332632/432000 [01:30<00:32, 3066.55it/s]prepro_backdoor:  77%|███████▋  | 333043/432000 [01:31<00:29, 3304.54it/s]prepro_backdoor:  77%|███████▋  | 333515/432000 [01:31<00:26, 3650.55it/s]prepro_backdoor:  77%|███████▋  | 333963/432000 [01:31<00:25, 3848.92it/s]prepro_backdoor:  77%|███████▋  | 334403/432000 [01:31<00:24, 3983.05it/s]prepro_backdoor:  78%|███████▊  | 334873/432000 [01:31<00:23, 4179.97it/s]prepro_backdoor:  78%|███████▊  | 335472/432000 [01:31<00:20, 4668.01it/s]prepro_backdoor:  78%|███████▊  | 335950/432000 [01:31<00:23, 4165.33it/s]prepro_backdoor:  78%|███████▊  | 336456/432000 [01:31<00:21, 4380.15it/s]prepro_backdoor:  78%|███████▊  | 336909/432000 [01:32<00:42, 2230.15it/s]prepro_backdoor:  78%|███████▊  | 337399/432000 [01:32<00:35, 2668.19it/s]prepro_backdoor:  78%|███████▊  | 337912/432000 [01:32<00:30, 3134.19it/s]prepro_backdoor:  78%|███████▊  | 338337/432000 [01:32<00:28, 3294.29it/s]prepro_backdoor:  78%|███████▊  | 338862/432000 [01:32<00:24, 3730.56it/s]prepro_backdoor:  79%|███████▊  | 339311/432000 [01:32<00:23, 3909.12it/s]prepro_backdoor:  79%|███████▊  | 339755/432000 [01:32<00:23, 3963.74it/s]prepro_backdoor:  79%|███████▊  | 340189/432000 [01:32<00:23, 3959.18it/s]prepro_backdoor:  79%|███████▉  | 340639/432000 [01:33<00:22, 4105.60it/s]prepro_backdoor:  79%|███████▉  | 341070/432000 [01:33<00:22, 4112.76it/s]prepro_backdoor:  79%|███████▉  | 341496/432000 [01:33<00:25, 3571.11it/s]prepro_backdoor:  79%|███████▉  | 342110/432000 [01:33<00:21, 4218.64it/s]prepro_backdoor:  79%|███████▉  | 342602/432000 [01:33<00:20, 4387.05it/s]prepro_backdoor:  79%|███████▉  | 343093/432000 [01:33<00:19, 4506.34it/s]prepro_backdoor:  80%|███████▉  | 343558/432000 [01:33<00:19, 4531.59it/s]prepro_backdoor:  80%|███████▉  | 344044/432000 [01:33<00:19, 4599.75it/s]prepro_backdoor:  80%|███████▉  | 344548/432000 [01:33<00:18, 4715.27it/s]prepro_backdoor:  80%|███████▉  | 345026/432000 [01:34<00:18, 4672.64it/s]prepro_backdoor:  80%|███████▉  | 345541/432000 [01:34<00:18, 4796.93it/s]prepro_backdoor:  80%|████████  | 346024/432000 [01:34<00:18, 4765.56it/s]prepro_backdoor:  80%|████████  | 346503/432000 [01:34<00:24, 3480.06it/s]prepro_backdoor:  80%|████████  | 346975/432000 [01:34<00:22, 3748.67it/s]prepro_backdoor:  80%|████████  | 347393/432000 [01:34<00:22, 3781.12it/s]prepro_backdoor:  81%|████████  | 347850/432000 [01:34<00:21, 3979.29it/s]prepro_backdoor:  81%|████████  | 348272/432000 [01:34<00:21, 3948.66it/s]prepro_backdoor:  81%|████████  | 348684/432000 [01:35<00:21, 3891.93it/s]prepro_backdoor:  81%|████████  | 349153/432000 [01:35<00:20, 4094.25it/s]prepro_backdoor:  81%|████████  | 349573/432000 [01:35<00:20, 4068.80it/s]prepro_backdoor:  81%|████████  | 350079/432000 [01:35<00:18, 4335.65it/s]prepro_backdoor:  81%|████████  | 350519/432000 [01:35<00:24, 3324.79it/s]prepro_backdoor:  81%|████████  | 350949/432000 [01:35<00:22, 3546.07it/s]prepro_backdoor:  81%|████████▏ | 351364/432000 [01:35<00:21, 3696.02it/s]prepro_backdoor:  81%|████████▏ | 351760/432000 [01:35<00:21, 3707.47it/s]prepro_backdoor:  82%|████████▏ | 352335/432000 [01:35<00:18, 4241.97it/s]prepro_backdoor:  82%|████████▏ | 352788/432000 [01:36<00:18, 4315.42it/s]prepro_backdoor:  82%|████████▏ | 353233/432000 [01:36<00:18, 4325.98it/s]prepro_backdoor:  82%|████████▏ | 353675/432000 [01:36<00:18, 4328.29it/s]prepro_backdoor:  82%|████████▏ | 354248/432000 [01:36<00:16, 4706.40it/s]prepro_backdoor:  82%|████████▏ | 354764/432000 [01:36<00:16, 4815.71it/s]prepro_backdoor:  82%|████████▏ | 355250/432000 [01:36<00:20, 3712.17it/s]prepro_backdoor:  82%|████████▏ | 355662/432000 [01:36<00:20, 3650.42it/s]prepro_backdoor:  82%|████████▏ | 356055/432000 [01:36<00:21, 3544.09it/s]prepro_backdoor:  83%|████████▎ | 356513/432000 [01:37<00:19, 3794.54it/s]prepro_backdoor:  83%|████████▎ | 356935/432000 [01:37<00:26, 2875.24it/s]prepro_backdoor:  83%|████████▎ | 357408/432000 [01:37<00:22, 3265.90it/s]prepro_backdoor:  83%|████████▎ | 357780/432000 [01:37<00:22, 3311.19it/s]prepro_backdoor:  83%|████████▎ | 358289/432000 [01:37<00:19, 3752.02it/s]prepro_backdoor:  83%|████████▎ | 358775/432000 [01:37<00:18, 4026.20it/s]prepro_backdoor:  83%|████████▎ | 359204/432000 [01:37<00:18, 3965.14it/s]prepro_backdoor:  83%|████████▎ | 359619/432000 [01:37<00:18, 3976.36it/s]prepro_backdoor:  83%|████████▎ | 360030/432000 [01:37<00:19, 3719.95it/s]prepro_backdoor:  83%|████████▎ | 360435/432000 [01:38<00:18, 3788.65it/s]prepro_backdoor:  84%|████████▎ | 360997/432000 [01:38<00:16, 4295.73it/s]prepro_backdoor:  84%|████████▎ | 361444/432000 [01:38<00:16, 4327.23it/s]prepro_backdoor:  84%|████████▍ | 361884/432000 [01:38<00:20, 3422.16it/s]prepro_backdoor:  84%|████████▍ | 362268/432000 [01:38<00:19, 3511.97it/s]prepro_backdoor:  84%|████████▍ | 362678/432000 [01:38<00:18, 3652.95it/s]prepro_backdoor:  84%|████████▍ | 363109/432000 [01:38<00:18, 3823.39it/s]prepro_backdoor:  84%|████████▍ | 363615/432000 [01:38<00:16, 4147.75it/s]prepro_backdoor:  84%|████████▍ | 364044/432000 [01:39<00:16, 4072.31it/s]prepro_backdoor:  84%|████████▍ | 364578/432000 [01:39<00:15, 4403.72it/s]prepro_backdoor:  84%|████████▍ | 365027/432000 [01:39<00:15, 4223.14it/s]prepro_backdoor:  85%|████████▍ | 365517/432000 [01:39<00:15, 4412.47it/s]prepro_backdoor:  85%|████████▍ | 365965/432000 [01:39<00:15, 4357.96it/s]prepro_backdoor:  85%|████████▍ | 366406/432000 [01:39<00:18, 3636.80it/s]prepro_backdoor:  85%|████████▍ | 366931/432000 [01:39<00:16, 4046.51it/s]prepro_backdoor:  85%|████████▌ | 367359/432000 [01:39<00:16, 4020.65it/s]prepro_backdoor:  85%|████████▌ | 367777/432000 [01:39<00:17, 3583.73it/s]prepro_backdoor:  85%|████████▌ | 368259/432000 [01:40<00:16, 3888.01it/s]prepro_backdoor:  85%|████████▌ | 368721/432000 [01:40<00:15, 4064.96it/s]prepro_backdoor:  85%|████████▌ | 369158/432000 [01:40<00:15, 4127.66it/s]prepro_backdoor:  86%|████████▌ | 369604/432000 [01:40<00:14, 4215.86it/s]prepro_backdoor:  86%|████████▌ | 370137/432000 [01:40<00:13, 4505.72it/s]prepro_backdoor:  86%|████████▌ | 370595/432000 [01:40<00:13, 4508.32it/s]prepro_backdoor:  86%|████████▌ | 371051/432000 [01:40<00:13, 4425.86it/s]prepro_backdoor:  86%|████████▌ | 371518/432000 [01:40<00:21, 2821.74it/s]prepro_backdoor:  86%|████████▌ | 372122/432000 [01:41<00:17, 3481.74it/s]prepro_backdoor:  86%|████████▌ | 372554/432000 [01:41<00:16, 3666.93it/s]prepro_backdoor:  86%|████████▋ | 373022/432000 [01:41<00:15, 3914.71it/s]prepro_backdoor:  86%|████████▋ | 373464/432000 [01:41<00:14, 4014.11it/s]prepro_backdoor:  87%|████████▋ | 373902/432000 [01:41<00:14, 4076.51it/s]prepro_backdoor:  87%|████████▋ | 374409/432000 [01:41<00:13, 4341.20it/s]prepro_backdoor:  87%|████████▋ | 374881/432000 [01:41<00:12, 4447.73it/s]prepro_backdoor:  87%|████████▋ | 375426/432000 [01:41<00:12, 4712.47it/s]prepro_backdoor:  87%|████████▋ | 375909/432000 [01:41<00:12, 4521.28it/s]prepro_backdoor:  87%|████████▋ | 376371/432000 [01:42<00:18, 2999.57it/s]prepro_backdoor:  87%|████████▋ | 376757/432000 [01:42<00:17, 3173.83it/s]prepro_backdoor:  87%|████████▋ | 377214/432000 [01:42<00:15, 3488.96it/s]prepro_backdoor:  87%|████████▋ | 377707/432000 [01:42<00:14, 3833.55it/s]prepro_backdoor:  88%|████████▊ | 378132/432000 [01:42<00:13, 3914.67it/s]prepro_backdoor:  88%|████████▊ | 378554/432000 [01:42<00:13, 3956.70it/s]prepro_backdoor:  88%|████████▊ | 378972/432000 [01:42<00:14, 3746.62it/s]prepro_backdoor:  88%|████████▊ | 379559/432000 [01:42<00:12, 4312.11it/s]prepro_backdoor:  88%|████████▊ | 380009/432000 [01:43<00:12, 4309.80it/s]prepro_backdoor:  88%|████████▊ | 380453/432000 [01:43<00:15, 3431.05it/s]prepro_backdoor:  88%|████████▊ | 380832/432000 [01:43<00:14, 3510.02it/s]prepro_backdoor:  88%|████████▊ | 381282/432000 [01:43<00:13, 3758.47it/s]prepro_backdoor:  88%|████████▊ | 381713/432000 [01:43<00:12, 3883.64it/s]prepro_backdoor:  88%|████████▊ | 382119/432000 [01:43<00:13, 3731.99it/s]prepro_backdoor:  89%|████████▊ | 382575/432000 [01:43<00:12, 3943.01it/s]prepro_backdoor:  89%|████████▊ | 382981/432000 [01:43<00:12, 3953.06it/s]prepro_backdoor:  89%|████████▊ | 383385/432000 [01:43<00:12, 3913.60it/s]prepro_backdoor:  89%|████████▉ | 383814/432000 [01:44<00:12, 4008.58it/s]prepro_backdoor:  89%|████████▉ | 384272/432000 [01:44<00:11, 4159.79it/s]prepro_backdoor:  89%|████████▉ | 384692/432000 [01:44<00:13, 3539.17it/s]prepro_backdoor:  89%|████████▉ | 385120/432000 [01:44<00:12, 3724.50it/s]prepro_backdoor:  89%|████████▉ | 385508/432000 [01:44<00:12, 3714.05it/s]prepro_backdoor:  89%|████████▉ | 385890/432000 [01:44<00:12, 3714.33it/s]prepro_backdoor:  89%|████████▉ | 386269/432000 [01:44<00:13, 3469.69it/s]prepro_backdoor:  90%|████████▉ | 386674/432000 [01:44<00:12, 3616.56it/s]prepro_backdoor:  90%|████████▉ | 387195/432000 [01:44<00:11, 4058.05it/s]prepro_backdoor:  90%|████████▉ | 387714/432000 [01:45<00:10, 4368.50it/s]prepro_backdoor:  90%|████████▉ | 388158/432000 [01:45<00:10, 4243.17it/s]prepro_backdoor:  90%|████████▉ | 388627/432000 [01:45<00:09, 4347.52it/s]prepro_backdoor:  90%|█████████ | 389066/432000 [01:45<00:12, 3338.95it/s]prepro_backdoor:  90%|█████████ | 389619/432000 [01:45<00:11, 3852.56it/s]prepro_backdoor:  90%|█████████ | 390043/432000 [01:45<00:10, 3871.37it/s]prepro_backdoor:  90%|█████████ | 390539/432000 [01:45<00:09, 4147.29it/s]prepro_backdoor:  91%|█████████ | 390981/432000 [01:45<00:09, 4199.38it/s]prepro_backdoor:  91%|█████████ | 391435/432000 [01:45<00:09, 4287.14it/s]prepro_backdoor:  91%|█████████ | 391945/432000 [01:46<00:08, 4514.89it/s]prepro_backdoor:  91%|█████████ | 392427/432000 [01:46<00:08, 4601.30it/s]prepro_backdoor:  91%|█████████ | 392895/432000 [01:46<00:08, 4469.83it/s]prepro_backdoor:  91%|█████████ | 393361/432000 [01:46<00:08, 4513.17it/s]prepro_backdoor:  91%|█████████ | 393817/432000 [01:46<00:09, 4215.86it/s]prepro_backdoor:  91%|█████████▏| 394245/432000 [01:46<00:12, 3020.22it/s]prepro_backdoor:  91%|█████████▏| 394598/432000 [01:46<00:11, 3125.39it/s]prepro_backdoor:  91%|█████████▏| 395017/432000 [01:46<00:10, 3376.17it/s]prepro_backdoor:  92%|█████████▏| 395481/432000 [01:47<00:09, 3682.17it/s]prepro_backdoor:  92%|█████████▏| 395878/432000 [01:47<00:15, 2304.75it/s]prepro_backdoor:  92%|█████████▏| 396392/432000 [01:47<00:12, 2833.42it/s]prepro_backdoor:  92%|█████████▏| 396882/432000 [01:47<00:10, 3269.59it/s]prepro_backdoor:  92%|█████████▏| 397441/432000 [01:47<00:09, 3808.43it/s]prepro_backdoor:  92%|█████████▏| 397894/432000 [01:47<00:08, 3975.77it/s]prepro_backdoor:  92%|█████████▏| 398345/432000 [01:47<00:08, 4073.51it/s]prepro_backdoor:  92%|█████████▏| 398791/432000 [01:48<00:08, 4091.47it/s]prepro_backdoor:  92%|█████████▏| 399227/432000 [01:48<00:08, 3956.16it/s]prepro_backdoor:  93%|█████████▎| 399677/432000 [01:48<00:07, 4085.77it/s]prepro_backdoor:  93%|█████████▎| 400118/432000 [01:48<00:07, 4158.42it/s]prepro_backdoor:  93%|█████████▎| 400545/432000 [01:48<00:09, 3347.02it/s]prepro_backdoor:  93%|█████████▎| 401034/432000 [01:48<00:08, 3717.69it/s]prepro_backdoor:  93%|█████████▎| 401491/432000 [01:48<00:07, 3934.53it/s]prepro_backdoor:  93%|█████████▎| 402029/432000 [01:48<00:06, 4299.47it/s]prepro_backdoor:  93%|█████████▎| 402480/432000 [01:48<00:06, 4247.33it/s]prepro_backdoor:  93%|█████████▎| 402920/432000 [01:49<00:07, 4151.96it/s]prepro_backdoor:  93%|█████████▎| 403378/432000 [01:49<00:06, 4265.17it/s]prepro_backdoor:  93%|█████████▎| 403875/432000 [01:49<00:06, 4454.99it/s]prepro_backdoor:  94%|█████████▎| 404343/432000 [01:49<00:06, 4515.57it/s]prepro_backdoor:  94%|█████████▎| 404894/432000 [01:49<00:05, 4802.86it/s]prepro_backdoor:  94%|█████████▍| 405379/432000 [01:49<00:07, 3374.21it/s]prepro_backdoor:  94%|█████████▍| 405848/432000 [01:49<00:07, 3662.48it/s]prepro_backdoor:  94%|█████████▍| 406276/432000 [01:49<00:06, 3807.03it/s]prepro_backdoor:  94%|█████████▍| 406770/432000 [01:50<00:06, 4074.52it/s]prepro_backdoor:  94%|█████████▍| 407209/432000 [01:50<00:06, 4093.35it/s]prepro_backdoor:  94%|█████████▍| 407671/432000 [01:50<00:05, 4224.95it/s]prepro_backdoor:  94%|█████████▍| 408152/432000 [01:50<00:05, 4376.33it/s]prepro_backdoor:  95%|█████████▍| 408705/432000 [01:50<00:04, 4704.74it/s]prepro_backdoor:  95%|█████████▍| 409232/432000 [01:50<00:04, 4839.17it/s]prepro_backdoor:  95%|█████████▍| 409724/432000 [01:50<00:05, 3804.21it/s]prepro_backdoor:  95%|█████████▍| 410144/432000 [01:50<00:05, 3825.14it/s]prepro_backdoor:  95%|█████████▌| 410555/432000 [01:50<00:05, 3650.47it/s]prepro_backdoor:  95%|█████████▌| 410940/432000 [01:51<00:05, 3664.03it/s]prepro_backdoor:  95%|█████████▌| 411389/432000 [01:51<00:05, 3869.60it/s]prepro_backdoor:  95%|█████████▌| 411925/432000 [01:51<00:04, 4256.03it/s]prepro_backdoor:  95%|█████████▌| 412375/432000 [01:51<00:04, 4323.34it/s]prepro_backdoor:  96%|█████████▌| 412816/432000 [01:51<00:04, 4100.33it/s]prepro_backdoor:  96%|█████████▌| 413234/432000 [01:51<00:04, 4084.14it/s]prepro_backdoor:  96%|█████████▌| 413648/432000 [01:51<00:04, 4032.78it/s]prepro_backdoor:  96%|█████████▌| 414218/432000 [01:51<00:03, 4498.24it/s]prepro_backdoor:  96%|█████████▌| 414673/432000 [01:51<00:03, 4467.91it/s]prepro_backdoor:  96%|█████████▌| 415124/432000 [01:52<00:04, 3526.00it/s]prepro_backdoor:  96%|█████████▌| 415510/432000 [01:52<00:07, 2348.02it/s]prepro_backdoor:  96%|█████████▋| 415817/432000 [01:52<00:06, 2479.81it/s]prepro_backdoor:  96%|█████████▋| 416313/432000 [01:52<00:05, 2998.51it/s]prepro_backdoor:  96%|█████████▋| 416700/432000 [01:52<00:04, 3185.28it/s]prepro_backdoor:  97%|█████████▋| 417074/432000 [01:52<00:04, 3308.78it/s]prepro_backdoor:  97%|█████████▋| 417442/432000 [01:52<00:04, 3337.15it/s]prepro_backdoor:  97%|█████████▋| 417857/432000 [01:53<00:03, 3548.44it/s]prepro_backdoor:  97%|█████████▋| 418235/432000 [01:53<00:03, 3610.94it/s]prepro_backdoor:  97%|█████████▋| 418661/432000 [01:53<00:03, 3787.34it/s]prepro_backdoor:  97%|█████████▋| 419054/432000 [01:53<00:03, 3813.08it/s]prepro_backdoor:  97%|█████████▋| 419519/432000 [01:53<00:03, 4045.29it/s]prepro_backdoor:  97%|█████████▋| 420013/432000 [01:53<00:02, 4288.26it/s]prepro_backdoor:  97%|█████████▋| 420447/432000 [01:53<00:03, 3130.35it/s]prepro_backdoor:  97%|█████████▋| 420826/432000 [01:53<00:03, 3273.47it/s]prepro_backdoor:  98%|█████████▊| 421275/432000 [01:53<00:02, 3576.60it/s]prepro_backdoor:  98%|█████████▊| 421665/432000 [01:54<00:02, 3537.85it/s]prepro_backdoor:  98%|█████████▊| 422086/432000 [01:54<00:02, 3704.22it/s]prepro_backdoor:  98%|█████████▊| 422523/432000 [01:54<00:02, 3872.52it/s]prepro_backdoor:  98%|█████████▊| 423031/432000 [01:54<00:02, 4201.43it/s]prepro_backdoor:  98%|█████████▊| 423501/432000 [01:54<00:01, 4326.43it/s]prepro_backdoor:  98%|█████████▊| 423973/432000 [01:54<00:01, 4426.06it/s]prepro_backdoor:  98%|█████████▊| 424422/432000 [01:54<00:02, 3224.10it/s]prepro_backdoor:  98%|█████████▊| 424795/432000 [01:54<00:02, 3299.94it/s]prepro_backdoor:  98%|█████████▊| 425247/432000 [01:55<00:01, 3584.90it/s]prepro_backdoor:  99%|█████████▊| 425781/432000 [01:55<00:01, 4017.94it/s]prepro_backdoor:  99%|█████████▊| 426211/432000 [01:55<00:01, 4085.28it/s]prepro_backdoor:  99%|█████████▉| 426643/432000 [01:55<00:01, 4134.99it/s]prepro_backdoor:  99%|█████████▉| 427072/432000 [01:55<00:01, 4083.32it/s]prepro_backdoor:  99%|█████████▉| 427491/432000 [01:55<00:01, 4066.88it/s]prepro_backdoor:  99%|█████████▉| 427905/432000 [01:55<00:01, 3998.02it/s]prepro_backdoor:  99%|█████████▉| 428396/432000 [01:55<00:00, 4252.86it/s]prepro_backdoor:  99%|█████████▉| 428979/432000 [01:55<00:00, 4704.79it/s]prepro_backdoor:  99%|█████████▉| 429459/432000 [01:56<00:00, 2889.35it/s]prepro_backdoor:  99%|█████████▉| 429837/432000 [01:56<00:00, 3004.51it/s]prepro_backdoor: 100%|█████████▉| 430289/432000 [01:56<00:00, 3335.94it/s]prepro_backdoor: 100%|█████████▉| 430751/432000 [01:56<00:00, 3632.56it/s]prepro_backdoor: 100%|█████████▉| 431206/432000 [01:56<00:00, 3864.41it/s]prepro_backdoor: 100%|█████████▉| 431645/432000 [01:56<00:00, 4001.59it/s]prepro_backdoor: 100%|██████████| 432000/432000 [01:56<00:00, 3699.74it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:7000.0,real pratio:0.8333333333333334
2024-12-23:01:44:56 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:7000.0,real pratio:0.8333333333333334
INFO:root:save file format is .png
2024-12-23:01:44:56 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/8400 [00:00<?, ?it/s]prepro_backdoor:  17%|█▋        | 1430/8400 [00:00<00:00, 14113.33it/s]prepro_backdoor:  34%|███▍      | 2842/8400 [00:03<00:08, 649.70it/s]  prepro_backdoor:  41%|████      | 3446/8400 [00:05<00:09, 507.28it/s]prepro_backdoor:  45%|████▌     | 3789/8400 [00:06<00:09, 491.46it/s]prepro_backdoor:  48%|████▊     | 4014/8400 [00:07<00:09, 463.90it/s]prepro_backdoor:  50%|████▉     | 4170/8400 [00:07<00:09, 458.61it/s]prepro_backdoor:  51%|█████     | 4288/8400 [00:07<00:09, 437.32it/s]prepro_backdoor:  52%|█████▏    | 4378/8400 [00:08<00:09, 435.43it/s]prepro_backdoor:  53%|█████▎    | 4453/8400 [00:08<00:09, 433.69it/s]prepro_backdoor:  54%|█████▍    | 4518/8400 [00:08<00:08, 432.71it/s]prepro_backdoor:  54%|█████▍    | 4576/8400 [00:08<00:08, 433.09it/s]prepro_backdoor:  55%|█████▌    | 4630/8400 [00:08<00:08, 432.02it/s]prepro_backdoor:  56%|█████▌    | 4681/8400 [00:08<00:09, 379.92it/s]prepro_backdoor:  56%|█████▌    | 4724/8400 [00:08<00:09, 385.19it/s]prepro_backdoor:  57%|█████▋    | 4768/8400 [00:09<00:09, 394.77it/s]prepro_backdoor:  57%|█████▋    | 4812/8400 [00:09<00:08, 402.89it/s]prepro_backdoor:  58%|█████▊    | 4855/8400 [00:09<00:08, 408.03it/s]prepro_backdoor:  58%|█████▊    | 4899/8400 [00:09<00:08, 413.63it/s]prepro_backdoor:  59%|█████▉    | 4943/8400 [00:09<00:08, 419.40it/s]prepro_backdoor:  59%|█████▉    | 4987/8400 [00:09<00:08, 422.71it/s]prepro_backdoor:  60%|█████▉    | 5031/8400 [00:09<00:07, 422.43it/s]prepro_backdoor:  60%|██████    | 5074/8400 [00:09<00:07, 424.14it/s]prepro_backdoor:  61%|██████    | 5117/8400 [00:09<00:09, 334.80it/s]prepro_backdoor:  61%|██████▏   | 5159/8400 [00:10<00:09, 355.03it/s]prepro_backdoor:  62%|██████▏   | 5201/8400 [00:10<00:08, 368.51it/s]prepro_backdoor:  62%|██████▏   | 5244/8400 [00:10<00:08, 382.71it/s]prepro_backdoor:  63%|██████▎   | 5284/8400 [00:10<00:11, 263.86it/s]prepro_backdoor:  63%|██████▎   | 5328/8400 [00:10<00:10, 299.90it/s]prepro_backdoor:  64%|██████▍   | 5370/8400 [00:10<00:09, 327.41it/s]prepro_backdoor:  64%|██████▍   | 5413/8400 [00:10<00:08, 351.01it/s]prepro_backdoor:  65%|██████▍   | 5456/8400 [00:10<00:07, 370.35it/s]prepro_backdoor:  65%|██████▌   | 5499/8400 [00:11<00:07, 386.10it/s]prepro_backdoor:  66%|██████▌   | 5542/8400 [00:11<00:07, 396.26it/s]prepro_backdoor:  66%|██████▋   | 5585/8400 [00:11<00:06, 404.78it/s]prepro_backdoor:  67%|██████▋   | 5627/8400 [00:11<00:07, 351.21it/s]prepro_backdoor:  68%|██████▊   | 5671/8400 [00:11<00:07, 373.59it/s]prepro_backdoor:  68%|██████▊   | 5713/8400 [00:11<00:06, 385.49it/s]prepro_backdoor:  69%|██████▊   | 5760/8400 [00:11<00:06, 408.42it/s]prepro_backdoor:  69%|██████▉   | 5802/8400 [00:12<00:10, 257.60it/s]prepro_backdoor:  70%|██████▉   | 5845/8400 [00:12<00:08, 292.21it/s]prepro_backdoor:  70%|███████   | 5889/8400 [00:12<00:07, 325.37it/s]prepro_backdoor:  71%|███████   | 5935/8400 [00:12<00:06, 356.60it/s]prepro_backdoor:  71%|███████   | 5980/8400 [00:12<00:06, 379.28it/s]prepro_backdoor:  72%|███████▏  | 6023/8400 [00:12<00:06, 392.40it/s]prepro_backdoor:  72%|███████▏  | 6066/8400 [00:12<00:05, 401.99it/s]prepro_backdoor:  73%|███████▎  | 6110/8400 [00:12<00:05, 410.73it/s]prepro_backdoor:  73%|███████▎  | 6153/8400 [00:12<00:05, 416.11it/s]prepro_backdoor:  74%|███████▍  | 6196/8400 [00:12<00:05, 414.07it/s]prepro_backdoor:  74%|███████▍  | 6239/8400 [00:13<00:06, 318.79it/s]prepro_backdoor:  75%|███████▍  | 6284/8400 [00:13<00:06, 348.54it/s]prepro_backdoor:  75%|███████▌  | 6328/8400 [00:13<00:05, 371.21it/s]prepro_backdoor:  76%|███████▌  | 6373/8400 [00:13<00:05, 391.62it/s]prepro_backdoor:  76%|███████▋  | 6416/8400 [00:13<00:04, 401.34it/s]prepro_backdoor:  77%|███████▋  | 6460/8400 [00:13<00:04, 411.82it/s]prepro_backdoor:  77%|███████▋  | 6504/8400 [00:13<00:04, 417.96it/s]prepro_backdoor:  78%|███████▊  | 6549/8400 [00:13<00:04, 426.28it/s]prepro_backdoor:  78%|███████▊  | 6593/8400 [00:13<00:04, 426.96it/s]prepro_backdoor:  79%|███████▉  | 6637/8400 [00:14<00:09, 184.81it/s]prepro_backdoor:  80%|███████▉  | 6681/8400 [00:14<00:07, 223.23it/s]prepro_backdoor:  80%|████████  | 6724/8400 [00:14<00:06, 259.55it/s]prepro_backdoor:  81%|████████  | 6767/8400 [00:14<00:05, 293.68it/s]prepro_backdoor:  81%|████████  | 6811/8400 [00:14<00:04, 324.82it/s]prepro_backdoor:  82%|████████▏ | 6854/8400 [00:15<00:04, 349.56it/s]prepro_backdoor:  82%|████████▏ | 6898/8400 [00:15<00:04, 371.74it/s]prepro_backdoor:  83%|████████▎ | 6941/8400 [00:15<00:03, 387.08it/s]prepro_backdoor:  83%|████████▎ | 6984/8400 [00:15<00:03, 397.33it/s]prepro_backdoor:  84%|████████▎ | 7027/8400 [00:15<00:06, 212.85it/s]prepro_backdoor:  84%|████████▍ | 7071/8400 [00:15<00:05, 251.44it/s]prepro_backdoor:  85%|████████▍ | 7114/8400 [00:15<00:04, 286.62it/s]prepro_backdoor:  85%|████████▌ | 7158/8400 [00:16<00:03, 319.77it/s]prepro_backdoor:  86%|████████▌ | 7202/8400 [00:16<00:03, 348.09it/s]prepro_backdoor:  86%|████████▋ | 7246/8400 [00:16<00:03, 369.37it/s]prepro_backdoor:  87%|████████▋ | 7291/8400 [00:16<00:02, 390.23it/s]prepro_backdoor:  87%|████████▋ | 7337/8400 [00:16<00:02, 408.12it/s]prepro_backdoor:  88%|████████▊ | 7383/8400 [00:16<00:02, 420.33it/s]prepro_backdoor:  88%|████████▊ | 7427/8400 [00:16<00:02, 328.08it/s]prepro_backdoor:  89%|████████▉ | 7470/8400 [00:16<00:02, 352.29it/s]prepro_backdoor:  89%|████████▉ | 7513/8400 [00:16<00:02, 370.32it/s]prepro_backdoor:  90%|████████▉ | 7557/8400 [00:17<00:02, 388.34it/s]prepro_backdoor:  90%|█████████ | 7600/8400 [00:17<00:02, 397.29it/s]prepro_backdoor:  91%|█████████ | 7643/8400 [00:17<00:01, 405.54it/s]prepro_backdoor:  91%|█████████▏| 7685/8400 [00:17<00:01, 409.45it/s]prepro_backdoor:  92%|█████████▏| 7728/8400 [00:17<00:01, 413.95it/s]prepro_backdoor:  93%|█████████▎| 7772/8400 [00:17<00:01, 418.81it/s]prepro_backdoor:  93%|█████████▎| 7816/8400 [00:17<00:01, 422.66it/s]prepro_backdoor:  94%|█████████▎| 7859/8400 [00:17<00:01, 321.05it/s]prepro_backdoor:  94%|█████████▍| 7902/8400 [00:17<00:01, 345.78it/s]prepro_backdoor:  95%|█████████▍| 7945/8400 [00:18<00:01, 366.03it/s]prepro_backdoor:  95%|█████████▌| 7987/8400 [00:18<00:01, 379.34it/s]prepro_backdoor:  96%|█████████▌| 8031/8400 [00:18<00:00, 395.68it/s]prepro_backdoor:  96%|█████████▌| 8074/8400 [00:18<00:00, 404.80it/s]prepro_backdoor:  97%|█████████▋| 8118/8400 [00:18<00:00, 414.27it/s]prepro_backdoor:  97%|█████████▋| 8161/8400 [00:18<00:00, 418.74it/s]prepro_backdoor:  98%|█████████▊| 8204/8400 [00:18<00:00, 419.50it/s]prepro_backdoor:  98%|█████████▊| 8247/8400 [00:18<00:00, 421.68it/s]prepro_backdoor:  99%|█████████▊| 8291/8400 [00:18<00:00, 425.80it/s]prepro_backdoor:  99%|█████████▉| 8334/8400 [00:19<00:00, 321.17it/s]prepro_backdoor: 100%|█████████▉| 8378/8400 [00:19<00:00, 349.49it/s]prepro_backdoor: 100%|██████████| 8400/8400 [00:19<00:00, 436.31it/s]
INFO:root:stage2 start
2024-12-23:01:45:15 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2024-12-23:01:45:15 [INFO    ] [trainer_cls.py:977] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2024-12-23:01:45:16 [INFO    ] [trainer_cls.py:1035] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 326.7303693294525 s
2024-12-23:01:50:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 326.7303693294525 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.16690476190476192,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
2024-12-23:01:50:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.16690476190476192,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 329.02483654022217 s
2024-12-23:01:56:18 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 329.02483654022217 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.1680952380952381,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
2024-12-23:01:56:25 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.1680952380952381,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 321.6961188316345 s
2024-12-23:02:01:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 321.6961188316345 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.2608333333333333,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
2024-12-23:02:01:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.2608333333333333,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 323.53090596199036 s
2024-12-23:02:07:17 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 323.53090596199036 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.35083333333333333,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
2024-12-23:02:07:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.35083333333333333,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 322.0457980632782 s
2024-12-23:02:12:45 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 322.0457980632782 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.616547619047619,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
2024-12-23:02:12:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.616547619047619,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 321.52670550346375 s
2024-12-23:02:18:14 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 321.52670550346375 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.6558333333333334,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
2024-12-23:02:18:20 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.6558333333333334,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 324.4252927303314 s
2024-12-23:02:23:45 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 324.4252927303314 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.6802380952380952,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
2024-12-23:02:23:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.6802380952380952,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 320.3717267513275 s
2024-12-23:02:29:12 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 320.3717267513275 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.7554761904761905,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
2024-12-23:02:29:18 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.7554761904761905,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 323.71170020103455 s
2024-12-23:02:34:42 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 323.71170020103455 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.789047619047619,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
2024-12-23:02:34:48 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.789047619047619,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 322.7306697368622 s
2024-12-23:02:40:11 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 322.7306697368622 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.7760714285714285,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
2024-12-23:02:40:17 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.7760714285714285,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 321.9650218486786 s
2024-12-23:02:45:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 321.9650218486786 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.7872619047619047,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
2024-12-23:02:45:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.7872619047619047,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 320.72801995277405 s
2024-12-23:02:51:07 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 320.72801995277405 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.7878571428571428,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
2024-12-23:02:51:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.7878571428571428,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.5277805328369 s
2024-12-23:02:56:32 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 317.5277805328369 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.7948809523809524,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
2024-12-23:02:56:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.7948809523809524,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.5140676498413 s
2024-12-23:03:01:53 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.5140676498413 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.8013095238095238,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
2024-12-23:03:01:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.8013095238095238,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.77086329460144 s
2024-12-23:03:07:16 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.77086329460144 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.7942857142857143,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
2024-12-23:03:07:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.7942857142857143,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.770384311676 s
2024-12-23:03:12:37 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.770384311676 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.8001190476190476,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
2024-12-23:03:12:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.8001190476190476,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.84211468696594 s
2024-12-23:03:17:59 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.84211468696594 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.7911904761904762,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
2024-12-23:03:18:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.7911904761904762,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7436361312866 s
2024-12-23:03:23:19 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.7436361312866 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.8023809523809524,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
2024-12-23:03:23:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.8023809523809524,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.91036581993103 s
2024-12-23:03:28:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.91036581993103 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.7941666666666667,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
2024-12-23:03:28:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.7941666666666667,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.32638359069824 s
2024-12-23:03:34:01 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.32638359069824 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.7945238095238095,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
2024-12-23:03:34:06 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.7945238095238095,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.85323214530945 s
2024-12-23:03:39:24 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.85323214530945 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.8279761904761904,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
2024-12-23:03:39:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.8279761904761904,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.80285000801086 s
2024-12-23:03:44:44 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.80285000801086 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.8147619047619048,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
2024-12-23:03:44:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.8147619047619048,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.07749795913696 s
2024-12-23:03:50:04 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.07749795913696 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.8101190476190476,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
2024-12-23:03:50:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.8101190476190476,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.3786189556122 s
2024-12-23:03:55:25 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.3786189556122 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.8219047619047619,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
2024-12-23:03:55:31 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.8219047619047619,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.59097242355347 s
2024-12-23:04:00:45 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.59097242355347 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.8196428571428571,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
2024-12-23:04:00:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.8196428571428571,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.6644811630249 s
2024-12-23:04:06:06 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.6644811630249 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.8011904761904762,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
2024-12-23:04:06:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.8011904761904762,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.2834937572479 s
2024-12-23:04:11:26 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.2834937572479 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.8294047619047619,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
2024-12-23:04:11:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.8294047619047619,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.3394470214844 s
2024-12-23:04:16:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.3394470214844 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.8317857142857142,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
2024-12-23:04:16:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.8317857142857142,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.8724002838135 s
2024-12-23:04:22:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.8724002838135 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.8183333333333334,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
2024-12-23:04:22:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.8183333333333334,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.60785937309265 s
2024-12-23:04:27:30 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.60785937309265 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.8185714285714286,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
2024-12-23:04:27:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.8185714285714286,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.15014696121216 s
2024-12-23:04:32:51 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.15014696121216 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.8321428571428572,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
2024-12-23:04:32:57 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.8321428571428572,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.90982818603516 s
2024-12-23:04:38:14 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.90982818603516 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.8136904761904762,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
2024-12-23:04:38:20 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.8136904761904762,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.61935687065125 s
2024-12-23:04:43:36 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.61935687065125 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.7988095238095239,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
2024-12-23:04:43:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.7988095238095239,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.0167167186737 s
2024-12-23:04:48:58 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.0167167186737 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.8188095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
2024-12-23:04:49:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.8188095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.4722671508789 s
2024-12-23:04:54:21 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.4722671508789 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.8430952380952381,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
2024-12-23:04:54:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.8430952380952381,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.38976669311523 s
2024-12-23:04:59:45 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 317.38976669311523 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.8310714285714286,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
2024-12-23:04:59:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.8310714285714286,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.42752742767334 s
2024-12-23:05:05:07 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.42752742767334 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.8230952380952381,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
2024-12-23:05:05:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.8230952380952381,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.29248309135437 s
2024-12-23:05:10:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.29248309135437 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.8282142857142857,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
2024-12-23:05:10:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.8282142857142857,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.67322063446045 s
2024-12-23:05:15:50 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.67322063446045 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.8339285714285715,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
2024-12-23:05:15:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.8339285714285715,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.0751404762268 s
2024-12-23:05:21:13 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 317.0751404762268 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.838452380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
2024-12-23:05:21:20 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.838452380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 318.93049573898315 s
2024-12-23:05:26:39 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 318.93049573898315 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.8169047619047619,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
2024-12-23:05:26:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.8169047619047619,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 318.58569169044495 s
2024-12-23:05:32:04 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 318.58569169044495 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.815952380952381,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
2024-12-23:05:32:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.815952380952381,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.21219968795776 s
2024-12-23:05:37:30 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.21219968795776 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.8372619047619048,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
2024-12-23:05:37:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.8372619047619048,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.97862482070923 s
2024-12-23:05:42:56 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.97862482070923 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.8352380952380952,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
2024-12-23:05:43:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.8352380952380952,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.8034722805023 s
2024-12-23:05:48:21 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 317.8034722805023 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.8192857142857143,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
2024-12-23:05:48:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.8192857142857143,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.4855086803436 s
2024-12-23:05:53:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.4855086803436 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.8234523809523809,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
2024-12-23:05:53:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.8234523809523809,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 318.9448564052582 s
2024-12-23:05:59:13 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 318.9448564052582 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.8282142857142857,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
2024-12-23:05:59:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.8282142857142857,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.41696786880493 s
2024-12-23:06:04:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.41696786880493 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.815595238095238,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
2024-12-23:06:04:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.815595238095238,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.1079638004303 s
2024-12-23:06:10:05 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.1079638004303 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.8242857142857143,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
2024-12-23:06:10:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.8242857142857143,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.16661262512207 s
2024-12-23:06:15:31 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.16661262512207 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.8325,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
2024-12-23:06:15:37 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.8325,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 320.86647033691406 s
2024-12-23:06:20:59 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 320.86647033691406 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.8234523809523809,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
2024-12-23:06:21:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.8234523809523809,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 320.2841684818268 s
2024-12-23:06:26:25 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 320.2841684818268 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.8407142857142857,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
2024-12-23:06:26:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.8407142857142857,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.72281074523926 s
2024-12-23:06:31:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.72281074523926 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.8219047619047619,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
2024-12-23:06:31:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.8219047619047619,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.09171509742737 s
2024-12-23:06:37:07 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.09171509742737 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.8385714285714285,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
2024-12-23:06:37:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.8385714285714285,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.5010607242584 s
2024-12-23:06:42:27 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.5010607242584 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.8354761904761905,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
2024-12-23:06:42:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.8354761904761905,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.39467692375183 s
2024-12-23:06:47:48 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.39467692375183 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.8336904761904762,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
2024-12-23:06:47:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.8336904761904762,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.27950501441956 s
2024-12-23:06:53:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.27950501441956 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.8352380952380952,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
2024-12-23:06:53:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.8352380952380952,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.0469470024109 s
2024-12-23:06:58:31 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.0469470024109 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.8372619047619048,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
2024-12-23:06:58:37 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.8372619047619048,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.89008116722107 s
2024-12-23:07:03:51 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.89008116722107 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.8448809523809524,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
2024-12-23:07:03:57 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.8448809523809524,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.47069811820984 s
2024-12-23:07:09:12 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.47069811820984 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.8275,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
2024-12-23:07:09:18 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.8275,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.8812277317047 s
2024-12-23:07:14:32 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.8812277317047 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.8414285714285714,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
2024-12-23:07:14:38 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.8414285714285714,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.61164140701294 s
2024-12-23:07:19:53 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.61164140701294 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.8313095238095238,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
2024-12-23:07:19:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.8313095238095238,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.4010934829712 s
2024-12-23:07:25:15 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.4010934829712 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.8192857142857143,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
2024-12-23:07:25:21 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.8192857142857143,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.3471772670746 s
2024-12-23:07:30:38 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.3471772670746 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.8366666666666667,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
2024-12-23:07:30:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.8366666666666667,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.1316819190979 s
2024-12-23:07:36:00 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.1316819190979 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.8530952380952381,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
2024-12-23:07:36:06 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.8530952380952381,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.3926274776459 s
2024-12-23:07:41:23 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.3926274776459 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.8295238095238096,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
2024-12-23:07:41:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.8295238095238096,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.23817253112793 s
2024-12-23:07:46:44 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.23817253112793 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.8365476190476191,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
2024-12-23:07:46:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.8365476190476191,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.24307107925415 s
2024-12-23:07:52:06 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.24307107925415 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.8451190476190477,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
2024-12-23:07:52:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.8451190476190477,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.60131454467773 s
2024-12-23:07:57:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.60131454467773 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.8417857142857142,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
2024-12-23:07:57:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.8417857142857142,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.2145998477936 s
2024-12-23:08:02:50 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.2145998477936 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.8380952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
2024-12-23:08:02:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.8380952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.68243527412415 s
2024-12-23:08:08:13 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.68243527412415 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.820952380952381,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
2024-12-23:08:08:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.820952380952381,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.60932779312134 s
2024-12-23:08:13:34 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.60932779312134 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.8313095238095238,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
2024-12-23:08:13:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.8313095238095238,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.59374737739563 s
2024-12-23:08:18:55 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.59374737739563 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.8378571428571429,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
2024-12-23:08:19:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.8378571428571429,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.1820237636566 s
2024-12-23:08:24:17 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.1820237636566 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.8195238095238095,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
2024-12-23:08:24:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.8195238095238095,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.2319407463074 s
2024-12-23:08:29:37 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.2319407463074 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.8488095238095238,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
2024-12-23:08:29:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.8488095238095238,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.42543029785156 s
2024-12-23:08:34:58 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.42543029785156 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.8392857142857143,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
2024-12-23:08:35:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.8392857142857143,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.41640973091125 s
2024-12-23:08:40:16 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 312.41640973091125 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.8451190476190477,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
2024-12-23:08:40:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.8451190476190477,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.7174439430237 s
2024-12-23:08:45:38 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.7174439430237 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.8351190476190476,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
2024-12-23:08:45:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.8351190476190476,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.13501620292664 s
2024-12-23:08:50:57 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.13501620292664 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.8478571428571429,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
2024-12-23:08:51:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.8478571428571429,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.8455419540405 s
2024-12-23:08:56:17 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 313.8455419540405 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.8417857142857142,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
2024-12-23:08:56:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.8417857142857142,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.6178529262543 s
2024-12-23:09:01:38 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.6178529262543 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.8377380952380953,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
2024-12-23:09:01:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.8377380952380953,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.57270646095276 s
2024-12-23:09:07:01 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.57270646095276 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.8346428571428571,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
2024-12-23:09:07:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.8346428571428571,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.117378950119 s
2024-12-23:09:12:22 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 314.117378950119 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.84,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
2024-12-23:09:12:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.84,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.0888669490814 s
2024-12-23:09:17:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 315.0888669490814 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.8361904761904762,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
2024-12-23:09:17:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.8361904761904762,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 316.72869753837585 s
2024-12-23:09:23:06 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 316.72869753837585 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.8361904761904762,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
2024-12-23:09:23:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.8361904761904762,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 321.091677904129 s
2024-12-23:09:28:34 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 321.091677904129 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.839047619047619,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
2024-12-23:09:28:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.839047619047619,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 321.2645072937012 s
2024-12-23:09:34:02 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 321.2645072937012 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.8422619047619048,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
2024-12-23:09:34:09 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.8422619047619048,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 319.90817403793335 s
2024-12-23:09:39:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 319.90817403793335 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.839047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
2024-12-23:09:39:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.839047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 320.9433219432831 s
2024-12-23:09:44:57 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 320.9433219432831 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.843452380952381,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
2024-12-23:09:45:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.843452380952381,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 322.97219014167786 s
2024-12-23:09:50:26 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 322.97219014167786 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.8435714285714285,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
2024-12-23:09:50:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.8435714285714285,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 323.7727258205414 s
2024-12-23:09:55:57 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 323.7727258205414 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.8410714285714286,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
2024-12-23:09:56:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.8410714285714286,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 324.6990783214569 s
2024-12-23:10:01:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 324.6990783214569 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.8389285714285715,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
2024-12-23:10:01:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.8389285714285715,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 326.15363240242004 s
2024-12-23:10:07:02 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 326.15363240242004 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.8345238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
2024-12-23:10:07:08 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.8345238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 326.5520043373108 s
2024-12-23:10:12:35 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 326.5520043373108 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.8405952380952381,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
2024-12-23:10:12:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.8405952380952381,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 326.64903140068054 s
2024-12-23:10:18:09 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 326.64903140068054 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.840952380952381,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
2024-12-23:10:18:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.840952380952381,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 327.2494466304779 s
2024-12-23:10:23:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 327.2494466304779 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.8383333333333334,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
2024-12-23:10:23:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.8383333333333334,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 324.30800700187683 s
2024-12-23:10:29:14 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 324.30800700187683 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.8379761904761904,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
2024-12-23:10:29:20 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.8379761904761904,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 326.1546308994293 s
2024-12-23:10:34:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 326.1546308994293 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.8382142857142857,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
2024-12-23:10:34:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.8382142857142857,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 324.70074820518494 s
2024-12-23:10:40:18 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 324.70074820518494 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.8373809523809523,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
2024-12-23:10:40:25 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.8373809523809523,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 327.39372658729553 s
2024-12-23:10:45:53 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 327.39372658729553 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.8377380952380953,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
2024-12-23:10:45:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.8377380952380953,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2024-12-23:10:46:00 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/badnet_attack_efficientnet_ffpp_6classes_to_binary/attack_result.pt
INFO:root:Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_6classes_to_binary
2024-12-23:10:46:01 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_6classes_to_binary
