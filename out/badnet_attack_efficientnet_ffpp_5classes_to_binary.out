/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_5classes',
 'dataset_path': './data/ffpp_5classes',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 5,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_5classes_to_binary',
 'save_path': './record/badnet_attack_efficientnet_ffpp_5classes_to_binary',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_5classes',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_5classes_to_binary'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2024-12-23:01:32:43 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_5classes',
 'dataset_path': './data/ffpp_5classes',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 5,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_5classes_to_binary',
 'save_path': './record/badnet_attack_efficientnet_ffpp_5classes_to_binary',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_5classes',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_5classes_to_binary'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': '--git_hash baafb796919dbe5ea0faf001b1e1287def93a2ff',
 'last 3 log': 'commit baafb796919dbe5ea0faf001b1e1287def93a2ff\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Mon Dec 23 01:31:30 2024 +0900\n'
               '\n'
               '    new script: badnet attack with merged fake classes metric\n'
               '\n'
               'commit 48331a545ce9a2a8917a1b9499c3e6ee3cf128df\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Wed Dec 11 17:09:59 2024 +0900\n'
               '\n'
               '    modify the acc metric, merge all fake classes\n'
               '\n'
               'commit 2062d7da585a3aa9fb0b274b54f3ba96c79be680\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Tue Dec 10 18:51:15 2024 +0900\n'
               '\n'
               '    new result: badnet nad 4 classes',
 'status': 'On branch modify-metric\n'
           "Your branch is up to date with 'origin/modify-metric'.\n"
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\n'
           '\tout/badnet_attack_efficientnet_ffpp_2classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_3classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_4classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_5classes_to_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_6classes_to_binary.out\n'
           '\n'
           'nothing added to commit but untracked files present (use "git add" '
           'to track)'}
INFO:root:stage1 start
2024-12-23:01:32:45 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2024-12-23:01:32:45 [WARNING ] [dataset_and_transform_generate.py:359] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:36000.0,real pratio:0.1
2024-12-23:01:41:19 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:36000.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2024-12-23:01:41:20 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/360000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 15/360000 [00:00<1:58:05, 50.81it/s]prepro_backdoor:   0%|          | 427/360000 [00:00<04:21, 1376.27it/s]prepro_backdoor:   0%|          | 802/360000 [00:00<02:49, 2118.04it/s]prepro_backdoor:   0%|          | 1207/360000 [00:00<02:12, 2714.55it/s]prepro_backdoor:   0%|          | 1549/360000 [00:00<02:30, 2386.07it/s]prepro_backdoor:   1%|          | 1957/360000 [00:00<02:07, 2814.29it/s]prepro_backdoor:   1%|          | 2291/360000 [00:00<02:01, 2939.78it/s]prepro_backdoor:   1%|          | 2624/360000 [00:01<01:57, 3033.61it/s]prepro_backdoor:   1%|          | 3054/360000 [00:01<01:45, 3374.68it/s]prepro_backdoor:   1%|          | 3511/360000 [00:01<01:36, 3705.73it/s]prepro_backdoor:   1%|          | 3897/360000 [00:01<01:35, 3711.78it/s]prepro_backdoor:   1%|          | 4324/360000 [00:01<01:32, 3851.60it/s]prepro_backdoor:   1%|▏         | 4746/360000 [00:01<01:30, 3943.98it/s]prepro_backdoor:   1%|▏         | 5210/360000 [00:01<01:25, 4127.22it/s]prepro_backdoor:   2%|▏         | 5627/360000 [00:01<01:48, 3264.90it/s]prepro_backdoor:   2%|▏         | 5985/360000 [00:01<01:46, 3336.02it/s]prepro_backdoor:   2%|▏         | 6393/360000 [00:02<01:40, 3522.49it/s]prepro_backdoor:   2%|▏         | 6802/360000 [00:02<01:36, 3674.32it/s]prepro_backdoor:   2%|▏         | 7184/360000 [00:02<01:36, 3653.89it/s]prepro_backdoor:   2%|▏         | 7589/360000 [00:02<01:33, 3754.28it/s]prepro_backdoor:   2%|▏         | 8069/360000 [00:02<01:27, 4031.87it/s]prepro_backdoor:   2%|▏         | 8559/360000 [00:02<01:22, 4258.54it/s]prepro_backdoor:   3%|▎         | 9064/360000 [00:02<01:18, 4470.51it/s]prepro_backdoor:   3%|▎         | 9515/360000 [00:02<01:46, 3285.51it/s]prepro_backdoor:   3%|▎         | 9914/360000 [00:03<01:41, 3438.66it/s]prepro_backdoor:   3%|▎         | 10316/360000 [00:03<01:38, 3567.79it/s]prepro_backdoor:   3%|▎         | 10786/360000 [00:03<01:30, 3847.95it/s]prepro_backdoor:   3%|▎         | 11252/360000 [00:03<01:26, 4045.90it/s]prepro_backdoor:   3%|▎         | 11806/360000 [00:03<01:18, 4459.54it/s]prepro_backdoor:   3%|▎         | 12353/360000 [00:03<01:13, 4736.54it/s]prepro_backdoor:   4%|▎         | 12840/360000 [00:03<01:18, 4422.46it/s]prepro_backdoor:   4%|▎         | 13295/360000 [00:03<01:20, 4284.54it/s]prepro_backdoor:   4%|▍         | 13802/360000 [00:03<01:17, 4482.87it/s]prepro_backdoor:   4%|▍         | 14259/360000 [00:04<01:38, 3512.63it/s]prepro_backdoor:   4%|▍         | 14878/360000 [00:04<01:23, 4132.42it/s]prepro_backdoor:   4%|▍         | 15332/360000 [00:04<01:22, 4184.81it/s]prepro_backdoor:   4%|▍         | 15780/360000 [00:04<01:23, 4145.86it/s]prepro_backdoor:   5%|▍         | 16293/360000 [00:04<01:18, 4400.84it/s]prepro_backdoor:   5%|▍         | 16751/360000 [00:04<01:19, 4343.48it/s]prepro_backdoor:   5%|▍         | 17198/360000 [00:04<01:20, 4282.91it/s]prepro_backdoor:   5%|▍         | 17635/360000 [00:04<01:22, 4165.58it/s]prepro_backdoor:   5%|▌         | 18058/360000 [00:04<01:28, 3842.86it/s]prepro_backdoor:   5%|▌         | 18450/360000 [00:05<02:23, 2388.27it/s]prepro_backdoor:   5%|▌         | 18991/360000 [00:05<01:55, 2955.55it/s]prepro_backdoor:   5%|▌         | 19413/360000 [00:05<01:45, 3216.91it/s]prepro_backdoor:   6%|▌         | 19802/360000 [00:05<01:40, 3368.75it/s]prepro_backdoor:   6%|▌         | 20238/360000 [00:05<01:34, 3607.76it/s]prepro_backdoor:   6%|▌         | 20639/360000 [00:05<01:34, 3605.02it/s]prepro_backdoor:   6%|▌         | 21127/360000 [00:05<01:26, 3930.90it/s]prepro_backdoor:   6%|▌         | 21596/360000 [00:06<01:21, 4130.57it/s]prepro_backdoor:   6%|▌         | 22032/360000 [00:06<01:20, 4194.71it/s]prepro_backdoor:   6%|▌         | 22465/360000 [00:06<01:23, 4034.50it/s]prepro_backdoor:   6%|▋         | 22879/360000 [00:06<01:46, 3166.22it/s]prepro_backdoor:   6%|▋         | 23279/360000 [00:06<01:40, 3360.63it/s]prepro_backdoor:   7%|▋         | 23689/360000 [00:06<01:35, 3525.51it/s]prepro_backdoor:   7%|▋         | 24112/360000 [00:06<01:30, 3704.54it/s]prepro_backdoor:   7%|▋         | 24558/360000 [00:06<01:25, 3904.66it/s]prepro_backdoor:   7%|▋         | 24964/360000 [00:06<01:25, 3910.59it/s]prepro_backdoor:   7%|▋         | 25366/360000 [00:07<01:25, 3929.02it/s]prepro_backdoor:   7%|▋         | 25767/360000 [00:07<01:25, 3901.55it/s]prepro_backdoor:   7%|▋         | 26163/360000 [00:07<01:25, 3913.86it/s]prepro_backdoor:   7%|▋         | 26558/360000 [00:07<01:27, 3808.00it/s]prepro_backdoor:   7%|▋         | 26966/360000 [00:07<01:25, 3877.54it/s]prepro_backdoor:   8%|▊         | 27357/360000 [00:07<01:48, 3069.35it/s]prepro_backdoor:   8%|▊         | 27823/360000 [00:07<01:36, 3455.80it/s]prepro_backdoor:   8%|▊         | 28240/360000 [00:07<01:31, 3636.15it/s]prepro_backdoor:   8%|▊         | 28626/360000 [00:07<01:31, 3634.71it/s]prepro_backdoor:   8%|▊         | 29048/360000 [00:08<01:27, 3784.05it/s]prepro_backdoor:   8%|▊         | 29466/360000 [00:08<01:25, 3879.20it/s]prepro_backdoor:   8%|▊         | 29933/360000 [00:08<01:20, 4085.19it/s]prepro_backdoor:   8%|▊         | 30384/360000 [00:08<01:18, 4200.80it/s]prepro_backdoor:   9%|▊         | 30819/360000 [00:08<01:17, 4242.95it/s]prepro_backdoor:   9%|▊         | 31290/360000 [00:08<01:15, 4368.42it/s]prepro_backdoor:   9%|▉         | 31730/360000 [00:08<01:44, 3128.61it/s]prepro_backdoor:   9%|▉         | 32094/360000 [00:08<01:44, 3126.75it/s]prepro_backdoor:   9%|▉         | 32529/360000 [00:09<01:35, 3415.41it/s]prepro_backdoor:   9%|▉         | 32996/360000 [00:09<01:27, 3735.05it/s]prepro_backdoor:   9%|▉         | 33461/360000 [00:09<01:22, 3969.89it/s]prepro_backdoor:   9%|▉         | 33880/360000 [00:09<01:21, 4010.06it/s]prepro_backdoor:  10%|▉         | 34297/360000 [00:09<01:25, 3814.29it/s]prepro_backdoor:  10%|▉         | 34814/360000 [00:09<01:18, 4164.52it/s]prepro_backdoor:  10%|▉         | 35253/360000 [00:09<01:16, 4221.67it/s]prepro_backdoor:  10%|▉         | 35710/360000 [00:09<01:15, 4310.83it/s]prepro_backdoor:  10%|█         | 36153/360000 [00:09<01:14, 4338.05it/s]prepro_backdoor:  10%|█         | 36592/360000 [00:10<02:17, 2359.66it/s]prepro_backdoor:  10%|█         | 37063/360000 [00:10<01:55, 2787.49it/s]prepro_backdoor:  10%|█         | 37456/360000 [00:10<01:46, 3024.55it/s]prepro_backdoor:  11%|█         | 37868/360000 [00:10<01:38, 3268.30it/s]prepro_backdoor:  11%|█         | 38259/360000 [00:10<01:37, 3311.34it/s]prepro_backdoor:  11%|█         | 38635/360000 [00:10<01:34, 3417.68it/s]prepro_backdoor:  11%|█         | 39072/360000 [00:10<01:27, 3661.79it/s]prepro_backdoor:  11%|█         | 39550/360000 [00:10<01:20, 3957.16it/s]prepro_backdoor:  11%|█         | 39967/360000 [00:11<01:21, 3947.09it/s]prepro_backdoor:  11%|█         | 40398/360000 [00:11<01:18, 4048.63it/s]prepro_backdoor:  11%|█▏        | 40814/360000 [00:11<01:39, 3210.39it/s]prepro_backdoor:  11%|█▏        | 41222/360000 [00:11<01:33, 3411.89it/s]prepro_backdoor:  12%|█▏        | 41674/360000 [00:11<01:26, 3686.05it/s]prepro_backdoor:  12%|█▏        | 42164/360000 [00:11<01:19, 3996.30it/s]prepro_backdoor:  12%|█▏        | 42672/360000 [00:11<01:14, 4281.51it/s]prepro_backdoor:  12%|█▏        | 43117/360000 [00:11<01:13, 4325.78it/s]prepro_backdoor:  12%|█▏        | 43562/360000 [00:11<01:15, 4199.16it/s]prepro_backdoor:  12%|█▏        | 44018/360000 [00:12<01:13, 4286.76it/s]prepro_backdoor:  12%|█▏        | 44454/360000 [00:12<01:16, 4144.46it/s]prepro_backdoor:  12%|█▏        | 44874/360000 [00:12<01:17, 4040.26it/s]prepro_backdoor:  13%|█▎        | 45282/360000 [00:12<03:09, 1663.46it/s]prepro_backdoor:  13%|█▎        | 45615/360000 [00:12<02:45, 1894.60it/s]prepro_backdoor:  13%|█▎        | 45957/360000 [00:13<02:26, 2150.94it/s]prepro_backdoor:  13%|█▎        | 46403/360000 [00:13<02:01, 2586.50it/s]prepro_backdoor:  13%|█▎        | 46799/360000 [00:13<01:48, 2882.15it/s]prepro_backdoor:  13%|█▎        | 47167/360000 [00:13<01:43, 3031.51it/s]prepro_backdoor:  13%|█▎        | 47596/360000 [00:13<01:33, 3329.85it/s]prepro_backdoor:  13%|█▎        | 47976/360000 [00:13<01:34, 3302.00it/s]prepro_backdoor:  13%|█▎        | 48420/360000 [00:13<01:26, 3595.07it/s]prepro_backdoor:  14%|█▎        | 48867/360000 [00:13<01:21, 3824.83it/s]prepro_backdoor:  14%|█▎        | 49271/360000 [00:14<01:50, 2821.13it/s]prepro_backdoor:  14%|█▍        | 49745/360000 [00:14<01:35, 3241.27it/s]prepro_backdoor:  14%|█▍        | 50119/360000 [00:14<01:33, 3316.42it/s]prepro_backdoor:  14%|█▍        | 50585/360000 [00:14<01:25, 3638.63it/s]prepro_backdoor:  14%|█▍        | 50980/360000 [00:14<01:28, 3473.13it/s]prepro_backdoor:  14%|█▍        | 51397/360000 [00:14<01:24, 3635.26it/s]prepro_backdoor:  14%|█▍        | 51892/360000 [00:14<01:17, 3982.59it/s]prepro_backdoor:  15%|█▍        | 52307/360000 [00:14<01:17, 3976.57it/s]prepro_backdoor:  15%|█▍        | 52744/360000 [00:14<01:15, 4086.64it/s]prepro_backdoor:  15%|█▍        | 53172/360000 [00:15<02:00, 2550.10it/s]prepro_backdoor:  15%|█▍        | 53557/360000 [00:15<01:49, 2809.30it/s]prepro_backdoor:  15%|█▍        | 53957/360000 [00:15<01:39, 3066.61it/s]prepro_backdoor:  15%|█▌        | 54524/360000 [00:15<01:22, 3693.18it/s]prepro_backdoor:  15%|█▌        | 55089/360000 [00:15<01:13, 4174.15it/s]prepro_backdoor:  15%|█▌        | 55552/360000 [00:15<01:14, 4108.04it/s]prepro_backdoor:  16%|█▌        | 55995/360000 [00:15<01:12, 4184.10it/s]prepro_backdoor:  16%|█▌        | 56448/360000 [00:15<01:10, 4275.44it/s]prepro_backdoor:  16%|█▌        | 56917/360000 [00:16<01:09, 4372.73it/s]prepro_backdoor:  16%|█▌        | 57417/360000 [00:16<01:06, 4542.26it/s]prepro_backdoor:  16%|█▌        | 57881/360000 [00:16<01:36, 3126.72it/s]prepro_backdoor:  16%|█▌        | 58319/360000 [00:16<01:28, 3403.48it/s]prepro_backdoor:  16%|█▋        | 58716/360000 [00:16<01:40, 3007.31it/s]prepro_backdoor:  16%|█▋        | 59150/360000 [00:16<01:31, 3299.80it/s]prepro_backdoor:  17%|█▋        | 59521/360000 [00:16<01:28, 3382.85it/s]prepro_backdoor:  17%|█▋        | 59928/360000 [00:16<01:24, 3550.79it/s]prepro_backdoor:  17%|█▋        | 60308/360000 [00:17<01:23, 3571.13it/s]prepro_backdoor:  17%|█▋        | 60737/360000 [00:17<01:19, 3746.25it/s]prepro_backdoor:  17%|█▋        | 61125/360000 [00:17<01:22, 3631.16it/s]prepro_backdoor:  17%|█▋        | 61498/360000 [00:17<01:45, 2823.85it/s]prepro_backdoor:  17%|█▋        | 61899/360000 [00:17<01:36, 3098.52it/s]prepro_backdoor:  17%|█▋        | 62340/360000 [00:17<01:27, 3409.64it/s]prepro_backdoor:  17%|█▋        | 62717/360000 [00:17<01:24, 3500.45it/s]prepro_backdoor:  18%|█▊        | 63150/360000 [00:17<01:19, 3721.06it/s]prepro_backdoor:  18%|█▊        | 63606/360000 [00:18<01:15, 3939.85it/s]prepro_backdoor:  18%|█▊        | 64047/360000 [00:18<01:13, 4050.87it/s]prepro_backdoor:  18%|█▊        | 64544/360000 [00:18<01:08, 4309.74it/s]prepro_backdoor:  18%|█▊        | 65107/360000 [00:18<01:02, 4685.74it/s]prepro_backdoor:  18%|█▊        | 65582/360000 [00:18<01:03, 4640.76it/s]prepro_backdoor:  18%|█▊        | 66051/360000 [00:18<01:28, 3306.95it/s]prepro_backdoor:  18%|█▊        | 66523/360000 [00:18<01:21, 3614.37it/s]prepro_backdoor:  19%|█▊        | 66964/360000 [00:18<01:17, 3788.91it/s]prepro_backdoor:  19%|█▊        | 67381/360000 [00:18<01:16, 3827.75it/s]prepro_backdoor:  19%|█▉        | 67827/360000 [00:19<01:13, 3978.27it/s]prepro_backdoor:  19%|█▉        | 68246/360000 [00:19<01:14, 3919.11it/s]prepro_backdoor:  19%|█▉        | 68652/360000 [00:19<01:16, 3825.56it/s]prepro_backdoor:  19%|█▉        | 69045/360000 [00:19<01:16, 3825.02it/s]prepro_backdoor:  19%|█▉        | 69435/360000 [00:19<01:24, 3459.07it/s]prepro_backdoor:  19%|█▉        | 69792/360000 [00:19<01:43, 2808.93it/s]prepro_backdoor:  19%|█▉        | 70137/360000 [00:19<01:38, 2950.98it/s]prepro_backdoor:  20%|█▉        | 70545/360000 [00:19<01:29, 3229.13it/s]prepro_backdoor:  20%|█▉        | 70889/360000 [00:20<02:12, 2180.46it/s]prepro_backdoor:  20%|█▉        | 71331/360000 [00:20<01:50, 2615.93it/s]prepro_backdoor:  20%|█▉        | 71710/360000 [00:20<01:40, 2862.90it/s]prepro_backdoor:  20%|██        | 72048/360000 [00:20<01:42, 2796.73it/s]prepro_backdoor:  20%|██        | 72431/360000 [00:20<01:34, 3035.76it/s]prepro_backdoor:  20%|██        | 72890/360000 [00:20<01:23, 3432.24it/s]prepro_backdoor:  20%|██        | 73377/360000 [00:20<01:15, 3806.62it/s]prepro_backdoor:  20%|██        | 73782/360000 [00:20<01:16, 3730.85it/s]prepro_backdoor:  21%|██        | 74300/360000 [00:21<01:09, 4126.28it/s]prepro_backdoor:  21%|██        | 74728/360000 [00:21<01:08, 4159.68it/s]prepro_backdoor:  21%|██        | 75155/360000 [00:21<01:29, 3187.88it/s]prepro_backdoor:  21%|██        | 75663/360000 [00:21<01:18, 3621.51it/s]prepro_backdoor:  21%|██        | 76184/360000 [00:21<01:10, 4021.10it/s]prepro_backdoor:  21%|██▏       | 76622/360000 [00:21<01:14, 3800.77it/s]prepro_backdoor:  21%|██▏       | 77141/360000 [00:21<01:08, 4149.31it/s]prepro_backdoor:  22%|██▏       | 77630/360000 [00:21<01:05, 4325.77it/s]prepro_backdoor:  22%|██▏       | 78081/360000 [00:22<01:05, 4292.86it/s]prepro_backdoor:  22%|██▏       | 78523/360000 [00:22<01:05, 4302.70it/s]prepro_backdoor:  22%|██▏       | 78972/360000 [00:22<01:04, 4336.83it/s]prepro_backdoor:  22%|██▏       | 79442/360000 [00:22<01:03, 4416.42it/s]prepro_backdoor:  22%|██▏       | 79889/360000 [00:22<01:26, 3229.71it/s]prepro_backdoor:  22%|██▏       | 80356/360000 [00:22<01:18, 3561.85it/s]prepro_backdoor:  22%|██▏       | 80836/360000 [00:22<01:12, 3852.00it/s]prepro_backdoor:  23%|██▎       | 81258/360000 [00:22<01:16, 3666.77it/s]prepro_backdoor:  23%|██▎       | 81651/360000 [00:22<01:14, 3729.82it/s]prepro_backdoor:  23%|██▎       | 82053/360000 [00:23<01:13, 3788.54it/s]prepro_backdoor:  23%|██▎       | 82446/360000 [00:23<01:15, 3677.32it/s]prepro_backdoor:  23%|██▎       | 82824/360000 [00:23<01:14, 3703.01it/s]prepro_backdoor:  23%|██▎       | 83252/360000 [00:23<01:11, 3851.13it/s]prepro_backdoor:  23%|██▎       | 83699/360000 [00:23<01:08, 4026.58it/s]prepro_backdoor:  23%|██▎       | 84107/360000 [00:23<01:22, 3336.99it/s]prepro_backdoor:  23%|██▎       | 84567/360000 [00:23<01:15, 3640.99it/s]prepro_backdoor:  24%|██▎       | 85042/360000 [00:23<01:10, 3923.86it/s]prepro_backdoor:  24%|██▎       | 85453/360000 [00:23<01:10, 3916.36it/s]prepro_backdoor:  24%|██▍       | 85882/360000 [00:24<01:08, 4014.34it/s]prepro_backdoor:  24%|██▍       | 86353/360000 [00:24<01:04, 4210.44it/s]prepro_backdoor:  24%|██▍       | 86786/360000 [00:24<01:04, 4238.20it/s]prepro_backdoor:  24%|██▍       | 87235/360000 [00:24<01:03, 4287.30it/s]prepro_backdoor:  24%|██▍       | 87668/360000 [00:24<01:05, 4158.93it/s]prepro_backdoor:  24%|██▍       | 88088/360000 [00:24<01:08, 3994.59it/s]prepro_backdoor:  25%|██▍       | 88491/360000 [00:24<01:27, 3093.57it/s]prepro_backdoor:  25%|██▍       | 88901/360000 [00:24<01:21, 3329.85it/s]prepro_backdoor:  25%|██▍       | 89263/360000 [00:25<02:00, 2250.15it/s]prepro_backdoor:  25%|██▍       | 89784/360000 [00:25<01:35, 2818.42it/s]prepro_backdoor:  25%|██▌       | 90207/360000 [00:25<01:26, 3120.86it/s]prepro_backdoor:  25%|██▌       | 90622/360000 [00:25<01:20, 3345.54it/s]prepro_backdoor:  25%|██▌       | 91103/360000 [00:25<01:12, 3692.81it/s]prepro_backdoor:  25%|██▌       | 91515/360000 [00:25<01:13, 3649.09it/s]prepro_backdoor:  26%|██▌       | 91998/360000 [00:25<01:07, 3949.32it/s]prepro_backdoor:  26%|██▌       | 92428/360000 [00:25<01:06, 4037.56it/s]prepro_backdoor:  26%|██▌       | 92908/360000 [00:26<01:03, 4227.82it/s]prepro_backdoor:  26%|██▌       | 93345/360000 [00:26<01:06, 3985.48it/s]prepro_backdoor:  26%|██▌       | 93756/360000 [00:26<01:20, 3293.89it/s]prepro_backdoor:  26%|██▌       | 94112/360000 [00:26<01:19, 3329.00it/s]prepro_backdoor:  26%|██▌       | 94482/360000 [00:26<01:17, 3419.84it/s]prepro_backdoor:  26%|██▋       | 94941/360000 [00:26<01:11, 3716.97it/s]prepro_backdoor:  26%|██▋       | 95340/360000 [00:26<01:09, 3790.61it/s]prepro_backdoor:  27%|██▋       | 95737/360000 [00:26<01:09, 3829.71it/s]prepro_backdoor:  27%|██▋       | 96128/360000 [00:26<01:09, 3791.88it/s]prepro_backdoor:  27%|██▋       | 96549/360000 [00:27<01:07, 3893.10it/s]prepro_backdoor:  27%|██▋       | 96950/360000 [00:27<01:07, 3907.54it/s]prepro_backdoor:  27%|██▋       | 97477/360000 [00:27<01:01, 4295.18it/s]prepro_backdoor:  27%|██▋       | 97910/360000 [00:28<03:17, 1327.79it/s]prepro_backdoor:  27%|██▋       | 98420/360000 [00:28<02:28, 1758.45it/s]prepro_backdoor:  27%|██▋       | 98903/360000 [00:28<01:59, 2187.65it/s]prepro_backdoor:  28%|██▊       | 99355/360000 [00:28<01:41, 2574.56it/s]prepro_backdoor:  28%|██▊       | 99801/360000 [00:28<01:28, 2927.54it/s]prepro_backdoor:  28%|██▊       | 100226/360000 [00:28<01:22, 3158.13it/s]prepro_backdoor:  28%|██▊       | 100690/360000 [00:28<01:14, 3489.93it/s]prepro_backdoor:  28%|██▊       | 101186/360000 [00:28<01:07, 3831.55it/s]prepro_backdoor:  28%|██▊       | 101631/360000 [00:28<01:06, 3856.42it/s]prepro_backdoor:  28%|██▊       | 102060/360000 [00:29<01:37, 2633.60it/s]prepro_backdoor:  28%|██▊       | 102405/360000 [00:29<01:32, 2780.38it/s]prepro_backdoor:  29%|██▊       | 102843/360000 [00:29<01:22, 3130.79it/s]prepro_backdoor:  29%|██▊       | 103213/360000 [00:29<01:19, 3224.09it/s]prepro_backdoor:  29%|██▉       | 103649/360000 [00:29<01:13, 3502.77it/s]prepro_backdoor:  29%|██▉       | 104150/360000 [00:29<01:05, 3880.39it/s]prepro_backdoor:  29%|██▉       | 104567/360000 [00:29<01:11, 3587.16it/s]prepro_backdoor:  29%|██▉       | 104949/360000 [00:30<02:07, 2007.85it/s]prepro_backdoor:  29%|██▉       | 105410/360000 [00:30<01:44, 2444.67it/s]prepro_backdoor:  29%|██▉       | 105849/360000 [00:30<01:29, 2824.33it/s]prepro_backdoor:  30%|██▉       | 106291/360000 [00:30<01:20, 3160.57it/s]prepro_backdoor:  30%|██▉       | 106682/360000 [00:30<01:16, 3323.81it/s]prepro_backdoor:  30%|██▉       | 107209/360000 [00:30<01:06, 3802.48it/s]prepro_backdoor:  30%|██▉       | 107638/360000 [00:30<01:04, 3893.70it/s]prepro_backdoor:  30%|███       | 108154/360000 [00:31<00:59, 4235.50it/s]prepro_backdoor:  30%|███       | 108606/360000 [00:31<01:00, 4165.75it/s]prepro_backdoor:  30%|███       | 109110/360000 [00:31<00:56, 4406.32it/s]prepro_backdoor:  30%|███       | 109567/360000 [00:31<01:13, 3406.95it/s]prepro_backdoor:  31%|███       | 109953/360000 [00:31<01:11, 3511.04it/s]prepro_backdoor:  31%|███       | 110431/360000 [00:31<01:05, 3831.49it/s]prepro_backdoor:  31%|███       | 110943/360000 [00:31<01:00, 4148.50it/s]prepro_backdoor:  31%|███       | 111383/360000 [00:31<01:02, 3951.05it/s]prepro_backdoor:  31%|███       | 111797/360000 [00:32<01:05, 3801.91it/s]prepro_backdoor:  31%|███       | 112191/360000 [00:32<01:07, 3678.59it/s]prepro_backdoor:  31%|███▏      | 112590/360000 [00:32<01:06, 3705.01it/s]prepro_backdoor:  31%|███▏      | 112967/360000 [00:32<01:08, 3581.62it/s]prepro_backdoor:  31%|███▏      | 113330/360000 [00:32<01:20, 3074.67it/s]prepro_backdoor:  32%|███▏      | 113731/360000 [00:32<01:14, 3306.73it/s]prepro_backdoor:  32%|███▏      | 114258/360000 [00:32<01:04, 3808.79it/s]prepro_backdoor:  32%|███▏      | 114694/360000 [00:32<01:02, 3943.77it/s]prepro_backdoor:  32%|███▏      | 115102/360000 [00:32<01:03, 3887.23it/s]prepro_backdoor:  32%|███▏      | 115500/360000 [00:33<01:02, 3905.39it/s]prepro_backdoor:  32%|███▏      | 115897/360000 [00:33<01:03, 3855.81it/s]prepro_backdoor:  32%|███▏      | 116503/360000 [00:33<00:54, 4460.12it/s]prepro_backdoor:  32%|███▏      | 116955/360000 [00:33<00:55, 4406.98it/s]prepro_backdoor:  33%|███▎      | 117486/360000 [00:33<00:52, 4632.43it/s]prepro_backdoor:  33%|███▎      | 117953/360000 [00:33<01:11, 3393.74it/s]prepro_backdoor:  33%|███▎      | 118464/360000 [00:33<01:03, 3775.15it/s]prepro_backdoor:  33%|███▎      | 118902/360000 [00:33<01:01, 3901.60it/s]prepro_backdoor:  33%|███▎      | 119326/360000 [00:33<01:03, 3793.10it/s]prepro_backdoor:  33%|███▎      | 119821/360000 [00:34<00:58, 4074.86it/s]prepro_backdoor:  33%|███▎      | 120249/360000 [00:34<00:59, 4007.58it/s]prepro_backdoor:  34%|███▎      | 120664/360000 [00:34<01:04, 3727.90it/s]prepro_backdoor:  34%|███▎      | 121067/360000 [00:34<01:02, 3793.66it/s]prepro_backdoor:  34%|███▍      | 121626/360000 [00:34<00:55, 4260.01it/s]prepro_backdoor:  34%|███▍      | 122063/360000 [00:34<01:11, 3314.49it/s]prepro_backdoor:  34%|███▍      | 122438/360000 [00:34<01:09, 3415.44it/s]prepro_backdoor:  34%|███▍      | 122809/360000 [00:34<01:09, 3414.16it/s]prepro_backdoor:  34%|███▍      | 123171/360000 [00:35<01:37, 2428.30it/s]prepro_backdoor:  34%|███▍      | 123627/360000 [00:35<01:22, 2855.87it/s]prepro_backdoor:  34%|███▍      | 124039/360000 [00:35<01:15, 3141.38it/s]prepro_backdoor:  35%|███▍      | 124480/360000 [00:35<01:08, 3435.41it/s]prepro_backdoor:  35%|███▍      | 124888/360000 [00:35<01:05, 3594.51it/s]prepro_backdoor:  35%|███▍      | 125316/360000 [00:35<01:02, 3768.52it/s]prepro_backdoor:  35%|███▍      | 125763/360000 [00:35<00:59, 3946.06it/s]prepro_backdoor:  35%|███▌      | 126175/360000 [00:35<00:59, 3924.48it/s]prepro_backdoor:  35%|███▌      | 126580/360000 [00:36<01:01, 3772.67it/s]prepro_backdoor:  35%|███▌      | 126967/360000 [00:36<01:02, 3734.99it/s]prepro_backdoor:  35%|███▌      | 127347/360000 [00:36<01:15, 3066.43it/s]prepro_backdoor:  35%|███▌      | 127682/360000 [00:36<01:14, 3136.00it/s]prepro_backdoor:  36%|███▌      | 128042/360000 [00:36<01:11, 3240.18it/s]prepro_backdoor:  36%|███▌      | 128512/360000 [00:36<01:03, 3618.82it/s]prepro_backdoor:  36%|███▌      | 128890/360000 [00:36<01:03, 3663.40it/s]prepro_backdoor:  36%|███▌      | 129266/360000 [00:36<01:03, 3633.08it/s]prepro_backdoor:  36%|███▌      | 129769/360000 [00:36<00:57, 4023.21it/s]prepro_backdoor:  36%|███▌      | 130178/360000 [00:37<00:57, 3969.14it/s]prepro_backdoor:  36%|███▋      | 130580/360000 [00:37<00:59, 3876.78it/s]prepro_backdoor:  36%|███▋      | 131005/360000 [00:37<00:57, 3960.99it/s]prepro_backdoor:  37%|███▋      | 131564/360000 [00:37<00:51, 4423.05it/s]prepro_backdoor:  37%|███▋      | 132010/360000 [00:37<01:10, 3213.34it/s]prepro_backdoor:  37%|███▋      | 132390/360000 [00:37<01:07, 3347.58it/s]prepro_backdoor:  37%|███▋      | 133017/360000 [00:37<00:56, 4052.00it/s]prepro_backdoor:  37%|███▋      | 133500/360000 [00:37<00:53, 4230.99it/s]prepro_backdoor:  37%|███▋      | 134063/360000 [00:37<00:49, 4583.56it/s]prepro_backdoor:  37%|███▋      | 134546/360000 [00:38<00:49, 4512.43it/s]prepro_backdoor:  38%|███▊      | 135015/360000 [00:38<00:51, 4402.67it/s]prepro_backdoor:  38%|███▊      | 135468/360000 [00:38<00:53, 4207.60it/s]prepro_backdoor:  38%|███▊      | 136037/360000 [00:38<00:48, 4602.36it/s]prepro_backdoor:  38%|███▊      | 136550/360000 [00:38<00:47, 4720.39it/s]prepro_backdoor:  38%|███▊      | 137030/360000 [00:38<00:49, 4501.45it/s]prepro_backdoor:  38%|███▊      | 137488/360000 [00:38<01:09, 3197.92it/s]prepro_backdoor:  38%|███▊      | 137864/360000 [00:39<01:08, 3242.45it/s]prepro_backdoor:  38%|███▊      | 138262/360000 [00:39<01:05, 3410.38it/s]prepro_backdoor:  39%|███▊      | 138722/360000 [00:39<00:59, 3696.76it/s]prepro_backdoor:  39%|███▊      | 139160/360000 [00:39<00:57, 3872.40it/s]prepro_backdoor:  39%|███▉      | 139576/360000 [00:39<00:55, 3939.90it/s]prepro_backdoor:  39%|███▉      | 140125/360000 [00:39<00:50, 4346.04it/s]prepro_backdoor:  39%|███▉      | 140577/360000 [00:39<00:50, 4370.91it/s]prepro_backdoor:  39%|███▉      | 141024/360000 [00:39<00:54, 4036.24it/s]prepro_backdoor:  39%|███▉      | 141439/360000 [00:39<00:55, 3934.12it/s]prepro_backdoor:  39%|███▉      | 141841/360000 [00:40<01:32, 2348.74it/s]prepro_backdoor:  40%|███▉      | 142299/360000 [00:40<01:18, 2762.53it/s]prepro_backdoor:  40%|███▉      | 142762/360000 [00:40<01:08, 3157.52it/s]prepro_backdoor:  40%|███▉      | 143244/360000 [00:40<01:01, 3525.52it/s]prepro_backdoor:  40%|███▉      | 143658/360000 [00:40<01:00, 3582.94it/s]prepro_backdoor:  40%|████      | 144060/360000 [00:40<00:59, 3636.12it/s]prepro_backdoor:  40%|████      | 144479/360000 [00:40<00:57, 3758.57it/s]prepro_backdoor:  40%|████      | 144971/360000 [00:40<00:52, 4065.64it/s]prepro_backdoor:  40%|████      | 145397/360000 [00:41<00:55, 3883.50it/s]prepro_backdoor:  41%|████      | 145822/360000 [00:41<00:53, 3975.23it/s]prepro_backdoor:  41%|████      | 146231/360000 [00:41<01:07, 3175.40it/s]prepro_backdoor:  41%|████      | 146665/360000 [00:41<01:02, 3438.17it/s]prepro_backdoor:  41%|████      | 147079/360000 [00:41<00:58, 3616.89it/s]prepro_backdoor:  41%|████      | 147531/360000 [00:41<00:55, 3839.36it/s]prepro_backdoor:  41%|████      | 148015/360000 [00:41<00:51, 4101.77it/s]prepro_backdoor:  41%|████      | 148486/360000 [00:41<00:49, 4254.77it/s]prepro_backdoor:  41%|████▏     | 148945/360000 [00:41<00:48, 4343.74it/s]prepro_backdoor:  42%|████▏     | 149498/360000 [00:42<00:44, 4685.14it/s]prepro_backdoor:  42%|████▏     | 149974/360000 [00:42<00:48, 4338.52it/s]prepro_backdoor:  42%|████▏     | 150442/360000 [00:42<00:47, 4425.86it/s]prepro_backdoor:  42%|████▏     | 150892/360000 [00:42<00:47, 4407.56it/s]prepro_backdoor:  42%|████▏     | 151338/360000 [00:42<01:04, 3246.91it/s]prepro_backdoor:  42%|████▏     | 151852/360000 [00:42<00:56, 3665.12it/s]prepro_backdoor:  42%|████▏     | 152263/360000 [00:42<00:55, 3773.27it/s]prepro_backdoor:  42%|████▏     | 152674/360000 [00:42<00:55, 3758.57it/s]prepro_backdoor:  43%|████▎     | 153073/360000 [00:43<00:54, 3805.33it/s]prepro_backdoor:  43%|████▎     | 153471/360000 [00:43<00:53, 3851.56it/s]prepro_backdoor:  43%|████▎     | 153897/360000 [00:43<00:52, 3957.36it/s]prepro_backdoor:  43%|████▎     | 154376/360000 [00:43<00:49, 4177.15it/s]prepro_backdoor:  43%|████▎     | 154880/360000 [00:43<00:46, 4412.36it/s]prepro_backdoor:  43%|████▎     | 155327/360000 [00:43<01:01, 3319.12it/s]prepro_backdoor:  43%|████▎     | 155725/360000 [00:43<00:59, 3458.14it/s]prepro_backdoor:  43%|████▎     | 156105/360000 [00:43<00:58, 3463.28it/s]prepro_backdoor:  44%|████▎     | 156604/360000 [00:43<00:52, 3855.97it/s]prepro_backdoor:  44%|████▎     | 157012/360000 [00:44<00:54, 3722.91it/s]prepro_backdoor:  44%|████▎     | 157475/360000 [00:44<00:51, 3944.83it/s]prepro_backdoor:  44%|████▍     | 157883/360000 [00:44<00:54, 3696.80it/s]prepro_backdoor:  44%|████▍     | 158367/360000 [00:44<00:50, 3992.74it/s]prepro_backdoor:  44%|████▍     | 158778/360000 [00:44<00:50, 4006.93it/s]prepro_backdoor:  44%|████▍     | 159187/360000 [00:44<00:50, 3948.66it/s]prepro_backdoor:  44%|████▍     | 159588/360000 [00:44<01:17, 2577.36it/s]prepro_backdoor:  44%|████▍     | 159910/360000 [00:45<02:00, 1659.22it/s]prepro_backdoor:  45%|████▍     | 160280/360000 [00:45<01:41, 1968.93it/s]prepro_backdoor:  45%|████▍     | 160700/360000 [00:45<01:24, 2367.45it/s]prepro_backdoor:  45%|████▍     | 161082/360000 [00:45<01:15, 2650.49it/s]prepro_backdoor:  45%|████▍     | 161497/360000 [00:45<01:06, 2984.17it/s]prepro_backdoor:  45%|████▍     | 161858/360000 [00:45<01:03, 3128.62it/s]prepro_backdoor:  45%|████▌     | 162332/360000 [00:45<00:56, 3527.82it/s]prepro_backdoor:  45%|████▌     | 162787/360000 [00:46<00:51, 3799.25it/s]prepro_backdoor:  45%|████▌     | 163198/360000 [00:46<00:53, 3644.94it/s]prepro_backdoor:  45%|████▌     | 163585/360000 [00:46<01:19, 2473.65it/s]prepro_backdoor:  46%|████▌     | 163985/360000 [00:46<01:10, 2779.62it/s]prepro_backdoor:  46%|████▌     | 164416/360000 [00:46<01:02, 3109.90it/s]prepro_backdoor:  46%|████▌     | 164781/360000 [00:46<01:00, 3236.14it/s]prepro_backdoor:  46%|████▌     | 165151/360000 [00:46<00:58, 3336.39it/s]prepro_backdoor:  46%|████▌     | 165586/360000 [00:46<00:54, 3588.75it/s]prepro_backdoor:  46%|████▌     | 165968/360000 [00:47<00:56, 3443.89it/s]prepro_backdoor:  46%|████▌     | 166403/360000 [00:47<00:52, 3678.57it/s]prepro_backdoor:  46%|████▋     | 166824/360000 [00:47<00:50, 3821.70it/s]prepro_backdoor:  46%|████▋     | 167227/360000 [00:47<00:49, 3858.58it/s]prepro_backdoor:  47%|████▋     | 167621/360000 [00:47<01:07, 2868.38it/s]prepro_backdoor:  47%|████▋     | 168048/360000 [00:47<01:00, 3177.70it/s]prepro_backdoor:  47%|████▋     | 168559/360000 [00:47<00:52, 3657.99it/s]prepro_backdoor:  47%|████▋     | 168990/360000 [00:47<00:49, 3828.56it/s]prepro_backdoor:  47%|████▋     | 169401/360000 [00:48<00:50, 3777.38it/s]prepro_backdoor:  47%|████▋     | 169799/360000 [00:48<00:50, 3748.36it/s]prepro_backdoor:  47%|████▋     | 170266/360000 [00:48<00:47, 3996.50it/s]prepro_backdoor:  47%|████▋     | 170678/360000 [00:48<00:53, 3565.65it/s]prepro_backdoor:  48%|████▊     | 171132/360000 [00:48<00:49, 3814.09it/s]prepro_backdoor:  48%|████▊     | 171528/360000 [00:48<00:49, 3776.42it/s]prepro_backdoor:  48%|████▊     | 171916/360000 [00:48<01:07, 2785.12it/s]prepro_backdoor:  48%|████▊     | 172290/360000 [00:48<01:02, 2994.56it/s]prepro_backdoor:  48%|████▊     | 172737/360000 [00:49<00:56, 3339.29it/s]prepro_backdoor:  48%|████▊     | 173105/360000 [00:49<00:54, 3425.99it/s]prepro_backdoor:  48%|████▊     | 173473/360000 [00:49<00:55, 3389.35it/s]prepro_backdoor:  48%|████▊     | 173900/360000 [00:49<00:51, 3608.59it/s]prepro_backdoor:  48%|████▊     | 174359/360000 [00:49<00:47, 3872.91it/s]prepro_backdoor:  49%|████▊     | 174830/360000 [00:49<00:45, 4094.97it/s]prepro_backdoor:  49%|████▊     | 175249/360000 [00:49<00:45, 4064.90it/s]prepro_backdoor:  49%|████▉     | 175663/360000 [00:49<00:49, 3758.22it/s]prepro_backdoor:  49%|████▉     | 176048/360000 [00:49<00:59, 3099.81it/s]prepro_backdoor:  49%|████▉     | 176382/360000 [00:50<01:04, 2832.41it/s]prepro_backdoor:  49%|████▉     | 176920/360000 [00:50<00:53, 3425.96it/s]prepro_backdoor:  49%|████▉     | 177343/360000 [00:50<00:50, 3611.79it/s]prepro_backdoor:  49%|████▉     | 177885/360000 [00:50<00:44, 4067.37it/s]prepro_backdoor:  50%|████▉     | 178313/360000 [00:50<00:49, 3639.50it/s]prepro_backdoor:  50%|████▉     | 178792/360000 [00:50<00:46, 3931.59it/s]prepro_backdoor:  50%|████▉     | 179206/360000 [00:50<00:46, 3918.47it/s]prepro_backdoor:  50%|████▉     | 179648/360000 [00:50<00:44, 4052.99it/s]prepro_backdoor:  50%|█████     | 180239/360000 [00:50<00:39, 4550.17it/s]prepro_backdoor:  50%|█████     | 180705/360000 [00:51<00:49, 3645.80it/s]prepro_backdoor:  50%|█████     | 181153/360000 [00:51<00:46, 3837.66it/s]prepro_backdoor:  50%|█████     | 181566/360000 [00:51<00:47, 3772.40it/s]prepro_backdoor:  51%|█████     | 181963/360000 [00:51<00:47, 3769.24it/s]prepro_backdoor:  51%|█████     | 182354/360000 [00:51<00:48, 3684.29it/s]prepro_backdoor:  51%|█████     | 182810/360000 [00:51<00:45, 3898.33it/s]prepro_backdoor:  51%|█████     | 183209/360000 [00:51<00:46, 3826.80it/s]prepro_backdoor:  51%|█████     | 183605/360000 [00:51<00:45, 3838.98it/s]prepro_backdoor:  51%|█████     | 184069/360000 [00:51<00:43, 4051.95it/s]prepro_backdoor:  51%|█████▏    | 184562/360000 [00:52<00:40, 4292.06it/s]prepro_backdoor:  51%|█████▏    | 184995/360000 [00:52<00:50, 3494.55it/s]prepro_backdoor:  51%|█████▏    | 185371/360000 [00:52<00:50, 3481.07it/s]prepro_backdoor:  52%|█████▏    | 185771/360000 [00:52<00:48, 3603.13it/s]prepro_backdoor:  52%|█████▏    | 186245/360000 [00:52<00:44, 3905.91it/s]prepro_backdoor:  52%|█████▏    | 186694/360000 [00:52<00:42, 4060.17it/s]prepro_backdoor:  52%|█████▏    | 187151/360000 [00:52<00:41, 4198.82it/s]prepro_backdoor:  52%|█████▏    | 187599/360000 [00:52<00:40, 4273.58it/s]prepro_backdoor:  52%|█████▏    | 188130/360000 [00:52<00:37, 4566.02it/s]prepro_backdoor:  52%|█████▏    | 188592/360000 [00:53<00:41, 4089.50it/s]prepro_backdoor:  53%|█████▎    | 189134/360000 [00:53<00:38, 4425.99it/s]prepro_backdoor:  53%|█████▎    | 189589/360000 [00:53<00:41, 4137.62it/s]prepro_backdoor:  53%|█████▎    | 190014/360000 [00:53<00:53, 3148.30it/s]prepro_backdoor:  53%|█████▎    | 190478/360000 [00:53<00:48, 3480.38it/s]prepro_backdoor:  53%|█████▎    | 190878/360000 [00:53<00:47, 3592.24it/s]prepro_backdoor:  53%|█████▎    | 191267/360000 [00:53<00:48, 3473.31it/s]prepro_backdoor:  53%|█████▎    | 191665/360000 [00:54<00:46, 3603.27it/s]prepro_backdoor:  53%|█████▎    | 192090/360000 [00:54<00:44, 3761.41it/s]prepro_backdoor:  53%|█████▎    | 192480/360000 [00:54<00:46, 3622.64it/s]prepro_backdoor:  54%|█████▎    | 192917/360000 [00:54<00:43, 3815.19it/s]prepro_backdoor:  54%|█████▎    | 193391/360000 [00:54<00:40, 4068.91it/s]prepro_backdoor:  54%|█████▍    | 193806/360000 [00:54<00:51, 3244.32it/s]prepro_backdoor:  54%|█████▍    | 194165/360000 [00:54<00:50, 3308.90it/s]prepro_backdoor:  54%|█████▍    | 194567/360000 [00:54<00:47, 3483.15it/s]prepro_backdoor:  54%|█████▍    | 194939/360000 [00:54<00:46, 3531.19it/s]prepro_backdoor:  54%|█████▍    | 195306/360000 [00:55<01:06, 2459.38it/s]prepro_backdoor:  54%|█████▍    | 195677/360000 [00:55<01:00, 2714.58it/s]prepro_backdoor:  54%|█████▍    | 196106/360000 [00:55<00:53, 3077.66it/s]prepro_backdoor:  55%|█████▍    | 196484/360000 [00:55<00:50, 3234.06it/s]prepro_backdoor:  55%|█████▍    | 196898/360000 [00:55<00:47, 3463.84it/s]prepro_backdoor:  55%|█████▍    | 197400/360000 [00:55<00:41, 3885.92it/s]prepro_backdoor:  55%|█████▍    | 197812/360000 [00:55<00:42, 3843.40it/s]prepro_backdoor:  55%|█████▌    | 198418/360000 [00:55<00:36, 4444.65it/s]prepro_backdoor:  55%|█████▌    | 198878/360000 [00:56<00:36, 4431.60it/s]prepro_backdoor:  55%|█████▌    | 199332/360000 [00:56<00:36, 4345.09it/s]prepro_backdoor:  55%|█████▌    | 199774/360000 [00:56<00:51, 3103.72it/s]prepro_backdoor:  56%|█████▌    | 200197/360000 [00:56<00:47, 3344.89it/s]prepro_backdoor:  56%|█████▌    | 200670/360000 [00:56<00:43, 3666.43it/s]prepro_backdoor:  56%|█████▌    | 201076/360000 [00:56<00:43, 3643.97it/s]prepro_backdoor:  56%|█████▌    | 201468/360000 [00:56<00:42, 3699.84it/s]prepro_backdoor:  56%|█████▌    | 201880/360000 [00:56<00:41, 3810.22it/s]prepro_backdoor:  56%|█████▌    | 202322/360000 [00:56<00:39, 3977.81it/s]prepro_backdoor:  56%|█████▋    | 202732/360000 [00:57<00:39, 3984.96it/s]prepro_backdoor:  56%|█████▋    | 203190/360000 [00:57<00:37, 4147.33it/s]prepro_backdoor:  57%|█████▋    | 203612/360000 [00:57<00:39, 3992.42it/s]prepro_backdoor:  57%|█████▋    | 204017/360000 [00:57<00:48, 3209.07it/s]prepro_backdoor:  57%|█████▋    | 204366/360000 [00:57<00:47, 3260.28it/s]prepro_backdoor:  57%|█████▋    | 204799/360000 [00:57<00:44, 3515.76it/s]prepro_backdoor:  57%|█████▋    | 205368/360000 [00:57<00:37, 4084.97it/s]prepro_backdoor:  57%|█████▋    | 205795/360000 [00:57<00:37, 4062.47it/s]prepro_backdoor:  57%|█████▋    | 206243/360000 [00:57<00:36, 4173.89it/s]prepro_backdoor:  57%|█████▋    | 206671/360000 [00:58<00:36, 4175.48it/s]prepro_backdoor:  58%|█████▊    | 207144/360000 [00:58<00:35, 4323.04it/s]prepro_backdoor:  58%|█████▊    | 207586/360000 [00:58<00:35, 4335.53it/s]prepro_backdoor:  58%|█████▊    | 208024/360000 [00:58<00:35, 4237.73it/s]prepro_backdoor:  58%|█████▊    | 208451/360000 [00:58<00:43, 3468.39it/s]prepro_backdoor:  58%|█████▊    | 208842/360000 [00:58<00:42, 3569.88it/s]prepro_backdoor:  58%|█████▊    | 209241/360000 [00:58<00:41, 3669.20it/s]prepro_backdoor:  58%|█████▊    | 209638/360000 [00:58<00:40, 3746.68it/s]prepro_backdoor:  58%|█████▊    | 210038/360000 [00:58<00:39, 3795.84it/s]prepro_backdoor:  58%|█████▊    | 210434/360000 [00:59<00:39, 3826.59it/s]prepro_backdoor:  59%|█████▊    | 210984/360000 [00:59<00:34, 4289.22it/s]prepro_backdoor:  59%|█████▊    | 211451/360000 [00:59<00:34, 4368.58it/s]prepro_backdoor:  59%|█████▉    | 211892/360000 [00:59<00:36, 4098.46it/s]prepro_backdoor:  59%|█████▉    | 212363/360000 [00:59<00:34, 4251.91it/s]prepro_backdoor:  59%|█████▉    | 212794/360000 [00:59<01:08, 2143.99it/s]prepro_backdoor:  59%|█████▉    | 213124/360000 [01:00<01:41, 1449.24it/s]prepro_backdoor:  59%|█████▉    | 213578/360000 [01:00<01:19, 1850.66it/s]prepro_backdoor:  59%|█████▉    | 214045/360000 [01:00<01:03, 2290.43it/s]prepro_backdoor:  60%|█████▉    | 214426/360000 [01:00<00:56, 2564.25it/s]prepro_backdoor:  60%|█████▉    | 214977/360000 [01:00<00:45, 3167.37it/s]prepro_backdoor:  60%|█████▉    | 215426/360000 [01:00<00:41, 3456.36it/s]prepro_backdoor:  60%|█████▉    | 215851/360000 [01:01<00:41, 3447.10it/s]prepro_backdoor:  60%|██████    | 216252/360000 [01:01<00:54, 2623.17it/s]prepro_backdoor:  60%|██████    | 216581/360000 [01:01<01:02, 2301.36it/s]prepro_backdoor:  60%|██████    | 216872/360000 [01:01<01:01, 2343.79it/s]prepro_backdoor:  60%|██████    | 217282/360000 [01:01<00:52, 2707.59it/s]prepro_backdoor:  60%|██████    | 217706/360000 [01:01<00:46, 3058.58it/s]prepro_backdoor:  61%|██████    | 218075/360000 [01:01<00:44, 3207.32it/s]prepro_backdoor:  61%|██████    | 218514/360000 [01:02<00:40, 3505.61it/s]prepro_backdoor:  61%|██████    | 218987/360000 [01:02<00:36, 3833.56it/s]prepro_backdoor:  61%|██████    | 219396/360000 [01:02<00:36, 3888.43it/s]prepro_backdoor:  61%|██████    | 219807/360000 [01:02<00:35, 3928.35it/s]prepro_backdoor:  61%|██████    | 220211/360000 [01:02<00:36, 3808.96it/s]prepro_backdoor:  61%|██████▏   | 220600/360000 [01:02<00:37, 3759.10it/s]prepro_backdoor:  61%|██████▏   | 220982/360000 [01:02<00:47, 2953.55it/s]prepro_backdoor:  62%|██████▏   | 221411/360000 [01:02<00:42, 3274.26it/s]prepro_backdoor:  62%|██████▏   | 221767/360000 [01:02<00:42, 3265.80it/s]prepro_backdoor:  62%|██████▏   | 222207/360000 [01:03<00:38, 3543.29it/s]prepro_backdoor:  62%|██████▏   | 222605/360000 [01:03<00:37, 3641.89it/s]prepro_backdoor:  62%|██████▏   | 223032/360000 [01:03<00:35, 3815.90it/s]prepro_backdoor:  62%|██████▏   | 223424/360000 [01:03<00:36, 3769.61it/s]prepro_backdoor:  62%|██████▏   | 223828/360000 [01:03<00:35, 3840.31it/s]prepro_backdoor:  62%|██████▏   | 224218/360000 [01:03<00:37, 3662.12it/s]prepro_backdoor:  62%|██████▏   | 224590/360000 [01:03<00:36, 3668.73it/s]prepro_backdoor:  63%|██████▎   | 225019/360000 [01:03<00:35, 3838.53it/s]prepro_backdoor:  63%|██████▎   | 225407/360000 [01:03<00:42, 3179.10it/s]prepro_backdoor:  63%|██████▎   | 225785/360000 [01:04<00:40, 3330.55it/s]prepro_backdoor:  63%|██████▎   | 226224/360000 [01:04<00:37, 3600.05it/s]prepro_backdoor:  63%|██████▎   | 226626/360000 [01:04<00:35, 3707.56it/s]prepro_backdoor:  63%|██████▎   | 227125/360000 [01:04<00:32, 4044.70it/s]prepro_backdoor:  63%|██████▎   | 227637/360000 [01:04<00:30, 4333.11it/s]prepro_backdoor:  63%|██████▎   | 228079/360000 [01:04<00:32, 4014.74it/s]prepro_backdoor:  64%|██████▎   | 228603/360000 [01:04<00:30, 4337.13it/s]prepro_backdoor:  64%|██████▎   | 229064/360000 [01:04<00:29, 4399.90it/s]prepro_backdoor:  64%|██████▍   | 229511/360000 [01:05<00:40, 3225.39it/s]prepro_backdoor:  64%|██████▍   | 229883/360000 [01:05<00:58, 2238.52it/s]prepro_backdoor:  64%|██████▍   | 230296/360000 [01:05<00:50, 2571.81it/s]prepro_backdoor:  64%|██████▍   | 230707/360000 [01:05<00:44, 2876.05it/s]prepro_backdoor:  64%|██████▍   | 231094/360000 [01:05<00:41, 3097.94it/s]prepro_backdoor:  64%|██████▍   | 231575/360000 [01:05<00:36, 3498.91it/s]prepro_backdoor:  64%|██████▍   | 231974/360000 [01:05<00:35, 3612.89it/s]prepro_backdoor:  65%|██████▍   | 232418/360000 [01:05<00:33, 3814.67it/s]prepro_backdoor:  65%|██████▍   | 232825/360000 [01:06<00:33, 3787.90it/s]prepro_backdoor:  65%|██████▍   | 233267/360000 [01:06<00:32, 3942.31it/s]prepro_backdoor:  65%|██████▍   | 233783/360000 [01:06<00:29, 4282.26it/s]prepro_backdoor:  65%|██████▌   | 234223/360000 [01:06<00:38, 3296.40it/s]prepro_backdoor:  65%|██████▌   | 234595/360000 [01:06<00:36, 3395.02it/s]prepro_backdoor:  65%|██████▌   | 235089/360000 [01:06<00:33, 3769.72it/s]prepro_backdoor:  65%|██████▌   | 235627/360000 [01:06<00:29, 4174.21it/s]prepro_backdoor:  66%|██████▌   | 236069/360000 [01:06<00:29, 4159.74it/s]prepro_backdoor:  66%|██████▌   | 236503/360000 [01:06<00:29, 4201.83it/s]prepro_backdoor:  66%|██████▌   | 236942/360000 [01:07<00:28, 4244.94it/s]prepro_backdoor:  66%|██████▌   | 237376/360000 [01:07<00:30, 4036.20it/s]prepro_backdoor:  66%|██████▌   | 237788/360000 [01:07<00:32, 3782.19it/s]prepro_backdoor:  66%|██████▌   | 238218/360000 [01:07<00:31, 3903.14it/s]prepro_backdoor:  66%|██████▋   | 238661/360000 [01:07<00:30, 4032.85it/s]prepro_backdoor:  66%|██████▋   | 239070/360000 [01:07<00:40, 3007.76it/s]prepro_backdoor:  67%|██████▋   | 239412/360000 [01:07<00:39, 3022.91it/s]prepro_backdoor:  67%|██████▋   | 239872/360000 [01:07<00:35, 3405.76it/s]prepro_backdoor:  67%|██████▋   | 240323/360000 [01:08<00:32, 3687.11it/s]prepro_backdoor:  67%|██████▋   | 240787/360000 [01:08<00:30, 3930.40it/s]prepro_backdoor:  67%|██████▋   | 241200/360000 [01:08<00:30, 3942.58it/s]prepro_backdoor:  67%|██████▋   | 241616/360000 [01:08<00:29, 3983.61it/s]prepro_backdoor:  67%|██████▋   | 242115/360000 [01:08<00:27, 4246.43it/s]prepro_backdoor:  67%|██████▋   | 242563/360000 [01:08<00:27, 4286.49it/s]prepro_backdoor:  67%|██████▋   | 242998/360000 [01:08<00:27, 4294.37it/s]prepro_backdoor:  68%|██████▊   | 243432/360000 [01:08<00:27, 4186.89it/s]prepro_backdoor:  68%|██████▊   | 243854/360000 [01:08<00:36, 3220.00it/s]prepro_backdoor:  68%|██████▊   | 244361/360000 [01:09<00:31, 3649.49it/s]prepro_backdoor:  68%|██████▊   | 244761/360000 [01:09<00:31, 3659.04it/s]prepro_backdoor:  68%|██████▊   | 245188/360000 [01:09<00:30, 3800.73it/s]prepro_backdoor:  68%|██████▊   | 245702/360000 [01:09<00:27, 4156.50it/s]prepro_backdoor:  68%|██████▊   | 246135/360000 [01:09<00:27, 4139.27it/s]prepro_backdoor:  68%|██████▊   | 246561/360000 [01:09<00:27, 4084.86it/s]prepro_backdoor:  69%|██████▊   | 246978/360000 [01:09<00:27, 4090.29it/s]prepro_backdoor:  69%|██████▊   | 247418/360000 [01:09<00:26, 4177.64it/s]prepro_backdoor:  69%|██████▉   | 247903/360000 [01:09<00:25, 4350.41it/s]prepro_backdoor:  69%|██████▉   | 248342/360000 [01:10<00:45, 2447.72it/s]prepro_backdoor:  69%|██████▉   | 248851/360000 [01:10<00:37, 2949.30it/s]prepro_backdoor:  69%|██████▉   | 249300/360000 [01:10<00:33, 3274.23it/s]prepro_backdoor:  69%|██████▉   | 249716/360000 [01:10<00:31, 3466.29it/s]prepro_backdoor:  69%|██████▉   | 250198/360000 [01:10<00:29, 3782.22it/s]prepro_backdoor:  70%|██████▉   | 250626/360000 [01:10<00:28, 3862.53it/s]prepro_backdoor:  70%|██████▉   | 251068/360000 [01:10<00:27, 3992.66it/s]prepro_backdoor:  70%|██████▉   | 251549/360000 [01:11<00:25, 4195.27it/s]prepro_backdoor:  70%|██████▉   | 251989/360000 [01:11<00:25, 4183.23it/s]prepro_backdoor:  70%|███████   | 252509/360000 [01:11<00:24, 4467.80it/s]prepro_backdoor:  70%|███████   | 252967/360000 [01:11<00:28, 3709.88it/s]prepro_backdoor:  70%|███████   | 253450/360000 [01:11<00:26, 3987.14it/s]prepro_backdoor:  71%|███████   | 254007/360000 [01:11<00:24, 4406.24it/s]prepro_backdoor:  71%|███████   | 254471/360000 [01:11<00:24, 4393.36it/s]prepro_backdoor:  71%|███████   | 254927/360000 [01:11<00:25, 4193.06it/s]prepro_backdoor:  71%|███████   | 255417/360000 [01:11<00:23, 4382.76it/s]prepro_backdoor:  71%|███████   | 255869/360000 [01:12<00:23, 4419.44it/s]prepro_backdoor:  71%|███████   | 256353/360000 [01:12<00:22, 4524.01it/s]prepro_backdoor:  71%|███████▏  | 256812/360000 [01:12<00:23, 4481.99it/s]prepro_backdoor:  71%|███████▏  | 257265/360000 [01:12<00:23, 4296.54it/s]prepro_backdoor:  72%|███████▏  | 257699/360000 [01:12<00:31, 3213.69it/s]prepro_backdoor:  72%|███████▏  | 258154/360000 [01:12<00:28, 3519.94it/s]prepro_backdoor:  72%|███████▏  | 258632/360000 [01:12<00:26, 3813.63it/s]prepro_backdoor:  72%|███████▏  | 259046/360000 [01:12<00:26, 3841.21it/s]prepro_backdoor:  72%|███████▏  | 259474/360000 [01:12<00:25, 3954.55it/s]prepro_backdoor:  72%|███████▏  | 259887/360000 [01:13<00:26, 3839.33it/s]prepro_backdoor:  72%|███████▏  | 260284/360000 [01:13<00:27, 3667.31it/s]prepro_backdoor:  72%|███████▏  | 260674/360000 [01:13<00:26, 3727.48it/s]prepro_backdoor:  73%|███████▎  | 261119/360000 [01:13<00:25, 3923.31it/s]prepro_backdoor:  73%|███████▎  | 261557/360000 [01:13<00:24, 4043.75it/s]prepro_backdoor:  73%|███████▎  | 261967/360000 [01:13<00:34, 2873.74it/s]prepro_backdoor:  73%|███████▎  | 262376/360000 [01:13<00:31, 3132.13it/s]prepro_backdoor:  73%|███████▎  | 262833/360000 [01:13<00:27, 3476.79it/s]prepro_backdoor:  73%|███████▎  | 263302/360000 [01:14<00:25, 3787.38it/s]prepro_backdoor:  73%|███████▎  | 263713/360000 [01:14<00:25, 3761.24it/s]prepro_backdoor:  73%|███████▎  | 264131/360000 [01:14<00:24, 3862.23it/s]prepro_backdoor:  73%|███████▎  | 264534/360000 [01:14<00:24, 3844.65it/s]prepro_backdoor:  74%|███████▎  | 264940/360000 [01:14<00:24, 3900.56it/s]prepro_backdoor:  74%|███████▎  | 265431/360000 [01:14<00:22, 4171.71it/s]prepro_backdoor:  74%|███████▍  | 265855/360000 [01:14<00:23, 4060.16it/s]prepro_backdoor:  74%|███████▍  | 266267/360000 [01:15<01:27, 1076.27it/s]prepro_backdoor:  74%|███████▍  | 266625/360000 [01:15<01:10, 1317.30it/s]prepro_backdoor:  74%|███████▍  | 266982/360000 [01:15<00:58, 1589.69it/s]prepro_backdoor:  74%|███████▍  | 267403/360000 [01:16<00:46, 1976.56it/s]prepro_backdoor:  74%|███████▍  | 267911/360000 [01:16<00:36, 2512.03it/s]prepro_backdoor:  75%|███████▍  | 268310/360000 [01:16<00:33, 2699.59it/s]prepro_backdoor:  75%|███████▍  | 268825/360000 [01:16<00:28, 3221.45it/s]prepro_backdoor:  75%|███████▍  | 269244/360000 [01:16<00:26, 3374.04it/s]prepro_backdoor:  75%|███████▍  | 269652/360000 [01:16<00:26, 3361.44it/s]prepro_backdoor:  75%|███████▌  | 270038/360000 [01:16<00:33, 2689.30it/s]prepro_backdoor:  75%|███████▌  | 270414/360000 [01:16<00:30, 2914.58it/s]prepro_backdoor:  75%|███████▌  | 270876/360000 [01:17<00:26, 3305.50it/s]prepro_backdoor:  75%|███████▌  | 271342/360000 [01:17<00:24, 3642.58it/s]prepro_backdoor:  75%|███████▌  | 271790/360000 [01:17<00:22, 3855.37it/s]prepro_backdoor:  76%|███████▌  | 272204/360000 [01:17<00:22, 3925.85it/s]prepro_backdoor:  76%|███████▌  | 272671/360000 [01:17<00:21, 4106.25it/s]prepro_backdoor:  76%|███████▌  | 273097/360000 [01:17<00:21, 4011.60it/s]prepro_backdoor:  76%|███████▌  | 273510/360000 [01:17<00:21, 3980.84it/s]prepro_backdoor:  76%|███████▌  | 273916/360000 [01:17<00:22, 3834.19it/s]prepro_backdoor:  76%|███████▌  | 274314/360000 [01:17<00:22, 3872.29it/s]prepro_backdoor:  76%|███████▋  | 274706/360000 [01:18<00:28, 3008.29it/s]prepro_backdoor:  76%|███████▋  | 275175/360000 [01:18<00:24, 3404.57it/s]prepro_backdoor:  77%|███████▋  | 275652/360000 [01:18<00:22, 3752.22it/s]prepro_backdoor:  77%|███████▋  | 276119/360000 [01:18<00:21, 3986.21it/s]prepro_backdoor:  77%|███████▋  | 276698/360000 [01:18<00:18, 4463.78it/s]prepro_backdoor:  77%|███████▋  | 277164/360000 [01:18<00:19, 4154.26it/s]prepro_backdoor:  77%|███████▋  | 277729/360000 [01:18<00:18, 4535.30it/s]prepro_backdoor:  77%|███████▋  | 278260/360000 [01:18<00:17, 4742.48it/s]prepro_backdoor:  77%|███████▋  | 278796/360000 [01:18<00:16, 4885.81it/s]prepro_backdoor:  78%|███████▊  | 279295/360000 [01:19<00:25, 3208.42it/s]prepro_backdoor:  78%|███████▊  | 279697/360000 [01:19<00:24, 3342.93it/s]prepro_backdoor:  78%|███████▊  | 280093/360000 [01:19<00:23, 3465.69it/s]prepro_backdoor:  78%|███████▊  | 280567/360000 [01:19<00:21, 3777.63it/s]prepro_backdoor:  78%|███████▊  | 280984/360000 [01:19<00:20, 3837.63it/s]prepro_backdoor:  78%|███████▊  | 281396/360000 [01:19<00:21, 3656.99it/s]prepro_backdoor:  78%|███████▊  | 281783/360000 [01:19<00:21, 3654.62it/s]prepro_backdoor:  78%|███████▊  | 282199/360000 [01:19<00:20, 3783.88it/s]prepro_backdoor:  79%|███████▊  | 282640/360000 [01:20<00:19, 3952.77it/s]prepro_backdoor:  79%|███████▊  | 283077/360000 [01:20<00:18, 4059.77it/s]prepro_backdoor:  79%|███████▊  | 283490/360000 [01:20<00:23, 3253.88it/s]prepro_backdoor:  79%|███████▉  | 283879/360000 [01:20<00:31, 2422.29it/s]prepro_backdoor:  79%|███████▉  | 284312/360000 [01:20<00:27, 2792.60it/s]prepro_backdoor:  79%|███████▉  | 284728/360000 [01:20<00:24, 3089.83it/s]prepro_backdoor:  79%|███████▉  | 285154/360000 [01:20<00:22, 3367.65it/s]prepro_backdoor:  79%|███████▉  | 285579/360000 [01:21<00:20, 3571.77it/s]prepro_backdoor:  79%|███████▉  | 286043/360000 [01:21<00:19, 3853.23it/s]prepro_backdoor:  80%|███████▉  | 286454/360000 [01:21<00:18, 3886.84it/s]prepro_backdoor:  80%|███████▉  | 286861/360000 [01:21<00:27, 2668.59it/s]prepro_backdoor:  80%|███████▉  | 287244/360000 [01:21<00:25, 2909.98it/s]prepro_backdoor:  80%|███████▉  | 287666/360000 [01:21<00:22, 3199.88it/s]prepro_backdoor:  80%|████████  | 288084/360000 [01:21<00:20, 3425.83it/s]prepro_backdoor:  80%|████████  | 288507/360000 [01:21<00:19, 3619.45it/s]prepro_backdoor:  80%|████████  | 288914/360000 [01:21<00:19, 3737.22it/s]prepro_backdoor:  80%|████████  | 289404/360000 [01:22<00:17, 4039.05it/s]prepro_backdoor:  81%|████████  | 289825/360000 [01:22<00:17, 3909.06it/s]prepro_backdoor:  81%|████████  | 290298/360000 [01:22<00:16, 4112.53it/s]prepro_backdoor:  81%|████████  | 290794/360000 [01:22<00:15, 4348.81it/s]prepro_backdoor:  81%|████████  | 291237/360000 [01:22<00:23, 2925.86it/s]prepro_backdoor:  81%|████████  | 291596/360000 [01:22<00:22, 3038.73it/s]prepro_backdoor:  81%|████████  | 292009/360000 [01:22<00:20, 3283.09it/s]prepro_backdoor:  81%|████████▏ | 292531/360000 [01:22<00:17, 3765.97it/s]prepro_backdoor:  81%|████████▏ | 292947/360000 [01:23<00:17, 3740.60it/s]prepro_backdoor:  81%|████████▏ | 293349/360000 [01:23<00:18, 3700.09it/s]prepro_backdoor:  82%|████████▏ | 293831/360000 [01:23<00:16, 3985.47it/s]prepro_backdoor:  82%|████████▏ | 294418/360000 [01:23<00:14, 4484.91it/s]prepro_backdoor:  82%|████████▏ | 294927/360000 [01:23<00:13, 4653.28it/s]prepro_backdoor:  82%|████████▏ | 295444/360000 [01:23<00:13, 4791.52it/s]prepro_backdoor:  82%|████████▏ | 295932/360000 [01:23<00:17, 3659.67it/s]prepro_backdoor:  82%|████████▏ | 296344/360000 [01:23<00:17, 3620.28it/s]prepro_backdoor:  82%|████████▏ | 296750/360000 [01:24<00:17, 3716.10it/s]prepro_backdoor:  83%|████████▎ | 297146/360000 [01:24<00:16, 3734.79it/s]prepro_backdoor:  83%|████████▎ | 297630/360000 [01:24<00:15, 4017.07it/s]prepro_backdoor:  83%|████████▎ | 298047/360000 [01:24<00:15, 3919.72it/s]prepro_backdoor:  83%|████████▎ | 298509/360000 [01:24<00:14, 4100.48it/s]prepro_backdoor:  83%|████████▎ | 298996/360000 [01:24<00:14, 4302.07it/s]prepro_backdoor:  83%|████████▎ | 299434/360000 [01:24<00:14, 4297.76it/s]prepro_backdoor:  83%|████████▎ | 299939/360000 [01:24<00:13, 4511.36it/s]prepro_backdoor:  83%|████████▎ | 300395/360000 [01:24<00:18, 3269.00it/s]prepro_backdoor:  84%|████████▎ | 300836/360000 [01:25<00:16, 3532.86it/s]prepro_backdoor:  84%|████████▎ | 301336/360000 [01:25<00:15, 3895.72it/s]prepro_backdoor:  84%|████████▍ | 301764/360000 [01:25<00:14, 3964.26it/s]prepro_backdoor:  84%|████████▍ | 302204/360000 [01:25<00:14, 4056.79it/s]prepro_backdoor:  84%|████████▍ | 302630/360000 [01:25<00:22, 2550.01it/s]prepro_backdoor:  84%|████████▍ | 303065/360000 [01:25<00:19, 2901.36it/s]prepro_backdoor:  84%|████████▍ | 303448/360000 [01:25<00:18, 3097.30it/s]prepro_backdoor:  84%|████████▍ | 303892/360000 [01:26<00:16, 3400.19it/s]prepro_backdoor:  85%|████████▍ | 304388/360000 [01:26<00:14, 3777.66it/s]prepro_backdoor:  85%|████████▍ | 304807/360000 [01:26<00:14, 3779.96it/s]prepro_backdoor:  85%|████████▍ | 305493/360000 [01:26<00:11, 4601.34it/s]prepro_backdoor:  85%|████████▍ | 305983/360000 [01:26<00:12, 4489.00it/s]prepro_backdoor:  85%|████████▌ | 306453/360000 [01:26<00:12, 4443.06it/s]prepro_backdoor:  85%|████████▌ | 306912/360000 [01:26<00:15, 3478.29it/s]prepro_backdoor:  85%|████████▌ | 307301/360000 [01:26<00:14, 3562.76it/s]prepro_backdoor:  85%|████████▌ | 307688/360000 [01:27<00:15, 3312.34it/s]prepro_backdoor:  86%|████████▌ | 308198/360000 [01:27<00:13, 3737.44it/s]prepro_backdoor:  86%|████████▌ | 308738/360000 [01:27<00:12, 4167.39it/s]prepro_backdoor:  86%|████████▌ | 309179/360000 [01:27<00:12, 4032.75it/s]prepro_backdoor:  86%|████████▌ | 309600/360000 [01:27<00:12, 3996.68it/s]prepro_backdoor:  86%|████████▌ | 310018/360000 [01:27<00:12, 4037.78it/s]prepro_backdoor:  86%|████████▌ | 310440/360000 [01:27<00:12, 4079.42it/s]prepro_backdoor:  86%|████████▋ | 310890/360000 [01:27<00:11, 4176.95it/s]prepro_backdoor:  86%|████████▋ | 311313/360000 [01:27<00:16, 2983.75it/s]prepro_backdoor:  87%|████████▋ | 311713/360000 [01:28<00:15, 3206.12it/s]prepro_backdoor:  87%|████████▋ | 312247/360000 [01:28<00:12, 3706.19it/s]prepro_backdoor:  87%|████████▋ | 312685/360000 [01:28<00:12, 3870.15it/s]prepro_backdoor:  87%|████████▋ | 313103/360000 [01:28<00:11, 3943.12it/s]prepro_backdoor:  87%|████████▋ | 313598/360000 [01:28<00:10, 4221.15it/s]prepro_backdoor:  87%|████████▋ | 314058/360000 [01:28<00:10, 4302.98it/s]prepro_backdoor:  87%|████████▋ | 314502/360000 [01:28<00:11, 4086.49it/s]prepro_backdoor:  87%|████████▋ | 314922/360000 [01:28<00:11, 3911.23it/s]prepro_backdoor:  88%|████████▊ | 315322/360000 [01:29<00:15, 2829.80it/s]prepro_backdoor:  88%|████████▊ | 315696/360000 [01:29<00:14, 3017.75it/s]prepro_backdoor:  88%|████████▊ | 316037/360000 [01:29<00:14, 3102.75it/s]prepro_backdoor:  88%|████████▊ | 316437/360000 [01:29<00:13, 3314.27it/s]prepro_backdoor:  88%|████████▊ | 316857/360000 [01:29<00:12, 3532.58it/s]prepro_backdoor:  88%|████████▊ | 317308/360000 [01:29<00:11, 3780.41it/s]prepro_backdoor:  88%|████████▊ | 317753/360000 [01:29<00:10, 3947.36it/s]prepro_backdoor:  88%|████████▊ | 318160/360000 [01:29<00:10, 3952.20it/s]prepro_backdoor:  88%|████████▊ | 318564/360000 [01:31<00:47, 879.58it/s] prepro_backdoor:  89%|████████▊ | 319001/360000 [01:31<00:35, 1169.73it/s]prepro_backdoor:  89%|████████▉ | 319604/360000 [01:31<00:23, 1685.57it/s]prepro_backdoor:  89%|████████▉ | 320138/360000 [01:31<00:18, 2160.48it/s]prepro_backdoor:  89%|████████▉ | 320585/360000 [01:31<00:15, 2492.16it/s]prepro_backdoor:  89%|████████▉ | 321022/360000 [01:31<00:13, 2798.50it/s]prepro_backdoor:  89%|████████▉ | 321450/360000 [01:31<00:12, 2990.67it/s]prepro_backdoor:  89%|████████▉ | 321859/360000 [01:31<00:11, 3224.01it/s]prepro_backdoor:  90%|████████▉ | 322267/360000 [01:31<00:11, 3413.08it/s]prepro_backdoor:  90%|████████▉ | 322706/360000 [01:32<00:10, 3645.79it/s]prepro_backdoor:  90%|████████▉ | 323167/360000 [01:32<00:09, 3879.81it/s]prepro_backdoor:  90%|████████▉ | 323610/360000 [01:32<00:09, 4024.70it/s]prepro_backdoor:  90%|█████████ | 324040/360000 [01:32<00:12, 2844.00it/s]prepro_backdoor:  90%|█████████ | 324481/360000 [01:32<00:11, 3169.85it/s]prepro_backdoor:  90%|█████████ | 324857/360000 [01:32<00:10, 3263.15it/s]prepro_backdoor:  90%|█████████ | 325340/360000 [01:32<00:09, 3647.02it/s]prepro_backdoor:  90%|█████████ | 325743/360000 [01:32<00:09, 3587.26it/s]prepro_backdoor:  91%|█████████ | 326164/360000 [01:33<00:09, 3751.23it/s]prepro_backdoor:  91%|█████████ | 326626/360000 [01:33<00:08, 3975.97it/s]prepro_backdoor:  91%|█████████ | 327040/360000 [01:33<00:08, 3906.45it/s]prepro_backdoor:  91%|█████████ | 327443/360000 [01:33<00:08, 3922.65it/s]prepro_backdoor:  91%|█████████ | 327844/360000 [01:33<00:08, 3836.95it/s]prepro_backdoor:  91%|█████████ | 328364/360000 [01:33<00:07, 4220.06it/s]prepro_backdoor:  91%|█████████▏| 328793/360000 [01:33<00:11, 2836.18it/s]prepro_backdoor:  91%|█████████▏| 329374/360000 [01:33<00:08, 3466.48it/s]prepro_backdoor:  92%|█████████▏| 329863/360000 [01:34<00:07, 3795.87it/s]prepro_backdoor:  92%|█████████▏| 330300/360000 [01:34<00:07, 3869.93it/s]prepro_backdoor:  92%|█████████▏| 330728/360000 [01:34<00:07, 3942.09it/s]prepro_backdoor:  92%|█████████▏| 331168/360000 [01:34<00:07, 4042.30it/s]prepro_backdoor:  92%|█████████▏| 331594/360000 [01:34<00:07, 4048.76it/s]prepro_backdoor:  92%|█████████▏| 332070/360000 [01:34<00:06, 4245.51it/s]prepro_backdoor:  92%|█████████▏| 332507/360000 [01:34<00:06, 4214.63it/s]prepro_backdoor:  92%|█████████▏| 332966/360000 [01:34<00:06, 4312.79it/s]prepro_backdoor:  93%|█████████▎| 333404/360000 [01:34<00:07, 3368.20it/s]prepro_backdoor:  93%|█████████▎| 333783/360000 [01:35<00:07, 3463.55it/s]prepro_backdoor:  93%|█████████▎| 334236/360000 [01:35<00:06, 3734.88it/s]prepro_backdoor:  93%|█████████▎| 334712/360000 [01:35<00:06, 3992.47it/s]prepro_backdoor:  93%|█████████▎| 335131/360000 [01:35<00:06, 4014.45it/s]prepro_backdoor:  93%|█████████▎| 335621/360000 [01:35<00:05, 4256.24it/s]prepro_backdoor:  93%|█████████▎| 336058/360000 [01:35<00:08, 2788.10it/s]prepro_backdoor:  94%|█████████▎| 336634/360000 [01:35<00:06, 3399.65it/s]prepro_backdoor:  94%|█████████▎| 337081/360000 [01:35<00:06, 3636.36it/s]prepro_backdoor:  94%|█████████▍| 337505/360000 [01:36<00:06, 3595.89it/s]prepro_backdoor:  94%|█████████▍| 338002/360000 [01:36<00:05, 3934.91it/s]prepro_backdoor:  94%|█████████▍| 338432/360000 [01:36<00:05, 4011.39it/s]prepro_backdoor:  94%|█████████▍| 338859/360000 [01:36<00:05, 4030.59it/s]prepro_backdoor:  94%|█████████▍| 339312/360000 [01:36<00:04, 4161.31it/s]prepro_backdoor:  94%|█████████▍| 339872/360000 [01:36<00:04, 4546.02it/s]prepro_backdoor:  95%|█████████▍| 340338/360000 [01:36<00:05, 3479.39it/s]prepro_backdoor:  95%|█████████▍| 340796/360000 [01:36<00:05, 3732.35it/s]prepro_backdoor:  95%|█████████▍| 341241/360000 [01:37<00:04, 3898.14it/s]prepro_backdoor:  95%|█████████▍| 341688/360000 [01:37<00:04, 4039.17it/s]prepro_backdoor:  95%|█████████▌| 342263/360000 [01:37<00:03, 4495.04it/s]prepro_backdoor:  95%|█████████▌| 342733/360000 [01:37<00:03, 4436.19it/s]prepro_backdoor:  95%|█████████▌| 343229/360000 [01:37<00:03, 4561.63it/s]prepro_backdoor:  95%|█████████▌| 343709/360000 [01:37<00:03, 4608.57it/s]prepro_backdoor:  96%|█████████▌| 344181/360000 [01:37<00:03, 4636.95it/s]prepro_backdoor:  96%|█████████▌| 344650/360000 [01:37<00:03, 4525.68it/s]prepro_backdoor:  96%|█████████▌| 345107/360000 [01:38<00:05, 2629.42it/s]prepro_backdoor:  96%|█████████▌| 345528/360000 [01:38<00:04, 2930.97it/s]prepro_backdoor:  96%|█████████▌| 346093/360000 [01:38<00:03, 3514.77it/s]prepro_backdoor:  96%|█████████▋| 346526/360000 [01:38<00:04, 3259.56it/s]prepro_backdoor:  96%|█████████▋| 347029/360000 [01:38<00:03, 3645.75it/s]prepro_backdoor:  97%|█████████▋| 347447/360000 [01:38<00:03, 3573.85it/s]prepro_backdoor:  97%|█████████▋| 347841/360000 [01:38<00:03, 3612.15it/s]prepro_backdoor:  97%|█████████▋| 348245/360000 [01:38<00:03, 3710.24it/s]prepro_backdoor:  97%|█████████▋| 348636/360000 [01:38<00:03, 3731.48it/s]prepro_backdoor:  97%|█████████▋| 349024/360000 [01:39<00:04, 2682.20it/s]prepro_backdoor:  97%|█████████▋| 349419/360000 [01:39<00:03, 2949.65it/s]prepro_backdoor:  97%|█████████▋| 349824/360000 [01:39<00:03, 3197.40it/s]prepro_backdoor:  97%|█████████▋| 350293/360000 [01:39<00:02, 3573.12it/s]prepro_backdoor:  97%|█████████▋| 350685/360000 [01:39<00:02, 3663.77it/s]prepro_backdoor:  98%|█████████▊| 351076/360000 [01:39<00:02, 3592.18it/s]prepro_backdoor:  98%|█████████▊| 351453/360000 [01:39<00:02, 3623.61it/s]prepro_backdoor:  98%|█████████▊| 351958/360000 [01:39<00:02, 4017.68it/s]prepro_backdoor:  98%|█████████▊| 352381/360000 [01:40<00:01, 4075.38it/s]prepro_backdoor:  98%|█████████▊| 352829/360000 [01:40<00:01, 4183.19it/s]prepro_backdoor:  98%|█████████▊| 353254/360000 [01:40<00:02, 3272.15it/s]prepro_backdoor:  98%|█████████▊| 353672/360000 [01:40<00:01, 3493.39it/s]prepro_backdoor:  98%|█████████▊| 354051/360000 [01:40<00:01, 3226.13it/s]prepro_backdoor:  98%|█████████▊| 354397/360000 [01:40<00:02, 2698.85it/s]prepro_backdoor:  99%|█████████▊| 354859/360000 [01:40<00:01, 3127.98it/s]prepro_backdoor:  99%|█████████▊| 355205/360000 [01:40<00:01, 3180.42it/s]prepro_backdoor:  99%|█████████▉| 355730/360000 [01:41<00:01, 3694.65it/s]prepro_backdoor:  99%|█████████▉| 356124/360000 [01:41<00:01, 3726.17it/s]prepro_backdoor:  99%|█████████▉| 356514/360000 [01:41<00:00, 3755.92it/s]prepro_backdoor:  99%|█████████▉| 356940/360000 [01:41<00:00, 3895.67it/s]prepro_backdoor:  99%|█████████▉| 357395/360000 [01:41<00:00, 4082.71it/s]prepro_backdoor:  99%|█████████▉| 357811/360000 [01:41<00:00, 4047.86it/s]prepro_backdoor: 100%|█████████▉| 358239/360000 [01:41<00:00, 4113.44it/s]prepro_backdoor: 100%|█████████▉| 358655/360000 [01:41<00:00, 2650.80it/s]prepro_backdoor: 100%|█████████▉| 359099/360000 [01:42<00:00, 3028.20it/s]prepro_backdoor: 100%|█████████▉| 359584/360000 [01:42<00:00, 3441.51it/s]prepro_backdoor: 100%|██████████| 360000/360000 [01:42<00:00, 3520.73it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:5600.0,real pratio:0.8
2024-12-23:01:43:02 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:5600.0,real pratio:0.8
INFO:root:save file format is .png
2024-12-23:01:43:02 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/7000 [00:00<?, ?it/s]prepro_backdoor:  20%|██        | 1430/7000 [00:00<00:00, 14273.78it/s]prepro_backdoor:  41%|████      | 2858/7000 [00:04<00:08, 492.11it/s]  prepro_backdoor:  49%|████▉     | 3464/7000 [00:06<00:07, 448.50it/s]prepro_backdoor:  54%|█████▍    | 3810/7000 [00:07<00:07, 429.79it/s]prepro_backdoor:  58%|█████▊    | 4034/7000 [00:08<00:06, 426.89it/s]prepro_backdoor:  60%|█████▉    | 4192/7000 [00:08<00:06, 401.36it/s]prepro_backdoor:  62%|██████▏   | 4306/7000 [00:09<00:06, 400.62it/s]prepro_backdoor:  63%|██████▎   | 4396/7000 [00:09<00:06, 403.33it/s]prepro_backdoor:  64%|██████▍   | 4471/7000 [00:09<00:06, 405.39it/s]prepro_backdoor:  65%|██████▍   | 4536/7000 [00:09<00:06, 408.14it/s]prepro_backdoor:  66%|██████▌   | 4594/7000 [00:09<00:05, 410.77it/s]prepro_backdoor:  66%|██████▋   | 4648/7000 [00:09<00:06, 362.57it/s]prepro_backdoor:  67%|██████▋   | 4692/7000 [00:10<00:06, 370.03it/s]prepro_backdoor:  68%|██████▊   | 4736/7000 [00:10<00:05, 378.58it/s]prepro_backdoor:  68%|██████▊   | 4779/7000 [00:10<00:05, 386.70it/s]prepro_backdoor:  69%|██████▉   | 4822/7000 [00:10<00:05, 395.02it/s]prepro_backdoor:  70%|██████▉   | 4865/7000 [00:10<00:05, 400.31it/s]prepro_backdoor:  70%|███████   | 4908/7000 [00:10<00:05, 405.97it/s]prepro_backdoor:  71%|███████   | 4952/7000 [00:10<00:04, 412.58it/s]prepro_backdoor:  71%|███████▏  | 4997/7000 [00:10<00:04, 421.05it/s]prepro_backdoor:  72%|███████▏  | 5041/7000 [00:10<00:04, 424.09it/s]prepro_backdoor:  73%|███████▎  | 5085/7000 [00:10<00:04, 421.26it/s]prepro_backdoor:  73%|███████▎  | 5128/7000 [00:11<00:06, 289.94it/s]prepro_backdoor:  74%|███████▍  | 5170/7000 [00:11<00:05, 317.35it/s]prepro_backdoor:  74%|███████▍  | 5212/7000 [00:11<00:05, 340.02it/s]prepro_backdoor:  75%|███████▌  | 5254/7000 [00:11<00:04, 358.31it/s]prepro_backdoor:  76%|███████▌  | 5296/7000 [00:11<00:04, 373.61it/s]prepro_backdoor:  76%|███████▋  | 5339/7000 [00:11<00:04, 386.70it/s]prepro_backdoor:  77%|███████▋  | 5381/7000 [00:11<00:04, 395.71it/s]prepro_backdoor:  77%|███████▋  | 5423/7000 [00:11<00:03, 400.48it/s]prepro_backdoor:  78%|███████▊  | 5465/7000 [00:12<00:03, 403.73it/s]prepro_backdoor:  79%|███████▊  | 5508/7000 [00:12<00:03, 408.44it/s]prepro_backdoor:  79%|███████▉  | 5550/7000 [00:12<00:04, 309.40it/s]prepro_backdoor:  80%|███████▉  | 5592/7000 [00:12<00:04, 334.26it/s]prepro_backdoor:  80%|████████  | 5631/7000 [00:12<00:03, 346.61it/s]prepro_backdoor:  81%|████████  | 5669/7000 [00:12<00:03, 353.73it/s]prepro_backdoor:  82%|████████▏ | 5711/7000 [00:12<00:03, 370.56it/s]prepro_backdoor:  82%|████████▏ | 5753/7000 [00:12<00:03, 382.11it/s]prepro_backdoor:  83%|████████▎ | 5796/7000 [00:12<00:03, 394.65it/s]prepro_backdoor:  83%|████████▎ | 5838/7000 [00:13<00:02, 399.70it/s]prepro_backdoor:  84%|████████▍ | 5880/7000 [00:13<00:02, 403.73it/s]prepro_backdoor:  85%|████████▍ | 5921/7000 [00:13<00:02, 404.36it/s]prepro_backdoor:  85%|████████▌ | 5962/7000 [00:13<00:03, 301.65it/s]prepro_backdoor:  86%|████████▌ | 5997/7000 [00:13<00:05, 184.74it/s]prepro_backdoor:  86%|████████▋ | 6039/7000 [00:13<00:04, 223.50it/s]prepro_backdoor:  87%|████████▋ | 6080/7000 [00:14<00:03, 259.01it/s]prepro_backdoor:  87%|████████▋ | 6123/7000 [00:14<00:02, 294.84it/s]prepro_backdoor:  88%|████████▊ | 6165/7000 [00:14<00:02, 323.54it/s]prepro_backdoor:  89%|████████▊ | 6208/7000 [00:14<00:02, 349.65it/s]prepro_backdoor:  89%|████████▉ | 6250/7000 [00:14<00:02, 366.47it/s]prepro_backdoor:  90%|████████▉ | 6292/7000 [00:14<00:01, 379.81it/s]prepro_backdoor:  90%|█████████ | 6333/7000 [00:14<00:01, 388.12it/s]prepro_backdoor:  91%|█████████ | 6374/7000 [00:14<00:01, 391.91it/s]prepro_backdoor:  92%|█████████▏| 6416/7000 [00:14<00:01, 398.82it/s]prepro_backdoor:  92%|█████████▏| 6457/7000 [00:15<00:01, 297.17it/s]prepro_backdoor:  93%|█████████▎| 6499/7000 [00:15<00:01, 324.73it/s]prepro_backdoor:  93%|█████████▎| 6542/7000 [00:15<00:01, 349.37it/s]prepro_backdoor:  94%|█████████▍| 6583/7000 [00:15<00:01, 365.23it/s]prepro_backdoor:  95%|█████████▍| 6625/7000 [00:15<00:00, 380.00it/s]prepro_backdoor:  95%|█████████▌| 6667/7000 [00:15<00:00, 388.87it/s]prepro_backdoor:  96%|█████████▌| 6709/7000 [00:15<00:00, 396.83it/s]prepro_backdoor:  96%|█████████▋| 6750/7000 [00:15<00:00, 399.79it/s]prepro_backdoor:  97%|█████████▋| 6791/7000 [00:15<00:00, 400.67it/s]prepro_backdoor:  98%|█████████▊| 6832/7000 [00:16<00:00, 402.34it/s]prepro_backdoor:  98%|█████████▊| 6876/7000 [00:16<00:00, 410.74it/s]prepro_backdoor:  99%|█████████▉| 6918/7000 [00:16<00:00, 303.65it/s]prepro_backdoor:  99%|█████████▉| 6960/7000 [00:16<00:00, 329.68it/s]prepro_backdoor: 100%|██████████| 7000/7000 [00:16<00:00, 423.20it/s]
INFO:root:stage2 start
2024-12-23:01:43:19 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2024-12-23:01:43:19 [INFO    ] [trainer_cls.py:977] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2024-12-23:01:43:20 [INFO    ] [trainer_cls.py:1035] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 268.1902770996094 s
2024-12-23:01:47:48 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.1902770996094 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.296061323447661,
 'clean_test_loss_avg_over_batch': 1.6267663435502486,
 'epoch': 0,
 'test_acc': 0.201,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.26688355707681366,
 'train_acc_clean_only': 0.1993628489050509,
 'train_asr_bd_only': 0.8745624270711785,
 'train_epoch_loss_avg_over_batch': 1.8940158920895154,
 'train_ra_bd_only': 0.20175584819692172}
2024-12-23:01:47:53 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.296061323447661,
 'clean_test_loss_avg_over_batch': 1.6267663435502486,
 'epoch': 0,
 'test_acc': 0.201,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.26688355707681366,
 'train_acc_clean_only': 0.1993628489050509,
 'train_asr_bd_only': 0.8745624270711785,
 'train_epoch_loss_avg_over_batch': 1.8940158920895154,
 'train_ra_bd_only': 0.20175584819692172}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.6608576774597 s
2024-12-23:01:52:19 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.6608576774597 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2234215275807814,
 'clean_test_loss_avg_over_batch': 1.63986684625799,
 'epoch': 1,
 'test_acc': 0.20142857142857143,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.00125,
 'train_acc': 0.27738820234708395,
 'train_acc_clean_only': 0.20008766974436862,
 'train_asr_bd_only': 0.9731058816992193,
 'train_epoch_loss_avg_over_batch': 1.6661626285797841,
 'train_ra_bd_only': 0.2014002722751646}
2024-12-23:01:52:24 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2234215275807814,
 'clean_test_loss_avg_over_batch': 1.63986684625799,
 'epoch': 1,
 'test_acc': 0.20142857142857143,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.00125,
 'train_acc': 0.27738820234708395,
 'train_acc_clean_only': 0.20008766974436862,
 'train_asr_bd_only': 0.9731058816992193,
 'train_epoch_loss_avg_over_batch': 1.6661626285797841,
 'train_ra_bd_only': 0.2014002722751646}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.23049664497375 s
2024-12-23:01:56:51 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.23049664497375 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2423677281899885,
 'clean_test_loss_avg_over_batch': 1.6310196204618974,
 'epoch': 2,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.2783272581792319,
 'train_acc_clean_only': 0.1999672776889405,
 'train_asr_bd_only': 0.9834713039613312,
 'train_epoch_loss_avg_over_batch': 1.5973023923158984,
 'train_ra_bd_only': 0.2010389466081449}
2024-12-23:01:56:56 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2423677281899885,
 'clean_test_loss_avg_over_batch': 1.6310196204618974,
 'epoch': 2,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.2783272581792319,
 'train_acc_clean_only': 0.1999672776889405,
 'train_asr_bd_only': 0.9834713039613312,
 'train_epoch_loss_avg_over_batch': 1.5973023923158984,
 'train_ra_bd_only': 0.2010389466081449}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.32066679000854 s
2024-12-23:02:01:23 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.32066679000854 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.223728055303747,
 'clean_test_loss_avg_over_batch': 1.6353893518447875,
 'epoch': 3,
 'test_acc': 0.2007142857142857,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0005357142857142857,
 'train_acc': 0.27932465771692744,
 'train_acc_clean_only': 0.19997221707723653,
 'train_asr_bd_only': 0.9934437159684409,
 'train_epoch_loss_avg_over_batch': 1.5929856722588898,
 'train_ra_bd_only': 0.20107789754417157}
2024-12-23:02:01:28 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.223728055303747,
 'clean_test_loss_avg_over_batch': 1.6353893518447875,
 'epoch': 3,
 'test_acc': 0.2007142857142857,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0005357142857142857,
 'train_acc': 0.27932465771692744,
 'train_acc_clean_only': 0.19997221707723653,
 'train_asr_bd_only': 0.9934437159684409,
 'train_epoch_loss_avg_over_batch': 1.5929856722588898,
 'train_ra_bd_only': 0.20107789754417157}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.36436796188354 s
2024-12-23:02:05:54 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.36436796188354 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.278797228227962,
 'clean_test_loss_avg_over_batch': 1.6253528161482378,
 'epoch': 4,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.0,
 'train_acc': 0.27940522759601705,
 'train_acc_clean_only': 0.19991418269824415,
 'train_asr_bd_only': 0.9948599688819738,
 'train_epoch_loss_avg_over_batch': 1.5920425636076487,
 'train_ra_bd_only': 0.20121138030673483}
2024-12-23:02:05:59 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.278797228227962,
 'clean_test_loss_avg_over_batch': 1.6253528161482378,
 'epoch': 4,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.0,
 'train_acc': 0.27940522759601705,
 'train_acc_clean_only': 0.19991418269824415,
 'train_asr_bd_only': 0.9948599688819738,
 'train_epoch_loss_avg_over_batch': 1.5920425636076487,
 'train_ra_bd_only': 0.20121138030673483}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.1857485771179 s
2024-12-23:02:10:25 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.1857485771179 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2596491168845783,
 'clean_test_loss_avg_over_batch': 1.6197900316931986,
 'epoch': 5,
 'test_acc': 0.202,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.00125,
 'train_acc': 0.2801470261379801,
 'train_acc_clean_only': 0.20290669317346932,
 'train_asr_bd_only': 0.9753014391287437,
 'train_epoch_loss_avg_over_batch': 1.5883252656731124,
 'train_ra_bd_only': 0.20428404734122355}
2024-12-23:02:10:31 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2596491168845783,
 'clean_test_loss_avg_over_batch': 1.6197900316931986,
 'epoch': 5,
 'test_acc': 0.202,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.00125,
 'train_acc': 0.2801470261379801,
 'train_acc_clean_only': 0.20290669317346932,
 'train_asr_bd_only': 0.9753014391287437,
 'train_epoch_loss_avg_over_batch': 1.5883252656731124,
 'train_ra_bd_only': 0.20428404734122355}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.4896972179413 s
2024-12-23:02:14:56 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.4896972179413 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.273507299748334,
 'clean_test_loss_avg_over_batch': 1.5975276188416914,
 'epoch': 6,
 'test_acc': 0.23914285714285713,
 'test_asr': 0.9496428571428571,
 'test_ra': 0.023392857142857142,
 'train_acc': 0.287109375,
 'train_acc_clean_only': 0.21637623670684838,
 'train_asr_bd_only': 0.9237587174571421,
 'train_epoch_loss_avg_over_batch': 1.5742344771900014,
 'train_ra_bd_only': 0.21874913172737628}
2024-12-23:02:15:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.273507299748334,
 'clean_test_loss_avg_over_batch': 1.5975276188416914,
 'epoch': 6,
 'test_acc': 0.23914285714285713,
 'test_asr': 0.9496428571428571,
 'test_ra': 0.023392857142857142,
 'train_acc': 0.287109375,
 'train_acc_clean_only': 0.21637623670684838,
 'train_asr_bd_only': 0.9237587174571421,
 'train_epoch_loss_avg_over_batch': 1.5742344771900014,
 'train_ra_bd_only': 0.21874913172737628}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 269.23382115364075 s
2024-12-23:02:19:31 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 269.23382115364075 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.3807154650037938,
 'clean_test_loss_avg_over_batch': 1.4617481730201027,
 'epoch': 7,
 'test_acc': 0.467,
 'test_asr': 0.6151785714285715,
 'test_ra': 0.22017857142857142,
 'train_acc': 0.33582914740398295,
 'train_acc_clean_only': 0.2929647465580046,
 'train_asr_bd_only': 0.7215801755750639,
 'train_epoch_loss_avg_over_batch': 1.4915719564320522,
 'train_ra_bd_only': 0.29778308700966777}
2024-12-23:02:19:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.3807154650037938,
 'clean_test_loss_avg_over_batch': 1.4617481730201027,
 'epoch': 7,
 'test_acc': 0.467,
 'test_asr': 0.6151785714285715,
 'test_ra': 0.22017857142857142,
 'train_acc': 0.33582914740398295,
 'train_acc_clean_only': 0.2929647465580046,
 'train_asr_bd_only': 0.7215801755750639,
 'train_epoch_loss_avg_over_batch': 1.4915719564320522,
 'train_ra_bd_only': 0.29778308700966777}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8193461894989 s
2024-12-23:02:24:01 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.8193461894989 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.5006179836663334,
 'clean_test_loss_avg_over_batch': 1.3778063893318175,
 'epoch': 8,
 'test_acc': 0.6551428571428571,
 'test_asr': 0.32375,
 'test_ra': 0.4125,
 'train_acc': 0.4287651137980085,
 'train_acc_clean_only': 0.42163103271573305,
 'train_asr_bd_only': 0.4929710507306773,
 'train_epoch_loss_avg_over_batch': 1.3172975840049652,
 'train_ra_bd_only': 0.42801578040784577}
2024-12-23:02:24:07 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.5006179836663334,
 'clean_test_loss_avg_over_batch': 1.3778063893318175,
 'epoch': 8,
 'test_acc': 0.6551428571428571,
 'test_asr': 0.32375,
 'test_ra': 0.4125,
 'train_acc': 0.4287651137980085,
 'train_acc_clean_only': 0.42163103271573305,
 'train_asr_bd_only': 0.4929710507306773,
 'train_epoch_loss_avg_over_batch': 1.3172975840049652,
 'train_ra_bd_only': 0.42801578040784577}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.2742006778717 s
2024-12-23:02:28:33 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.2742006778717 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.6186449067159132,
 'clean_test_loss_avg_over_batch': 1.269265685298226,
 'epoch': 9,
 'test_acc': 0.7055714285714285,
 'test_asr': 0.24517857142857144,
 'test_ra': 0.4907142857142857,
 'train_acc': 0.5344672386201992,
 'train_acc_clean_only': 0.5510403161079213,
 'train_asr_bd_only': 0.3853205911767974,
 'train_epoch_loss_avg_over_batch': 1.086020001730912,
 'train_ra_bd_only': 0.5545060562284698}
2024-12-23:02:28:39 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.6186449067159132,
 'clean_test_loss_avg_over_batch': 1.269265685298226,
 'epoch': 9,
 'test_acc': 0.7055714285714285,
 'test_asr': 0.24517857142857144,
 'test_ra': 0.4907142857142857,
 'train_acc': 0.5344672386201992,
 'train_acc_clean_only': 0.5510403161079213,
 'train_asr_bd_only': 0.3853205911767974,
 'train_epoch_loss_avg_over_batch': 1.086020001730912,
 'train_ra_bd_only': 0.5545060562284698}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.52535223960876 s
2024-12-23:02:33:05 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.52535223960876 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.056684386553983626,
 'clean_test_loss_avg_over_batch': 1.5459458372809671,
 'epoch': 10,
 'test_acc': 0.6921428571428572,
 'test_asr': 0.97625,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.616390136024182,
 'train_acc_clean_only': 0.6275694948216518,
 'train_asr_bd_only': 0.5157678308466005,
 'train_epoch_loss_avg_over_batch': 0.8949776149194576,
 'train_ra_bd_only': 0.5181295323830958}
2024-12-23:02:33:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.056684386553983626,
 'clean_test_loss_avg_over_batch': 1.5459458372809671,
 'epoch': 10,
 'test_acc': 0.6921428571428572,
 'test_asr': 0.97625,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.616390136024182,
 'train_acc_clean_only': 0.6275694948216518,
 'train_asr_bd_only': 0.5157678308466005,
 'train_epoch_loss_avg_over_batch': 0.8949776149194576,
 'train_ra_bd_only': 0.5181295323830958}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.31479692459106 s
2024-12-23:02:37:36 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.31479692459106 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0457967043092305,
 'clean_test_loss_avg_over_batch': 1.4107328284870495,
 'epoch': 11,
 'test_acc': 0.7595714285714286,
 'test_asr': 0.9826785714285714,
 'test_ra': 0.013392857142857142,
 'train_acc': 0.6828352818278806,
 'train_acc_clean_only': 0.6815911490328516,
 'train_asr_bd_only': 0.6940323387231205,
 'train_epoch_loss_avg_over_batch': 0.73768311591652,
 'train_ra_bd_only': 0.4153747846863366}
2024-12-23:02:37:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0457967043092305,
 'clean_test_loss_avg_over_batch': 1.4107328284870495,
 'epoch': 11,
 'test_acc': 0.7595714285714286,
 'test_asr': 0.9826785714285714,
 'test_ra': 0.013392857142857142,
 'train_acc': 0.6828352818278806,
 'train_acc_clean_only': 0.6815911490328516,
 'train_asr_bd_only': 0.6940323387231205,
 'train_epoch_loss_avg_over_batch': 0.73768311591652,
 'train_ra_bd_only': 0.4153747846863366}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.7116906642914 s
2024-12-23:02:42:09 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.7116906642914 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04591412894131446,
 'clean_test_loss_avg_over_batch': 1.3179534429853612,
 'epoch': 12,
 'test_acc': 0.7594285714285715,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.72404260757468,
 'train_acc_clean_only': 0.7264465463166473,
 'train_asr_bd_only': 0.7024060902422761,
 'train_epoch_loss_avg_over_batch': 0.6465890171856833,
 'train_ra_bd_only': 0.4195654589908869}
2024-12-23:02:42:14 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04591412894131446,
 'clean_test_loss_avg_over_batch': 1.3179534429853612,
 'epoch': 12,
 'test_acc': 0.7594285714285715,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.72404260757468,
 'train_acc_clean_only': 0.7264465463166473,
 'train_asr_bd_only': 0.7024060902422761,
 'train_epoch_loss_avg_over_batch': 0.6465890171856833,
 'train_ra_bd_only': 0.4195654589908869}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 269.18252515792847 s
2024-12-23:02:46:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 269.18252515792847 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.08747583209663969,
 'clean_test_loss_avg_over_batch': 1.4223892125216397,
 'epoch': 13,
 'test_acc': 0.7555714285714286,
 'test_asr': 0.9694642857142857,
 'test_ra': 0.025892857142857145,
 'train_acc': 0.7506306676742532,
 'train_acc_clean_only': 0.7566137566137566,
 'train_asr_bd_only': 0.696776882467352,
 'train_epoch_loss_avg_over_batch': 0.5841039120833023,
 'train_ra_bd_only': 0.43189774937482633}
2024-12-23:02:46:49 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.08747583209663969,
 'clean_test_loss_avg_over_batch': 1.4223892125216397,
 'epoch': 13,
 'test_acc': 0.7555714285714286,
 'test_asr': 0.9694642857142857,
 'test_ra': 0.025892857142857145,
 'train_acc': 0.7506306676742532,
 'train_acc_clean_only': 0.7566137566137566,
 'train_asr_bd_only': 0.696776882467352,
 'train_epoch_loss_avg_over_batch': 0.5841039120833023,
 'train_ra_bd_only': 0.43189774937482633}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.3271543979645 s
2024-12-23:02:51:15 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.3271543979645 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0970886972182515,
 'clean_test_loss_avg_over_batch': 1.7520854592323303,
 'epoch': 14,
 'test_acc': 0.7624285714285715,
 'test_asr': 0.9685714285714285,
 'test_ra': 0.025,
 'train_acc': 0.7703980707681366,
 'train_acc_clean_only': 0.7784733734021109,
 'train_asr_bd_only': 0.6977190009168449,
 'train_epoch_loss_avg_over_batch': 0.5393134548009544,
 'train_ra_bd_only': 0.43772400188925625}
2024-12-23:02:51:21 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0970886972182515,
 'clean_test_loss_avg_over_batch': 1.7520854592323303,
 'epoch': 14,
 'test_acc': 0.7624285714285715,
 'test_asr': 0.9685714285714285,
 'test_ra': 0.025,
 'train_acc': 0.7703980707681366,
 'train_acc_clean_only': 0.7784733734021109,
 'train_asr_bd_only': 0.6977190009168449,
 'train_epoch_loss_avg_over_batch': 0.5393134548009544,
 'train_ra_bd_only': 0.43772400188925625}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.06611490249634 s
2024-12-23:02:55:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.06611490249634 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3935508354360619,
 'clean_test_loss_avg_over_batch': 3.0268147945404054,
 'epoch': 15,
 'test_acc': 0.7851428571428571,
 'test_asr': 0.9758928571428571,
 'test_ra': 0.010892857142857143,
 'train_acc': 0.7851840327169275,
 'train_acc_clean_only': 0.7952893238049669,
 'train_asr_bd_only': 0.694229112833764,
 'train_epoch_loss_avg_over_batch': 0.505451303966354,
 'train_ra_bd_only': 0.4448056458559084}
2024-12-23:02:55:52 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3935508354360619,
 'clean_test_loss_avg_over_batch': 3.0268147945404054,
 'epoch': 15,
 'test_acc': 0.7851428571428571,
 'test_asr': 0.9758928571428571,
 'test_ra': 0.010892857142857143,
 'train_acc': 0.7851840327169275,
 'train_acc_clean_only': 0.7952893238049669,
 'train_asr_bd_only': 0.694229112833764,
 'train_epoch_loss_avg_over_batch': 0.505451303966354,
 'train_ra_bd_only': 0.4448056458559084}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.87963461875916 s
2024-12-23:03:00:20 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.87963461875916 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3217821016759527,
 'clean_test_loss_avg_over_batch': 1.378995587609031,
 'epoch': 16,
 'test_acc': 0.7812857142857143,
 'test_asr': 0.9603571428571429,
 'test_ra': 0.027678571428571427,
 'train_acc': 0.7964860419630156,
 'train_acc_clean_only': 0.8082058152564819,
 'train_asr_bd_only': 0.6910126406445339,
 'train_epoch_loss_avg_over_batch': 0.4798744494892964,
 'train_ra_bd_only': 0.4494235310459786}
2024-12-23:03:00:25 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3217821016759527,
 'clean_test_loss_avg_over_batch': 1.378995587609031,
 'epoch': 16,
 'test_acc': 0.7812857142857143,
 'test_asr': 0.9603571428571429,
 'test_ra': 0.027678571428571427,
 'train_acc': 0.7964860419630156,
 'train_acc_clean_only': 0.8082058152564819,
 'train_asr_bd_only': 0.6910126406445339,
 'train_epoch_loss_avg_over_batch': 0.4798744494892964,
 'train_ra_bd_only': 0.4494235310459786}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.9185507297516 s
2024-12-23:03:04:50 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.9185507297516 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 3.6124213080122654,
 'clean_test_loss_avg_over_batch': 1.448784007809379,
 'epoch': 17,
 'test_acc': 0.7721428571428571,
 'test_asr': 0.94875,
 'test_ra': 0.008214285714285714,
 'train_acc': 0.8056515602773826,
 'train_acc_clean_only': 0.8181559994690326,
 'train_asr_bd_only': 0.6931303647323537,
 'train_epoch_loss_avg_over_batch': 0.457969307295374,
 'train_ra_bd_only': 0.4497069363037862}
2024-12-23:03:04:55 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 3.6124213080122654,
 'clean_test_loss_avg_over_batch': 1.448784007809379,
 'epoch': 17,
 'test_acc': 0.7721428571428571,
 'test_asr': 0.94875,
 'test_ra': 0.008214285714285714,
 'train_acc': 0.8056515602773826,
 'train_acc_clean_only': 0.8181559994690326,
 'train_asr_bd_only': 0.6931303647323537,
 'train_epoch_loss_avg_over_batch': 0.457969307295374,
 'train_ra_bd_only': 0.4497069363037862}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.14644408226013 s
2024-12-23:03:09:23 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.14644408226013 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07169031284072182,
 'clean_test_loss_avg_over_batch': 1.319159215146845,
 'epoch': 18,
 'test_acc': 0.7748571428571429,
 'test_asr': 0.9764285714285714,
 'test_ra': 0.02107142857142857,
 'train_acc': 0.8120110241820768,
 'train_acc_clean_only': 0.8255757238994875,
 'train_asr_bd_only': 0.6899377708634292,
 'train_epoch_loss_avg_over_batch': 0.4447613153527166,
 'train_ra_bd_only': 0.4548283142571397}
2024-12-23:03:09:28 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07169031284072182,
 'clean_test_loss_avg_over_batch': 1.319159215146845,
 'epoch': 18,
 'test_acc': 0.7748571428571429,
 'test_asr': 0.9764285714285714,
 'test_ra': 0.02107142857142857,
 'train_acc': 0.8120110241820768,
 'train_acc_clean_only': 0.8255757238994875,
 'train_asr_bd_only': 0.6899377708634292,
 'train_epoch_loss_avg_over_batch': 0.4447613153527166,
 'train_ra_bd_only': 0.4548283142571397}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.17597699165344 s
2024-12-23:03:13:57 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.17597699165344 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013494678080116335,
 'clean_test_loss_avg_over_batch': 1.3998691336675124,
 'epoch': 19,
 'test_acc': 0.796,
 'test_asr': 0.9953571428571428,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.8197846283783784,
 'train_acc_clean_only': 0.8339229486942026,
 'train_asr_bd_only': 0.6925491721302367,
 'train_epoch_loss_avg_over_batch': 0.4295944265311168,
 'train_ra_bd_only': 0.45538393154794976}
2024-12-23:03:14:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013494678080116335,
 'clean_test_loss_avg_over_batch': 1.3998691336675124,
 'epoch': 19,
 'test_acc': 0.796,
 'test_asr': 0.9953571428571428,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.8197846283783784,
 'train_acc_clean_only': 0.8339229486942026,
 'train_asr_bd_only': 0.6925491721302367,
 'train_epoch_loss_avg_over_batch': 0.4295944265311168,
 'train_ra_bd_only': 0.45538393154794976}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.07996129989624 s
2024-12-23:03:18:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.07996129989624 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04283406930070752,
 'clean_test_loss_avg_over_batch': 1.3856310242956336,
 'epoch': 20,
 'test_acc': 0.7892857142857143,
 'test_asr': 0.9835714285714285,
 'test_ra': 0.013035714285714286,
 'train_acc': 0.8258690433854907,
 'train_acc_clean_only': 0.8406901256710327,
 'train_asr_bd_only': 0.6924850673704681,
 'train_epoch_loss_avg_over_batch': 0.4173153427881248,
 'train_ra_bd_only': 0.4569245728573413}
2024-12-23:03:18:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04283406930070752,
 'clean_test_loss_avg_over_batch': 1.3856310242956336,
 'epoch': 20,
 'test_acc': 0.7892857142857143,
 'test_asr': 0.9835714285714285,
 'test_ra': 0.013035714285714286,
 'train_acc': 0.8258690433854907,
 'train_acc_clean_only': 0.8406901256710327,
 'train_asr_bd_only': 0.6924850673704681,
 'train_epoch_loss_avg_over_batch': 0.4173153427881248,
 'train_ra_bd_only': 0.4569245728573413}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.4247124195099 s
2024-12-23:03:23:03 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.4247124195099 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005035625398291318,
 'clean_test_loss_avg_over_batch': 1.4099625435742464,
 'epoch': 21,
 'test_acc': 0.7637142857142857,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.8319534583926032,
 'train_acc_clean_only': 0.8475102101295598,
 'train_asr_bd_only': 0.6919400994637847,
 'train_epoch_loss_avg_over_batch': 0.4041052454841425,
 'train_ra_bd_only': 0.45825577195565803}
2024-12-23:03:23:09 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005035625398291318,
 'clean_test_loss_avg_over_batch': 1.4099625435742464,
 'epoch': 21,
 'test_acc': 0.7637142857142857,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.8319534583926032,
 'train_acc_clean_only': 0.8475102101295598,
 'train_asr_bd_only': 0.6919400994637847,
 'train_epoch_loss_avg_over_batch': 0.4041052454841425,
 'train_ra_bd_only': 0.45825577195565803}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.7226119041443 s
2024-12-23:03:27:36 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.7226119041443 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0450455112202855,
 'clean_test_loss_avg_over_batch': 1.3584608999165622,
 'epoch': 22,
 'test_acc': 0.7725714285714286,
 'test_asr': 0.9894642857142857,
 'test_ra': 0.007678571428571429,
 'train_acc': 0.8366709637268848,
 'train_acc_clean_only': 0.8530367809350353,
 'train_asr_bd_only': 0.6893667861409797,
 'train_epoch_loss_avg_over_batch': 0.3956264395208481,
 'train_ra_bd_only': 0.4602261676530244}
2024-12-23:03:27:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0450455112202855,
 'clean_test_loss_avg_over_batch': 1.3584608999165622,
 'epoch': 22,
 'test_acc': 0.7725714285714286,
 'test_asr': 0.9894642857142857,
 'test_ra': 0.007678571428571429,
 'train_acc': 0.8366709637268848,
 'train_acc_clean_only': 0.8530367809350353,
 'train_asr_bd_only': 0.6893667861409797,
 'train_epoch_loss_avg_over_batch': 0.3956264395208481,
 'train_ra_bd_only': 0.4602261676530244}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.3493616580963 s
2024-12-23:03:32:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.3493616580963 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.019201869879907463,
 'clean_test_loss_avg_over_batch': 1.3242597899653694,
 'epoch': 23,
 'test_acc': 0.7952857142857143,
 'test_asr': 0.9923214285714286,
 'test_ra': 0.007321428571428572,
 'train_acc': 0.8425275604551921,
 'train_acc_clean_only': 0.8595538048830181,
 'train_asr_bd_only': 0.6893074422868573,
 'train_epoch_loss_avg_over_batch': 0.38524800722366714,
 'train_ra_bd_only': 0.4653998944356474}
2024-12-23:03:32:13 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.019201869879907463,
 'clean_test_loss_avg_over_batch': 1.3242597899653694,
 'epoch': 23,
 'test_acc': 0.7952857142857143,
 'test_asr': 0.9923214285714286,
 'test_ra': 0.007321428571428572,
 'train_acc': 0.8425275604551921,
 'train_acc_clean_only': 0.8595538048830181,
 'train_asr_bd_only': 0.6893074422868573,
 'train_epoch_loss_avg_over_batch': 0.38524800722366714,
 'train_ra_bd_only': 0.4653998944356474}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.5595738887787 s
2024-12-23:03:36:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.5595738887787 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010225460020592436,
 'clean_test_loss_avg_over_batch': 1.3502661881121722,
 'epoch': 24,
 'test_acc': 0.7608571428571429,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8469727951635846,
 'train_acc_clean_only': 0.863816388584482,
 'train_asr_bd_only': 0.6953682865160734,
 'train_epoch_loss_avg_over_batch': 0.37561343120116936,
 'train_ra_bd_only': 0.46239337612180825}
2024-12-23:03:36:52 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010225460020592436,
 'clean_test_loss_avg_over_batch': 1.3502661881121722,
 'epoch': 24,
 'test_acc': 0.7608571428571429,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8469727951635846,
 'train_acc_clean_only': 0.863816388584482,
 'train_asr_bd_only': 0.6953682865160734,
 'train_epoch_loss_avg_over_batch': 0.37561343120116936,
 'train_ra_bd_only': 0.46239337612180825}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 269.26318407058716 s
2024-12-23:03:41:22 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 269.26318407058716 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0033832732063853077,
 'clean_test_loss_avg_over_batch': 1.2975261997092853,
 'epoch': 25,
 'test_acc': 0.7931428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.8509568367709816,
 'train_acc_clean_only': 0.8686849042741691,
 'train_asr_bd_only': 0.6913864962489581,
 'train_epoch_loss_avg_over_batch': 0.3689210476409405,
 'train_ra_bd_only': 0.46440677966101696}
2024-12-23:03:41:27 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0033832732063853077,
 'clean_test_loss_avg_over_batch': 1.2975261997092853,
 'epoch': 25,
 'test_acc': 0.7931428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.8509568367709816,
 'train_acc_clean_only': 0.8686849042741691,
 'train_asr_bd_only': 0.6913864962489581,
 'train_epoch_loss_avg_over_batch': 0.3689210476409405,
 'train_ra_bd_only': 0.46440677966101696}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.13656544685364 s
2024-12-23:03:45:53 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.13656544685364 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0020995496412400494,
 'clean_test_loss_avg_over_batch': 1.335387286272916,
 'epoch': 26,
 'test_acc': 0.7984285714285714,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8547741820768137,
 'train_acc_clean_only': 0.8732763064879099,
 'train_asr_bd_only': 0.6882622586470343,
 'train_epoch_loss_avg_over_batch': 0.3617111957853244,
 'train_ra_bd_only': 0.4718710932073899}
2024-12-23:03:45:58 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0020995496412400494,
 'clean_test_loss_avg_over_batch': 1.335387286272916,
 'epoch': 26,
 'test_acc': 0.7984285714285714,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8547741820768137,
 'train_acc_clean_only': 0.8732763064879099,
 'train_asr_bd_only': 0.6882622586470343,
 'train_epoch_loss_avg_over_batch': 0.3617111957853244,
 'train_ra_bd_only': 0.4718710932073899}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.8065142631531 s
2024-12-23:03:50:24 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.8065142631531 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.12094788367606023,
 'clean_test_loss_avg_over_batch': 1.3506268566304986,
 'epoch': 27,
 'test_acc': 0.7868571428571428,
 'test_asr': 0.9658928571428571,
 'test_ra': 0.02875,
 'train_acc': 0.8580692123044097,
 'train_acc_clean_only': 0.8767121173300076,
 'train_asr_bd_only': 0.6902903180997361,
 'train_epoch_loss_avg_over_batch': 0.35344407314257126,
 'train_ra_bd_only': 0.4706209195721628}
2024-12-23:03:50:29 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.12094788367606023,
 'clean_test_loss_avg_over_batch': 1.3506268566304986,
 'epoch': 27,
 'test_acc': 0.7868571428571428,
 'test_asr': 0.9658928571428571,
 'test_ra': 0.02875,
 'train_acc': 0.8580692123044097,
 'train_acc_clean_only': 0.8767121173300076,
 'train_asr_bd_only': 0.6902903180997361,
 'train_epoch_loss_avg_over_batch': 0.35344407314257126,
 'train_ra_bd_only': 0.4706209195721628}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.2171130180359 s
2024-12-23:03:54:57 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.2171130180359 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04977597069757229,
 'clean_test_loss_avg_over_batch': 1.294140829823234,
 'epoch': 28,
 'test_acc': 0.773,
 'test_asr': 0.9873214285714286,
 'test_ra': 0.011964285714285714,
 'train_acc': 0.8629450791251778,
 'train_acc_clean_only': 0.8821822492367437,
 'train_asr_bd_only': 0.6898180302819836,
 'train_epoch_loss_avg_over_batch': 0.34410015849733083,
 'train_ra_bd_only': 0.47125989720794553}
2024-12-23:03:55:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04977597069757229,
 'clean_test_loss_avg_over_batch': 1.294140829823234,
 'epoch': 28,
 'test_acc': 0.773,
 'test_asr': 0.9873214285714286,
 'test_ra': 0.011964285714285714,
 'train_acc': 0.8629450791251778,
 'train_acc_clean_only': 0.8821822492367437,
 'train_asr_bd_only': 0.6898180302819836,
 'train_epoch_loss_avg_over_batch': 0.34410015849733083,
 'train_ra_bd_only': 0.47125989720794553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.735737323761 s
2024-12-23:03:59:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.735737323761 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04995071136561984,
 'clean_test_loss_avg_over_batch': 1.2100661670619792,
 'epoch': 29,
 'test_acc': 0.8085714285714286,
 'test_asr': 0.9817857142857143,
 'test_ra': 0.015714285714285715,
 'train_acc': 0.8650565656116643,
 'train_acc_clean_only': 0.8844217382580376,
 'train_asr_bd_only': 0.6907560223389181,
 'train_epoch_loss_avg_over_batch': 0.3406358478937939,
 'train_ra_bd_only': 0.47203467533550053}
2024-12-23:03:59:35 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04995071136561984,
 'clean_test_loss_avg_over_batch': 1.2100661670619792,
 'epoch': 29,
 'test_acc': 0.8085714285714286,
 'test_asr': 0.9817857142857143,
 'test_ra': 0.015714285714285715,
 'train_acc': 0.8650565656116643,
 'train_acc_clean_only': 0.8844217382580376,
 'train_asr_bd_only': 0.6907560223389181,
 'train_epoch_loss_avg_over_batch': 0.3406358478937939,
 'train_ra_bd_only': 0.47203467533550053}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.51688408851624 s
2024-12-23:04:04:02 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.51688408851624 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015148373913358559,
 'clean_test_loss_avg_over_batch': 1.2488386785442178,
 'epoch': 30,
 'test_acc': 0.8021428571428572,
 'test_asr': 0.9942857142857143,
 'test_ra': 0.005714285714285714,
 'train_acc': 0.868835015113798,
 'train_acc_clean_only': 0.88911801295923,
 'train_asr_bd_only': 0.6863071922660222,
 'train_epoch_loss_avg_over_batch': 0.3328851118291679,
 'train_ra_bd_only': 0.47840097785926605}
2024-12-23:04:04:08 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015148373913358559,
 'clean_test_loss_avg_over_batch': 1.2488386785442178,
 'epoch': 30,
 'test_acc': 0.8021428571428572,
 'test_asr': 0.9942857142857143,
 'test_ra': 0.005714285714285714,
 'train_acc': 0.868835015113798,
 'train_acc_clean_only': 0.88911801295923,
 'train_asr_bd_only': 0.6863071922660222,
 'train_epoch_loss_avg_over_batch': 0.3328851118291679,
 'train_ra_bd_only': 0.47840097785926605}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.7854664325714 s
2024-12-23:04:08:35 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.7854664325714 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03611273645021191,
 'clean_test_loss_avg_over_batch': 1.34367267110131,
 'epoch': 31,
 'test_acc': 0.7931428571428571,
 'test_asr': 0.9851785714285715,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8696990576102418,
 'train_acc_clean_only': 0.8902245148066172,
 'train_asr_bd_only': 0.6849665212680244,
 'train_epoch_loss_avg_over_batch': 0.330603864520873,
 'train_ra_bd_only': 0.47950990470369237}
2024-12-23:04:08:40 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03611273645021191,
 'clean_test_loss_avg_over_batch': 1.34367267110131,
 'epoch': 31,
 'test_acc': 0.7931428571428571,
 'test_asr': 0.9851785714285715,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8696990576102418,
 'train_acc_clean_only': 0.8902245148066172,
 'train_asr_bd_only': 0.6849665212680244,
 'train_epoch_loss_avg_over_batch': 0.330603864520873,
 'train_ra_bd_only': 0.47950990470369237}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.4992136955261 s
2024-12-23:04:13:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.4992136955261 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.024432400155505588,
 'clean_test_loss_avg_over_batch': 1.3474825647744266,
 'epoch': 32,
 'test_acc': 0.7714285714285715,
 'test_asr': 0.9889285714285714,
 'test_ra': 0.009821428571428571,
 'train_acc': 0.8737108819345661,
 'train_acc_clean_only': 0.8945634826309892,
 'train_asr_bd_only': 0.6860571714309526,
 'train_epoch_loss_avg_over_batch': 0.3235229424348003,
 'train_ra_bd_only': 0.4788176792510487}
2024-12-23:04:13:14 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.024432400155505588,
 'clean_test_loss_avg_over_batch': 1.3474825647744266,
 'epoch': 32,
 'test_acc': 0.7714285714285715,
 'test_asr': 0.9889285714285714,
 'test_ra': 0.009821428571428571,
 'train_acc': 0.8737108819345661,
 'train_acc_clean_only': 0.8945634826309892,
 'train_asr_bd_only': 0.6860571714309526,
 'train_epoch_loss_avg_over_batch': 0.3235229424348003,
 'train_ra_bd_only': 0.4788176792510487}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.05446004867554 s
2024-12-23:04:17:42 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.05446004867554 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005474193808781406,
 'clean_test_loss_avg_over_batch': 1.3268290517005052,
 'epoch': 33,
 'test_acc': 0.7877142857142857,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.874399893314367,
 'train_acc_clean_only': 0.895544641561737,
 'train_asr_bd_only': 0.6840701325404985,
 'train_epoch_loss_avg_over_batch': 0.32056693692995,
 'train_ra_bd_only': 0.4800911389591264}
2024-12-23:04:17:47 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005474193808781406,
 'clean_test_loss_avg_over_batch': 1.3268290517005052,
 'epoch': 33,
 'test_acc': 0.7877142857142857,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.874399893314367,
 'train_acc_clean_only': 0.895544641561737,
 'train_asr_bd_only': 0.6840701325404985,
 'train_epoch_loss_avg_over_batch': 0.32056693692995,
 'train_ra_bd_only': 0.4800911389591264}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.9560182094574 s
2024-12-23:04:22:13 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.9560182094574 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.037101503080603754,
 'clean_test_loss_avg_over_batch': 1.2372162076559934,
 'epoch': 34,
 'test_acc': 0.8031428571428572,
 'test_asr': 0.9860714285714286,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8772003911806543,
 'train_acc_clean_only': 0.8982002840032105,
 'train_asr_bd_only': 0.688215357261918,
 'train_epoch_loss_avg_over_batch': 0.31487452279601463,
 'train_ra_bd_only': 0.4808589843315924}
2024-12-23:04:22:17 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.037101503080603754,
 'clean_test_loss_avg_over_batch': 1.2372162076559934,
 'epoch': 34,
 'test_acc': 0.8031428571428572,
 'test_asr': 0.9860714285714286,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8772003911806543,
 'train_acc_clean_only': 0.8982002840032105,
 'train_asr_bd_only': 0.688215357261918,
 'train_epoch_loss_avg_over_batch': 0.31487452279601463,
 'train_ra_bd_only': 0.4808589843315924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8565101623535 s
2024-12-23:04:26:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.8565101623535 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07116500944142569,
 'clean_test_loss_avg_over_batch': 1.299200515313582,
 'epoch': 35,
 'test_acc': 0.7952857142857143,
 'test_asr': 0.9801785714285715,
 'test_ra': 0.016785714285714286,
 'train_acc': 0.87947301742532,
 'train_acc_clean_only': 0.9009168364511947,
 'train_asr_bd_only': 0.6864929436604067,
 'train_epoch_loss_avg_over_batch': 0.30992019428721873,
 'train_ra_bd_only': 0.4801089009889988}
2024-12-23:04:26:48 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07116500944142569,
 'clean_test_loss_avg_over_batch': 1.299200515313582,
 'epoch': 35,
 'test_acc': 0.7952857142857143,
 'test_asr': 0.9801785714285715,
 'test_ra': 0.016785714285714286,
 'train_acc': 0.87947301742532,
 'train_acc_clean_only': 0.9009168364511947,
 'train_asr_bd_only': 0.6864929436604067,
 'train_epoch_loss_avg_over_batch': 0.30992019428721873,
 'train_ra_bd_only': 0.4801089009889988}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.4056725502014 s
2024-12-23:04:31:15 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.4056725502014 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.1268075559478761,
 'clean_test_loss_avg_over_batch': 1.2495136760852554,
 'epoch': 36,
 'test_acc': 0.819,
 'test_asr': 0.9625,
 'test_ra': 0.03321428571428572,
 'train_acc': 0.880259268314367,
 'train_acc_clean_only': 0.9020907999246781,
 'train_asr_bd_only': 0.6837718445253244,
 'train_epoch_loss_avg_over_batch': 0.3082887398272456,
 'train_ra_bd_only': 0.482732753590976}
2024-12-23:04:31:20 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.1268075559478761,
 'clean_test_loss_avg_over_batch': 1.2495136760852554,
 'epoch': 36,
 'test_acc': 0.819,
 'test_asr': 0.9625,
 'test_ra': 0.03321428571428572,
 'train_acc': 0.880259268314367,
 'train_acc_clean_only': 0.9020907999246781,
 'train_asr_bd_only': 0.6837718445253244,
 'train_epoch_loss_avg_over_batch': 0.3082887398272456,
 'train_ra_bd_only': 0.482732753590976}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.0483148097992 s
2024-12-23:04:35:48 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.0483148097992 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.029768578327176245,
 'clean_test_loss_avg_over_batch': 1.2522584774277428,
 'epoch': 37,
 'test_acc': 0.8154285714285714,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8832014580369844,
 'train_acc_clean_only': 0.905421340857314,
 'train_asr_bd_only': 0.6832249819414347,
 'train_epoch_loss_avg_over_batch': 0.3027412502537581,
 'train_ra_bd_only': 0.48566427737956325}
2024-12-23:04:35:53 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.029768578327176245,
 'clean_test_loss_avg_over_batch': 1.2522584774277428,
 'epoch': 37,
 'test_acc': 0.8154285714285714,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8832014580369844,
 'train_acc_clean_only': 0.905421340857314,
 'train_asr_bd_only': 0.6832249819414347,
 'train_epoch_loss_avg_over_batch': 0.3027412502537581,
 'train_ra_bd_only': 0.48566427737956325}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.136967420578 s
2024-12-23:04:40:22 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.136967420578 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.10368916425729614,
 'clean_test_loss_avg_over_batch': 1.3391667103225535,
 'epoch': 38,
 'test_acc': 0.8188571428571428,
 'test_asr': 0.9783928571428572,
 'test_ra': 0.0175,
 'train_acc': 0.885060121799431,
 'train_acc_clean_only': 0.907152845734254,
 'train_asr_bd_only': 0.6862341991943326,
 'train_epoch_loss_avg_over_batch': 0.2982473927331429,
 'train_ra_bd_only': 0.48406723155993886}
2024-12-23:04:40:27 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.10368916425729614,
 'clean_test_loss_avg_over_batch': 1.3391667103225535,
 'epoch': 38,
 'test_acc': 0.8188571428571428,
 'test_asr': 0.9783928571428572,
 'test_ra': 0.0175,
 'train_acc': 0.885060121799431,
 'train_acc_clean_only': 0.907152845734254,
 'train_asr_bd_only': 0.6862341991943326,
 'train_epoch_loss_avg_over_batch': 0.2982473927331429,
 'train_ra_bd_only': 0.48406723155993886}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.203049659729 s
2024-12-23:04:44:50 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 263.203049659729 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.036051611237698206,
 'clean_test_loss_avg_over_batch': 1.4468395360491493,
 'epoch': 39,
 'test_acc': 0.8138571428571428,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8861769870199147,
 'train_acc_clean_only': 0.9083230948750085,
 'train_asr_bd_only': 0.6868644774129021,
 'train_epoch_loss_avg_over_batch': 0.29556238523566536,
 'train_ra_bd_only': 0.4819414346835584}
2024-12-23:04:44:55 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.036051611237698206,
 'clean_test_loss_avg_over_batch': 1.4468395360491493,
 'epoch': 39,
 'test_acc': 0.8138571428571428,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8861769870199147,
 'train_acc_clean_only': 0.9083230948750085,
 'train_asr_bd_only': 0.6868644774129021,
 'train_epoch_loss_avg_over_batch': 0.29556238523566536,
 'train_ra_bd_only': 0.4819414346835584}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.22172951698303 s
2024-12-23:04:49:16 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 260.22172951698303 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01796336308259263,
 'clean_test_loss_avg_over_batch': 1.4237765951590104,
 'epoch': 40,
 'test_acc': 0.7762857142857142,
 'test_asr': 0.995,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8880939944879089,
 'train_acc_clean_only': 0.9102799583874841,
 'train_asr_bd_only': 0.6884289484650646,
 'train_epoch_loss_avg_over_batch': 0.29109479578617287,
 'train_ra_bd_only': 0.4830670926517572}
2024-12-23:04:49:20 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01796336308259263,
 'clean_test_loss_avg_over_batch': 1.4237765951590104,
 'epoch': 40,
 'test_acc': 0.7762857142857142,
 'test_asr': 0.995,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8880939944879089,
 'train_acc_clean_only': 0.9102799583874841,
 'train_asr_bd_only': 0.6884289484650646,
 'train_epoch_loss_avg_over_batch': 0.29109479578617287,
 'train_ra_bd_only': 0.4830670926517572}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.77435660362244 s
2024-12-23:04:53:42 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 261.77435660362244 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.016636229141361335,
 'clean_test_loss_avg_over_batch': 1.3417680298740213,
 'epoch': 41,
 'test_acc': 0.8152857142857143,
 'test_asr': 0.9921428571428571,
 'test_ra': 0.0075,
 'train_acc': 0.8896387135490754,
 'train_acc_clean_only': 0.912885102179416,
 'train_asr_bd_only': 0.6804367151905767,
 'train_epoch_loss_avg_over_batch': 0.2886819968246464,
 'train_ra_bd_only': 0.48927658628736526}
2024-12-23:04:53:47 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.016636229141361335,
 'clean_test_loss_avg_over_batch': 1.3417680298740213,
 'epoch': 41,
 'test_acc': 0.8152857142857143,
 'test_asr': 0.9921428571428571,
 'test_ra': 0.0075,
 'train_acc': 0.8896387135490754,
 'train_acc_clean_only': 0.912885102179416,
 'train_asr_bd_only': 0.6804367151905767,
 'train_epoch_loss_avg_over_batch': 0.2886819968246464,
 'train_ra_bd_only': 0.48927658628736526}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.42725563049316 s
2024-12-23:04:58:11 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 263.42725563049316 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.027494496618931986,
 'clean_test_loss_avg_over_batch': 1.3394588362086903,
 'epoch': 42,
 'test_acc': 0.8007142857142857,
 'test_asr': 0.9892857142857143,
 'test_ra': 0.009285714285714286,
 'train_acc': 0.8911500933499289,
 'train_acc_clean_only': 0.9139341478924979,
 'train_asr_bd_only': 0.6861214511917328,
 'train_epoch_loss_avg_over_batch': 0.28521121790365,
 'train_ra_bd_only': 0.48561031168398244}
2024-12-23:04:58:16 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.027494496618931986,
 'clean_test_loss_avg_over_batch': 1.3394588362086903,
 'epoch': 42,
 'test_acc': 0.8007142857142857,
 'test_asr': 0.9892857142857143,
 'test_ra': 0.009285714285714286,
 'train_acc': 0.8911500933499289,
 'train_acc_clean_only': 0.9139341478924979,
 'train_asr_bd_only': 0.6861214511917328,
 'train_epoch_loss_avg_over_batch': 0.28521121790365,
 'train_ra_bd_only': 0.48561031168398244}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.18368673324585 s
2024-12-23:05:02:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.18368673324585 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.014092064631933516,
 'clean_test_loss_avg_over_batch': 1.4486721716143869,
 'epoch': 43,
 'test_acc': 0.7687142857142857,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.00375,
 'train_acc': 0.8927753822901849,
 'train_acc_clean_only': 0.9159391746721656,
 'train_asr_bd_only': 0.6842909535452323,
 'train_epoch_loss_avg_over_batch': 0.28063032524143566,
 'train_ra_bd_only': 0.4870804623249611}
2024-12-23:05:02:45 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.014092064631933516,
 'clean_test_loss_avg_over_batch': 1.4486721716143869,
 'epoch': 43,
 'test_acc': 0.7687142857142857,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.00375,
 'train_acc': 0.8927753822901849,
 'train_acc_clean_only': 0.9159391746721656,
 'train_asr_bd_only': 0.6842909535452323,
 'train_epoch_loss_avg_over_batch': 0.28063032524143566,
 'train_ra_bd_only': 0.4870804623249611}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.74343276023865 s
2024-12-23:05:07:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 261.74343276023865 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0062807384284414266,
 'clean_test_loss_avg_over_batch': 1.2851484791799026,
 'epoch': 44,
 'test_acc': 0.8098571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.8940978396159317,
 'train_acc_clean_only': 0.9178168033659827,
 'train_asr_bd_only': 0.6805968490372059,
 'train_epoch_loss_avg_over_batch': 0.2783900199148004,
 'train_ra_bd_only': 0.48959404262413514}
2024-12-23:05:07:12 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0062807384284414266,
 'clean_test_loss_avg_over_batch': 1.2851484791799026,
 'epoch': 44,
 'test_acc': 0.8098571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.8940978396159317,
 'train_acc_clean_only': 0.9178168033659827,
 'train_asr_bd_only': 0.6805968490372059,
 'train_epoch_loss_avg_over_batch': 0.2783900199148004,
 'train_ra_bd_only': 0.48959404262413514}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.2307999134064 s
2024-12-23:05:11:37 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.2307999134064 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008369211908509235,
 'clean_test_loss_avg_over_batch': 1.47862835038792,
 'epoch': 45,
 'test_acc': 0.7697142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0025,
 'train_acc': 0.8961343127667141,
 'train_acc_clean_only': 0.9198778797504499,
 'train_asr_bd_only': 0.6824382518823104,
 'train_epoch_loss_avg_over_batch': 0.27448156351491193,
 'train_ra_bd_only': 0.4900952963076154}
2024-12-23:05:11:42 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008369211908509235,
 'clean_test_loss_avg_over_batch': 1.47862835038792,
 'epoch': 45,
 'test_acc': 0.7697142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0025,
 'train_acc': 0.8961343127667141,
 'train_acc_clean_only': 0.9198778797504499,
 'train_asr_bd_only': 0.6824382518823104,
 'train_epoch_loss_avg_over_batch': 0.27448156351491193,
 'train_ra_bd_only': 0.4900952963076154}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.6561462879181 s
2024-12-23:05:16:09 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.6561462879181 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.05262943866810846,
 'clean_test_loss_avg_over_batch': 1.3302996266971936,
 'epoch': 46,
 'test_acc': 0.7948571428571428,
 'test_asr': 0.9833928571428572,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8971483819345661,
 'train_acc_clean_only': 0.9205997388413322,
 'train_asr_bd_only': 0.6860952910126407,
 'train_epoch_loss_avg_over_batch': 0.2711374573833488,
 'train_ra_bd_only': 0.48534518683150435}
2024-12-23:05:16:15 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.05262943866810846,
 'clean_test_loss_avg_over_batch': 1.3302996266971936,
 'epoch': 46,
 'test_acc': 0.7948571428571428,
 'test_asr': 0.9833928571428572,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8971483819345661,
 'train_acc_clean_only': 0.9205997388413322,
 'train_asr_bd_only': 0.6860952910126407,
 'train_epoch_loss_avg_over_batch': 0.2711374573833488,
 'train_ra_bd_only': 0.48534518683150435}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.8377480506897 s
2024-12-23:05:20:43 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.8377480506897 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0022865026330691762,
 'clean_test_loss_avg_over_batch': 1.4086279094219207,
 'epoch': 47,
 'test_acc': 0.7711428571428571,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.8999933321479374,
 'train_acc_clean_only': 0.923548042550827,
 'train_asr_bd_only': 0.6880035561482469,
 'train_epoch_loss_avg_over_batch': 0.26695923671486704,
 'train_ra_bd_only': 0.48455298105239764}
2024-12-23:05:20:48 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0022865026330691762,
 'clean_test_loss_avg_over_batch': 1.4086279094219207,
 'epoch': 47,
 'test_acc': 0.7711428571428571,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.8999933321479374,
 'train_acc_clean_only': 0.923548042550827,
 'train_asr_bd_only': 0.6880035561482469,
 'train_epoch_loss_avg_over_batch': 0.26695923671486704,
 'train_ra_bd_only': 0.48455298105239764}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.4821298122406 s
2024-12-23:05:25:14 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.4821298122406 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.02083029304975009,
 'clean_test_loss_avg_over_batch': 1.3443456408652392,
 'epoch': 48,
 'test_acc': 0.8092857142857143,
 'test_asr': 0.9905357142857143,
 'test_ra': 0.0066071428571428574,
 'train_acc': 0.9005851040184921,
 'train_acc_clean_only': 0.9245667434293793,
 'train_asr_bd_only': 0.6847530143912874,
 'train_epoch_loss_avg_over_batch': 0.2648713859977203,
 'train_ra_bd_only': 0.49019280991276326}
2024-12-23:05:25:19 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.02083029304975009,
 'clean_test_loss_avg_over_batch': 1.3443456408652392,
 'epoch': 48,
 'test_acc': 0.8092857142857143,
 'test_asr': 0.9905357142857143,
 'test_ra': 0.0066071428571428574,
 'train_acc': 0.9005851040184921,
 'train_acc_clean_only': 0.9245667434293793,
 'train_asr_bd_only': 0.6847530143912874,
 'train_epoch_loss_avg_over_batch': 0.2648713859977203,
 'train_ra_bd_only': 0.49019280991276326}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.1671657562256 s
2024-12-23:05:29:46 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.1671657562256 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03512451892575799,
 'clean_test_loss_avg_over_batch': 1.4707515440203927,
 'epoch': 49,
 'test_acc': 0.7848571428571428,
 'test_asr': 0.9867857142857143,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.9024465460526315,
 'train_acc_clean_only': 0.9270550683299222,
 'train_asr_bd_only': 0.6809657433389826,
 'train_epoch_loss_avg_over_batch': 0.26152596420808505,
 'train_ra_bd_only': 0.49401272469646873}
2024-12-23:05:29:51 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03512451892575799,
 'clean_test_loss_avg_over_batch': 1.4707515440203927,
 'epoch': 49,
 'test_acc': 0.7848571428571428,
 'test_asr': 0.9867857142857143,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.9024465460526315,
 'train_acc_clean_only': 0.9270550683299222,
 'train_asr_bd_only': 0.6809657433389826,
 'train_epoch_loss_avg_over_batch': 0.26152596420808505,
 'train_ra_bd_only': 0.49401272469646873}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.79146456718445 s
2024-12-23:05:34:17 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.79146456718445 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03040460500580428,
 'clean_test_loss_avg_over_batch': 1.2796065260063518,
 'epoch': 50,
 'test_acc': 0.8048571428571428,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.008571428571428572,
 'train_acc': 0.9043941145092461,
 'train_acc_clean_only': 0.9290183766897263,
 'train_asr_bd_only': 0.682771650043064,
 'train_epoch_loss_avg_over_batch': 0.2561919739069801,
 'train_ra_bd_only': 0.49042869446836884}
2024-12-23:05:34:22 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03040460500580428,
 'clean_test_loss_avg_over_batch': 1.2796065260063518,
 'epoch': 50,
 'test_acc': 0.8048571428571428,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.008571428571428572,
 'train_acc': 0.9043941145092461,
 'train_acc_clean_only': 0.9290183766897263,
 'train_asr_bd_only': 0.682771650043064,
 'train_epoch_loss_avg_over_batch': 0.2561919739069801,
 'train_ra_bd_only': 0.49042869446836884}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.542343378067 s
2024-12-23:05:38:49 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.542343378067 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007150299263726497,
 'clean_test_loss_avg_over_batch': 1.188133968277411,
 'epoch': 51,
 'test_acc': 0.8155714285714286,
 'test_asr': 0.9983928571428572,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9051581392247511,
 'train_acc_clean_only': 0.929620334441553,
 'train_asr_bd_only': 0.6849943044480872,
 'train_epoch_loss_avg_over_batch': 0.25498549863802084,
 'train_ra_bd_only': 0.4927624815936432}
2024-12-23:05:38:54 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007150299263726497,
 'clean_test_loss_avg_over_batch': 1.188133968277411,
 'epoch': 51,
 'test_acc': 0.8155714285714286,
 'test_asr': 0.9983928571428572,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9051581392247511,
 'train_acc_clean_only': 0.929620334441553,
 'train_asr_bd_only': 0.6849943044480872,
 'train_epoch_loss_avg_over_batch': 0.25498549863802084,
 'train_ra_bd_only': 0.4927624815936432}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.78369975090027 s
2024-12-23:05:43:19 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.78369975090027 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0048535575326902535,
 'clean_test_loss_avg_over_batch': 1.477314506335692,
 'epoch': 52,
 'test_acc': 0.771,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0008928571428571428,
 'train_acc': 0.9057026804765291,
 'train_acc_clean_only': 0.9304659476079051,
 'train_asr_bd_only': 0.6828360282269267,
 'train_epoch_loss_avg_over_batch': 0.2537013614155447,
 'train_ra_bd_only': 0.493498916486081}
2024-12-23:05:43:25 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0048535575326902535,
 'clean_test_loss_avg_over_batch': 1.477314506335692,
 'epoch': 52,
 'test_acc': 0.771,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0008928571428571428,
 'train_acc': 0.9057026804765291,
 'train_acc_clean_only': 0.9304659476079051,
 'train_asr_bd_only': 0.6828360282269267,
 'train_epoch_loss_avg_over_batch': 0.2537013614155447,
 'train_ra_bd_only': 0.493498916486081}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.77934169769287 s
2024-12-23:05:47:51 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.77934169769287 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007556100929584566,
 'clean_test_loss_avg_over_batch': 1.343236942453818,
 'epoch': 53,
 'test_acc': 0.7927142857142857,
 'test_asr': 0.9975,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9074140958392604,
 'train_acc_clean_only': 0.9322469215073115,
 'train_asr_bd_only': 0.6839283233782469,
 'train_epoch_loss_avg_over_batch': 0.24945771400611397,
 'train_ra_bd_only': 0.4949854146409223}
2024-12-23:05:47:56 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007556100929584566,
 'clean_test_loss_avg_over_batch': 1.343236942453818,
 'epoch': 53,
 'test_acc': 0.7927142857142857,
 'test_asr': 0.9975,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9074140958392604,
 'train_acc_clean_only': 0.9322469215073115,
 'train_asr_bd_only': 0.6839283233782469,
 'train_epoch_loss_avg_over_batch': 0.24945771400611397,
 'train_ra_bd_only': 0.4949854146409223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.5156512260437 s
2024-12-23:05:52:23 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.5156512260437 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03426162297414108,
 'clean_test_loss_avg_over_batch': 1.3220816639336672,
 'epoch': 54,
 'test_acc': 0.8092857142857143,
 'test_asr': 0.9876785714285714,
 'test_ra': 0.01,
 'train_acc': 0.9095978173897582,
 'train_acc_clean_only': 0.9343835180880588,
 'train_asr_bd_only': 0.6865223793515406,
 'train_epoch_loss_avg_over_batch': 0.2448173994079211,
 'train_ra_bd_only': 0.48992859722723864}
2024-12-23:05:52:28 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03426162297414108,
 'clean_test_loss_avg_over_batch': 1.3220816639336672,
 'epoch': 54,
 'test_acc': 0.8092857142857143,
 'test_asr': 0.9876785714285714,
 'test_ra': 0.01,
 'train_acc': 0.9095978173897582,
 'train_acc_clean_only': 0.9343835180880588,
 'train_asr_bd_only': 0.6865223793515406,
 'train_epoch_loss_avg_over_batch': 0.2448173994079211,
 'train_ra_bd_only': 0.48992859722723864}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.37181544303894 s
2024-12-23:05:56:55 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.37181544303894 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.034845817848690785,
 'clean_test_loss_avg_over_batch': 1.3189340090209787,
 'epoch': 55,
 'test_acc': 0.8205714285714286,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.911106418918919,
 'train_acc_clean_only': 0.9362227573007347,
 'train_asr_bd_only': 0.685076119568841,
 'train_epoch_loss_avg_over_batch': 0.24231918268488617,
 'train_ra_bd_only': 0.49405489498833205}
2024-12-23:05:57:00 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.034845817848690785,
 'clean_test_loss_avg_over_batch': 1.3189340090209787,
 'epoch': 55,
 'test_acc': 0.8205714285714286,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.911106418918919,
 'train_acc_clean_only': 0.9362227573007347,
 'train_asr_bd_only': 0.685076119568841,
 'train_epoch_loss_avg_over_batch': 0.24231918268488617,
 'train_ra_bd_only': 0.49405489498833205}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.5747346878052 s
2024-12-23:06:01:27 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.5747346878052 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0307966950862134,
 'clean_test_loss_avg_over_batch': 1.2349090549078854,
 'epoch': 56,
 'test_acc': 0.8124285714285714,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.009464285714285715,
 'train_acc': 0.9120232485775249,
 'train_acc_clean_only': 0.9373097653283613,
 'train_asr_bd_only': 0.6844474079013169,
 'train_epoch_loss_avg_over_batch': 0.23955109783025674,
 'train_ra_bd_only': 0.4941656942823804}
2024-12-23:06:01:32 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0307966950862134,
 'clean_test_loss_avg_over_batch': 1.2349090549078854,
 'epoch': 56,
 'test_acc': 0.8124285714285714,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.009464285714285715,
 'train_acc': 0.9120232485775249,
 'train_acc_clean_only': 0.9373097653283613,
 'train_asr_bd_only': 0.6844474079013169,
 'train_epoch_loss_avg_over_batch': 0.23955109783025674,
 'train_ra_bd_only': 0.4941656942823804}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.42289543151855 s
2024-12-23:06:05:58 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.42289543151855 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03258474825799402,
 'clean_test_loss_avg_over_batch': 1.2511858885938472,
 'epoch': 57,
 'test_acc': 0.8114285714285714,
 'test_asr': 0.9853571428571428,
 'test_ra': 0.012142857142857143,
 'train_acc': 0.9129206303342816,
 'train_acc_clean_only': 0.9385875823066546,
 'train_asr_bd_only': 0.6819280455618836,
 'train_epoch_loss_avg_over_batch': 0.2359838575697047,
 'train_ra_bd_only': 0.49592999027642726}
2024-12-23:06:06:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03258474825799402,
 'clean_test_loss_avg_over_batch': 1.2511858885938472,
 'epoch': 57,
 'test_acc': 0.8114285714285714,
 'test_asr': 0.9853571428571428,
 'test_ra': 0.012142857142857143,
 'train_acc': 0.9129206303342816,
 'train_acc_clean_only': 0.9385875823066546,
 'train_asr_bd_only': 0.6819280455618836,
 'train_epoch_loss_avg_over_batch': 0.2359838575697047,
 'train_ra_bd_only': 0.49592999027642726}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.97767090797424 s
2024-12-23:06:10:29 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.97767090797424 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013599583215016703,
 'clean_test_loss_avg_over_batch': 1.320570997758345,
 'epoch': 58,
 'test_acc': 0.805,
 'test_asr': 0.9944642857142857,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.9138902471550497,
 'train_acc_clean_only': 0.9394800937201915,
 'train_asr_bd_only': 0.6835773622648849,
 'train_epoch_loss_avg_over_batch': 0.234701299883563,
 'train_ra_bd_only': 0.4955963659600478}
2024-12-23:06:10:35 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013599583215016703,
 'clean_test_loss_avg_over_batch': 1.320570997758345,
 'epoch': 58,
 'test_acc': 0.805,
 'test_asr': 0.9944642857142857,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.9138902471550497,
 'train_acc_clean_only': 0.9394800937201915,
 'train_asr_bd_only': 0.6835773622648849,
 'train_epoch_loss_avg_over_batch': 0.234701299883563,
 'train_ra_bd_only': 0.4955963659600478}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.98039841651917 s
2024-12-23:06:15:00 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.98039841651917 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01157563067946202,
 'clean_test_loss_avg_over_batch': 1.246899941292676,
 'epoch': 59,
 'test_acc': 0.8037142857142857,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004464285714285714,
 'train_acc': 0.9161712082147937,
 'train_acc_clean_only': 0.9420825821746969,
 'train_asr_bd_only': 0.6829573238497444,
 'train_epoch_loss_avg_over_batch': 0.22987722674620525,
 'train_ra_bd_only': 0.49799955545676816}
2024-12-23:06:15:06 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01157563067946202,
 'clean_test_loss_avg_over_batch': 1.246899941292676,
 'epoch': 59,
 'test_acc': 0.8037142857142857,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004464285714285714,
 'train_acc': 0.9161712082147937,
 'train_acc_clean_only': 0.9420825821746969,
 'train_asr_bd_only': 0.6829573238497444,
 'train_epoch_loss_avg_over_batch': 0.22987722674620525,
 'train_ra_bd_only': 0.49799955545676816}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8731782436371 s
2024-12-23:06:19:31 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.8731782436371 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0042757602396622215,
 'clean_test_loss_avg_over_batch': 1.2388480338183316,
 'epoch': 60,
 'test_acc': 0.8198571428571428,
 'test_asr': 0.99875,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9171602729374111,
 'train_acc_clean_only': 0.9429865314980197,
 'train_asr_bd_only': 0.68473399083206,
 'train_epoch_loss_avg_over_batch': 0.22685481904400445,
 'train_ra_bd_only': 0.4964856230031949}
2024-12-23:06:19:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0042757602396622215,
 'clean_test_loss_avg_over_batch': 1.2388480338183316,
 'epoch': 60,
 'test_acc': 0.8198571428571428,
 'test_asr': 0.99875,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9171602729374111,
 'train_acc_clean_only': 0.9429865314980197,
 'train_asr_bd_only': 0.68473399083206,
 'train_epoch_loss_avg_over_batch': 0.22685481904400445,
 'train_ra_bd_only': 0.4964856230031949}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.6495726108551 s
2024-12-23:06:24:00 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 263.6495726108551 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025106333272891457,
 'clean_test_loss_avg_over_batch': 1.3818625330924987,
 'epoch': 61,
 'test_acc': 0.8274285714285714,
 'test_asr': 0.9917857142857143,
 'test_ra': 0.005892857142857143,
 'train_acc': 0.9187049919985776,
 'train_acc_clean_only': 0.9449683738705505,
 'train_asr_bd_only': 0.6823447701069593,
 'train_epoch_loss_avg_over_batch': 0.22416284293529828,
 'train_ra_bd_only': 0.49837477427420473}
2024-12-23:06:24:05 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025106333272891457,
 'clean_test_loss_avg_over_batch': 1.3818625330924987,
 'epoch': 61,
 'test_acc': 0.8274285714285714,
 'test_asr': 0.9917857142857143,
 'test_ra': 0.005892857142857143,
 'train_acc': 0.9187049919985776,
 'train_acc_clean_only': 0.9449683738705505,
 'train_asr_bd_only': 0.6823447701069593,
 'train_epoch_loss_avg_over_batch': 0.22416284293529828,
 'train_ra_bd_only': 0.49837477427420473}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.862233877182 s
2024-12-23:06:28:33 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.862233877182 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.040861958668260326,
 'clean_test_loss_avg_over_batch': 1.4273922887715427,
 'epoch': 62,
 'test_acc': 0.8084285714285714,
 'test_asr': 0.9855357142857143,
 'test_ra': 0.0125,
 'train_acc': 0.9196468261024182,
 'train_acc_clean_only': 0.9456140567505494,
 'train_asr_bd_only': 0.6859302067126029,
 'train_epoch_loss_avg_over_batch': 0.22090636896682245,
 'train_ra_bd_only': 0.4946932651700378}
2024-12-23:06:28:39 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.040861958668260326,
 'clean_test_loss_avg_over_batch': 1.4273922887715427,
 'epoch': 62,
 'test_acc': 0.8084285714285714,
 'test_asr': 0.9855357142857143,
 'test_ra': 0.0125,
 'train_acc': 0.9196468261024182,
 'train_acc_clean_only': 0.9456140567505494,
 'train_asr_bd_only': 0.6859302067126029,
 'train_epoch_loss_avg_over_batch': 0.22090636896682245,
 'train_ra_bd_only': 0.4946932651700378}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.71642231941223 s
2024-12-23:06:33:05 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.71642231941223 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04982936111363498,
 'clean_test_loss_avg_over_batch': 1.3467810815030878,
 'epoch': 63,
 'test_acc': 0.8055714285714286,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.9205608774893315,
 'train_acc_clean_only': 0.9470840999172707,
 'train_asr_bd_only': 0.6818106035345115,
 'train_epoch_loss_avg_over_batch': 0.21849125805463254,
 'train_ra_bd_only': 0.4997221295987551}
2024-12-23:06:33:10 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04982936111363498,
 'clean_test_loss_avg_over_batch': 1.3467810815030878,
 'epoch': 63,
 'test_acc': 0.8055714285714286,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.9205608774893315,
 'train_acc_clean_only': 0.9470840999172707,
 'train_asr_bd_only': 0.6818106035345115,
 'train_epoch_loss_avg_over_batch': 0.21849125805463254,
 'train_ra_bd_only': 0.4997221295987551}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.2474217414856 s
2024-12-23:06:37:37 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.2474217414856 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04388476906950183,
 'clean_test_loss_avg_over_batch': 1.419353055412119,
 'epoch': 64,
 'test_acc': 0.8068571428571428,
 'test_asr': 0.9858928571428571,
 'test_ra': 0.01125,
 'train_acc': 0.922288962482219,
 'train_acc_clean_only': 0.9488644607230284,
 'train_asr_bd_only': 0.6831050482038175,
 'train_epoch_loss_avg_over_batch': 0.21556452867094095,
 'train_ra_bd_only': 0.49901369710777094}
2024-12-23:06:37:42 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04388476906950183,
 'clean_test_loss_avg_over_batch': 1.419353055412119,
 'epoch': 64,
 'test_acc': 0.8068571428571428,
 'test_asr': 0.9858928571428571,
 'test_ra': 0.01125,
 'train_acc': 0.922288962482219,
 'train_acc_clean_only': 0.9488644607230284,
 'train_asr_bd_only': 0.6831050482038175,
 'train_epoch_loss_avg_over_batch': 0.21556452867094095,
 'train_ra_bd_only': 0.49901369710777094}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.6657495498657 s
2024-12-23:06:42:05 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 262.6657495498657 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005528833125440128,
 'clean_test_loss_avg_over_batch': 1.4962964762340893,
 'epoch': 65,
 'test_acc': 0.7994285714285714,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9236253111664295,
 'train_acc_clean_only': 0.9503398756567534,
 'train_asr_bd_only': 0.6831971995332555,
 'train_epoch_loss_avg_over_batch': 0.21242841825970207,
 'train_ra_bd_only': 0.501583597266211}
2024-12-23:06:42:10 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005528833125440128,
 'clean_test_loss_avg_over_batch': 1.4962964762340893,
 'epoch': 65,
 'test_acc': 0.7994285714285714,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9236253111664295,
 'train_acc_clean_only': 0.9503398756567534,
 'train_asr_bd_only': 0.6831971995332555,
 'train_epoch_loss_avg_over_batch': 0.21242841825970207,
 'train_ra_bd_only': 0.501583597266211}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.05256748199463 s
2024-12-23:06:46:36 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.05256748199463 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0274170351119458,
 'clean_test_loss_avg_over_batch': 1.37021179524335,
 'epoch': 66,
 'test_acc': 0.8145714285714286,
 'test_asr': 0.9896428571428572,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.9252089260312945,
 'train_acc_clean_only': 0.9519511269027384,
 'train_asr_bd_only': 0.6845395193776913,
 'train_epoch_loss_avg_over_batch': 0.2087108637067154,
 'train_ra_bd_only': 0.5004028337269065}
2024-12-23:06:46:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0274170351119458,
 'clean_test_loss_avg_over_batch': 1.37021179524335,
 'epoch': 66,
 'test_acc': 0.8145714285714286,
 'test_asr': 0.9896428571428572,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.9252089260312945,
 'train_acc_clean_only': 0.9519511269027384,
 'train_asr_bd_only': 0.6845395193776913,
 'train_epoch_loss_avg_over_batch': 0.2087108637067154,
 'train_ra_bd_only': 0.5004028337269065}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.0525062084198 s
2024-12-23:06:51:06 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.0525062084198 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.022246286657966928,
 'clean_test_loss_avg_over_batch': 1.4045121030374006,
 'epoch': 67,
 'test_acc': 0.8204285714285714,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.00625,
 'train_acc': 0.9272037251066856,
 'train_acc_clean_only': 0.9540940591767121,
 'train_asr_bd_only': 0.6851712928232058,
 'train_epoch_loss_avg_over_batch': 0.20445051510019457,
 'train_ra_bd_only': 0.4987913645077936}
2024-12-23:06:51:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.022246286657966928,
 'clean_test_loss_avg_over_batch': 1.4045121030374006,
 'epoch': 67,
 'test_acc': 0.8204285714285714,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.00625,
 'train_acc': 0.9272037251066856,
 'train_acc_clean_only': 0.9540940591767121,
 'train_asr_bd_only': 0.6851712928232058,
 'train_epoch_loss_avg_over_batch': 0.20445051510019457,
 'train_ra_bd_only': 0.4987913645077936}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.57199001312256 s
2024-12-23:06:55:38 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.57199001312256 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007170520979508927,
 'clean_test_loss_avg_over_batch': 1.3359940722584724,
 'epoch': 68,
 'test_acc': 0.8228571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9276315789473685,
 'train_acc_clean_only': 0.9549644382979774,
 'train_asr_bd_only': 0.6816236941542565,
 'train_epoch_loss_avg_over_batch': 0.20237793696045367,
 'train_ra_bd_only': 0.5038619693265171}
2024-12-23:06:55:43 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007170520979508927,
 'clean_test_loss_avg_over_batch': 1.3359940722584724,
 'epoch': 68,
 'test_acc': 0.8228571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9276315789473685,
 'train_acc_clean_only': 0.9549644382979774,
 'train_asr_bd_only': 0.6816236941542565,
 'train_epoch_loss_avg_over_batch': 0.20237793696045367,
 'train_ra_bd_only': 0.5038619693265171}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8238363265991 s
2024-12-23:07:00:08 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.8238363265991 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013845373164671897,
 'clean_test_loss_avg_over_batch': 1.4373107064854016,
 'epoch': 69,
 'test_acc': 0.8027142857142857,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9293624422119487,
 'train_acc_clean_only': 0.9565264366680661,
 'train_asr_bd_only': 0.6848744165370082,
 'train_epoch_loss_avg_over_batch': 0.19851022739636356,
 'train_ra_bd_only': 0.50041675927984}
2024-12-23:07:00:13 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013845373164671897,
 'clean_test_loss_avg_over_batch': 1.4373107064854016,
 'epoch': 69,
 'test_acc': 0.8027142857142857,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9293624422119487,
 'train_acc_clean_only': 0.9565264366680661,
 'train_asr_bd_only': 0.6848744165370082,
 'train_epoch_loss_avg_over_batch': 0.19851022739636356,
 'train_ra_bd_only': 0.50041675927984}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.23140573501587 s
2024-12-23:07:04:40 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.23140573501587 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005341949620659844,
 'clean_test_loss_avg_over_batch': 1.444847309589386,
 'epoch': 70,
 'test_acc': 0.7992857142857143,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9309460570768137,
 'train_acc_clean_only': 0.9580174351122416,
 'train_asr_bd_only': 0.6872916203600801,
 'train_epoch_loss_avg_over_batch': 0.19469588987561073,
 'train_ra_bd_only': 0.4967770615692376}
2024-12-23:07:04:45 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005341949620659844,
 'clean_test_loss_avg_over_batch': 1.444847309589386,
 'epoch': 70,
 'test_acc': 0.7992857142857143,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9309460570768137,
 'train_acc_clean_only': 0.9580174351122416,
 'train_asr_bd_only': 0.6872916203600801,
 'train_epoch_loss_avg_over_batch': 0.19469588987561073,
 'train_ra_bd_only': 0.4967770615692376}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.73604369163513 s
2024-12-23:07:09:11 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.73604369163513 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04979842101139101,
 'clean_test_loss_avg_over_batch': 1.45478684685447,
 'epoch': 71,
 'test_acc': 0.8091428571428572,
 'test_asr': 0.985,
 'test_ra': 0.0125,
 'train_acc': 0.9317517558677099,
 'train_acc_clean_only': 0.9593549641766811,
 'train_asr_bd_only': 0.6832569126024732,
 'train_epoch_loss_avg_over_batch': 0.19299580236820035,
 'train_ra_bd_only': 0.5027094622759483}
2024-12-23:07:09:17 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04979842101139101,
 'clean_test_loss_avg_over_batch': 1.45478684685447,
 'epoch': 71,
 'test_acc': 0.8091428571428572,
 'test_asr': 0.985,
 'test_ra': 0.0125,
 'train_acc': 0.9317517558677099,
 'train_acc_clean_only': 0.9593549641766811,
 'train_asr_bd_only': 0.6832569126024732,
 'train_epoch_loss_avg_over_batch': 0.19299580236820035,
 'train_ra_bd_only': 0.5027094622759483}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.0305142402649 s
2024-12-23:07:13:42 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.0305142402649 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.055896732227252374,
 'clean_test_loss_avg_over_batch': 1.40997616648674,
 'epoch': 72,
 'test_acc': 0.8101428571428572,
 'test_asr': 0.98375,
 'test_ra': 0.013571428571428571,
 'train_acc': 0.9337771159317212,
 'train_acc_clean_only': 0.9612617034478288,
 'train_asr_bd_only': 0.6864112466312894,
 'train_epoch_loss_avg_over_batch': 0.18897664858025642,
 'train_ra_bd_only': 0.5004028561109105}
2024-12-23:07:13:47 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.055896732227252374,
 'clean_test_loss_avg_over_batch': 1.40997616648674,
 'epoch': 72,
 'test_acc': 0.8101428571428572,
 'test_asr': 0.98375,
 'test_ra': 0.013571428571428571,
 'train_acc': 0.9337771159317212,
 'train_acc_clean_only': 0.9612617034478288,
 'train_asr_bd_only': 0.6864112466312894,
 'train_epoch_loss_avg_over_batch': 0.18897664858025642,
 'train_ra_bd_only': 0.5004028561109105}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.3779957294464 s
2024-12-23:07:18:14 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.3779957294464 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015154500301419334,
 'clean_test_loss_avg_over_batch': 1.4457129976966165,
 'epoch': 73,
 'test_acc': 0.8095714285714286,
 'test_asr': 0.9941071428571429,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.9345800364509246,
 'train_acc_clean_only': 0.9625773272253572,
 'train_asr_bd_only': 0.6825608536178727,
 'train_epoch_loss_avg_over_batch': 0.18655953095804576,
 'train_ra_bd_only': 0.5040291208180505}
2024-12-23:07:18:19 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015154500301419334,
 'clean_test_loss_avg_over_batch': 1.4457129976966165,
 'epoch': 73,
 'test_acc': 0.8095714285714286,
 'test_asr': 0.9941071428571429,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.9345800364509246,
 'train_acc_clean_only': 0.9625773272253572,
 'train_asr_bd_only': 0.6825608536178727,
 'train_epoch_loss_avg_over_batch': 0.18655953095804576,
 'train_ra_bd_only': 0.5040291208180505}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.3543589115143 s
2024-12-23:07:22:47 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.3543589115143 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005560807138945992,
 'clean_test_loss_avg_over_batch': 1.5189206957817079,
 'epoch': 74,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9363025649004267,
 'train_acc_clean_only': 0.9643484461676664,
 'train_asr_bd_only': 0.6839005417419086,
 'train_epoch_loss_avg_over_batch': 0.1825919116517346,
 'train_ra_bd_only': 0.5024308931796083}
2024-12-23:07:22:52 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005560807138945992,
 'clean_test_loss_avg_over_batch': 1.5189206957817079,
 'epoch': 74,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9363025649004267,
 'train_acc_clean_only': 0.9643484461676664,
 'train_asr_bd_only': 0.6839005417419086,
 'train_epoch_loss_avg_over_batch': 0.1825919116517346,
 'train_ra_bd_only': 0.5024308931796083}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.0530002117157 s
2024-12-23:07:27:20 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.0530002117157 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01018915735767223,
 'clean_test_loss_avg_over_batch': 1.430295225165107,
 'epoch': 75,
 'test_acc': 0.8075714285714286,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0030357142857142857,
 'train_acc': 0.9382223506401138,
 'train_acc_clean_only': 0.9666236548517945,
 'train_asr_bd_only': 0.6826137689614936,
 'train_epoch_loss_avg_over_batch': 0.17854509897302215,
 'train_ra_bd_only': 0.5065844307384564}
2024-12-23:07:27:26 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01018915735767223,
 'clean_test_loss_avg_over_batch': 1.430295225165107,
 'epoch': 75,
 'test_acc': 0.8075714285714286,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0030357142857142857,
 'train_acc': 0.9382223506401138,
 'train_acc_clean_only': 0.9666236548517945,
 'train_asr_bd_only': 0.6826137689614936,
 'train_epoch_loss_avg_over_batch': 0.17854509897302215,
 'train_ra_bd_only': 0.5065844307384564}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.31953477859497 s
2024-12-23:07:31:55 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.31953477859497 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.017962747904345055,
 'clean_test_loss_avg_over_batch': 1.4181302775036204,
 'epoch': 76,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9933928571428572,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9390280494310099,
 'train_acc_clean_only': 0.9677629466821426,
 'train_asr_bd_only': 0.6804012002667259,
 'train_epoch_loss_avg_over_batch': 0.17621235970466015,
 'train_ra_bd_only': 0.5076683707490554}
2024-12-23:07:32:00 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.017962747904345055,
 'clean_test_loss_avg_over_batch': 1.4181302775036204,
 'epoch': 76,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9933928571428572,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9390280494310099,
 'train_acc_clean_only': 0.9677629466821426,
 'train_asr_bd_only': 0.6804012002667259,
 'train_epoch_loss_avg_over_batch': 0.17621235970466015,
 'train_ra_bd_only': 0.5076683707490554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 268.1515316963196 s
2024-12-23:07:36:28 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 268.1515316963196 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013184209921746515,
 'clean_test_loss_avg_over_batch': 1.3854517297311262,
 'epoch': 77,
 'test_acc': 0.81,
 'test_asr': 0.99375,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9403866242887624,
 'train_acc_clean_only': 0.9689946410490702,
 'train_asr_bd_only': 0.6829017559457657,
 'train_epoch_loss_avg_over_batch': 0.17277320072447,
 'train_ra_bd_only': 0.5066125805734608}
2024-12-23:07:36:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013184209921746515,
 'clean_test_loss_avg_over_batch': 1.3854517297311262,
 'epoch': 77,
 'test_acc': 0.81,
 'test_asr': 0.99375,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9403866242887624,
 'train_acc_clean_only': 0.9689946410490702,
 'train_asr_bd_only': 0.6829017559457657,
 'train_epoch_loss_avg_over_batch': 0.17277320072447,
 'train_ra_bd_only': 0.5066125805734608}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.084196805954 s
2024-12-23:07:41:00 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.084196805954 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0037016277849695393,
 'clean_test_loss_avg_over_batch': 1.4118886839259754,
 'epoch': 78,
 'test_acc': 0.8067142857142857,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9413534628378378,
 'train_acc_clean_only': 0.970479009937056,
 'train_asr_bd_only': 0.6792510486985026,
 'train_epoch_loss_avg_over_batch': 0.17004989757392008,
 'train_ra_bd_only': 0.5099313831708198}
2024-12-23:07:41:05 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0037016277849695393,
 'clean_test_loss_avg_over_batch': 1.4118886839259754,
 'epoch': 78,
 'test_acc': 0.8067142857142857,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9413534628378378,
 'train_acc_clean_only': 0.970479009937056,
 'train_asr_bd_only': 0.6792510486985026,
 'train_epoch_loss_avg_over_batch': 0.17004989757392008,
 'train_ra_bd_only': 0.5099313831708198}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.2320840358734 s
2024-12-23:07:45:33 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.2320840358734 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007146789211467628,
 'clean_test_loss_avg_over_batch': 1.3915956155820326,
 'epoch': 79,
 'test_acc': 0.8157142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0026785714285714286,
 'train_acc': 0.9432538006756757,
 'train_acc_clean_only': 0.9721244674939804,
 'train_asr_bd_only': 0.6834370485609512,
 'train_epoch_loss_avg_over_batch': 0.16654092314021177,
 'train_ra_bd_only': 0.5086120680075564}
2024-12-23:07:45:38 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007146789211467628,
 'clean_test_loss_avg_over_batch': 1.3915956155820326,
 'epoch': 79,
 'test_acc': 0.8157142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0026785714285714286,
 'train_acc': 0.9432538006756757,
 'train_acc_clean_only': 0.9721244674939804,
 'train_asr_bd_only': 0.6834370485609512,
 'train_epoch_loss_avg_over_batch': 0.16654092314021177,
 'train_ra_bd_only': 0.5086120680075564}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.9605860710144 s
2024-12-23:07:50:04 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.9605860710144 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.030954912019131534,
 'clean_test_loss_avg_over_batch': 1.5179429411888123,
 'epoch': 80,
 'test_acc': 0.8127142857142857,
 'test_asr': 0.9891071428571429,
 'test_ra': 0.00875,
 'train_acc': 0.9449235419630156,
 'train_acc_clean_only': 0.9738161387911342,
 'train_asr_bd_only': 0.6849094343815979,
 'train_epoch_loss_avg_over_batch': 0.16199909270890747,
 'train_ra_bd_only': 0.5063062562506945}
2024-12-23:07:50:10 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.030954912019131534,
 'clean_test_loss_avg_over_batch': 1.5179429411888123,
 'epoch': 80,
 'test_acc': 0.8127142857142857,
 'test_asr': 0.9891071428571429,
 'test_ra': 0.00875,
 'train_acc': 0.9449235419630156,
 'train_acc_clean_only': 0.9738161387911342,
 'train_asr_bd_only': 0.6849094343815979,
 'train_epoch_loss_avg_over_batch': 0.16199909270890747,
 'train_ra_bd_only': 0.5063062562506945}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 271.6255283355713 s
2024-12-23:07:54:42 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 271.6255283355713 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007211355181590823,
 'clean_test_loss_avg_over_batch': 1.4945620769804173,
 'epoch': 81,
 'test_acc': 0.8102857142857143,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9464377000355618,
 'train_acc_clean_only': 0.975662309919677,
 'train_asr_bd_only': 0.6834194587986887,
 'train_epoch_loss_avg_over_batch': 0.1589845797023173,
 'train_ra_bd_only': 0.5081402455964883}
2024-12-23:07:54:47 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007211355181590823,
 'clean_test_loss_avg_over_batch': 1.4945620769804173,
 'epoch': 81,
 'test_acc': 0.8102857142857143,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9464377000355618,
 'train_acc_clean_only': 0.975662309919677,
 'train_asr_bd_only': 0.6834194587986887,
 'train_epoch_loss_avg_over_batch': 0.1589845797023173,
 'train_ra_bd_only': 0.5081402455964883}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.14009070396423 s
2024-12-23:07:59:13 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.14009070396423 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010672646990728523,
 'clean_test_loss_avg_over_batch': 1.482089962200685,
 'epoch': 82,
 'test_acc': 0.8075714285714286,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.003928571428571429,
 'train_acc': 0.9477490442745377,
 'train_acc_clean_only': 0.9769123199120822,
 'train_asr_bd_only': 0.6853071089257438,
 'train_epoch_loss_avg_over_batch': 0.1560417407869254,
 'train_ra_bd_only': 0.5080423368614051}
2024-12-23:07:59:19 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010672646990728523,
 'clean_test_loss_avg_over_batch': 1.482089962200685,
 'epoch': 82,
 'test_acc': 0.8075714285714286,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.003928571428571429,
 'train_acc': 0.9477490442745377,
 'train_acc_clean_only': 0.9769123199120822,
 'train_asr_bd_only': 0.6853071089257438,
 'train_epoch_loss_avg_over_batch': 0.1560417407869254,
 'train_ra_bd_only': 0.5080423368614051}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.39797163009644 s
2024-12-23:08:03:45 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.39797163009644 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00499374274328478,
 'clean_test_loss_avg_over_batch': 1.5177468825470317,
 'epoch': 83,
 'test_acc': 0.8115714285714286,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9488409050497866,
 'train_acc_clean_only': 0.9782952293340084,
 'train_asr_bd_only': 0.6837879882215678,
 'train_epoch_loss_avg_over_batch': 0.15256803798201796,
 'train_ra_bd_only': 0.5096949830546141}
2024-12-23:08:03:51 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00499374274328478,
 'clean_test_loss_avg_over_batch': 1.5177468825470317,
 'epoch': 83,
 'test_acc': 0.8115714285714286,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9488409050497866,
 'train_acc_clean_only': 0.9782952293340084,
 'train_asr_bd_only': 0.6837879882215678,
 'train_epoch_loss_avg_over_batch': 0.15256803798201796,
 'train_ra_bd_only': 0.5096949830546141}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.821457862854 s
2024-12-23:08:08:17 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.821457862854 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00418434381770732,
 'clean_test_loss_avg_over_batch': 1.4761791689829393,
 'epoch': 84,
 'test_acc': 0.812,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9495965949502134,
 'train_acc_clean_only': 0.9792588248005063,
 'train_asr_bd_only': 0.6826150982189992,
 'train_epoch_loss_avg_over_batch': 0.15056542177839605,
 'train_ra_bd_only': 0.5096551915756717}
2024-12-23:08:08:22 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00418434381770732,
 'clean_test_loss_avg_over_batch': 1.4761791689829393,
 'epoch': 84,
 'test_acc': 0.812,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9495965949502134,
 'train_acc_clean_only': 0.9792588248005063,
 'train_asr_bd_only': 0.6826150982189992,
 'train_epoch_loss_avg_over_batch': 0.15056542177839605,
 'train_ra_bd_only': 0.5096551915756717}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.51418471336365 s
2024-12-23:08:12:50 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.51418471336365 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025116856500972062,
 'clean_test_loss_avg_over_batch': 1.4963945722038097,
 'epoch': 85,
 'test_acc': 0.8201428571428572,
 'test_asr': 0.9903571428571428,
 'test_ra': 0.0075,
 'train_acc': 0.9511440922830725,
 'train_acc_clean_only': 0.9808668862539783,
 'train_asr_bd_only': 0.6836505070148632,
 'train_epoch_loss_avg_over_batch': 0.14736333333756008,
 'train_ra_bd_only': 0.5097652451729406}
2024-12-23:08:12:55 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025116856500972062,
 'clean_test_loss_avg_over_batch': 1.4963945722038097,
 'epoch': 85,
 'test_acc': 0.8201428571428572,
 'test_asr': 0.9903571428571428,
 'test_ra': 0.0075,
 'train_acc': 0.9511440922830725,
 'train_acc_clean_only': 0.9808668862539783,
 'train_asr_bd_only': 0.6836505070148632,
 'train_epoch_loss_avg_over_batch': 0.14736333333756008,
 'train_ra_bd_only': 0.5097652451729406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.43062138557434 s
2024-12-23:08:17:21 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.43062138557434 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0032297336219926365,
 'clean_test_loss_avg_over_batch': 1.5117702681909908,
 'epoch': 86,
 'test_acc': 0.8124285714285714,
 'test_asr': 0.9996428571428572,
 'test_ra': 0.00035714285714285714,
 'train_acc': 0.9521581614509246,
 'train_acc_clean_only': 0.9819938013977725,
 'train_asr_bd_only': 0.6836241386974883,
 'train_epoch_loss_avg_over_batch': 0.14470343353759343,
 'train_ra_bd_only': 0.5104745498999778}
2024-12-23:08:17:26 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0032297336219926365,
 'clean_test_loss_avg_over_batch': 1.5117702681909908,
 'epoch': 86,
 'test_acc': 0.8124285714285714,
 'test_asr': 0.9996428571428572,
 'test_ra': 0.00035714285714285714,
 'train_acc': 0.9521581614509246,
 'train_acc_clean_only': 0.9819938013977725,
 'train_asr_bd_only': 0.6836241386974883,
 'train_epoch_loss_avg_over_batch': 0.14470343353759343,
 'train_ra_bd_only': 0.5104745498999778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.4006106853485 s
2024-12-23:08:21:52 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.4006106853485 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005082859530706297,
 'clean_test_loss_avg_over_batch': 1.5071678394621069,
 'epoch': 87,
 'test_acc': 0.8091428571428572,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9533917140825036,
 'train_acc_clean_only': 0.9833242782703183,
 'train_asr_bd_only': 0.6839853300733496,
 'train_epoch_loss_avg_over_batch': 0.1418375257325821,
 'train_ra_bd_only': 0.5109468770837964}
2024-12-23:08:21:57 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005082859530706297,
 'clean_test_loss_avg_over_batch': 1.5071678394621069,
 'epoch': 87,
 'test_acc': 0.8091428571428572,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9533917140825036,
 'train_acc_clean_only': 0.9833242782703183,
 'train_asr_bd_only': 0.6839853300733496,
 'train_epoch_loss_avg_over_batch': 0.1418375257325821,
 'train_ra_bd_only': 0.5109468770837964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.6638882160187 s
2024-12-23:08:26:24 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.6638882160187 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.003371532217980447,
 'clean_test_loss_avg_over_batch': 1.5083545690233058,
 'epoch': 88,
 'test_acc': 0.8161428571428572,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.9544113397937412,
 'train_acc_clean_only': 0.9845839455715115,
 'train_asr_bd_only': 0.682810936978993,
 'train_epoch_loss_avg_over_batch': 0.13914323386843522,
 'train_ra_bd_only': 0.5132822051795043}
2024-12-23:08:26:29 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.003371532217980447,
 'clean_test_loss_avg_over_batch': 1.5083545690233058,
 'epoch': 88,
 'test_acc': 0.8161428571428572,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.9544113397937412,
 'train_acc_clean_only': 0.9845839455715115,
 'train_asr_bd_only': 0.682810936978993,
 'train_epoch_loss_avg_over_batch': 0.13914323386843522,
 'train_ra_bd_only': 0.5132822051795043}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.2308783531189 s
2024-12-23:08:30:55 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.2308783531189 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005141392691505395,
 'clean_test_loss_avg_over_batch': 1.5153538758104497,
 'epoch': 89,
 'test_acc': 0.811,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9550031116642959,
 'train_acc_clean_only': 0.9851671436024239,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.13709980041546427,
 'train_ra_bd_only': 0.5125996721584752}
2024-12-23:08:31:00 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005141392691505395,
 'clean_test_loss_avg_over_batch': 1.5153538758104497,
 'epoch': 89,
 'test_acc': 0.811,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9550031116642959,
 'train_acc_clean_only': 0.9851671436024239,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.13709980041546427,
 'train_ra_bd_only': 0.5125996721584752}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.082284450531 s
2024-12-23:08:35:26 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.082284450531 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0046287892460399735,
 'clean_test_loss_avg_over_batch': 1.5422791109843688,
 'epoch': 90,
 'test_acc': 0.8121428571428572,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9562033250355618,
 'train_acc_clean_only': 0.9863833649233504,
 'train_asr_bd_only': 0.6845863199422126,
 'train_epoch_loss_avg_over_batch': 0.13493659703132524,
 'train_ra_bd_only': 0.5117241762515975}
2024-12-23:08:35:31 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0046287892460399735,
 'clean_test_loss_avg_over_batch': 1.5422791109843688,
 'epoch': 90,
 'test_acc': 0.8121428571428572,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9562033250355618,
 'train_acc_clean_only': 0.9863833649233504,
 'train_asr_bd_only': 0.6845863199422126,
 'train_epoch_loss_avg_over_batch': 0.13493659703132524,
 'train_ra_bd_only': 0.5117241762515975}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.91471338272095 s
2024-12-23:08:39:56 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.91471338272095 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00880769268736582,
 'clean_test_loss_avg_over_batch': 1.571345576914874,
 'epoch': 91,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9964285714285714,
 'test_ra': 0.002857142857142857,
 'train_acc': 0.9572618465504978,
 'train_acc_clean_only': 0.987288083272624,
 'train_asr_bd_only': 0.6869789929976658,
 'train_epoch_loss_avg_over_batch': 0.13180643217810356,
 'train_ra_bd_only': 0.5082805379570968}
2024-12-23:08:40:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00880769268736582,
 'clean_test_loss_avg_over_batch': 1.571345576914874,
 'epoch': 91,
 'test_acc': 0.8111428571428572,
 'test_asr': 0.9964285714285714,
 'test_ra': 0.002857142857142857,
 'train_acc': 0.9572618465504978,
 'train_acc_clean_only': 0.987288083272624,
 'train_asr_bd_only': 0.6869789929976658,
 'train_epoch_loss_avg_over_batch': 0.13180643217810356,
 'train_ra_bd_only': 0.5082805379570968}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 266.19796800613403 s
2024-12-23:08:44:28 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 266.19796800613403 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00576904332410777,
 'clean_test_loss_avg_over_batch': 1.564117845621976,
 'epoch': 92,
 'test_acc': 0.8138571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9569034495021337,
 'train_acc_clean_only': 0.9877910243191682,
 'train_asr_bd_only': 0.6789187086736679,
 'train_epoch_loss_avg_over_batch': 0.13270713460193165,
 'train_ra_bd_only': 0.5181974773573373}
2024-12-23:08:44:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00576904332410777,
 'clean_test_loss_avg_over_batch': 1.564117845621976,
 'epoch': 92,
 'test_acc': 0.8138571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9569034495021337,
 'train_acc_clean_only': 0.9877910243191682,
 'train_asr_bd_only': 0.6789187086736679,
 'train_epoch_loss_avg_over_batch': 0.13270713460193165,
 'train_ra_bd_only': 0.5181974773573373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.2634332180023 s
2024-12-23:08:48:59 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.2634332180023 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005723064847354015,
 'clean_test_loss_avg_over_batch': 1.578278913823041,
 'epoch': 93,
 'test_acc': 0.8121428571428572,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9581897892958748,
 'train_acc_clean_only': 0.9887604377286268,
 'train_asr_bd_only': 0.6830318690783808,
 'train_epoch_loss_avg_over_batch': 0.12995564364887785,
 'train_ra_bd_only': 0.5138506848934455}
2024-12-23:08:49:04 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005723064847354015,
 'clean_test_loss_avg_over_batch': 1.578278913823041,
 'epoch': 93,
 'test_acc': 0.8121428571428572,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9581897892958748,
 'train_acc_clean_only': 0.9887604377286268,
 'train_asr_bd_only': 0.6830318690783808,
 'train_epoch_loss_avg_over_batch': 0.12995564364887785,
 'train_ra_bd_only': 0.5138506848934455}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 267.51557064056396 s
2024-12-23:08:53:32 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 267.51557064056396 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.012714090557313863,
 'clean_test_loss_avg_over_batch': 1.5786212146282197,
 'epoch': 94,
 'test_acc': 0.8117142857142857,
 'test_asr': 0.9948214285714285,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9582703591749644,
 'train_acc_clean_only': 0.9892172055491415,
 'train_asr_bd_only': 0.6797521809190421,
 'train_epoch_loss_avg_over_batch': 0.12954547878481967,
 'train_ra_bd_only': 0.5166416624993054}
2024-12-23:08:53:38 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.012714090557313863,
 'clean_test_loss_avg_over_batch': 1.5786212146282197,
 'epoch': 94,
 'test_acc': 0.8117142857142857,
 'test_asr': 0.9948214285714285,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9582703591749644,
 'train_acc_clean_only': 0.9892172055491415,
 'train_asr_bd_only': 0.6797521809190421,
 'train_epoch_loss_avg_over_batch': 0.12954547878481967,
 'train_ra_bd_only': 0.5166416624993054}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.28996324539185 s
2024-12-23:08:58:03 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.28996324539185 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010330577804283663,
 'clean_test_loss_avg_over_batch': 1.5546601975506003,
 'epoch': 95,
 'test_acc': 0.813,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0032142857142857142,
 'train_acc': 0.9591482930298719,
 'train_acc_clean_only': 0.989652564478538,
 'train_asr_bd_only': 0.6845878136200717,
 'train_epoch_loss_avg_over_batch': 0.12756514586084344,
 'train_ra_bd_only': 0.5124614486955072}
2024-12-23:08:58:08 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010330577804283663,
 'clean_test_loss_avg_over_batch': 1.5546601975506003,
 'epoch': 95,
 'test_acc': 0.813,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0032142857142857142,
 'train_acc': 0.9591482930298719,
 'train_acc_clean_only': 0.989652564478538,
 'train_asr_bd_only': 0.6845878136200717,
 'train_epoch_loss_avg_over_batch': 0.12756514586084344,
 'train_ra_bd_only': 0.5124614486955072}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.6020848751068 s
2024-12-23:09:02:34 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.6020848751068 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005820373642067848,
 'clean_test_loss_avg_over_batch': 1.5736727611585097,
 'epoch': 96,
 'test_acc': 0.81,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9598373044096729,
 'train_acc_clean_only': 0.9901371233121978,
 'train_asr_bd_only': 0.6871423014946936,
 'train_epoch_loss_avg_over_batch': 0.12597708243831654,
 'train_ra_bd_only': 0.5097516252708785}
2024-12-23:09:02:39 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005820373642067848,
 'clean_test_loss_avg_over_batch': 1.5736727611585097,
 'epoch': 96,
 'test_acc': 0.81,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9598373044096729,
 'train_acc_clean_only': 0.9901371233121978,
 'train_asr_bd_only': 0.6871423014946936,
 'train_epoch_loss_avg_over_batch': 0.12597708243831654,
 'train_ra_bd_only': 0.5097516252708785}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.83914589881897 s
2024-12-23:09:07:04 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 264.83914589881897 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008034496516550214,
 'clean_test_loss_avg_over_batch': 1.5905301508578387,
 'epoch': 97,
 'test_acc': 0.8098571428571428,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9599484352773826,
 'train_acc_clean_only': 0.9903779071562193,
 'train_asr_bd_only': 0.6860865699838862,
 'train_epoch_loss_avg_over_batch': 0.12548278215716183,
 'train_ra_bd_only': 0.5106684447407901}
2024-12-23:09:07:09 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008034496516550214,
 'clean_test_loss_avg_over_batch': 1.5905301508578387,
 'epoch': 97,
 'test_acc': 0.8098571428571428,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9599484352773826,
 'train_acc_clean_only': 0.9903779071562193,
 'train_asr_bd_only': 0.6860865699838862,
 'train_epoch_loss_avg_over_batch': 0.12548278215716183,
 'train_ra_bd_only': 0.5106684447407901}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.7616055011749 s
2024-12-23:09:11:36 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.7616055011749 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008340558530604043,
 'clean_test_loss_avg_over_batch': 1.5791023164987563,
 'epoch': 98,
 'test_acc': 0.8105714285714286,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9598734219416786,
 'train_acc_clean_only': 0.9905785894432045,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.12568315631970975,
 'train_ra_bd_only': 0.5139332648014892}
2024-12-23:09:11:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008340558530604043,
 'clean_test_loss_avg_over_batch': 1.5791023164987563,
 'epoch': 98,
 'test_acc': 0.8105714285714286,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9598734219416786,
 'train_acc_clean_only': 0.9905785894432045,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.12568315631970975,
 'train_ra_bd_only': 0.5139332648014892}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.3702178001404 s
2024-12-23:09:16:06 [INFO    ] [trainer_cls.py:1805] one epoch training part done, use time = 265.3702178001404 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.004301056841954546,
 'clean_test_loss_avg_over_batch': 1.567738943479278,
 'epoch': 99,
 'test_acc': 0.807,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9601429142958748,
 'train_acc_clean_only': 0.9906372706393698,
 'train_asr_bd_only': 0.6856801511446988,
 'train_epoch_loss_avg_over_batch': 0.12500884285617944,
 'train_ra_bd_only': 0.511419204267615}
2024-12-23:09:16:12 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.004301056841954546,
 'clean_test_loss_avg_over_batch': 1.567738943479278,
 'epoch': 99,
 'test_acc': 0.807,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9601429142958748,
 'train_acc_clean_only': 0.9906372706393698,
 'train_asr_bd_only': 0.6856801511446988,
 'train_epoch_loss_avg_over_batch': 0.12500884285617944,
 'train_ra_bd_only': 0.511419204267615}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2024-12-23:09:16:12 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/badnet_attack_efficientnet_ffpp_5classes_to_binary/attack_result.pt
INFO:root:Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_5classes_to_binary
2024-12-23:09:16:13 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_5classes_to_binary
