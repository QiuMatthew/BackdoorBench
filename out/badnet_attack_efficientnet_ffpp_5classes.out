/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_5classes',
 'dataset_path': './data/ffpp_5classes',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 5,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_5classes',
 'save_path': './record/badnet_attack_efficientnet_ffpp_5classes',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_5classes',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_5classes'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2024-11-17:20:06:19 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_5classes',
 'dataset_path': './data/ffpp_5classes',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 5,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_5classes',
 'save_path': './record/badnet_attack_efficientnet_ffpp_5classes',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_5classes',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_5classes'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': None,
 'last 3 log': 'commit 8bc0d4cdd3c6f605f1ed08794342ddb7fdeea1ba\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 19:58:36 2024 +0900\n'
               '\n'
               '    new script: remove unneeded data in ffpp_345_classes '
               'dataset\n'
               '\n'
               'commit 9d712a96178e3fef60dffc2abef24948f4b53d32\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 17:27:05 2024 +0900\n'
               '\n'
               '    new script: badnet attack on ffpp_3/4/5_classes dataset on '
               'efficientnet\n'
               '\n'
               'commit 95fc46fa147247bc9144dd7ab4f9122c0f6d6109\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Nov 17 17:24:01 2024 +0900\n'
               '\n'
               '    support ffpp_3classes, ffpp_4classes, ffpp_5classes '
               'dataset',
 'status': 'On branch test-number-of-class\n'
           "Your branch is up to date with 'origin/test-number-of-class'.\n"
           '\n'
           'Changes not staged for commit:\n'
           '  (use "git add/rm <file>..." to update what will be committed)\n'
           '  (use "git checkout -- <file>..." to discard changes in working '
           'directory)\n'
           '\n'
           '\tdeleted:    out/sample.out\n'
           '\tmodified:   resource/badnet/trigger_image.png\n'
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\n'
           '\tout/badnet_attack_efficientnet_ffpp_3classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_4classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_5classes.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_binary.out\n'
           '\tout/badnet_attack_efficientnet_ffpp_multiclass.out\n'
           '\tout/badnet_attack_preactresnet_cifar10.out\n'
           '\tout/badnet_attack_preactresnet_cifar10_2classes.out\n'
           '\tout/badnet_attack_preactresnet_ffpp_binary.out\n'
           '\tout/badnet_attack_preactresnet_ffpp_multiclass.out\n'
           '\tout/copy_ffpp_binary_dataset.out\n'
           '\tout/copy_ffpp_multiclass_dataset.out\n'
           '\tout/generate_ffpp_with_345_classes.out\n'
           '\tout/remove_unnecessary_data.out\n'
           '\n'
           'no changes added to commit (use "git add" and/or "git commit -a")'}
INFO:root:stage1 start
2024-11-17:20:06:20 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2024-11-17:20:06:20 [WARNING ] [dataset_and_transform_generate.py:357] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:36000.0,real pratio:0.1
2024-11-17:20:12:07 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:36000.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2024-11-17:20:12:08 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/360000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 372/360000 [00:00<01:38, 3642.80it/s]prepro_backdoor:   0%|          | 737/360000 [00:00<01:39, 3605.01it/s]prepro_backdoor:   0%|          | 1186/360000 [00:00<01:29, 3991.62it/s]prepro_backdoor:   0%|          | 1586/360000 [00:00<01:31, 3903.73it/s]prepro_backdoor:   1%|          | 2005/360000 [00:00<01:29, 3993.03it/s]prepro_backdoor:   1%|          | 2405/360000 [00:00<01:33, 3807.56it/s]prepro_backdoor:   1%|          | 2788/360000 [00:00<01:34, 3788.93it/s]prepro_backdoor:   1%|          | 3281/360000 [00:00<01:26, 4135.87it/s]prepro_backdoor:   1%|          | 3697/360000 [00:00<01:27, 4051.42it/s]prepro_backdoor:   1%|          | 4127/360000 [00:01<01:26, 4121.28it/s]prepro_backdoor:   1%|▏         | 4541/360000 [00:01<01:27, 4043.67it/s]prepro_backdoor:   1%|▏         | 4975/360000 [00:01<01:26, 4110.13it/s]prepro_backdoor:   2%|▏         | 5440/360000 [00:01<01:23, 4244.55it/s]prepro_backdoor:   2%|▏         | 5866/360000 [00:01<01:26, 4089.73it/s]prepro_backdoor:   2%|▏         | 6336/360000 [00:01<01:22, 4264.45it/s]prepro_backdoor:   2%|▏         | 6765/360000 [00:01<01:25, 4137.99it/s]prepro_backdoor:   2%|▏         | 7181/360000 [00:01<01:27, 4035.96it/s]prepro_backdoor:   2%|▏         | 7606/360000 [00:01<01:26, 4074.87it/s]prepro_backdoor:   2%|▏         | 8144/360000 [00:01<01:19, 4427.27it/s]prepro_backdoor:   2%|▏         | 8615/360000 [00:02<01:17, 4506.11it/s]prepro_backdoor:   3%|▎         | 9126/360000 [00:02<01:15, 4668.60it/s]prepro_backdoor:   3%|▎         | 9595/360000 [00:02<01:17, 4537.28it/s]prepro_backdoor:   3%|▎         | 10051/360000 [00:02<01:18, 4446.85it/s]prepro_backdoor:   3%|▎         | 10497/360000 [00:02<01:20, 4365.15it/s]prepro_backdoor:   3%|▎         | 11055/360000 [00:02<01:14, 4686.45it/s]prepro_backdoor:   3%|▎         | 11595/360000 [00:02<01:11, 4892.57it/s]prepro_backdoor:   3%|▎         | 12203/360000 [00:02<01:06, 5221.68it/s]prepro_backdoor:   4%|▎         | 12727/360000 [00:02<01:09, 4977.72it/s]prepro_backdoor:   4%|▎         | 13229/360000 [00:03<01:14, 4682.93it/s]prepro_backdoor:   4%|▍         | 13795/360000 [00:03<01:14, 4670.16it/s]prepro_backdoor:   4%|▍         | 14363/360000 [00:03<01:10, 4935.37it/s]prepro_backdoor:   4%|▍         | 14903/360000 [00:03<01:09, 4977.66it/s]prepro_backdoor:   4%|▍         | 15405/360000 [00:03<01:11, 4820.61it/s]prepro_backdoor:   4%|▍         | 15890/360000 [00:03<01:11, 4784.84it/s]prepro_backdoor:   5%|▍         | 16397/360000 [00:03<01:10, 4848.00it/s]prepro_backdoor:   5%|▍         | 16884/360000 [00:03<01:12, 4712.90it/s]prepro_backdoor:   5%|▍         | 17357/360000 [00:03<01:16, 4501.52it/s]prepro_backdoor:   5%|▍         | 17810/360000 [00:04<01:22, 4145.64it/s]prepro_backdoor:   5%|▌         | 18280/360000 [00:04<01:19, 4274.64it/s]prepro_backdoor:   5%|▌         | 18768/360000 [00:04<01:17, 4427.06it/s]prepro_backdoor:   5%|▌         | 19216/360000 [00:04<01:17, 4396.08it/s]prepro_backdoor:   5%|▌         | 19659/360000 [00:04<01:18, 4356.00it/s]prepro_backdoor:   6%|▌         | 20119/360000 [00:04<01:17, 4400.66it/s]prepro_backdoor:   6%|▌         | 20561/360000 [00:04<01:19, 4264.75it/s]prepro_backdoor:   6%|▌         | 20990/360000 [00:04<01:23, 4079.24it/s]prepro_backdoor:   6%|▌         | 21464/360000 [00:04<01:19, 4261.31it/s]prepro_backdoor:   6%|▌         | 21971/360000 [00:05<01:15, 4471.89it/s]prepro_backdoor:   6%|▌         | 22421/360000 [00:05<01:20, 4203.01it/s]prepro_backdoor:   6%|▋         | 22846/360000 [00:05<01:20, 4177.56it/s]prepro_backdoor:   6%|▋         | 23267/360000 [00:05<01:20, 4172.42it/s]prepro_backdoor:   7%|▋         | 23690/360000 [00:05<01:20, 4174.43it/s]prepro_backdoor:   7%|▋         | 24133/360000 [00:05<01:19, 4234.53it/s]prepro_backdoor:   7%|▋         | 24633/360000 [00:05<01:15, 4444.96it/s]prepro_backdoor:   7%|▋         | 25079/360000 [00:05<01:18, 4265.42it/s]prepro_backdoor:   7%|▋         | 25508/360000 [00:05<01:18, 4270.52it/s]prepro_backdoor:   7%|▋         | 25937/360000 [00:05<01:18, 4234.02it/s]prepro_backdoor:   7%|▋         | 26362/360000 [00:06<01:18, 4227.03it/s]prepro_backdoor:   7%|▋         | 26786/360000 [00:06<01:21, 4070.33it/s]prepro_backdoor:   8%|▊         | 27195/360000 [00:06<01:23, 4000.77it/s]prepro_backdoor:   8%|▊         | 27624/360000 [00:06<01:21, 4069.39it/s]prepro_backdoor:   8%|▊         | 28094/360000 [00:06<01:18, 4251.73it/s]prepro_backdoor:   8%|▊         | 28521/360000 [00:06<01:18, 4220.68it/s]prepro_backdoor:   8%|▊         | 28944/360000 [00:06<01:21, 4068.48it/s]prepro_backdoor:   8%|▊         | 29431/360000 [00:06<01:17, 4289.70it/s]prepro_backdoor:   8%|▊         | 29869/360000 [00:06<01:16, 4308.69it/s]prepro_backdoor:   8%|▊         | 30352/360000 [00:06<01:14, 4452.34it/s]prepro_backdoor:   9%|▊         | 30806/360000 [00:07<01:13, 4477.39it/s]prepro_backdoor:   9%|▊         | 31255/360000 [00:07<01:13, 4469.78it/s]prepro_backdoor:   9%|▉         | 31703/360000 [00:07<01:17, 4231.97it/s]prepro_backdoor:   9%|▉         | 32130/360000 [00:07<01:24, 3894.77it/s]prepro_backdoor:   9%|▉         | 32597/360000 [00:07<01:19, 4101.52it/s]prepro_backdoor:   9%|▉         | 33040/360000 [00:07<01:18, 4180.07it/s]prepro_backdoor:   9%|▉         | 33562/360000 [00:07<01:13, 4469.03it/s]prepro_backdoor:   9%|▉         | 34014/360000 [00:07<01:16, 4272.08it/s]prepro_backdoor:  10%|▉         | 34447/360000 [00:07<01:20, 4028.91it/s]prepro_backdoor:  10%|▉         | 34923/360000 [00:08<01:16, 4223.90it/s]prepro_backdoor:  10%|▉         | 35351/360000 [00:08<01:23, 3899.74it/s]prepro_backdoor:  10%|▉         | 35847/360000 [00:08<01:17, 4165.74it/s]prepro_backdoor:  10%|█         | 36272/360000 [00:08<01:18, 4142.26it/s]prepro_backdoor:  10%|█         | 36744/360000 [00:08<01:15, 4297.90it/s]prepro_backdoor:  10%|█         | 37179/360000 [00:08<01:15, 4284.21it/s]prepro_backdoor:  10%|█         | 37611/360000 [00:08<01:18, 4124.26it/s]prepro_backdoor:  11%|█         | 38050/360000 [00:08<01:16, 4190.65it/s]prepro_backdoor:  11%|█         | 38472/360000 [00:08<01:22, 3881.44it/s]prepro_backdoor:  11%|█         | 38974/360000 [00:09<01:16, 4183.91it/s]prepro_backdoor:  11%|█         | 39479/360000 [00:09<01:12, 4415.72it/s]prepro_backdoor:  11%|█         | 39927/360000 [00:09<01:15, 4258.77it/s]prepro_backdoor:  11%|█         | 40358/360000 [00:09<01:15, 4207.39it/s]prepro_backdoor:  11%|█▏        | 40811/360000 [00:09<01:14, 4284.68it/s]prepro_backdoor:  11%|█▏        | 41243/360000 [00:09<01:14, 4267.42it/s]prepro_backdoor:  12%|█▏        | 41741/360000 [00:09<01:11, 4464.81it/s]prepro_backdoor:  12%|█▏        | 42211/360000 [00:09<01:10, 4511.33it/s]prepro_backdoor:  12%|█▏        | 42704/360000 [00:09<01:08, 4618.58it/s]prepro_backdoor:  12%|█▏        | 43193/360000 [00:09<01:07, 4691.75it/s]prepro_backdoor:  12%|█▏        | 43664/360000 [00:10<01:09, 4584.33it/s]prepro_backdoor:  12%|█▏        | 44124/360000 [00:10<01:09, 4567.48it/s]prepro_backdoor:  12%|█▏        | 44582/360000 [00:10<01:09, 4549.38it/s]prepro_backdoor:  13%|█▎        | 45038/360000 [00:10<01:17, 4070.76it/s]prepro_backdoor:  13%|█▎        | 45455/360000 [00:10<01:19, 3957.17it/s]prepro_backdoor:  13%|█▎        | 45858/360000 [00:10<01:23, 3775.35it/s]prepro_backdoor:  13%|█▎        | 46241/360000 [00:10<01:27, 3581.06it/s]prepro_backdoor:  13%|█▎        | 46696/360000 [00:10<01:21, 3830.58it/s]prepro_backdoor:  13%|█▎        | 47097/360000 [00:11<01:21, 3858.64it/s]prepro_backdoor:  13%|█▎        | 47488/360000 [00:11<01:21, 3841.60it/s]prepro_backdoor:  13%|█▎        | 47876/360000 [00:11<01:23, 3756.48it/s]prepro_backdoor:  13%|█▎        | 48287/360000 [00:11<01:20, 3848.42it/s]prepro_backdoor:  14%|█▎        | 48677/360000 [00:11<01:20, 3863.00it/s]prepro_backdoor:  14%|█▎        | 49121/360000 [00:11<01:17, 4023.69it/s]prepro_backdoor:  14%|█▍        | 49545/360000 [00:11<01:16, 4077.54it/s]prepro_backdoor:  14%|█▍        | 49954/360000 [00:11<01:17, 3993.60it/s]prepro_backdoor:  14%|█▍        | 50357/360000 [00:11<01:17, 3978.87it/s]prepro_backdoor:  14%|█▍        | 50756/360000 [00:11<01:24, 3645.49it/s]prepro_backdoor:  14%|█▍        | 51179/360000 [00:12<01:21, 3784.92it/s]prepro_backdoor:  14%|█▍        | 51563/360000 [00:12<01:21, 3767.61it/s]prepro_backdoor:  14%|█▍        | 52072/360000 [00:12<01:14, 4124.67it/s]prepro_backdoor:  15%|█▍        | 52489/360000 [00:12<01:17, 3971.70it/s]prepro_backdoor:  15%|█▍        | 52993/360000 [00:12<01:12, 4245.89it/s]prepro_backdoor:  15%|█▍        | 53422/360000 [00:12<01:15, 4081.44it/s]prepro_backdoor:  15%|█▍        | 53834/360000 [00:12<01:15, 4050.83it/s]prepro_backdoor:  15%|█▌        | 54352/360000 [00:12<01:09, 4371.34it/s]prepro_backdoor:  15%|█▌        | 54943/360000 [00:12<01:03, 4809.58it/s]prepro_backdoor:  15%|█▌        | 55428/360000 [00:13<01:09, 4412.33it/s]prepro_backdoor:  16%|█▌        | 55895/360000 [00:13<01:07, 4481.78it/s]prepro_backdoor:  16%|█▌        | 56350/360000 [00:13<01:12, 4175.43it/s]prepro_backdoor:  16%|█▌        | 56863/360000 [00:13<01:08, 4406.71it/s]prepro_backdoor:  16%|█▌        | 57355/360000 [00:13<01:06, 4541.99it/s]prepro_backdoor:  16%|█▌        | 57816/360000 [00:13<01:08, 4428.42it/s]prepro_backdoor:  16%|█▌        | 58264/360000 [00:13<01:08, 4428.82it/s]prepro_backdoor:  16%|█▋        | 58710/360000 [00:14<02:14, 2236.44it/s]prepro_backdoor:  16%|█▋        | 59072/360000 [00:14<02:01, 2468.71it/s]prepro_backdoor:  17%|█▋        | 59420/360000 [00:14<02:37, 1903.44it/s]prepro_backdoor:  17%|█▋        | 59860/360000 [00:14<02:09, 2315.68it/s]prepro_backdoor:  17%|█▋        | 60207/360000 [00:14<01:58, 2536.82it/s]prepro_backdoor:  17%|█▋        | 60629/360000 [00:14<01:43, 2892.56it/s]prepro_backdoor:  17%|█▋        | 60987/360000 [00:14<01:42, 2908.26it/s]prepro_backdoor:  17%|█▋        | 61418/360000 [00:15<01:31, 3246.02it/s]prepro_backdoor:  17%|█▋        | 61784/360000 [00:15<03:08, 1581.04it/s]prepro_backdoor:  17%|█▋        | 62061/360000 [00:15<02:52, 1727.16it/s]prepro_backdoor:  17%|█▋        | 62459/360000 [00:15<02:21, 2109.91it/s]prepro_backdoor:  17%|█▋        | 62846/360000 [00:15<02:01, 2451.93it/s]prepro_backdoor:  18%|█▊        | 63192/360000 [00:16<01:51, 2657.10it/s]prepro_backdoor:  18%|█▊        | 63684/360000 [00:16<01:33, 3175.00it/s]prepro_backdoor:  18%|█▊        | 64063/360000 [00:16<01:29, 3319.10it/s]prepro_backdoor:  18%|█▊        | 64646/360000 [00:16<01:14, 3973.99it/s]prepro_backdoor:  18%|█▊        | 65194/360000 [00:16<01:07, 4382.65it/s]prepro_backdoor:  18%|█▊        | 65664/360000 [00:16<01:06, 4410.27it/s]prepro_backdoor:  18%|█▊        | 66127/360000 [00:16<01:09, 4202.48it/s]prepro_backdoor:  18%|█▊        | 66598/360000 [00:16<01:07, 4324.82it/s]prepro_backdoor:  19%|█▊        | 67044/360000 [00:16<01:08, 4274.85it/s]prepro_backdoor:  19%|█▊        | 67481/360000 [00:16<01:09, 4208.94it/s]prepro_backdoor:  19%|█▉        | 67909/360000 [00:17<01:10, 4124.48it/s]prepro_backdoor:  19%|█▉        | 68326/360000 [00:17<01:11, 4067.58it/s]prepro_backdoor:  19%|█▉        | 68736/360000 [00:17<01:12, 4032.45it/s]prepro_backdoor:  19%|█▉        | 69142/360000 [00:17<01:16, 3817.54it/s]prepro_backdoor:  19%|█▉        | 69527/360000 [00:17<01:21, 3581.94it/s]prepro_backdoor:  19%|█▉        | 69898/360000 [00:17<01:20, 3597.89it/s]prepro_backdoor:  20%|█▉        | 70261/360000 [00:17<01:21, 3552.28it/s]prepro_backdoor:  20%|█▉        | 70687/360000 [00:17<01:17, 3744.63it/s]prepro_backdoor:  20%|█▉        | 71153/360000 [00:17<01:12, 3984.20it/s]prepro_backdoor:  20%|█▉        | 71554/360000 [00:18<01:12, 3971.98it/s]prepro_backdoor:  20%|██        | 72048/360000 [00:18<01:07, 4247.21it/s]prepro_backdoor:  20%|██        | 72475/360000 [00:18<01:14, 3862.07it/s]prepro_backdoor:  20%|██        | 72895/360000 [00:18<01:12, 3949.22it/s]prepro_backdoor:  20%|██        | 73360/360000 [00:18<01:09, 4133.74it/s]prepro_backdoor:  20%|██        | 73779/360000 [00:18<01:12, 3953.32it/s]prepro_backdoor:  21%|██        | 74293/360000 [00:18<01:06, 4285.19it/s]prepro_backdoor:  21%|██        | 74728/360000 [00:18<01:07, 4257.73it/s]prepro_backdoor:  21%|██        | 75239/360000 [00:18<01:03, 4495.04it/s]prepro_backdoor:  21%|██        | 75746/360000 [00:18<01:01, 4635.24it/s]prepro_backdoor:  21%|██        | 76244/360000 [00:19<01:00, 4715.28it/s]prepro_backdoor:  21%|██▏       | 76718/360000 [00:19<01:02, 4506.18it/s]prepro_backdoor:  21%|██▏       | 77172/360000 [00:19<01:02, 4489.35it/s]prepro_backdoor:  22%|██▏       | 77658/360000 [00:19<01:01, 4588.58it/s]prepro_backdoor:  22%|██▏       | 78119/360000 [00:19<01:01, 4548.88it/s]prepro_backdoor:  22%|██▏       | 78576/360000 [00:19<01:03, 4441.68it/s]prepro_backdoor:  22%|██▏       | 79022/360000 [00:19<01:04, 4376.32it/s]prepro_backdoor:  22%|██▏       | 79529/360000 [00:19<01:01, 4561.81it/s]prepro_backdoor:  22%|██▏       | 79987/360000 [00:19<01:02, 4491.25it/s]prepro_backdoor:  22%|██▏       | 80438/360000 [00:20<01:02, 4449.23it/s]prepro_backdoor:  22%|██▏       | 80884/360000 [00:20<01:02, 4445.58it/s]prepro_backdoor:  23%|██▎       | 81329/360000 [00:20<01:10, 3964.65it/s]prepro_backdoor:  23%|██▎       | 81755/360000 [00:20<01:09, 4028.35it/s]prepro_backdoor:  23%|██▎       | 82165/360000 [00:20<01:10, 3931.47it/s]prepro_backdoor:  23%|██▎       | 82564/360000 [00:20<01:13, 3788.48it/s]prepro_backdoor:  23%|██▎       | 82967/360000 [00:20<01:12, 3831.86it/s]prepro_backdoor:  23%|██▎       | 83354/360000 [00:20<01:13, 3777.06it/s]prepro_backdoor:  23%|██▎       | 83875/360000 [00:20<01:06, 4163.66it/s]prepro_backdoor:  23%|██▎       | 84333/360000 [00:21<01:04, 4263.10it/s]prepro_backdoor:  24%|██▎       | 84805/360000 [00:21<01:02, 4374.73it/s]prepro_backdoor:  24%|██▎       | 85280/360000 [00:21<01:01, 4454.75it/s]prepro_backdoor:  24%|██▍       | 85727/360000 [00:21<01:03, 4315.38it/s]prepro_backdoor:  24%|██▍       | 86181/360000 [00:21<01:02, 4370.56it/s]prepro_backdoor:  24%|██▍       | 86645/360000 [00:21<01:01, 4442.15it/s]prepro_backdoor:  24%|██▍       | 87107/360000 [00:21<01:01, 4469.33it/s]prepro_backdoor:  24%|██▍       | 87555/360000 [00:21<01:03, 4282.03it/s]prepro_backdoor:  24%|██▍       | 87986/360000 [00:21<01:04, 4202.51it/s]prepro_backdoor:  25%|██▍       | 88451/360000 [00:21<01:03, 4305.50it/s]prepro_backdoor:  25%|██▍       | 88883/360000 [00:22<01:04, 4229.94it/s]prepro_backdoor:  25%|██▍       | 89488/360000 [00:22<00:57, 4726.50it/s]prepro_backdoor:  25%|██▍       | 89963/360000 [00:22<01:00, 4492.40it/s]prepro_backdoor:  25%|██▌       | 90416/360000 [00:22<01:01, 4398.83it/s]prepro_backdoor:  25%|██▌       | 90891/360000 [00:22<01:00, 4470.86it/s]prepro_backdoor:  25%|██▌       | 91340/360000 [00:22<01:03, 4214.75it/s]prepro_backdoor:  26%|██▌       | 91918/360000 [00:22<00:57, 4641.71it/s]prepro_backdoor:  26%|██▌       | 92388/360000 [00:22<00:59, 4511.13it/s]prepro_backdoor:  26%|██▌       | 92844/360000 [00:22<00:59, 4480.44it/s]prepro_backdoor:  26%|██▌       | 93295/360000 [00:23<01:02, 4258.76it/s]prepro_backdoor:  26%|██▌       | 93753/360000 [00:23<01:01, 4338.09it/s]prepro_backdoor:  26%|██▌       | 94190/360000 [00:23<01:10, 3784.15it/s]prepro_backdoor:  26%|██▋       | 94582/360000 [00:23<01:09, 3818.94it/s]prepro_backdoor:  26%|██▋       | 95048/360000 [00:23<01:05, 4025.70it/s]prepro_backdoor:  27%|██▋       | 95479/360000 [00:23<01:04, 4101.85it/s]prepro_backdoor:  27%|██▋       | 95896/360000 [00:23<01:04, 4083.87it/s]prepro_backdoor:  27%|██▋       | 96310/360000 [00:23<01:08, 3844.83it/s]prepro_backdoor:  27%|██▋       | 96824/360000 [00:23<01:02, 4185.02it/s]prepro_backdoor:  27%|██▋       | 97270/360000 [00:24<01:01, 4257.96it/s]prepro_backdoor:  27%|██▋       | 97721/360000 [00:24<01:00, 4329.69it/s]prepro_backdoor:  27%|██▋       | 98199/360000 [00:24<00:58, 4441.90it/s]prepro_backdoor:  27%|██▋       | 98793/360000 [00:24<00:53, 4853.31it/s]prepro_backdoor:  28%|██▊       | 99288/360000 [00:24<00:53, 4869.92it/s]prepro_backdoor:  28%|██▊       | 99777/360000 [00:24<00:55, 4719.06it/s]prepro_backdoor:  28%|██▊       | 100251/360000 [00:24<00:57, 4506.29it/s]prepro_backdoor:  28%|██▊       | 100760/360000 [00:24<00:55, 4643.80it/s]prepro_backdoor:  28%|██▊       | 101228/360000 [00:24<00:57, 4504.69it/s]prepro_backdoor:  28%|██▊       | 101696/360000 [00:24<00:56, 4534.63it/s]prepro_backdoor:  28%|██▊       | 102152/360000 [00:25<01:00, 4237.38it/s]prepro_backdoor:  28%|██▊       | 102581/360000 [00:25<01:02, 4134.47it/s]prepro_backdoor:  29%|██▊       | 102998/360000 [00:25<01:02, 4112.20it/s]prepro_backdoor:  29%|██▊       | 103412/360000 [00:25<01:05, 3928.61it/s]prepro_backdoor:  29%|██▉       | 103916/360000 [00:25<01:00, 4207.94it/s]prepro_backdoor:  29%|██▉       | 104341/360000 [00:25<01:03, 4011.77it/s]prepro_backdoor:  29%|██▉       | 104747/360000 [00:25<01:03, 4024.49it/s]prepro_backdoor:  29%|██▉       | 105180/360000 [00:25<01:02, 4097.87it/s]prepro_backdoor:  29%|██▉       | 105592/360000 [00:25<01:02, 4055.65it/s]prepro_backdoor:  29%|██▉       | 106071/360000 [00:26<00:59, 4251.53it/s]prepro_backdoor:  30%|██▉       | 106498/360000 [00:26<01:02, 4049.97it/s]prepro_backdoor:  30%|██▉       | 107059/360000 [00:26<00:56, 4470.02it/s]prepro_backdoor:  30%|██▉       | 107522/360000 [00:26<00:56, 4507.23it/s]prepro_backdoor:  30%|███       | 108038/360000 [00:26<00:53, 4689.71it/s]prepro_backdoor:  30%|███       | 108510/360000 [00:26<00:55, 4561.05it/s]prepro_backdoor:  30%|███       | 109012/360000 [00:26<00:53, 4682.52it/s]prepro_backdoor:  30%|███       | 109483/360000 [00:26<00:56, 4439.74it/s]prepro_backdoor:  31%|███       | 109931/360000 [00:26<01:01, 4092.99it/s]prepro_backdoor:  31%|███       | 110414/360000 [00:27<00:58, 4273.39it/s]prepro_backdoor:  31%|███       | 110942/360000 [00:27<00:55, 4527.22it/s]prepro_backdoor:  31%|███       | 111401/360000 [00:27<01:00, 4101.64it/s]prepro_backdoor:  31%|███       | 111822/360000 [00:27<01:02, 3971.76it/s]prepro_backdoor:  31%|███       | 112227/360000 [00:27<01:04, 3862.31it/s]prepro_backdoor:  31%|███▏      | 112624/360000 [00:27<01:03, 3870.62it/s]prepro_backdoor:  31%|███▏      | 113015/360000 [00:27<01:04, 3851.69it/s]prepro_backdoor:  32%|███▏      | 113403/360000 [00:27<01:04, 3847.47it/s]prepro_backdoor:  32%|███▏      | 113846/360000 [00:27<01:01, 3993.24it/s]prepro_backdoor:  32%|███▏      | 114321/360000 [00:28<00:58, 4211.51it/s]prepro_backdoor:  32%|███▏      | 114764/360000 [00:28<00:57, 4265.24it/s]prepro_backdoor:  32%|███▏      | 115192/360000 [00:28<01:05, 3719.67it/s]prepro_backdoor:  32%|███▏      | 115578/360000 [00:28<01:05, 3750.04it/s]prepro_backdoor:  32%|███▏      | 115965/360000 [00:28<01:04, 3782.84it/s]prepro_backdoor:  32%|███▏      | 116593/360000 [00:28<00:54, 4471.21it/s]prepro_backdoor:  33%|███▎      | 117049/360000 [00:28<01:12, 3374.13it/s]prepro_backdoor:  33%|███▎      | 117497/360000 [00:28<01:06, 3621.99it/s]prepro_backdoor:  33%|███▎      | 117919/360000 [00:29<01:04, 3754.67it/s]prepro_backdoor:  33%|███▎      | 118435/360000 [00:29<00:58, 4112.78it/s]prepro_backdoor:  33%|███▎      | 118882/360000 [00:29<00:57, 4207.98it/s]prepro_backdoor:  33%|███▎      | 119322/360000 [00:29<01:00, 3977.47it/s]prepro_backdoor:  33%|███▎      | 119811/360000 [00:29<00:56, 4222.04it/s]prepro_backdoor:  33%|███▎      | 120247/360000 [00:29<00:57, 4140.41it/s]prepro_backdoor:  34%|███▎      | 120671/360000 [00:29<01:02, 3833.49it/s]prepro_backdoor:  34%|███▎      | 121067/360000 [00:29<01:01, 3856.71it/s]prepro_backdoor:  34%|███▍      | 121626/360000 [00:29<00:55, 4318.78it/s]prepro_backdoor:  34%|███▍      | 122067/360000 [00:29<00:55, 4263.85it/s]prepro_backdoor:  34%|███▍      | 122500/360000 [00:30<00:56, 4197.29it/s]prepro_backdoor:  34%|███▍      | 122924/360000 [00:30<00:57, 4095.34it/s]prepro_backdoor:  34%|███▍      | 123368/360000 [00:30<00:56, 4164.40it/s]prepro_backdoor:  34%|███▍      | 123841/360000 [00:30<00:54, 4317.76it/s]prepro_backdoor:  35%|███▍      | 124276/360000 [00:30<00:56, 4173.36it/s]prepro_backdoor:  35%|███▍      | 124772/360000 [00:30<00:53, 4393.65it/s]prepro_backdoor:  35%|███▍      | 125215/360000 [00:30<00:56, 4138.45it/s]prepro_backdoor:  35%|███▍      | 125695/360000 [00:30<00:54, 4322.02it/s]prepro_backdoor:  35%|███▌      | 126132/360000 [00:30<00:55, 4217.94it/s]prepro_backdoor:  35%|███▌      | 126558/360000 [00:31<00:58, 3958.47it/s]prepro_backdoor:  35%|███▌      | 126959/360000 [00:31<00:59, 3896.56it/s]prepro_backdoor:  35%|███▌      | 127352/360000 [00:31<01:00, 3841.43it/s]prepro_backdoor:  35%|███▌      | 127739/360000 [00:31<01:03, 3655.00it/s]prepro_backdoor:  36%|███▌      | 128107/360000 [00:31<01:03, 3624.44it/s]prepro_backdoor:  36%|███▌      | 128574/360000 [00:31<00:59, 3907.55it/s]prepro_backdoor:  36%|███▌      | 128968/360000 [00:31<00:59, 3888.02it/s]prepro_backdoor:  36%|███▌      | 129359/360000 [00:31<01:00, 3837.87it/s]prepro_backdoor:  36%|███▌      | 129817/360000 [00:31<00:56, 4049.03it/s]prepro_backdoor:  36%|███▌      | 130224/360000 [00:32<00:58, 3912.83it/s]prepro_backdoor:  36%|███▋      | 130618/360000 [00:32<00:59, 3876.65it/s]prepro_backdoor:  36%|███▋      | 131112/360000 [00:32<00:55, 4160.63it/s]prepro_backdoor:  37%|███▋      | 131616/360000 [00:32<00:51, 4392.82it/s]prepro_backdoor:  37%|███▋      | 132057/360000 [00:32<01:00, 3787.23it/s]prepro_backdoor:  37%|███▋      | 132467/360000 [00:32<00:58, 3861.69it/s]prepro_backdoor:  37%|███▋      | 133079/360000 [00:32<00:50, 4470.02it/s]prepro_backdoor:  37%|███▋      | 133574/360000 [00:32<00:49, 4576.99it/s]prepro_backdoor:  37%|███▋      | 134127/360000 [00:32<00:46, 4816.76it/s]prepro_backdoor:  37%|███▋      | 134617/360000 [00:33<00:48, 4652.68it/s]prepro_backdoor:  38%|███▊      | 135089/360000 [00:33<00:49, 4550.00it/s]prepro_backdoor:  38%|███▊      | 135549/360000 [00:33<00:57, 3925.28it/s]prepro_backdoor:  38%|███▊      | 136117/360000 [00:33<00:51, 4372.32it/s]prepro_backdoor:  38%|███▊      | 136661/360000 [00:33<00:48, 4646.37it/s]prepro_backdoor:  38%|███▊      | 137142/360000 [00:33<00:50, 4419.17it/s]prepro_backdoor:  38%|███▊      | 137606/360000 [00:33<00:49, 4456.30it/s]prepro_backdoor:  38%|███▊      | 138061/360000 [00:33<00:51, 4276.36it/s]prepro_backdoor:  38%|███▊      | 138510/360000 [00:33<00:51, 4312.39it/s]prepro_backdoor:  39%|███▊      | 138966/360000 [00:34<00:50, 4356.96it/s]prepro_backdoor:  39%|███▊      | 139406/360000 [00:34<00:51, 4305.40it/s]prepro_backdoor:  39%|███▉      | 139865/360000 [00:34<00:50, 4363.30it/s]prepro_backdoor:  39%|███▉      | 140432/360000 [00:34<00:46, 4714.54it/s]prepro_backdoor:  39%|███▉      | 140906/360000 [00:34<00:51, 4239.48it/s]prepro_backdoor:  39%|███▉      | 141340/360000 [00:34<00:53, 4103.31it/s]prepro_backdoor:  39%|███▉      | 141758/360000 [00:34<00:53, 4073.00it/s]prepro_backdoor:  40%|███▉      | 142249/360000 [00:34<00:50, 4292.87it/s]prepro_backdoor:  40%|███▉      | 142720/360000 [00:34<00:49, 4400.84it/s]prepro_backdoor:  40%|███▉      | 143216/360000 [00:34<00:47, 4548.36it/s]prepro_backdoor:  40%|███▉      | 143675/360000 [00:35<00:50, 4317.79it/s]prepro_backdoor:  40%|████      | 144112/360000 [00:35<00:49, 4320.50it/s]prepro_backdoor:  40%|████      | 144607/360000 [00:35<00:47, 4496.29it/s]prepro_backdoor:  40%|████      | 145062/360000 [00:35<00:47, 4484.22it/s]prepro_backdoor:  40%|████      | 145513/360000 [00:35<00:49, 4323.08it/s]prepro_backdoor:  41%|████      | 145948/360000 [00:35<00:49, 4319.63it/s]prepro_backdoor:  41%|████      | 146382/360000 [00:35<00:52, 4099.65it/s]prepro_backdoor:  41%|████      | 146841/360000 [00:35<00:50, 4212.40it/s]prepro_backdoor:  41%|████      | 147326/360000 [00:35<00:48, 4377.97it/s]prepro_backdoor:  41%|████      | 147767/360000 [00:36<00:49, 4320.18it/s]prepro_backdoor:  41%|████      | 148296/360000 [00:36<00:46, 4594.35it/s]prepro_backdoor:  41%|████▏     | 148820/360000 [00:36<00:44, 4771.32it/s]prepro_backdoor:  41%|████▏     | 149367/360000 [00:36<00:42, 4961.37it/s]prepro_backdoor:  42%|████▏     | 149865/360000 [00:36<00:45, 4588.65it/s]prepro_backdoor:  42%|████▏     | 150331/360000 [00:36<00:45, 4598.57it/s]prepro_backdoor:  42%|████▏     | 150796/360000 [00:36<00:47, 4441.87it/s]prepro_backdoor:  42%|████▏     | 151244/360000 [00:36<00:49, 4181.15it/s]prepro_backdoor:  42%|████▏     | 151773/360000 [00:36<00:46, 4477.93it/s]prepro_backdoor:  42%|████▏     | 152237/360000 [00:37<00:46, 4501.48it/s]prepro_backdoor:  42%|████▏     | 152692/360000 [00:37<00:47, 4376.47it/s]prepro_backdoor:  43%|████▎     | 153133/360000 [00:37<00:47, 4334.88it/s]prepro_backdoor:  43%|████▎     | 153569/360000 [00:37<00:49, 4206.22it/s]prepro_backdoor:  43%|████▎     | 154032/360000 [00:37<00:47, 4323.39it/s]prepro_backdoor:  43%|████▎     | 154542/360000 [00:37<00:45, 4542.65it/s]prepro_backdoor:  43%|████▎     | 155005/360000 [00:37<00:45, 4546.24it/s]prepro_backdoor:  43%|████▎     | 155462/360000 [00:37<00:47, 4339.39it/s]prepro_backdoor:  43%|████▎     | 155899/360000 [00:37<00:51, 3992.39it/s]prepro_backdoor:  43%|████▎     | 156378/360000 [00:38<00:48, 4198.03it/s]prepro_backdoor:  44%|████▎     | 156805/360000 [00:38<00:51, 3913.90it/s]prepro_backdoor:  44%|████▎     | 157204/360000 [00:38<00:54, 3731.06it/s]prepro_backdoor:  44%|████▍     | 157668/360000 [00:38<00:51, 3960.34it/s]prepro_backdoor:  44%|████▍     | 158071/360000 [00:38<00:53, 3806.28it/s]prepro_backdoor:  44%|████▍     | 158512/360000 [00:38<00:50, 3956.51it/s]prepro_backdoor:  44%|████▍     | 158913/360000 [00:38<00:51, 3900.59it/s]prepro_backdoor:  44%|████▍     | 159338/360000 [00:38<00:50, 3989.02it/s]prepro_backdoor:  44%|████▍     | 159761/360000 [00:38<00:49, 4053.33it/s]prepro_backdoor:  44%|████▍     | 160186/360000 [00:38<00:48, 4110.43it/s]prepro_backdoor:  45%|████▍     | 160643/360000 [00:39<00:47, 4220.09it/s]prepro_backdoor:  45%|████▍     | 161067/360000 [00:39<00:47, 4177.90it/s]prepro_backdoor:  45%|████▍     | 161486/360000 [00:39<00:48, 4114.88it/s]prepro_backdoor:  45%|████▍     | 161899/360000 [00:39<00:48, 4102.69it/s]prepro_backdoor:  45%|████▌     | 162346/360000 [00:39<00:47, 4183.39it/s]prepro_backdoor:  45%|████▌     | 162792/360000 [00:39<00:46, 4244.11it/s]prepro_backdoor:  45%|████▌     | 163217/360000 [00:39<00:49, 3987.82it/s]prepro_backdoor:  45%|████▌     | 163619/360000 [00:39<00:49, 3940.65it/s]prepro_backdoor:  46%|████▌     | 164016/360000 [00:40<01:19, 2467.49it/s]prepro_backdoor:  46%|████▌     | 164443/360000 [00:40<01:09, 2826.97it/s]prepro_backdoor:  46%|████▌     | 164861/360000 [00:40<01:02, 3122.62it/s]prepro_backdoor:  46%|████▌     | 165275/360000 [00:40<00:58, 3355.95it/s]prepro_backdoor:  46%|████▌     | 165658/360000 [00:40<00:56, 3458.49it/s]prepro_backdoor:  46%|████▌     | 166037/360000 [00:40<00:54, 3540.85it/s]prepro_backdoor:  46%|████▌     | 166457/360000 [00:40<00:52, 3717.77it/s]prepro_backdoor:  46%|████▋     | 166896/360000 [00:40<00:49, 3883.42it/s]prepro_backdoor:  46%|████▋     | 167301/360000 [00:40<00:49, 3905.51it/s]prepro_backdoor:  47%|████▋     | 167785/360000 [00:41<00:46, 4166.79it/s]prepro_backdoor:  47%|████▋     | 168309/360000 [00:41<00:42, 4459.27it/s]prepro_backdoor:  47%|████▋     | 168761/360000 [00:41<00:43, 4444.32it/s]prepro_backdoor:  47%|████▋     | 169210/360000 [00:41<00:43, 4429.88it/s]prepro_backdoor:  47%|████▋     | 169656/360000 [00:41<00:44, 4305.75it/s]prepro_backdoor:  47%|████▋     | 170090/360000 [00:41<00:44, 4309.61it/s]prepro_backdoor:  47%|████▋     | 170540/360000 [00:41<00:43, 4349.10it/s]prepro_backdoor:  48%|████▊     | 171128/360000 [00:41<00:39, 4730.46it/s]prepro_backdoor:  48%|████▊     | 171602/360000 [00:41<00:42, 4414.63it/s]prepro_backdoor:  48%|████▊     | 172048/360000 [00:42<00:45, 4171.47it/s]prepro_backdoor:  48%|████▊     | 172596/360000 [00:42<00:41, 4525.51it/s]prepro_backdoor:  48%|████▊     | 173055/360000 [00:42<00:45, 4102.29it/s]prepro_backdoor:  48%|████▊     | 173476/360000 [00:42<00:48, 3883.00it/s]prepro_backdoor:  48%|████▊     | 173909/360000 [00:42<00:46, 3992.34it/s]prepro_backdoor:  48%|████▊     | 174405/360000 [00:42<00:43, 4242.16it/s]prepro_backdoor:  49%|████▊     | 174857/360000 [00:42<00:42, 4310.62it/s]prepro_backdoor:  49%|████▊     | 175294/360000 [00:42<00:42, 4321.14it/s]prepro_backdoor:  49%|████▉     | 175731/360000 [00:42<00:47, 3903.69it/s]prepro_backdoor:  49%|████▉     | 176132/360000 [00:43<00:47, 3869.97it/s]prepro_backdoor:  49%|████▉     | 176568/360000 [00:43<00:45, 3994.44it/s]prepro_backdoor:  49%|████▉     | 176974/360000 [00:43<00:48, 3783.18it/s]prepro_backdoor:  49%|████▉     | 177445/360000 [00:43<00:45, 4037.05it/s]prepro_backdoor:  49%|████▉     | 177916/360000 [00:43<00:43, 4209.34it/s]prepro_backdoor:  50%|████▉     | 178343/360000 [00:43<00:48, 3783.44it/s]prepro_backdoor:  50%|████▉     | 178804/360000 [00:43<00:45, 3998.91it/s]prepro_backdoor:  50%|████▉     | 179218/360000 [00:43<00:44, 4021.30it/s]prepro_backdoor:  50%|████▉     | 179670/360000 [00:43<00:43, 4154.07it/s]prepro_backdoor:  50%|█████     | 180239/360000 [00:43<00:39, 4587.29it/s]prepro_backdoor:  50%|█████     | 180786/360000 [00:44<00:37, 4835.98it/s]prepro_backdoor:  50%|█████     | 181275/360000 [00:44<01:15, 2356.96it/s]prepro_backdoor:  50%|█████     | 181649/360000 [00:44<01:10, 2525.14it/s]prepro_backdoor:  51%|█████     | 182008/360000 [00:44<01:05, 2717.70it/s]prepro_backdoor:  51%|█████     | 182365/360000 [00:44<01:01, 2877.61it/s]prepro_backdoor:  51%|█████     | 182830/360000 [00:44<00:53, 3281.12it/s]prepro_backdoor:  51%|█████     | 183216/360000 [00:45<00:52, 3386.85it/s]prepro_backdoor:  51%|█████     | 183601/360000 [00:45<00:50, 3491.29it/s]prepro_backdoor:  51%|█████     | 183984/360000 [00:45<00:49, 3569.22it/s]prepro_backdoor:  51%|█████     | 184426/360000 [00:45<00:46, 3803.02it/s]prepro_backdoor:  51%|█████▏    | 184906/360000 [00:45<00:42, 4072.03it/s]prepro_backdoor:  51%|█████▏    | 185334/360000 [00:45<00:42, 4117.05it/s]prepro_backdoor:  52%|█████▏    | 185756/360000 [00:45<00:43, 3998.60it/s]prepro_backdoor:  52%|█████▏    | 186237/360000 [00:45<00:41, 4224.85it/s]prepro_backdoor:  52%|█████▏    | 186691/360000 [00:45<00:40, 4314.60it/s]prepro_backdoor:  52%|█████▏    | 187151/360000 [00:46<00:39, 4373.64it/s]prepro_backdoor:  52%|█████▏    | 187617/360000 [00:46<00:38, 4433.67it/s]prepro_backdoor:  52%|█████▏    | 188139/360000 [00:46<00:37, 4641.18it/s]prepro_backdoor:  52%|█████▏    | 188605/360000 [00:46<00:40, 4258.26it/s]prepro_backdoor:  53%|█████▎    | 189179/360000 [00:46<00:36, 4646.42it/s]prepro_backdoor:  53%|█████▎    | 189652/360000 [00:46<00:39, 4265.48it/s]prepro_backdoor:  53%|█████▎    | 190089/360000 [00:46<00:41, 4125.82it/s]prepro_backdoor:  53%|█████▎    | 190549/360000 [00:46<00:40, 4234.01it/s]prepro_backdoor:  53%|█████▎    | 190979/360000 [00:46<00:40, 4175.34it/s]prepro_backdoor:  53%|█████▎    | 191401/360000 [00:47<00:44, 3776.90it/s]prepro_backdoor:  53%|█████▎    | 191818/360000 [00:47<00:43, 3878.74it/s]prepro_backdoor:  53%|█████▎    | 192258/360000 [00:47<00:41, 4018.93it/s]prepro_backdoor:  54%|█████▎    | 192667/360000 [00:47<00:43, 3819.18it/s]prepro_backdoor:  54%|█████▎    | 193126/360000 [00:47<00:41, 4024.54it/s]prepro_backdoor:  54%|█████▍    | 193582/360000 [00:47<00:39, 4167.23it/s]prepro_backdoor:  54%|█████▍    | 194004/360000 [00:47<00:40, 4074.60it/s]prepro_backdoor:  54%|█████▍    | 194416/360000 [00:47<00:40, 4052.35it/s]prepro_backdoor:  54%|█████▍    | 194824/360000 [00:47<00:41, 4008.41it/s]prepro_backdoor:  54%|█████▍    | 195227/360000 [00:47<00:41, 3985.94it/s]prepro_backdoor:  54%|█████▍    | 195627/360000 [00:48<00:42, 3886.60it/s]prepro_backdoor:  54%|█████▍    | 196017/360000 [00:48<00:43, 3768.64it/s]prepro_backdoor:  55%|█████▍    | 196395/360000 [00:48<00:43, 3767.22it/s]prepro_backdoor:  55%|█████▍    | 196773/360000 [00:48<00:44, 3687.60it/s]prepro_backdoor:  55%|█████▍    | 197304/360000 [00:48<00:39, 4133.76it/s]prepro_backdoor:  55%|█████▍    | 197720/360000 [00:48<00:40, 4034.76it/s]prepro_backdoor:  55%|█████▌    | 198307/360000 [00:48<00:35, 4534.72it/s]prepro_backdoor:  55%|█████▌    | 198763/360000 [00:48<00:35, 4500.87it/s]prepro_backdoor:  55%|█████▌    | 199215/360000 [00:48<00:36, 4429.90it/s]prepro_backdoor:  55%|█████▌    | 199660/360000 [00:49<00:37, 4252.37it/s]prepro_backdoor:  56%|█████▌    | 200088/360000 [00:49<00:38, 4152.45it/s]prepro_backdoor:  56%|█████▌    | 200536/360000 [00:49<00:37, 4240.52it/s]prepro_backdoor:  56%|█████▌    | 200962/360000 [00:49<00:38, 4108.56it/s]prepro_backdoor:  56%|█████▌    | 201375/360000 [00:49<00:39, 3995.70it/s]prepro_backdoor:  56%|█████▌    | 201813/360000 [00:49<00:38, 4102.31it/s]prepro_backdoor:  56%|█████▌    | 202237/360000 [00:49<00:38, 4141.03it/s]prepro_backdoor:  56%|█████▋    | 202698/360000 [00:49<00:36, 4270.32it/s]prepro_backdoor:  56%|█████▋    | 203185/360000 [00:49<00:35, 4422.50it/s]prepro_backdoor:  57%|█████▋    | 203629/360000 [00:50<00:38, 4095.79it/s]prepro_backdoor:  57%|█████▋    | 204058/360000 [00:50<00:37, 4131.83it/s]prepro_backdoor:  57%|█████▋    | 204475/360000 [00:50<00:39, 3916.31it/s]prepro_backdoor:  57%|█████▋    | 205024/360000 [00:50<00:35, 4333.48it/s]prepro_backdoor:  57%|█████▋    | 205545/360000 [00:50<00:33, 4578.24it/s]prepro_backdoor:  57%|█████▋    | 206009/360000 [00:50<00:35, 4326.26it/s]prepro_backdoor:  57%|█████▋    | 206506/360000 [00:50<00:34, 4482.69it/s]prepro_backdoor:  57%|█████▋    | 206960/360000 [00:50<00:34, 4422.92it/s]prepro_backdoor:  58%|█████▊    | 207426/360000 [00:50<00:34, 4467.19it/s]prepro_backdoor:  58%|█████▊    | 207895/360000 [00:50<00:33, 4508.53it/s]prepro_backdoor:  58%|█████▊    | 208348/360000 [00:51<00:33, 4498.43it/s]prepro_backdoor:  58%|█████▊    | 208821/360000 [00:51<00:33, 4553.10it/s]prepro_backdoor:  58%|█████▊    | 209278/360000 [00:51<00:35, 4216.65it/s]prepro_backdoor:  58%|█████▊    | 209705/360000 [00:51<00:35, 4189.83it/s]prepro_backdoor:  58%|█████▊    | 210128/360000 [00:51<00:36, 4091.82it/s]prepro_backdoor:  58%|█████▊    | 210574/360000 [00:51<00:35, 4189.96it/s]prepro_backdoor:  59%|█████▊    | 211106/360000 [00:51<00:33, 4502.31it/s]prepro_backdoor:  59%|█████▉    | 211560/360000 [00:51<00:33, 4432.44it/s]prepro_backdoor:  59%|█████▉    | 212006/360000 [00:51<00:34, 4304.30it/s]prepro_backdoor:  59%|█████▉    | 212473/360000 [00:52<00:33, 4392.93it/s]prepro_backdoor:  59%|█████▉    | 212917/360000 [00:52<00:33, 4377.53it/s]prepro_backdoor:  59%|█████▉    | 213356/360000 [00:52<00:35, 4111.21it/s]prepro_backdoor:  59%|█████▉    | 213898/360000 [00:52<00:32, 4470.21it/s]prepro_backdoor:  60%|█████▉    | 214350/360000 [00:52<00:33, 4329.76it/s]prepro_backdoor:  60%|█████▉    | 214822/360000 [00:52<00:32, 4438.94it/s]prepro_backdoor:  60%|█████▉    | 215309/360000 [00:52<00:31, 4562.93it/s]prepro_backdoor:  60%|█████▉    | 215769/360000 [00:52<00:32, 4392.53it/s]prepro_backdoor:  60%|██████    | 216212/360000 [00:52<00:33, 4246.65it/s]prepro_backdoor:  60%|██████    | 216640/360000 [00:52<00:34, 4157.03it/s]prepro_backdoor:  60%|██████    | 217058/360000 [00:53<00:34, 4110.98it/s]prepro_backdoor:  60%|██████    | 217473/360000 [00:53<00:34, 4114.87it/s]prepro_backdoor:  61%|██████    | 217886/360000 [00:53<00:34, 4105.82it/s]prepro_backdoor:  61%|██████    | 218298/360000 [00:53<00:36, 3926.62it/s]prepro_backdoor:  61%|██████    | 218726/360000 [00:53<00:35, 4016.09it/s]prepro_backdoor:  61%|██████    | 219157/360000 [00:53<00:34, 4093.92it/s]prepro_backdoor:  61%|██████    | 219568/360000 [00:53<00:35, 3962.15it/s]prepro_backdoor:  61%|██████    | 219966/360000 [00:53<00:35, 3895.73it/s]prepro_backdoor:  61%|██████    | 220357/360000 [00:53<00:37, 3766.76it/s]prepro_backdoor:  61%|██████▏   | 220735/360000 [00:54<00:37, 3721.91it/s]prepro_backdoor:  61%|██████▏   | 221117/360000 [00:54<00:37, 3735.61it/s]prepro_backdoor:  62%|██████▏   | 221503/360000 [00:54<00:36, 3768.33it/s]prepro_backdoor:  62%|██████▏   | 221896/360000 [00:54<00:36, 3803.28it/s]prepro_backdoor:  62%|██████▏   | 222282/360000 [00:54<00:36, 3797.29it/s]prepro_backdoor:  62%|██████▏   | 222741/360000 [00:54<00:34, 4017.08it/s]prepro_backdoor:  62%|██████▏   | 223144/360000 [00:54<00:34, 3969.72it/s]prepro_backdoor:  62%|██████▏   | 223542/360000 [00:54<00:36, 3785.97it/s]prepro_backdoor:  62%|██████▏   | 223945/360000 [00:54<00:35, 3841.59it/s]prepro_backdoor:  62%|██████▏   | 224331/360000 [00:55<00:37, 3639.55it/s]prepro_backdoor:  62%|██████▏   | 224742/360000 [00:55<00:35, 3764.67it/s]prepro_backdoor:  63%|██████▎   | 225231/360000 [00:55<00:33, 4061.70it/s]prepro_backdoor:  63%|██████▎   | 225692/360000 [00:55<00:31, 4216.27it/s]prepro_backdoor:  63%|██████▎   | 226117/360000 [00:55<00:32, 4102.65it/s]prepro_backdoor:  63%|██████▎   | 226548/360000 [00:55<00:32, 4145.16it/s]prepro_backdoor:  63%|██████▎   | 227002/360000 [00:55<00:31, 4258.44it/s]prepro_backdoor:  63%|██████▎   | 227548/360000 [00:55<00:28, 4589.34it/s]prepro_backdoor:  63%|██████▎   | 228009/360000 [00:55<00:32, 4097.79it/s]prepro_backdoor:  63%|██████▎   | 228520/360000 [00:55<00:30, 4360.10it/s]prepro_backdoor:  64%|██████▎   | 228997/360000 [00:56<00:29, 4447.15it/s]prepro_backdoor:  64%|██████▎   | 229449/360000 [00:56<00:31, 4086.76it/s]prepro_backdoor:  64%|██████▍   | 229868/360000 [00:56<00:35, 3672.94it/s]prepro_backdoor:  64%|██████▍   | 230287/360000 [00:56<00:34, 3787.84it/s]prepro_backdoor:  64%|██████▍   | 230698/360000 [00:56<00:33, 3872.26it/s]prepro_backdoor:  64%|██████▍   | 231094/360000 [00:56<00:33, 3834.29it/s]prepro_backdoor:  64%|██████▍   | 231566/360000 [00:56<00:31, 4081.26it/s]prepro_backdoor:  64%|██████▍   | 231980/360000 [00:56<00:31, 4027.89it/s]prepro_backdoor:  65%|██████▍   | 232439/360000 [00:56<00:30, 4185.31it/s]prepro_backdoor:  65%|██████▍   | 232862/360000 [00:57<00:31, 4076.69it/s]prepro_backdoor:  65%|██████▍   | 233350/360000 [00:57<00:29, 4301.21it/s]prepro_backdoor:  65%|██████▍   | 233816/360000 [00:57<00:28, 4381.75it/s]prepro_backdoor:  65%|██████▌   | 234257/360000 [00:57<00:29, 4260.44it/s]prepro_backdoor:  65%|██████▌   | 234686/360000 [00:57<00:30, 4154.21it/s]prepro_backdoor:  65%|██████▌   | 235244/360000 [00:57<00:27, 4534.72it/s]prepro_backdoor:  65%|██████▌   | 235755/360000 [00:57<00:26, 4682.03it/s]prepro_backdoor:  66%|██████▌   | 236226/360000 [00:57<00:28, 4288.20it/s]prepro_backdoor:  66%|██████▌   | 236745/360000 [00:57<00:27, 4511.42it/s]prepro_backdoor:  66%|██████▌   | 237203/360000 [00:58<00:27, 4411.37it/s]prepro_backdoor:  66%|██████▌   | 237649/360000 [00:58<00:29, 4101.97it/s]prepro_backdoor:  66%|██████▌   | 238066/360000 [00:58<00:34, 3561.54it/s]prepro_backdoor:  66%|██████▌   | 238480/360000 [00:58<00:32, 3690.26it/s]prepro_backdoor:  66%|██████▋   | 238965/360000 [00:58<00:30, 3982.25it/s]prepro_backdoor:  66%|██████▋   | 239376/360000 [00:58<00:31, 3834.44it/s]prepro_backdoor:  67%|██████▋   | 239862/360000 [00:58<00:29, 4101.95it/s]prepro_backdoor:  67%|██████▋   | 240365/360000 [00:58<00:27, 4359.28it/s]prepro_backdoor:  67%|██████▋   | 240817/360000 [00:58<00:27, 4379.43it/s]prepro_backdoor:  67%|██████▋   | 241261/360000 [00:59<00:28, 4221.52it/s]prepro_backdoor:  67%|██████▋   | 241785/360000 [00:59<00:26, 4506.26it/s]prepro_backdoor:  67%|██████▋   | 242241/360000 [00:59<00:26, 4429.35it/s]prepro_backdoor:  67%|██████▋   | 242688/360000 [00:59<00:26, 4435.06it/s]prepro_backdoor:  68%|██████▊   | 243135/360000 [00:59<00:26, 4367.95it/s]prepro_backdoor:  68%|██████▊   | 243574/360000 [00:59<00:28, 4150.97it/s]prepro_backdoor:  68%|██████▊   | 244018/360000 [00:59<00:27, 4224.45it/s]prepro_backdoor:  68%|██████▊   | 244503/360000 [00:59<00:26, 4376.76it/s]prepro_backdoor:  68%|██████▊   | 244943/360000 [00:59<00:26, 4300.97it/s]prepro_backdoor:  68%|██████▊   | 245426/360000 [01:00<00:25, 4443.89it/s]prepro_backdoor:  68%|██████▊   | 245904/360000 [01:00<00:25, 4532.47it/s]prepro_backdoor:  68%|██████▊   | 246359/360000 [01:00<00:26, 4345.04it/s]prepro_backdoor:  69%|██████▊   | 246868/360000 [01:00<00:24, 4552.31it/s]prepro_backdoor:  69%|██████▊   | 247326/360000 [01:00<00:25, 4448.78it/s]prepro_backdoor:  69%|██████▉   | 247780/360000 [01:00<00:25, 4453.01it/s]prepro_backdoor:  69%|██████▉   | 248283/360000 [01:00<00:24, 4587.73it/s]prepro_backdoor:  69%|██████▉   | 248779/360000 [01:00<00:23, 4672.10it/s]prepro_backdoor:  69%|██████▉   | 249248/360000 [01:00<00:23, 4654.68it/s]prepro_backdoor:  69%|██████▉   | 249715/360000 [01:00<00:24, 4454.75it/s]prepro_backdoor:  69%|██████▉   | 250177/360000 [01:01<00:24, 4490.32it/s]prepro_backdoor:  70%|██████▉   | 250628/360000 [01:01<00:25, 4348.28it/s]prepro_backdoor:  70%|██████▉   | 251066/360000 [01:01<00:25, 4332.69it/s]prepro_backdoor:  70%|██████▉   | 251504/360000 [01:01<00:25, 4333.55it/s]prepro_backdoor:  70%|██████▉   | 251939/360000 [01:01<00:25, 4216.01it/s]prepro_backdoor:  70%|███████   | 252499/360000 [01:01<00:23, 4598.05it/s]prepro_backdoor:  70%|███████   | 252961/360000 [01:01<00:23, 4592.16it/s]prepro_backdoor:  70%|███████   | 253446/360000 [01:01<00:22, 4636.64it/s]prepro_backdoor:  71%|███████   | 253967/360000 [01:01<00:22, 4791.60it/s]prepro_backdoor:  71%|███████   | 254448/360000 [01:02<00:23, 4574.04it/s]prepro_backdoor:  71%|███████   | 254908/360000 [01:02<00:24, 4223.08it/s]prepro_backdoor:  71%|███████   | 255337/360000 [01:02<00:24, 4207.76it/s]prepro_backdoor:  71%|███████   | 255786/360000 [01:02<00:24, 4264.95it/s]prepro_backdoor:  71%|███████   | 256216/360000 [01:02<00:24, 4262.59it/s]prepro_backdoor:  71%|███████▏  | 256655/360000 [01:02<00:24, 4285.93it/s]prepro_backdoor:  71%|███████▏  | 257086/360000 [01:02<00:24, 4233.23it/s]prepro_backdoor:  72%|███████▏  | 257511/360000 [01:02<00:25, 3951.79it/s]prepro_backdoor:  72%|███████▏  | 257911/360000 [01:02<00:27, 3669.26it/s]prepro_backdoor:  72%|███████▏  | 258434/360000 [01:02<00:24, 4081.74it/s]prepro_backdoor:  72%|███████▏  | 258852/360000 [01:03<00:24, 4088.35it/s]prepro_backdoor:  72%|███████▏  | 259267/360000 [01:03<00:26, 3844.12it/s]prepro_backdoor:  72%|███████▏  | 259658/360000 [01:03<00:27, 3633.89it/s]prepro_backdoor:  72%|███████▏  | 260027/360000 [01:03<00:28, 3519.66it/s]prepro_backdoor:  72%|███████▏  | 260390/360000 [01:03<00:28, 3538.45it/s]prepro_backdoor:  72%|███████▏  | 260833/360000 [01:03<00:26, 3765.23it/s]prepro_backdoor:  73%|███████▎  | 261213/360000 [01:03<00:26, 3744.84it/s]prepro_backdoor:  73%|███████▎  | 261616/360000 [01:03<00:25, 3811.29it/s]prepro_backdoor:  73%|███████▎  | 261999/360000 [01:03<00:27, 3600.45it/s]prepro_backdoor:  73%|███████▎  | 262384/360000 [01:04<00:26, 3666.69it/s]prepro_backdoor:  73%|███████▎  | 262848/360000 [01:04<00:24, 3922.62it/s]prepro_backdoor:  73%|███████▎  | 263285/360000 [01:04<00:23, 4034.70it/s]prepro_backdoor:  73%|███████▎  | 263691/360000 [01:04<00:24, 3891.49it/s]prepro_backdoor:  73%|███████▎  | 264092/360000 [01:04<00:24, 3924.81it/s]prepro_backdoor:  73%|███████▎  | 264487/360000 [01:04<00:24, 3831.45it/s]prepro_backdoor:  74%|███████▎  | 264884/360000 [01:04<00:24, 3859.77it/s]prepro_backdoor:  74%|███████▎  | 265358/360000 [01:04<00:23, 4113.12it/s]prepro_backdoor:  74%|███████▍  | 265771/360000 [01:04<00:23, 3952.27it/s]prepro_backdoor:  74%|███████▍  | 266215/360000 [01:05<00:23, 4072.54it/s]prepro_backdoor:  74%|███████▍  | 266625/360000 [01:05<00:23, 3934.01it/s]prepro_backdoor:  74%|███████▍  | 267021/360000 [01:05<00:24, 3838.29it/s]prepro_backdoor:  74%|███████▍  | 267431/360000 [01:05<00:23, 3910.69it/s]prepro_backdoor:  74%|███████▍  | 267932/360000 [01:05<00:21, 4206.04it/s]prepro_backdoor:  75%|███████▍  | 268355/360000 [01:05<00:22, 4033.77it/s]prepro_backdoor:  75%|███████▍  | 268866/360000 [01:05<00:21, 4336.15it/s]prepro_backdoor:  75%|███████▍  | 269303/360000 [01:05<00:22, 4048.40it/s]prepro_backdoor:  75%|███████▍  | 269714/360000 [01:05<00:22, 4015.22it/s]prepro_backdoor:  75%|███████▌  | 270120/360000 [01:06<00:22, 4002.81it/s]prepro_backdoor:  75%|███████▌  | 270523/360000 [01:06<00:22, 3901.88it/s]prepro_backdoor:  75%|███████▌  | 270985/360000 [01:06<00:21, 4095.26it/s]prepro_backdoor:  75%|███████▌  | 271442/360000 [01:06<00:21, 4203.59it/s]prepro_backdoor:  76%|███████▌  | 271891/360000 [01:06<00:20, 4284.31it/s]prepro_backdoor:  76%|███████▌  | 272321/360000 [01:06<00:21, 4146.97it/s]prepro_backdoor:  76%|███████▌  | 272793/360000 [01:06<00:20, 4285.79it/s]prepro_backdoor:  76%|███████▌  | 273224/360000 [01:06<00:20, 4249.07it/s]prepro_backdoor:  76%|███████▌  | 273651/360000 [01:06<00:20, 4166.78it/s]prepro_backdoor:  76%|███████▌  | 274069/360000 [01:06<00:21, 4013.29it/s]prepro_backdoor:  76%|███████▌  | 274472/360000 [01:07<00:21, 3941.75it/s]prepro_backdoor:  76%|███████▋  | 274912/360000 [01:07<00:21, 4050.17it/s]prepro_backdoor:  76%|███████▋  | 275319/360000 [01:07<00:20, 4054.35it/s]prepro_backdoor:  77%|███████▋  | 275849/360000 [01:07<00:19, 4387.31it/s]prepro_backdoor:  77%|███████▋  | 276343/360000 [01:07<00:18, 4517.20it/s]prepro_backdoor:  77%|███████▋  | 276796/360000 [01:07<00:18, 4487.22it/s]prepro_backdoor:  77%|███████▋  | 277246/360000 [01:07<00:19, 4284.78it/s]prepro_backdoor:  77%|███████▋  | 277811/360000 [01:07<00:17, 4663.83it/s]prepro_backdoor:  77%|███████▋  | 278302/360000 [01:07<00:17, 4705.41it/s]prepro_backdoor:  77%|███████▋  | 278803/360000 [01:07<00:17, 4772.06it/s]prepro_backdoor:  78%|███████▊  | 279282/360000 [01:08<00:18, 4330.02it/s]prepro_backdoor:  78%|███████▊  | 279724/360000 [01:08<00:20, 3976.47it/s]prepro_backdoor:  78%|███████▊  | 280132/360000 [01:08<00:20, 3906.61it/s]prepro_backdoor:  78%|███████▊  | 280652/360000 [01:08<00:18, 4253.75it/s]prepro_backdoor:  78%|███████▊  | 281086/360000 [01:08<00:18, 4153.79it/s]prepro_backdoor:  78%|███████▊  | 281508/360000 [01:08<00:20, 3913.87it/s]prepro_backdoor:  78%|███████▊  | 281958/360000 [01:08<00:19, 4063.14it/s]prepro_backdoor:  78%|███████▊  | 282378/360000 [01:08<00:18, 4091.79it/s]prepro_backdoor:  79%|███████▊  | 282846/360000 [01:09<00:18, 4242.14it/s]prepro_backdoor:  79%|███████▊  | 283329/360000 [01:09<00:17, 4394.45it/s]prepro_backdoor:  79%|███████▉  | 283772/360000 [01:09<00:18, 4106.40it/s]prepro_backdoor:  79%|███████▉  | 284252/360000 [01:09<00:17, 4282.29it/s]prepro_backdoor:  79%|███████▉  | 284686/360000 [01:09<00:18, 4177.59it/s]prepro_backdoor:  79%|███████▉  | 285132/360000 [01:09<00:17, 4242.44it/s]prepro_backdoor:  79%|███████▉  | 285563/360000 [01:09<00:17, 4246.42it/s]prepro_backdoor:  79%|███████▉  | 286100/360000 [01:09<00:16, 4555.39it/s]prepro_backdoor:  80%|███████▉  | 286558/360000 [01:09<00:17, 4308.32it/s]prepro_backdoor:  80%|███████▉  | 286993/360000 [01:09<00:17, 4153.25it/s]prepro_backdoor:  80%|███████▉  | 287412/360000 [01:10<00:18, 4021.40it/s]prepro_backdoor:  80%|███████▉  | 287832/360000 [01:10<00:17, 4062.65it/s]prepro_backdoor:  80%|████████  | 288355/360000 [01:10<00:16, 4368.37it/s]prepro_backdoor:  80%|████████  | 288795/360000 [01:10<00:16, 4192.44it/s]prepro_backdoor:  80%|████████  | 289273/360000 [01:10<00:16, 4336.34it/s]prepro_backdoor:  80%|████████  | 289710/360000 [01:10<00:16, 4246.50it/s]prepro_backdoor:  81%|████████  | 290188/360000 [01:10<00:15, 4398.83it/s]prepro_backdoor:  81%|████████  | 290658/360000 [01:10<00:15, 4464.65it/s]prepro_backdoor:  81%|████████  | 291143/360000 [01:10<00:15, 4550.42it/s]prepro_backdoor:  81%|████████  | 291600/360000 [01:11<00:15, 4331.06it/s]prepro_backdoor:  81%|████████  | 292040/360000 [01:11<00:15, 4333.03it/s]prepro_backdoor:  81%|████████▏ | 292565/360000 [01:11<00:14, 4594.01it/s]prepro_backdoor:  81%|████████▏ | 293027/360000 [01:11<00:15, 4456.03it/s]prepro_backdoor:  82%|████████▏ | 293475/360000 [01:11<00:16, 4065.97it/s]prepro_backdoor:  82%|████████▏ | 293999/360000 [01:11<00:15, 4383.82it/s]prepro_backdoor:  82%|████████▏ | 294588/360000 [01:11<00:13, 4793.96it/s]prepro_backdoor:  82%|████████▏ | 295076/360000 [01:11<00:13, 4775.82it/s]prepro_backdoor:  82%|████████▏ | 295583/360000 [01:11<00:13, 4843.78it/s]prepro_backdoor:  82%|████████▏ | 296072/360000 [01:11<00:13, 4852.66it/s]prepro_backdoor:  82%|████████▏ | 296561/360000 [01:12<00:14, 4281.50it/s]prepro_backdoor:  83%|████████▎ | 297004/360000 [01:12<00:14, 4220.40it/s]prepro_backdoor:  83%|████████▎ | 297436/360000 [01:12<00:15, 4147.63it/s]prepro_backdoor:  83%|████████▎ | 297903/360000 [01:12<00:14, 4270.25it/s]prepro_backdoor:  83%|████████▎ | 298336/360000 [01:12<00:14, 4206.09it/s]prepro_backdoor:  83%|████████▎ | 298877/360000 [01:12<00:13, 4534.61it/s]prepro_backdoor:  83%|████████▎ | 299335/360000 [01:12<00:13, 4488.36it/s]prepro_backdoor:  83%|████████▎ | 299849/360000 [01:12<00:12, 4646.73it/s]prepro_backdoor:  83%|████████▎ | 300317/360000 [01:12<00:13, 4568.91it/s]prepro_backdoor:  84%|████████▎ | 300776/360000 [01:13<00:13, 4536.43it/s]prepro_backdoor:  84%|████████▎ | 301231/360000 [01:13<00:14, 4048.40it/s]prepro_backdoor:  84%|████████▍ | 301697/360000 [01:13<00:13, 4205.01it/s]prepro_backdoor:  84%|████████▍ | 302157/360000 [01:13<00:13, 4314.44it/s]prepro_backdoor:  84%|████████▍ | 302596/360000 [01:13<00:13, 4246.95it/s]prepro_backdoor:  84%|████████▍ | 303026/360000 [01:13<00:13, 4190.92it/s]prepro_backdoor:  84%|████████▍ | 303449/360000 [01:13<00:13, 4081.82it/s]prepro_backdoor:  84%|████████▍ | 303880/360000 [01:13<00:13, 4141.41it/s]prepro_backdoor:  85%|████████▍ | 304298/360000 [01:13<00:13, 4134.56it/s]prepro_backdoor:  85%|████████▍ | 304732/360000 [01:14<00:13, 4178.64it/s]prepro_backdoor:  85%|████████▍ | 305407/360000 [01:14<00:11, 4923.25it/s]prepro_backdoor:  85%|████████▍ | 305902/360000 [01:14<00:11, 4606.68it/s]prepro_backdoor:  85%|████████▌ | 306369/360000 [01:14<00:11, 4566.88it/s]prepro_backdoor:  85%|████████▌ | 306830/360000 [01:14<00:11, 4458.47it/s]prepro_backdoor:  85%|████████▌ | 307279/360000 [01:14<00:12, 4195.77it/s]prepro_backdoor:  85%|████████▌ | 307703/360000 [01:14<00:13, 3880.98it/s]prepro_backdoor:  86%|████████▌ | 308236/360000 [01:14<00:12, 4243.76it/s]prepro_backdoor:  86%|████████▌ | 308766/360000 [01:14<00:11, 4518.03it/s]prepro_backdoor:  86%|████████▌ | 309226/360000 [01:15<00:11, 4411.35it/s]prepro_backdoor:  86%|████████▌ | 309673/360000 [01:15<00:11, 4231.72it/s]prepro_backdoor:  86%|████████▌ | 310101/360000 [01:15<00:12, 4081.97it/s]prepro_backdoor:  86%|████████▋ | 310576/360000 [01:15<00:11, 4238.54it/s]prepro_backdoor:  86%|████████▋ | 311004/360000 [01:15<00:11, 4149.26it/s]prepro_backdoor:  87%|████████▋ | 311440/360000 [01:15<00:11, 4182.49it/s]prepro_backdoor:  87%|████████▋ | 311919/360000 [01:15<00:11, 4352.02it/s]prepro_backdoor:  87%|████████▋ | 312357/360000 [01:15<00:11, 4293.10it/s]prepro_backdoor:  87%|████████▋ | 312788/360000 [01:15<00:11, 4261.08it/s]prepro_backdoor:  87%|████████▋ | 313226/360000 [01:16<00:10, 4275.35it/s]prepro_backdoor:  87%|████████▋ | 313690/360000 [01:16<00:10, 4365.51it/s]prepro_backdoor:  87%|████████▋ | 314128/360000 [01:16<00:10, 4318.04it/s]prepro_backdoor:  87%|████████▋ | 314561/360000 [01:16<00:10, 4172.15it/s]prepro_backdoor:  87%|████████▋ | 314980/360000 [01:16<00:11, 4002.68it/s]prepro_backdoor:  88%|████████▊ | 315383/360000 [01:16<00:12, 3712.24it/s]prepro_backdoor:  88%|████████▊ | 315759/360000 [01:16<00:11, 3701.92it/s]prepro_backdoor:  88%|████████▊ | 316133/360000 [01:16<00:11, 3678.23it/s]prepro_backdoor:  88%|████████▊ | 316548/360000 [01:16<00:11, 3809.16it/s]prepro_backdoor:  88%|████████▊ | 316984/360000 [01:16<00:10, 3955.17it/s]prepro_backdoor:  88%|████████▊ | 317403/360000 [01:17<00:10, 4002.93it/s]prepro_backdoor:  88%|████████▊ | 317840/360000 [01:17<00:10, 4101.85it/s]prepro_backdoor:  88%|████████▊ | 318252/360000 [01:17<00:10, 4067.18it/s]prepro_backdoor:  89%|████████▊ | 318817/360000 [01:17<00:09, 4505.82it/s]prepro_backdoor:  89%|████████▊ | 319401/360000 [01:17<00:08, 4870.35it/s]prepro_backdoor:  89%|████████▉ | 319955/360000 [01:17<00:07, 5048.52it/s]prepro_backdoor:  89%|████████▉ | 320461/360000 [01:17<00:08, 4708.55it/s]prepro_backdoor:  89%|████████▉ | 320937/360000 [01:17<00:08, 4690.29it/s]prepro_backdoor:  89%|████████▉ | 321410/360000 [01:17<00:08, 4367.55it/s]prepro_backdoor:  89%|████████▉ | 321853/360000 [01:18<00:09, 4205.58it/s]prepro_backdoor:  90%|████████▉ | 322278/360000 [01:18<00:09, 4161.53it/s]prepro_backdoor:  90%|████████▉ | 322697/360000 [01:18<00:09, 3954.26it/s]prepro_backdoor:  90%|████████▉ | 323159/360000 [01:18<00:08, 4111.58it/s]prepro_backdoor:  90%|████████▉ | 323597/360000 [01:18<00:08, 4185.70it/s]prepro_backdoor:  90%|█████████ | 324019/360000 [01:18<00:08, 4045.51it/s]prepro_backdoor:  90%|█████████ | 324427/360000 [01:18<00:09, 3894.86it/s]prepro_backdoor:  90%|█████████ | 324819/360000 [01:18<00:09, 3878.12it/s]prepro_backdoor:  90%|█████████ | 325260/360000 [01:18<00:08, 4003.87it/s]prepro_backdoor:  90%|█████████ | 325662/360000 [01:19<00:08, 3843.78it/s]prepro_backdoor:  91%|█████████ | 326070/360000 [01:19<00:08, 3886.14it/s]prepro_backdoor:  91%|█████████ | 326489/360000 [01:19<00:08, 3950.91it/s]prepro_backdoor:  91%|█████████ | 326921/360000 [01:19<00:08, 4030.82it/s]prepro_backdoor:  91%|█████████ | 327326/360000 [01:19<00:08, 3934.92it/s]prepro_backdoor:  91%|█████████ | 327721/360000 [01:19<00:08, 3848.13it/s]prepro_backdoor:  91%|█████████ | 328177/360000 [01:19<00:07, 4033.30it/s]prepro_backdoor:  91%|█████████▏| 328582/360000 [01:19<00:07, 3933.30it/s]prepro_backdoor:  91%|█████████▏| 328981/360000 [01:19<00:07, 3932.97it/s]prepro_backdoor:  92%|█████████▏| 329590/360000 [01:19<00:06, 4542.55it/s]prepro_backdoor:  92%|█████████▏| 330047/360000 [01:20<00:06, 4377.79it/s]prepro_backdoor:  92%|█████████▏| 330488/360000 [01:20<00:06, 4267.98it/s]prepro_backdoor:  92%|█████████▏| 330917/360000 [01:20<00:07, 4148.47it/s]prepro_backdoor:  92%|█████████▏| 331366/360000 [01:20<00:06, 4236.53it/s]prepro_backdoor:  92%|█████████▏| 331792/360000 [01:20<00:06, 4077.69it/s]prepro_backdoor:  92%|█████████▏| 332239/360000 [01:20<00:06, 4186.45it/s]prepro_backdoor:  92%|█████████▏| 332660/360000 [01:20<00:06, 4049.31it/s]prepro_backdoor:  93%|█████████▎| 333070/360000 [01:20<00:06, 4038.54it/s]prepro_backdoor:  93%|█████████▎| 333570/360000 [01:20<00:06, 4302.60it/s]prepro_backdoor:  93%|█████████▎| 334003/360000 [01:21<00:06, 4102.66it/s]prepro_backdoor:  93%|█████████▎| 334417/360000 [01:21<00:06, 4091.85it/s]prepro_backdoor:  93%|█████████▎| 334838/360000 [01:21<00:06, 4125.16it/s]prepro_backdoor:  93%|█████████▎| 335253/360000 [01:21<00:06, 4088.48it/s]prepro_backdoor:  93%|█████████▎| 335759/360000 [01:21<00:05, 4345.51it/s]prepro_backdoor:  93%|█████████▎| 336195/360000 [01:21<00:05, 4318.80it/s]prepro_backdoor:  94%|█████████▎| 336708/360000 [01:21<00:05, 4547.86it/s]prepro_backdoor:  94%|█████████▎| 337164/360000 [01:21<00:05, 4543.59it/s]prepro_backdoor:  94%|█████████▍| 337620/360000 [01:21<00:05, 4276.47it/s]prepro_backdoor:  94%|█████████▍| 338052/360000 [01:21<00:05, 4285.75it/s]prepro_backdoor:  94%|█████████▍| 338533/360000 [01:22<00:04, 4409.08it/s]prepro_backdoor:  94%|█████████▍| 338976/360000 [01:22<00:04, 4379.91it/s]prepro_backdoor:  94%|█████████▍| 339425/360000 [01:22<00:04, 4393.87it/s]prepro_backdoor:  94%|█████████▍| 339973/360000 [01:22<00:04, 4700.83it/s]prepro_backdoor:  95%|█████████▍| 340445/360000 [01:22<00:04, 4379.96it/s]prepro_backdoor:  95%|█████████▍| 341006/360000 [01:22<00:04, 4715.01it/s]prepro_backdoor:  95%|█████████▍| 341483/360000 [01:22<00:04, 4468.00it/s]prepro_backdoor:  95%|█████████▌| 342045/360000 [01:22<00:03, 4765.20it/s]prepro_backdoor:  95%|█████████▌| 342549/360000 [01:22<00:03, 4816.67it/s]prepro_backdoor:  95%|█████████▌| 343036/360000 [01:23<00:03, 4777.16it/s]prepro_backdoor:  95%|█████████▌| 343517/360000 [01:23<00:03, 4725.00it/s]prepro_backdoor:  96%|█████████▌| 343992/360000 [01:23<00:03, 4163.79it/s]prepro_backdoor:  96%|█████████▌| 344421/360000 [01:23<00:03, 4148.92it/s]prepro_backdoor:  96%|█████████▌| 344845/360000 [01:23<00:03, 4129.05it/s]prepro_backdoor:  96%|█████████▌| 345264/360000 [01:23<00:03, 4038.29it/s]prepro_backdoor:  96%|█████████▌| 345761/360000 [01:23<00:03, 4277.56it/s]prepro_backdoor:  96%|█████████▌| 346232/360000 [01:23<00:03, 4379.24it/s]prepro_backdoor:  96%|█████████▋| 346674/360000 [01:23<00:03, 4257.39it/s]prepro_backdoor:  96%|█████████▋| 347137/360000 [01:24<00:02, 4341.52it/s]prepro_backdoor:  97%|█████████▋| 347574/360000 [01:24<00:02, 4273.77it/s]prepro_backdoor:  97%|█████████▋| 348003/360000 [01:24<00:03, 3978.62it/s]prepro_backdoor:  97%|█████████▋| 348455/360000 [01:24<00:02, 4117.34it/s]prepro_backdoor:  97%|█████████▋| 348871/360000 [01:24<00:02, 3926.93it/s]prepro_backdoor:  97%|█████████▋| 349287/360000 [01:24<00:02, 3987.74it/s]prepro_backdoor:  97%|█████████▋| 349717/360000 [01:24<00:02, 4064.78it/s]prepro_backdoor:  97%|█████████▋| 350127/360000 [01:24<00:02, 4072.44it/s]prepro_backdoor:  97%|█████████▋| 350537/360000 [01:24<00:02, 4058.16it/s]prepro_backdoor:  97%|█████████▋| 350945/360000 [01:25<00:02, 3858.97it/s]prepro_backdoor:  98%|█████████▊| 351334/360000 [01:25<00:02, 3799.15it/s]prepro_backdoor:  98%|█████████▊| 351810/360000 [01:25<00:02, 4054.84it/s]prepro_backdoor:  98%|█████████▊| 352218/360000 [01:25<00:01, 4026.89it/s]prepro_backdoor:  98%|█████████▊| 352715/360000 [01:25<00:01, 4272.54it/s]prepro_backdoor:  98%|█████████▊| 353144/360000 [01:25<00:01, 4227.79it/s]prepro_backdoor:  98%|█████████▊| 353575/360000 [01:25<00:01, 4237.09it/s]prepro_backdoor:  98%|█████████▊| 354074/360000 [01:25<00:01, 4442.17it/s]prepro_backdoor:  99%|█████████▊| 354662/360000 [01:25<00:01, 4845.25it/s]prepro_backdoor:  99%|█████████▊| 355148/360000 [01:25<00:01, 4515.45it/s]prepro_backdoor:  99%|█████████▉| 355682/360000 [01:26<00:00, 4730.88it/s]prepro_backdoor:  99%|█████████▉| 356160/360000 [01:26<00:00, 4531.68it/s]prepro_backdoor:  99%|█████████▉| 356618/360000 [01:26<00:00, 4046.00it/s]prepro_backdoor:  99%|█████████▉| 357059/360000 [01:26<00:00, 4140.16it/s]prepro_backdoor:  99%|█████████▉| 357585/360000 [01:26<00:00, 4420.42it/s]prepro_backdoor:  99%|█████████▉| 358036/360000 [01:26<00:00, 4368.82it/s]prepro_backdoor: 100%|█████████▉| 358479/360000 [01:26<00:00, 4087.44it/s]prepro_backdoor: 100%|█████████▉| 358909/360000 [01:26<00:00, 4142.83it/s]prepro_backdoor: 100%|█████████▉| 359329/360000 [01:26<00:00, 4112.75it/s]prepro_backdoor: 100%|█████████▉| 359892/360000 [01:27<00:00, 4542.86it/s]prepro_backdoor: 100%|██████████| 360000/360000 [01:27<00:00, 4133.81it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:5600.0,real pratio:0.8
2024-11-17:20:13:35 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:5600.0,real pratio:0.8
INFO:root:save file format is .png
2024-11-17:20:13:35 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/7000 [00:00<?, ?it/s]prepro_backdoor:  21%|██        | 1442/7000 [00:00<00:00, 14136.66it/s]prepro_backdoor:  41%|████      | 2856/7000 [00:04<00:07, 522.06it/s]  prepro_backdoor:  49%|████▉     | 3457/7000 [00:06<00:07, 491.36it/s]prepro_backdoor:  54%|█████▍    | 3803/7000 [00:06<00:06, 477.13it/s]prepro_backdoor:  58%|█████▊    | 4029/7000 [00:07<00:06, 469.02it/s]prepro_backdoor:  60%|█████▉    | 4189/7000 [00:07<00:06, 462.26it/s]prepro_backdoor:  62%|██████▏   | 4309/7000 [00:08<00:05, 457.55it/s]prepro_backdoor:  63%|██████▎   | 4404/7000 [00:08<00:05, 454.04it/s]prepro_backdoor:  64%|██████▍   | 4483/7000 [00:08<00:05, 448.94it/s]prepro_backdoor:  65%|██████▌   | 4550/7000 [00:08<00:05, 446.17it/s]prepro_backdoor:  66%|██████▌   | 4610/7000 [00:08<00:05, 440.94it/s]prepro_backdoor:  67%|██████▋   | 4664/7000 [00:08<00:05, 436.77it/s]prepro_backdoor:  67%|██████▋   | 4715/7000 [00:09<00:05, 434.56it/s]prepro_backdoor:  68%|██████▊   | 4763/7000 [00:09<00:05, 433.47it/s]prepro_backdoor:  69%|██████▊   | 4810/7000 [00:09<00:05, 432.44it/s]prepro_backdoor:  69%|██████▉   | 4856/7000 [00:09<00:04, 430.14it/s]prepro_backdoor:  70%|███████   | 4901/7000 [00:09<00:04, 428.35it/s]prepro_backdoor:  71%|███████   | 4947/7000 [00:09<00:04, 433.91it/s]prepro_backdoor:  71%|███████▏  | 4992/7000 [00:09<00:04, 435.95it/s]prepro_backdoor:  72%|███████▏  | 5037/7000 [00:09<00:04, 438.58it/s]prepro_backdoor:  73%|███████▎  | 5082/7000 [00:09<00:04, 440.04it/s]prepro_backdoor:  73%|███████▎  | 5127/7000 [00:10<00:04, 437.70it/s]prepro_backdoor:  74%|███████▍  | 5171/7000 [00:10<00:04, 436.36it/s]prepro_backdoor:  75%|███████▍  | 5216/7000 [00:10<00:04, 438.06it/s]prepro_backdoor:  75%|███████▌  | 5260/7000 [00:10<00:04, 434.93it/s]prepro_backdoor:  76%|███████▌  | 5304/7000 [00:10<00:03, 430.33it/s]prepro_backdoor:  76%|███████▋  | 5348/7000 [00:10<00:03, 429.51it/s]prepro_backdoor:  77%|███████▋  | 5391/7000 [00:10<00:03, 422.63it/s]prepro_backdoor:  78%|███████▊  | 5434/7000 [00:10<00:03, 418.04it/s]prepro_backdoor:  78%|███████▊  | 5476/7000 [00:10<00:03, 414.93it/s]prepro_backdoor:  79%|███████▉  | 5518/7000 [00:10<00:03, 412.87it/s]prepro_backdoor:  79%|███████▉  | 5560/7000 [00:11<00:03, 410.38it/s]prepro_backdoor:  80%|████████  | 5602/7000 [00:11<00:03, 384.08it/s]prepro_backdoor:  81%|████████  | 5643/7000 [00:11<00:03, 391.14it/s]prepro_backdoor:  81%|████████  | 5683/7000 [00:11<00:04, 319.62it/s]prepro_backdoor:  82%|████████▏ | 5725/7000 [00:11<00:03, 343.12it/s]prepro_backdoor:  82%|████████▏ | 5766/7000 [00:11<00:03, 360.05it/s]prepro_backdoor:  83%|████████▎ | 5809/7000 [00:11<00:03, 377.03it/s]prepro_backdoor:  84%|████████▎ | 5851/7000 [00:11<00:02, 387.80it/s]prepro_backdoor:  84%|████████▍ | 5892/7000 [00:11<00:02, 392.72it/s]prepro_backdoor:  85%|████████▍ | 5935/7000 [00:12<00:02, 401.70it/s]prepro_backdoor:  85%|████████▌ | 5978/7000 [00:12<00:02, 407.57it/s]prepro_backdoor:  86%|████████▌ | 6020/7000 [00:12<00:02, 408.67it/s]prepro_backdoor:  87%|████████▋ | 6062/7000 [00:12<00:02, 409.10it/s]prepro_backdoor:  87%|████████▋ | 6104/7000 [00:12<00:02, 410.05it/s]prepro_backdoor:  88%|████████▊ | 6146/7000 [00:12<00:02, 311.63it/s]prepro_backdoor:  88%|████████▊ | 6189/7000 [00:12<00:02, 339.80it/s]prepro_backdoor:  89%|████████▉ | 6231/7000 [00:12<00:02, 358.64it/s]prepro_backdoor:  90%|████████▉ | 6272/7000 [00:12<00:01, 371.85it/s]prepro_backdoor:  90%|█████████ | 6313/7000 [00:13<00:01, 381.56it/s]prepro_backdoor:  91%|█████████ | 6355/7000 [00:13<00:01, 391.30it/s]prepro_backdoor:  91%|█████████▏| 6396/7000 [00:13<00:01, 395.50it/s]prepro_backdoor:  92%|█████████▏| 6437/7000 [00:13<00:01, 398.67it/s]prepro_backdoor:  93%|█████████▎| 6479/7000 [00:13<00:01, 403.95it/s]prepro_backdoor:  93%|█████████▎| 6521/7000 [00:13<00:01, 408.45it/s]prepro_backdoor:  94%|█████████▍| 6564/7000 [00:13<00:01, 413.25it/s]prepro_backdoor:  94%|█████████▍| 6606/7000 [00:13<00:00, 413.69it/s]prepro_backdoor:  95%|█████████▍| 6648/7000 [00:14<00:01, 324.28it/s]prepro_backdoor:  96%|█████████▌| 6688/7000 [00:14<00:00, 342.15it/s]prepro_backdoor:  96%|█████████▌| 6729/7000 [00:14<00:00, 357.98it/s]prepro_backdoor:  97%|█████████▋| 6770/7000 [00:14<00:00, 371.71it/s]prepro_backdoor:  97%|█████████▋| 6812/7000 [00:14<00:00, 382.68it/s]prepro_backdoor:  98%|█████████▊| 6854/7000 [00:14<00:00, 392.14it/s]prepro_backdoor:  99%|█████████▊| 6896/7000 [00:14<00:00, 398.39it/s]prepro_backdoor:  99%|█████████▉| 6938/7000 [00:14<00:00, 402.20it/s]prepro_backdoor: 100%|█████████▉| 6980/7000 [00:14<00:00, 405.90it/s]prepro_backdoor: 100%|██████████| 7000/7000 [00:14<00:00, 471.02it/s]
INFO:root:stage2 start
2024-11-17:20:13:50 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2024-11-17:20:13:50 [INFO    ] [trainer_cls.py:972] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2024-11-17:20:13:51 [INFO    ] [trainer_cls.py:1030] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 262.8731060028076 s
2024-11-17:20:18:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.8731060028076 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.296061323447661,
 'clean_test_loss_avg_over_batch': 1.6267663435502486,
 'epoch': 0,
 'test_acc': 0.2,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.26688355707681366,
 'train_acc_clean_only': 0.1993628489050509,
 'train_asr_bd_only': 0.8745624270711785,
 'train_epoch_loss_avg_over_batch': 1.8940158920895154,
 'train_ra_bd_only': 0.20175584819692172}
2024-11-17:20:18:18 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.296061323447661,
 'clean_test_loss_avg_over_batch': 1.6267663435502486,
 'epoch': 0,
 'test_acc': 0.2,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.26688355707681366,
 'train_acc_clean_only': 0.1993628489050509,
 'train_asr_bd_only': 0.8745624270711785,
 'train_epoch_loss_avg_over_batch': 1.8940158920895154,
 'train_ra_bd_only': 0.20175584819692172}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.72977781295776 s
2024-11-17:20:22:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.72977781295776 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2234215275807814,
 'clean_test_loss_avg_over_batch': 1.63986684625799,
 'epoch': 1,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.00125,
 'train_acc': 0.27738820234708395,
 'train_acc_clean_only': 0.20008766974436862,
 'train_asr_bd_only': 0.9731058816992193,
 'train_epoch_loss_avg_over_batch': 1.6661626285797841,
 'train_ra_bd_only': 0.2014002722751646}
2024-11-17:20:22:42 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2234215275807814,
 'clean_test_loss_avg_over_batch': 1.63986684625799,
 'epoch': 1,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.00125,
 'train_acc': 0.27738820234708395,
 'train_acc_clean_only': 0.20008766974436862,
 'train_asr_bd_only': 0.9731058816992193,
 'train_epoch_loss_avg_over_batch': 1.6661626285797841,
 'train_ra_bd_only': 0.2014002722751646}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.44548058509827 s
2024-11-17:20:27:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.44548058509827 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2423677281899885,
 'clean_test_loss_avg_over_batch': 1.6310196204618974,
 'epoch': 2,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.2783272581792319,
 'train_acc_clean_only': 0.1999672776889405,
 'train_asr_bd_only': 0.9834713039613312,
 'train_epoch_loss_avg_over_batch': 1.5973023923158984,
 'train_ra_bd_only': 0.2010389466081449}
2024-11-17:20:27:07 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2423677281899885,
 'clean_test_loss_avg_over_batch': 1.6310196204618974,
 'epoch': 2,
 'test_acc': 0.20014285714285715,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.2783272581792319,
 'train_acc_clean_only': 0.1999672776889405,
 'train_asr_bd_only': 0.9834713039613312,
 'train_epoch_loss_avg_over_batch': 1.5973023923158984,
 'train_ra_bd_only': 0.2010389466081449}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.3772077560425 s
2024-11-17:20:31:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.3772077560425 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.223728055303747,
 'clean_test_loss_avg_over_batch': 1.6353893518447875,
 'epoch': 3,
 'test_acc': 0.20042857142857143,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0005357142857142857,
 'train_acc': 0.27932465771692744,
 'train_acc_clean_only': 0.19997221707723653,
 'train_asr_bd_only': 0.9934437159684409,
 'train_epoch_loss_avg_over_batch': 1.5929856722588898,
 'train_ra_bd_only': 0.20107789754417157}
2024-11-17:20:31:33 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.223728055303747,
 'clean_test_loss_avg_over_batch': 1.6353893518447875,
 'epoch': 3,
 'test_acc': 0.20042857142857143,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0005357142857142857,
 'train_acc': 0.27932465771692744,
 'train_acc_clean_only': 0.19997221707723653,
 'train_asr_bd_only': 0.9934437159684409,
 'train_epoch_loss_avg_over_batch': 1.5929856722588898,
 'train_ra_bd_only': 0.20107789754417157}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.68194556236267 s
2024-11-17:20:35:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.68194556236267 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.278797228227962,
 'clean_test_loss_avg_over_batch': 1.6253528161482378,
 'epoch': 4,
 'test_acc': 0.2,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.0,
 'train_acc': 0.27940522759601705,
 'train_acc_clean_only': 0.19991418269824415,
 'train_asr_bd_only': 0.9948599688819738,
 'train_epoch_loss_avg_over_batch': 1.5920425636076487,
 'train_ra_bd_only': 0.20121138030673483}
2024-11-17:20:35:59 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.278797228227962,
 'clean_test_loss_avg_over_batch': 1.6253528161482378,
 'epoch': 4,
 'test_acc': 0.2,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.0,
 'train_acc': 0.27940522759601705,
 'train_acc_clean_only': 0.19991418269824415,
 'train_asr_bd_only': 0.9948599688819738,
 'train_epoch_loss_avg_over_batch': 1.5920425636076487,
 'train_ra_bd_only': 0.20121138030673483}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.2124035358429 s
2024-11-17:20:40:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.2124035358429 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2596491168845783,
 'clean_test_loss_avg_over_batch': 1.6197900316931986,
 'epoch': 5,
 'test_acc': 0.20085714285714285,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.00125,
 'train_acc': 0.2801470261379801,
 'train_acc_clean_only': 0.20290669317346932,
 'train_asr_bd_only': 0.9753014391287437,
 'train_epoch_loss_avg_over_batch': 1.5883252656731124,
 'train_ra_bd_only': 0.20428404734122355}
2024-11-17:20:40:24 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.2596491168845783,
 'clean_test_loss_avg_over_batch': 1.6197900316931986,
 'epoch': 5,
 'test_acc': 0.20085714285714285,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.00125,
 'train_acc': 0.2801470261379801,
 'train_acc_clean_only': 0.20290669317346932,
 'train_asr_bd_only': 0.9753014391287437,
 'train_epoch_loss_avg_over_batch': 1.5883252656731124,
 'train_ra_bd_only': 0.20428404734122355}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.5048654079437 s
2024-11-17:20:44:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.5048654079437 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.273507299748334,
 'clean_test_loss_avg_over_batch': 1.5975276188416914,
 'epoch': 6,
 'test_acc': 0.21771428571428572,
 'test_asr': 0.9496428571428571,
 'test_ra': 0.023392857142857142,
 'train_acc': 0.287109375,
 'train_acc_clean_only': 0.21637623670684838,
 'train_asr_bd_only': 0.9237587174571421,
 'train_epoch_loss_avg_over_batch': 1.5742344771900014,
 'train_ra_bd_only': 0.21874913172737628}
2024-11-17:20:44:49 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.273507299748334,
 'clean_test_loss_avg_over_batch': 1.5975276188416914,
 'epoch': 6,
 'test_acc': 0.21771428571428572,
 'test_asr': 0.9496428571428571,
 'test_ra': 0.023392857142857142,
 'train_acc': 0.287109375,
 'train_acc_clean_only': 0.21637623670684838,
 'train_asr_bd_only': 0.9237587174571421,
 'train_epoch_loss_avg_over_batch': 1.5742344771900014,
 'train_ra_bd_only': 0.21874913172737628}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.7004373073578 s
2024-11-17:20:49:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.7004373073578 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.3807154650037938,
 'clean_test_loss_avg_over_batch': 1.4617481730201027,
 'epoch': 7,
 'test_acc': 0.33514285714285713,
 'test_asr': 0.6151785714285715,
 'test_ra': 0.22017857142857142,
 'train_acc': 0.33582914740398295,
 'train_acc_clean_only': 0.2929647465580046,
 'train_asr_bd_only': 0.7215801755750639,
 'train_epoch_loss_avg_over_batch': 1.4915719564320522,
 'train_ra_bd_only': 0.29778308700966777}
2024-11-17:20:49:17 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.3807154650037938,
 'clean_test_loss_avg_over_batch': 1.4617481730201027,
 'epoch': 7,
 'test_acc': 0.33514285714285713,
 'test_asr': 0.6151785714285715,
 'test_ra': 0.22017857142857142,
 'train_acc': 0.33582914740398295,
 'train_acc_clean_only': 0.2929647465580046,
 'train_asr_bd_only': 0.7215801755750639,
 'train_epoch_loss_avg_over_batch': 1.4915719564320522,
 'train_ra_bd_only': 0.29778308700966777}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.47392892837524 s
2024-11-17:20:53:40 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.47392892837524 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.5006179836663334,
 'clean_test_loss_avg_over_batch': 1.3778063893318175,
 'epoch': 8,
 'test_acc': 0.444,
 'test_asr': 0.32375,
 'test_ra': 0.4125,
 'train_acc': 0.4287651137980085,
 'train_acc_clean_only': 0.42163103271573305,
 'train_asr_bd_only': 0.4929710507306773,
 'train_epoch_loss_avg_over_batch': 1.3172975840049652,
 'train_ra_bd_only': 0.42801578040784577}
2024-11-17:20:53:45 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.5006179836663334,
 'clean_test_loss_avg_over_batch': 1.3778063893318175,
 'epoch': 8,
 'test_acc': 0.444,
 'test_asr': 0.32375,
 'test_ra': 0.4125,
 'train_acc': 0.4287651137980085,
 'train_acc_clean_only': 0.42163103271573305,
 'train_asr_bd_only': 0.4929710507306773,
 'train_epoch_loss_avg_over_batch': 1.3172975840049652,
 'train_ra_bd_only': 0.42801578040784577}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.57645869255066 s
2024-11-17:20:58:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.57645869255066 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.6186449067159132,
 'clean_test_loss_avg_over_batch': 1.269265685298226,
 'epoch': 9,
 'test_acc': 0.49257142857142855,
 'test_asr': 0.24517857142857144,
 'test_ra': 0.4907142857142857,
 'train_acc': 0.5344672386201992,
 'train_acc_clean_only': 0.5510403161079213,
 'train_asr_bd_only': 0.3853205911767974,
 'train_epoch_loss_avg_over_batch': 1.086020001730912,
 'train_ra_bd_only': 0.5545060562284698}
2024-11-17:20:58:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 1.6186449067159132,
 'clean_test_loss_avg_over_batch': 1.269265685298226,
 'epoch': 9,
 'test_acc': 0.49257142857142855,
 'test_asr': 0.24517857142857144,
 'test_ra': 0.4907142857142857,
 'train_acc': 0.5344672386201992,
 'train_acc_clean_only': 0.5510403161079213,
 'train_asr_bd_only': 0.3853205911767974,
 'train_epoch_loss_avg_over_batch': 1.086020001730912,
 'train_ra_bd_only': 0.5545060562284698}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.50520730018616 s
2024-11-17:21:02:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.50520730018616 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.056684386553983626,
 'clean_test_loss_avg_over_batch': 1.5459458372809671,
 'epoch': 10,
 'test_acc': 0.477,
 'test_asr': 0.97625,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.616390136024182,
 'train_acc_clean_only': 0.6275694948216518,
 'train_asr_bd_only': 0.5157678308466005,
 'train_epoch_loss_avg_over_batch': 0.8949776149194576,
 'train_ra_bd_only': 0.5181295323830958}
2024-11-17:21:02:37 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.056684386553983626,
 'clean_test_loss_avg_over_batch': 1.5459458372809671,
 'epoch': 10,
 'test_acc': 0.477,
 'test_asr': 0.97625,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.616390136024182,
 'train_acc_clean_only': 0.6275694948216518,
 'train_asr_bd_only': 0.5157678308466005,
 'train_epoch_loss_avg_over_batch': 0.8949776149194576,
 'train_ra_bd_only': 0.5181295323830958}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.47494649887085 s
2024-11-17:21:06:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.47494649887085 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0457967043092305,
 'clean_test_loss_avg_over_batch': 1.4107328284870495,
 'epoch': 11,
 'test_acc': 0.5348571428571428,
 'test_asr': 0.9826785714285714,
 'test_ra': 0.013392857142857142,
 'train_acc': 0.6828352818278806,
 'train_acc_clean_only': 0.6815911490328516,
 'train_asr_bd_only': 0.6940323387231205,
 'train_epoch_loss_avg_over_batch': 0.73768311591652,
 'train_ra_bd_only': 0.4153747846863366}
2024-11-17:21:07:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0457967043092305,
 'clean_test_loss_avg_over_batch': 1.4107328284870495,
 'epoch': 11,
 'test_acc': 0.5348571428571428,
 'test_asr': 0.9826785714285714,
 'test_ra': 0.013392857142857142,
 'train_acc': 0.6828352818278806,
 'train_acc_clean_only': 0.6815911490328516,
 'train_asr_bd_only': 0.6940323387231205,
 'train_epoch_loss_avg_over_batch': 0.73768311591652,
 'train_ra_bd_only': 0.4153747846863366}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.90510511398315 s
2024-11-17:21:11:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.90510511398315 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04591412894131446,
 'clean_test_loss_avg_over_batch': 1.3179534429853612,
 'epoch': 12,
 'test_acc': 0.5392857142857143,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.72404260757468,
 'train_acc_clean_only': 0.7264465463166473,
 'train_asr_bd_only': 0.7024060902422761,
 'train_epoch_loss_avg_over_batch': 0.6465890171856833,
 'train_ra_bd_only': 0.4195654589908869}
2024-11-17:21:11:29 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04591412894131446,
 'clean_test_loss_avg_over_batch': 1.3179534429853612,
 'epoch': 12,
 'test_acc': 0.5392857142857143,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.72404260757468,
 'train_acc_clean_only': 0.7264465463166473,
 'train_asr_bd_only': 0.7024060902422761,
 'train_epoch_loss_avg_over_batch': 0.6465890171856833,
 'train_ra_bd_only': 0.4195654589908869}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.01444840431213 s
2024-11-17:21:15:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.01444840431213 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.08747583209663969,
 'clean_test_loss_avg_over_batch': 1.4223892125216397,
 'epoch': 13,
 'test_acc': 0.5454285714285714,
 'test_asr': 0.9694642857142857,
 'test_ra': 0.025892857142857145,
 'train_acc': 0.7506306676742532,
 'train_acc_clean_only': 0.7566137566137566,
 'train_asr_bd_only': 0.696776882467352,
 'train_epoch_loss_avg_over_batch': 0.5841039120833023,
 'train_ra_bd_only': 0.43189774937482633}
2024-11-17:21:15:53 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.08747583209663969,
 'clean_test_loss_avg_over_batch': 1.4223892125216397,
 'epoch': 13,
 'test_acc': 0.5454285714285714,
 'test_asr': 0.9694642857142857,
 'test_ra': 0.025892857142857145,
 'train_acc': 0.7506306676742532,
 'train_acc_clean_only': 0.7566137566137566,
 'train_asr_bd_only': 0.696776882467352,
 'train_epoch_loss_avg_over_batch': 0.5841039120833023,
 'train_ra_bd_only': 0.43189774937482633}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.88152956962585 s
2024-11-17:21:20:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.88152956962585 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0970886972182515,
 'clean_test_loss_avg_over_batch': 1.7520854592323303,
 'epoch': 14,
 'test_acc': 0.5614285714285714,
 'test_asr': 0.9685714285714285,
 'test_ra': 0.025,
 'train_acc': 0.7703980707681366,
 'train_acc_clean_only': 0.7784733734021109,
 'train_asr_bd_only': 0.6977190009168449,
 'train_epoch_loss_avg_over_batch': 0.5393134548009544,
 'train_ra_bd_only': 0.43772400188925625}
2024-11-17:21:20:20 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0970886972182515,
 'clean_test_loss_avg_over_batch': 1.7520854592323303,
 'epoch': 14,
 'test_acc': 0.5614285714285714,
 'test_asr': 0.9685714285714285,
 'test_ra': 0.025,
 'train_acc': 0.7703980707681366,
 'train_acc_clean_only': 0.7784733734021109,
 'train_asr_bd_only': 0.6977190009168449,
 'train_epoch_loss_avg_over_batch': 0.5393134548009544,
 'train_ra_bd_only': 0.43772400188925625}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.66965413093567 s
2024-11-17:21:24:42 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.66965413093567 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3935508354360619,
 'clean_test_loss_avg_over_batch': 3.0268147945404054,
 'epoch': 15,
 'test_acc': 0.5527142857142857,
 'test_asr': 0.9758928571428571,
 'test_ra': 0.010892857142857143,
 'train_acc': 0.7851840327169275,
 'train_acc_clean_only': 0.7952893238049669,
 'train_asr_bd_only': 0.694229112833764,
 'train_epoch_loss_avg_over_batch': 0.505451303966354,
 'train_ra_bd_only': 0.4448056458559084}
2024-11-17:21:24:47 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3935508354360619,
 'clean_test_loss_avg_over_batch': 3.0268147945404054,
 'epoch': 15,
 'test_acc': 0.5527142857142857,
 'test_asr': 0.9758928571428571,
 'test_ra': 0.010892857142857143,
 'train_acc': 0.7851840327169275,
 'train_acc_clean_only': 0.7952893238049669,
 'train_asr_bd_only': 0.694229112833764,
 'train_epoch_loss_avg_over_batch': 0.505451303966354,
 'train_ra_bd_only': 0.4448056458559084}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.35657119750977 s
2024-11-17:21:29:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.35657119750977 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3217821016759527,
 'clean_test_loss_avg_over_batch': 1.378995587609031,
 'epoch': 16,
 'test_acc': 0.5787142857142857,
 'test_asr': 0.9603571428571429,
 'test_ra': 0.027678571428571427,
 'train_acc': 0.7964860419630156,
 'train_acc_clean_only': 0.8082058152564819,
 'train_asr_bd_only': 0.6910126406445339,
 'train_epoch_loss_avg_over_batch': 0.4798744494892964,
 'train_ra_bd_only': 0.4494235310459786}
2024-11-17:21:29:15 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.3217821016759527,
 'clean_test_loss_avg_over_batch': 1.378995587609031,
 'epoch': 16,
 'test_acc': 0.5787142857142857,
 'test_asr': 0.9603571428571429,
 'test_ra': 0.027678571428571427,
 'train_acc': 0.7964860419630156,
 'train_acc_clean_only': 0.8082058152564819,
 'train_asr_bd_only': 0.6910126406445339,
 'train_epoch_loss_avg_over_batch': 0.4798744494892964,
 'train_ra_bd_only': 0.4494235310459786}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.7209849357605 s
2024-11-17:21:33:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.7209849357605 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 3.6124213080122654,
 'clean_test_loss_avg_over_batch': 1.448784007809379,
 'epoch': 17,
 'test_acc': 0.575,
 'test_asr': 0.94875,
 'test_ra': 0.008214285714285714,
 'train_acc': 0.8056515602773826,
 'train_acc_clean_only': 0.8181559994690326,
 'train_asr_bd_only': 0.6931303647323537,
 'train_epoch_loss_avg_over_batch': 0.457969307295374,
 'train_ra_bd_only': 0.4497069363037862}
2024-11-17:21:33:43 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 3.6124213080122654,
 'clean_test_loss_avg_over_batch': 1.448784007809379,
 'epoch': 17,
 'test_acc': 0.575,
 'test_asr': 0.94875,
 'test_ra': 0.008214285714285714,
 'train_acc': 0.8056515602773826,
 'train_acc_clean_only': 0.8181559994690326,
 'train_asr_bd_only': 0.6931303647323537,
 'train_epoch_loss_avg_over_batch': 0.457969307295374,
 'train_ra_bd_only': 0.4497069363037862}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.37555980682373 s
2024-11-17:21:38:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.37555980682373 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07169031284072182,
 'clean_test_loss_avg_over_batch': 1.319159215146845,
 'epoch': 18,
 'test_acc': 0.592,
 'test_asr': 0.9764285714285714,
 'test_ra': 0.02107142857142857,
 'train_acc': 0.8120110241820768,
 'train_acc_clean_only': 0.8255757238994875,
 'train_asr_bd_only': 0.6899377708634292,
 'train_epoch_loss_avg_over_batch': 0.4447613153527166,
 'train_ra_bd_only': 0.4548283142571397}
2024-11-17:21:38:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07169031284072182,
 'clean_test_loss_avg_over_batch': 1.319159215146845,
 'epoch': 18,
 'test_acc': 0.592,
 'test_asr': 0.9764285714285714,
 'test_ra': 0.02107142857142857,
 'train_acc': 0.8120110241820768,
 'train_acc_clean_only': 0.8255757238994875,
 'train_asr_bd_only': 0.6899377708634292,
 'train_epoch_loss_avg_over_batch': 0.4447613153527166,
 'train_ra_bd_only': 0.4548283142571397}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.74103927612305 s
2024-11-17:21:42:35 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.74103927612305 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013494678080116335,
 'clean_test_loss_avg_over_batch': 1.3998691336675124,
 'epoch': 19,
 'test_acc': 0.596,
 'test_asr': 0.9953571428571428,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.8197846283783784,
 'train_acc_clean_only': 0.8339229486942026,
 'train_asr_bd_only': 0.6925491721302367,
 'train_epoch_loss_avg_over_batch': 0.4295944265311168,
 'train_ra_bd_only': 0.45538393154794976}
2024-11-17:21:42:40 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013494678080116335,
 'clean_test_loss_avg_over_batch': 1.3998691336675124,
 'epoch': 19,
 'test_acc': 0.596,
 'test_asr': 0.9953571428571428,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.8197846283783784,
 'train_acc_clean_only': 0.8339229486942026,
 'train_asr_bd_only': 0.6925491721302367,
 'train_epoch_loss_avg_over_batch': 0.4295944265311168,
 'train_ra_bd_only': 0.45538393154794976}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.4932234287262 s
2024-11-17:21:47:04 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.4932234287262 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04283406930070752,
 'clean_test_loss_avg_over_batch': 1.3856310242956336,
 'epoch': 20,
 'test_acc': 0.5922857142857143,
 'test_asr': 0.9835714285714285,
 'test_ra': 0.013035714285714286,
 'train_acc': 0.8258690433854907,
 'train_acc_clean_only': 0.8406901256710327,
 'train_asr_bd_only': 0.6924850673704681,
 'train_epoch_loss_avg_over_batch': 0.4173153427881248,
 'train_ra_bd_only': 0.4569245728573413}
2024-11-17:21:47:08 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04283406930070752,
 'clean_test_loss_avg_over_batch': 1.3856310242956336,
 'epoch': 20,
 'test_acc': 0.5922857142857143,
 'test_asr': 0.9835714285714285,
 'test_ra': 0.013035714285714286,
 'train_acc': 0.8258690433854907,
 'train_acc_clean_only': 0.8406901256710327,
 'train_asr_bd_only': 0.6924850673704681,
 'train_epoch_loss_avg_over_batch': 0.4173153427881248,
 'train_ra_bd_only': 0.4569245728573413}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.99302077293396 s
2024-11-17:21:51:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.99302077293396 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005035625398291318,
 'clean_test_loss_avg_over_batch': 1.4099625435742464,
 'epoch': 21,
 'test_acc': 0.6135714285714285,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.8319534583926032,
 'train_acc_clean_only': 0.8475102101295598,
 'train_asr_bd_only': 0.6919400994637847,
 'train_epoch_loss_avg_over_batch': 0.4041052454841425,
 'train_ra_bd_only': 0.45825577195565803}
2024-11-17:21:51:39 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005035625398291318,
 'clean_test_loss_avg_over_batch': 1.4099625435742464,
 'epoch': 21,
 'test_acc': 0.6135714285714285,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.8319534583926032,
 'train_acc_clean_only': 0.8475102101295598,
 'train_asr_bd_only': 0.6919400994637847,
 'train_epoch_loss_avg_over_batch': 0.4041052454841425,
 'train_ra_bd_only': 0.45825577195565803}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.25605964660645 s
2024-11-17:21:56:04 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.25605964660645 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0450455112202855,
 'clean_test_loss_avg_over_batch': 1.3584608999165622,
 'epoch': 22,
 'test_acc': 0.613,
 'test_asr': 0.9894642857142857,
 'test_ra': 0.007678571428571429,
 'train_acc': 0.8366709637268848,
 'train_acc_clean_only': 0.8530367809350353,
 'train_asr_bd_only': 0.6893667861409797,
 'train_epoch_loss_avg_over_batch': 0.3956264395208481,
 'train_ra_bd_only': 0.4602261676530244}
2024-11-17:21:56:08 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0450455112202855,
 'clean_test_loss_avg_over_batch': 1.3584608999165622,
 'epoch': 22,
 'test_acc': 0.613,
 'test_asr': 0.9894642857142857,
 'test_ra': 0.007678571428571429,
 'train_acc': 0.8366709637268848,
 'train_acc_clean_only': 0.8530367809350353,
 'train_asr_bd_only': 0.6893667861409797,
 'train_epoch_loss_avg_over_batch': 0.3956264395208481,
 'train_ra_bd_only': 0.4602261676530244}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.6656210422516 s
2024-11-17:22:00:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.6656210422516 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.019201869879907463,
 'clean_test_loss_avg_over_batch': 1.3242597899653694,
 'epoch': 23,
 'test_acc': 0.6167142857142857,
 'test_asr': 0.9923214285714286,
 'test_ra': 0.007321428571428572,
 'train_acc': 0.8425275604551921,
 'train_acc_clean_only': 0.8595538048830181,
 'train_asr_bd_only': 0.6893074422868573,
 'train_epoch_loss_avg_over_batch': 0.38524800722366714,
 'train_ra_bd_only': 0.4653998944356474}
2024-11-17:22:00:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.019201869879907463,
 'clean_test_loss_avg_over_batch': 1.3242597899653694,
 'epoch': 23,
 'test_acc': 0.6167142857142857,
 'test_asr': 0.9923214285714286,
 'test_ra': 0.007321428571428572,
 'train_acc': 0.8425275604551921,
 'train_acc_clean_only': 0.8595538048830181,
 'train_asr_bd_only': 0.6893074422868573,
 'train_epoch_loss_avg_over_batch': 0.38524800722366714,
 'train_ra_bd_only': 0.4653998944356474}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.5978174209595 s
2024-11-17:22:05:00 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.5978174209595 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010225460020592436,
 'clean_test_loss_avg_over_batch': 1.3502661881121722,
 'epoch': 24,
 'test_acc': 0.6148571428571429,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8469727951635846,
 'train_acc_clean_only': 0.863816388584482,
 'train_asr_bd_only': 0.6953682865160734,
 'train_epoch_loss_avg_over_batch': 0.37561343120116936,
 'train_ra_bd_only': 0.46239337612180825}
2024-11-17:22:05:05 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010225460020592436,
 'clean_test_loss_avg_over_batch': 1.3502661881121722,
 'epoch': 24,
 'test_acc': 0.6148571428571429,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8469727951635846,
 'train_acc_clean_only': 0.863816388584482,
 'train_asr_bd_only': 0.6953682865160734,
 'train_epoch_loss_avg_over_batch': 0.37561343120116936,
 'train_ra_bd_only': 0.46239337612180825}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 263.7348732948303 s
2024-11-17:22:09:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 263.7348732948303 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0033832732063853077,
 'clean_test_loss_avg_over_batch': 1.2975261997092853,
 'epoch': 25,
 'test_acc': 0.6221428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.8509568367709816,
 'train_acc_clean_only': 0.8686849042741691,
 'train_asr_bd_only': 0.6913864962489581,
 'train_epoch_loss_avg_over_batch': 0.3689210476409405,
 'train_ra_bd_only': 0.46440677966101696}
2024-11-17:22:09:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0033832732063853077,
 'clean_test_loss_avg_over_batch': 1.2975261997092853,
 'epoch': 25,
 'test_acc': 0.6221428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.8509568367709816,
 'train_acc_clean_only': 0.8686849042741691,
 'train_asr_bd_only': 0.6913864962489581,
 'train_epoch_loss_avg_over_batch': 0.3689210476409405,
 'train_ra_bd_only': 0.46440677966101696}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.0933885574341 s
2024-11-17:22:13:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.0933885574341 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0020995496412400494,
 'clean_test_loss_avg_over_batch': 1.335387286272916,
 'epoch': 26,
 'test_acc': 0.6235714285714286,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8547741820768137,
 'train_acc_clean_only': 0.8732763064879099,
 'train_asr_bd_only': 0.6882622586470343,
 'train_epoch_loss_avg_over_batch': 0.3617111957853244,
 'train_ra_bd_only': 0.4718710932073899}
2024-11-17:22:14:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0020995496412400494,
 'clean_test_loss_avg_over_batch': 1.335387286272916,
 'epoch': 26,
 'test_acc': 0.6235714285714286,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8547741820768137,
 'train_acc_clean_only': 0.8732763064879099,
 'train_asr_bd_only': 0.6882622586470343,
 'train_epoch_loss_avg_over_batch': 0.3617111957853244,
 'train_ra_bd_only': 0.4718710932073899}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8324887752533 s
2024-11-17:22:18:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.8324887752533 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.12094788367606023,
 'clean_test_loss_avg_over_batch': 1.3506268566304986,
 'epoch': 27,
 'test_acc': 0.6222857142857143,
 'test_asr': 0.9658928571428571,
 'test_ra': 0.02875,
 'train_acc': 0.8580692123044097,
 'train_acc_clean_only': 0.8767121173300076,
 'train_asr_bd_only': 0.6902903180997361,
 'train_epoch_loss_avg_over_batch': 0.35344407314257126,
 'train_ra_bd_only': 0.4706209195721628}
2024-11-17:22:18:33 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.12094788367606023,
 'clean_test_loss_avg_over_batch': 1.3506268566304986,
 'epoch': 27,
 'test_acc': 0.6222857142857143,
 'test_asr': 0.9658928571428571,
 'test_ra': 0.02875,
 'train_acc': 0.8580692123044097,
 'train_acc_clean_only': 0.8767121173300076,
 'train_asr_bd_only': 0.6902903180997361,
 'train_epoch_loss_avg_over_batch': 0.35344407314257126,
 'train_ra_bd_only': 0.4706209195721628}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.16923570632935 s
2024-11-17:22:22:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.16923570632935 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04977597069757229,
 'clean_test_loss_avg_over_batch': 1.294140829823234,
 'epoch': 28,
 'test_acc': 0.6364285714285715,
 'test_asr': 0.9873214285714286,
 'test_ra': 0.011964285714285714,
 'train_acc': 0.8629450791251778,
 'train_acc_clean_only': 0.8821822492367437,
 'train_asr_bd_only': 0.6898180302819836,
 'train_epoch_loss_avg_over_batch': 0.34410015849733083,
 'train_ra_bd_only': 0.47125989720794553}
2024-11-17:22:23:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04977597069757229,
 'clean_test_loss_avg_over_batch': 1.294140829823234,
 'epoch': 28,
 'test_acc': 0.6364285714285715,
 'test_asr': 0.9873214285714286,
 'test_ra': 0.011964285714285714,
 'train_acc': 0.8629450791251778,
 'train_acc_clean_only': 0.8821822492367437,
 'train_asr_bd_only': 0.6898180302819836,
 'train_epoch_loss_avg_over_batch': 0.34410015849733083,
 'train_ra_bd_only': 0.47125989720794553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.1839530467987 s
2024-11-17:22:27:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.1839530467987 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04995071136561984,
 'clean_test_loss_avg_over_batch': 1.2100661670619792,
 'epoch': 29,
 'test_acc': 0.641,
 'test_asr': 0.9817857142857143,
 'test_ra': 0.015714285714285715,
 'train_acc': 0.8650565656116643,
 'train_acc_clean_only': 0.8844217382580376,
 'train_asr_bd_only': 0.6907560223389181,
 'train_epoch_loss_avg_over_batch': 0.3406358478937939,
 'train_ra_bd_only': 0.47203467533550053}
2024-11-17:22:27:33 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04995071136561984,
 'clean_test_loss_avg_over_batch': 1.2100661670619792,
 'epoch': 29,
 'test_acc': 0.641,
 'test_asr': 0.9817857142857143,
 'test_ra': 0.015714285714285715,
 'train_acc': 0.8650565656116643,
 'train_acc_clean_only': 0.8844217382580376,
 'train_asr_bd_only': 0.6907560223389181,
 'train_epoch_loss_avg_over_batch': 0.3406358478937939,
 'train_ra_bd_only': 0.47203467533550053}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.2466537952423 s
2024-11-17:22:31:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.2466537952423 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015148373913358559,
 'clean_test_loss_avg_over_batch': 1.2488386785442178,
 'epoch': 30,
 'test_acc': 0.6548571428571428,
 'test_asr': 0.9942857142857143,
 'test_ra': 0.005714285714285714,
 'train_acc': 0.868835015113798,
 'train_acc_clean_only': 0.88911801295923,
 'train_asr_bd_only': 0.6863071922660222,
 'train_epoch_loss_avg_over_batch': 0.3328851118291679,
 'train_ra_bd_only': 0.47840097785926605}
2024-11-17:22:32:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015148373913358559,
 'clean_test_loss_avg_over_batch': 1.2488386785442178,
 'epoch': 30,
 'test_acc': 0.6548571428571428,
 'test_asr': 0.9942857142857143,
 'test_ra': 0.005714285714285714,
 'train_acc': 0.868835015113798,
 'train_acc_clean_only': 0.88911801295923,
 'train_asr_bd_only': 0.6863071922660222,
 'train_epoch_loss_avg_over_batch': 0.3328851118291679,
 'train_ra_bd_only': 0.47840097785926605}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.50073766708374 s
2024-11-17:22:36:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.50073766708374 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03611273645021191,
 'clean_test_loss_avg_over_batch': 1.34367267110131,
 'epoch': 31,
 'test_acc': 0.6385714285714286,
 'test_asr': 0.9851785714285715,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8696990576102418,
 'train_acc_clean_only': 0.8902245148066172,
 'train_asr_bd_only': 0.6849665212680244,
 'train_epoch_loss_avg_over_batch': 0.330603864520873,
 'train_ra_bd_only': 0.47950990470369237}
2024-11-17:22:36:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03611273645021191,
 'clean_test_loss_avg_over_batch': 1.34367267110131,
 'epoch': 31,
 'test_acc': 0.6385714285714286,
 'test_asr': 0.9851785714285715,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8696990576102418,
 'train_acc_clean_only': 0.8902245148066172,
 'train_asr_bd_only': 0.6849665212680244,
 'train_epoch_loss_avg_over_batch': 0.330603864520873,
 'train_ra_bd_only': 0.47950990470369237}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.2593729496002 s
2024-11-17:22:40:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.2593729496002 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.024432400155505588,
 'clean_test_loss_avg_over_batch': 1.3474825647744266,
 'epoch': 32,
 'test_acc': 0.644,
 'test_asr': 0.9889285714285714,
 'test_ra': 0.009821428571428571,
 'train_acc': 0.8737108819345661,
 'train_acc_clean_only': 0.8945634826309892,
 'train_asr_bd_only': 0.6860571714309526,
 'train_epoch_loss_avg_over_batch': 0.3235229424348003,
 'train_ra_bd_only': 0.4788176792510487}
2024-11-17:22:41:04 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.024432400155505588,
 'clean_test_loss_avg_over_batch': 1.3474825647744266,
 'epoch': 32,
 'test_acc': 0.644,
 'test_asr': 0.9889285714285714,
 'test_ra': 0.009821428571428571,
 'train_acc': 0.8737108819345661,
 'train_acc_clean_only': 0.8945634826309892,
 'train_asr_bd_only': 0.6860571714309526,
 'train_epoch_loss_avg_over_batch': 0.3235229424348003,
 'train_ra_bd_only': 0.4788176792510487}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 272.6635594367981 s
2024-11-17:22:45:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 272.6635594367981 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005474193808781406,
 'clean_test_loss_avg_over_batch': 1.3268290517005052,
 'epoch': 33,
 'test_acc': 0.628,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.874399893314367,
 'train_acc_clean_only': 0.895544641561737,
 'train_asr_bd_only': 0.6840701325404985,
 'train_epoch_loss_avg_over_batch': 0.32056693692995,
 'train_ra_bd_only': 0.4800911389591264}
2024-11-17:22:45:42 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005474193808781406,
 'clean_test_loss_avg_over_batch': 1.3268290517005052,
 'epoch': 33,
 'test_acc': 0.628,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.874399893314367,
 'train_acc_clean_only': 0.895544641561737,
 'train_asr_bd_only': 0.6840701325404985,
 'train_epoch_loss_avg_over_batch': 0.32056693692995,
 'train_ra_bd_only': 0.4800911389591264}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 265.1394941806793 s
2024-11-17:22:50:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 265.1394941806793 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.037101503080603754,
 'clean_test_loss_avg_over_batch': 1.2372162076559934,
 'epoch': 34,
 'test_acc': 0.6358571428571429,
 'test_asr': 0.9860714285714286,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8772003911806543,
 'train_acc_clean_only': 0.8982002840032105,
 'train_asr_bd_only': 0.688215357261918,
 'train_epoch_loss_avg_over_batch': 0.31487452279601463,
 'train_ra_bd_only': 0.4808589843315924}
2024-11-17:22:50:12 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.037101503080603754,
 'clean_test_loss_avg_over_batch': 1.2372162076559934,
 'epoch': 34,
 'test_acc': 0.6358571428571429,
 'test_asr': 0.9860714285714286,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8772003911806543,
 'train_acc_clean_only': 0.8982002840032105,
 'train_asr_bd_only': 0.688215357261918,
 'train_epoch_loss_avg_over_batch': 0.31487452279601463,
 'train_ra_bd_only': 0.4808589843315924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.9650194644928 s
2024-11-17:22:54:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.9650194644928 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07116500944142569,
 'clean_test_loss_avg_over_batch': 1.299200515313582,
 'epoch': 35,
 'test_acc': 0.643,
 'test_asr': 0.9801785714285715,
 'test_ra': 0.016785714285714286,
 'train_acc': 0.87947301742532,
 'train_acc_clean_only': 0.9009168364511947,
 'train_asr_bd_only': 0.6864929436604067,
 'train_epoch_loss_avg_over_batch': 0.30992019428721873,
 'train_ra_bd_only': 0.4801089009889988}
2024-11-17:22:54:42 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.07116500944142569,
 'clean_test_loss_avg_over_batch': 1.299200515313582,
 'epoch': 35,
 'test_acc': 0.643,
 'test_asr': 0.9801785714285715,
 'test_ra': 0.016785714285714286,
 'train_acc': 0.87947301742532,
 'train_acc_clean_only': 0.9009168364511947,
 'train_asr_bd_only': 0.6864929436604067,
 'train_epoch_loss_avg_over_batch': 0.30992019428721873,
 'train_ra_bd_only': 0.4801089009889988}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.2980206012726 s
2024-11-17:22:59:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.2980206012726 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.1268075559478761,
 'clean_test_loss_avg_over_batch': 1.2495136760852554,
 'epoch': 36,
 'test_acc': 0.6648571428571428,
 'test_asr': 0.9625,
 'test_ra': 0.03321428571428572,
 'train_acc': 0.880259268314367,
 'train_acc_clean_only': 0.9020907999246781,
 'train_asr_bd_only': 0.6837718445253244,
 'train_epoch_loss_avg_over_batch': 0.3082887398272456,
 'train_ra_bd_only': 0.482732753590976}
2024-11-17:22:59:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.1268075559478761,
 'clean_test_loss_avg_over_batch': 1.2495136760852554,
 'epoch': 36,
 'test_acc': 0.6648571428571428,
 'test_asr': 0.9625,
 'test_ra': 0.03321428571428572,
 'train_acc': 0.880259268314367,
 'train_acc_clean_only': 0.9020907999246781,
 'train_asr_bd_only': 0.6837718445253244,
 'train_epoch_loss_avg_over_batch': 0.3082887398272456,
 'train_ra_bd_only': 0.482732753590976}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.3060519695282 s
2024-11-17:23:03:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.3060519695282 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.029768578327176245,
 'clean_test_loss_avg_over_batch': 1.2522584774277428,
 'epoch': 37,
 'test_acc': 0.6515714285714286,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8832014580369844,
 'train_acc_clean_only': 0.905421340857314,
 'train_asr_bd_only': 0.6832249819414347,
 'train_epoch_loss_avg_over_batch': 0.3027412502537581,
 'train_ra_bd_only': 0.48566427737956325}
2024-11-17:23:03:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.029768578327176245,
 'clean_test_loss_avg_over_batch': 1.2522584774277428,
 'epoch': 37,
 'test_acc': 0.6515714285714286,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8832014580369844,
 'train_acc_clean_only': 0.905421340857314,
 'train_asr_bd_only': 0.6832249819414347,
 'train_epoch_loss_avg_over_batch': 0.3027412502537581,
 'train_ra_bd_only': 0.48566427737956325}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.332710981369 s
2024-11-17:23:08:05 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.332710981369 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.10368916425729614,
 'clean_test_loss_avg_over_batch': 1.3391667103225535,
 'epoch': 38,
 'test_acc': 0.6438571428571429,
 'test_asr': 0.9783928571428572,
 'test_ra': 0.0175,
 'train_acc': 0.885060121799431,
 'train_acc_clean_only': 0.907152845734254,
 'train_asr_bd_only': 0.6862341991943326,
 'train_epoch_loss_avg_over_batch': 0.2982473927331429,
 'train_ra_bd_only': 0.48406723155993886}
2024-11-17:23:08:10 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.10368916425729614,
 'clean_test_loss_avg_over_batch': 1.3391667103225535,
 'epoch': 38,
 'test_acc': 0.6438571428571429,
 'test_asr': 0.9783928571428572,
 'test_ra': 0.0175,
 'train_acc': 0.885060121799431,
 'train_acc_clean_only': 0.907152845734254,
 'train_asr_bd_only': 0.6862341991943326,
 'train_epoch_loss_avg_over_batch': 0.2982473927331429,
 'train_ra_bd_only': 0.48406723155993886}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 264.8979923725128 s
2024-11-17:23:12:35 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 264.8979923725128 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.036051611237698206,
 'clean_test_loss_avg_over_batch': 1.4468395360491493,
 'epoch': 39,
 'test_acc': 0.6305714285714286,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8861769870199147,
 'train_acc_clean_only': 0.9083230948750085,
 'train_asr_bd_only': 0.6868644774129021,
 'train_epoch_loss_avg_over_batch': 0.29556238523566536,
 'train_ra_bd_only': 0.4819414346835584}
2024-11-17:23:12:40 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.036051611237698206,
 'clean_test_loss_avg_over_batch': 1.4468395360491493,
 'epoch': 39,
 'test_acc': 0.6305714285714286,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.8861769870199147,
 'train_acc_clean_only': 0.9083230948750085,
 'train_asr_bd_only': 0.6868644774129021,
 'train_epoch_loss_avg_over_batch': 0.29556238523566536,
 'train_ra_bd_only': 0.4819414346835584}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.9173176288605 s
2024-11-17:23:17:04 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.9173176288605 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01796336308259263,
 'clean_test_loss_avg_over_batch': 1.4237765951590104,
 'epoch': 40,
 'test_acc': 0.6355714285714286,
 'test_asr': 0.995,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8880939944879089,
 'train_acc_clean_only': 0.9102799583874841,
 'train_asr_bd_only': 0.6884289484650646,
 'train_epoch_loss_avg_over_batch': 0.29109479578617287,
 'train_ra_bd_only': 0.4830670926517572}
2024-11-17:23:17:08 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01796336308259263,
 'clean_test_loss_avg_over_batch': 1.4237765951590104,
 'epoch': 40,
 'test_acc': 0.6355714285714286,
 'test_asr': 0.995,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.8880939944879089,
 'train_acc_clean_only': 0.9102799583874841,
 'train_asr_bd_only': 0.6884289484650646,
 'train_epoch_loss_avg_over_batch': 0.29109479578617287,
 'train_ra_bd_only': 0.4830670926517572}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.6761100292206 s
2024-11-17:23:21:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.6761100292206 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.016636229141361335,
 'clean_test_loss_avg_over_batch': 1.3417680298740213,
 'epoch': 41,
 'test_acc': 0.6321428571428571,
 'test_asr': 0.9921428571428571,
 'test_ra': 0.0075,
 'train_acc': 0.8896387135490754,
 'train_acc_clean_only': 0.912885102179416,
 'train_asr_bd_only': 0.6804367151905767,
 'train_epoch_loss_avg_over_batch': 0.2886819968246464,
 'train_ra_bd_only': 0.48927658628736526}
2024-11-17:23:21:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.016636229141361335,
 'clean_test_loss_avg_over_batch': 1.3417680298740213,
 'epoch': 41,
 'test_acc': 0.6321428571428571,
 'test_asr': 0.9921428571428571,
 'test_ra': 0.0075,
 'train_acc': 0.8896387135490754,
 'train_acc_clean_only': 0.912885102179416,
 'train_asr_bd_only': 0.6804367151905767,
 'train_epoch_loss_avg_over_batch': 0.2886819968246464,
 'train_ra_bd_only': 0.48927658628736526}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.5633933544159 s
2024-11-17:23:25:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.5633933544159 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.027494496618931986,
 'clean_test_loss_avg_over_batch': 1.3394588362086903,
 'epoch': 42,
 'test_acc': 0.6474285714285715,
 'test_asr': 0.9892857142857143,
 'test_ra': 0.009285714285714286,
 'train_acc': 0.8911500933499289,
 'train_acc_clean_only': 0.9139341478924979,
 'train_asr_bd_only': 0.6861214511917328,
 'train_epoch_loss_avg_over_batch': 0.28521121790365,
 'train_ra_bd_only': 0.48561031168398244}
2024-11-17:23:26:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.027494496618931986,
 'clean_test_loss_avg_over_batch': 1.3394588362086903,
 'epoch': 42,
 'test_acc': 0.6474285714285715,
 'test_asr': 0.9892857142857143,
 'test_ra': 0.009285714285714286,
 'train_acc': 0.8911500933499289,
 'train_acc_clean_only': 0.9139341478924979,
 'train_asr_bd_only': 0.6861214511917328,
 'train_epoch_loss_avg_over_batch': 0.28521121790365,
 'train_ra_bd_only': 0.48561031168398244}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.14386010169983 s
2024-11-17:23:30:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.14386010169983 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.014092064631933516,
 'clean_test_loss_avg_over_batch': 1.4486721716143869,
 'epoch': 43,
 'test_acc': 0.64,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.00375,
 'train_acc': 0.8927753822901849,
 'train_acc_clean_only': 0.9159391746721656,
 'train_asr_bd_only': 0.6842909535452323,
 'train_epoch_loss_avg_over_batch': 0.28063032524143566,
 'train_ra_bd_only': 0.4870804623249611}
2024-11-17:23:30:28 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.014092064631933516,
 'clean_test_loss_avg_over_batch': 1.4486721716143869,
 'epoch': 43,
 'test_acc': 0.64,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.00375,
 'train_acc': 0.8927753822901849,
 'train_acc_clean_only': 0.9159391746721656,
 'train_asr_bd_only': 0.6842909535452323,
 'train_epoch_loss_avg_over_batch': 0.28063032524143566,
 'train_ra_bd_only': 0.4870804623249611}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.7136332988739 s
2024-11-17:23:34:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.7136332988739 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0062807384284414266,
 'clean_test_loss_avg_over_batch': 1.2851484791799026,
 'epoch': 44,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.8940978396159317,
 'train_acc_clean_only': 0.9178168033659827,
 'train_asr_bd_only': 0.6805968490372059,
 'train_epoch_loss_avg_over_batch': 0.2783900199148004,
 'train_ra_bd_only': 0.48959404262413514}
2024-11-17:23:34:54 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0062807384284414266,
 'clean_test_loss_avg_over_batch': 1.2851484791799026,
 'epoch': 44,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.8940978396159317,
 'train_acc_clean_only': 0.9178168033659827,
 'train_asr_bd_only': 0.6805968490372059,
 'train_epoch_loss_avg_over_batch': 0.2783900199148004,
 'train_ra_bd_only': 0.48959404262413514}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.0617501735687 s
2024-11-17:23:39:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.0617501735687 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008369211908509235,
 'clean_test_loss_avg_over_batch': 1.47862835038792,
 'epoch': 45,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0025,
 'train_acc': 0.8961343127667141,
 'train_acc_clean_only': 0.9198778797504499,
 'train_asr_bd_only': 0.6824382518823104,
 'train_epoch_loss_avg_over_batch': 0.27448156351491193,
 'train_ra_bd_only': 0.4900952963076154}
2024-11-17:23:39:21 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008369211908509235,
 'clean_test_loss_avg_over_batch': 1.47862835038792,
 'epoch': 45,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0025,
 'train_acc': 0.8961343127667141,
 'train_acc_clean_only': 0.9198778797504499,
 'train_asr_bd_only': 0.6824382518823104,
 'train_epoch_loss_avg_over_batch': 0.27448156351491193,
 'train_ra_bd_only': 0.4900952963076154}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.19052839279175 s
2024-11-17:23:43:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.19052839279175 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.05262943866810846,
 'clean_test_loss_avg_over_batch': 1.3302996266971936,
 'epoch': 46,
 'test_acc': 0.649,
 'test_asr': 0.9833928571428572,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8971483819345661,
 'train_acc_clean_only': 0.9205997388413322,
 'train_asr_bd_only': 0.6860952910126407,
 'train_epoch_loss_avg_over_batch': 0.2711374573833488,
 'train_ra_bd_only': 0.48534518683150435}
2024-11-17:23:43:46 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.05262943866810846,
 'clean_test_loss_avg_over_batch': 1.3302996266971936,
 'epoch': 46,
 'test_acc': 0.649,
 'test_asr': 0.9833928571428572,
 'test_ra': 0.013214285714285715,
 'train_acc': 0.8971483819345661,
 'train_acc_clean_only': 0.9205997388413322,
 'train_asr_bd_only': 0.6860952910126407,
 'train_epoch_loss_avg_over_batch': 0.2711374573833488,
 'train_ra_bd_only': 0.48534518683150435}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.55695271492004 s
2024-11-17:23:48:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.55695271492004 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0022865026330691762,
 'clean_test_loss_avg_over_batch': 1.4086279094219207,
 'epoch': 47,
 'test_acc': 0.6441428571428571,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.8999933321479374,
 'train_acc_clean_only': 0.923548042550827,
 'train_asr_bd_only': 0.6880035561482469,
 'train_epoch_loss_avg_over_batch': 0.26695923671486704,
 'train_ra_bd_only': 0.48455298105239764}
2024-11-17:23:48:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0022865026330691762,
 'clean_test_loss_avg_over_batch': 1.4086279094219207,
 'epoch': 47,
 'test_acc': 0.6441428571428571,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.8999933321479374,
 'train_acc_clean_only': 0.923548042550827,
 'train_asr_bd_only': 0.6880035561482469,
 'train_epoch_loss_avg_over_batch': 0.26695923671486704,
 'train_ra_bd_only': 0.48455298105239764}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.8417053222656 s
2024-11-17:23:52:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.8417053222656 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.02083029304975009,
 'clean_test_loss_avg_over_batch': 1.3443456408652392,
 'epoch': 48,
 'test_acc': 0.6558571428571428,
 'test_asr': 0.9905357142857143,
 'test_ra': 0.0066071428571428574,
 'train_acc': 0.9005851040184921,
 'train_acc_clean_only': 0.9245667434293793,
 'train_asr_bd_only': 0.6847530143912874,
 'train_epoch_loss_avg_over_batch': 0.2648713859977203,
 'train_ra_bd_only': 0.49019280991276326}
2024-11-17:23:52:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.02083029304975009,
 'clean_test_loss_avg_over_batch': 1.3443456408652392,
 'epoch': 48,
 'test_acc': 0.6558571428571428,
 'test_asr': 0.9905357142857143,
 'test_ra': 0.0066071428571428574,
 'train_acc': 0.9005851040184921,
 'train_acc_clean_only': 0.9245667434293793,
 'train_asr_bd_only': 0.6847530143912874,
 'train_epoch_loss_avg_over_batch': 0.2648713859977203,
 'train_ra_bd_only': 0.49019280991276326}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 261.6533796787262 s
2024-11-17:23:56:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 261.6533796787262 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03512451892575799,
 'clean_test_loss_avg_over_batch': 1.4707515440203927,
 'epoch': 49,
 'test_acc': 0.6482857142857142,
 'test_asr': 0.9867857142857143,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.9024465460526315,
 'train_acc_clean_only': 0.9270550683299222,
 'train_asr_bd_only': 0.6809657433389826,
 'train_epoch_loss_avg_over_batch': 0.26152596420808505,
 'train_ra_bd_only': 0.49401272469646873}
2024-11-17:23:57:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03512451892575799,
 'clean_test_loss_avg_over_batch': 1.4707515440203927,
 'epoch': 49,
 'test_acc': 0.6482857142857142,
 'test_asr': 0.9867857142857143,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.9024465460526315,
 'train_acc_clean_only': 0.9270550683299222,
 'train_asr_bd_only': 0.6809657433389826,
 'train_epoch_loss_avg_over_batch': 0.26152596420808505,
 'train_ra_bd_only': 0.49401272469646873}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.5889484882355 s
2024-11-18:00:01:23 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.5889484882355 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03040460500580428,
 'clean_test_loss_avg_over_batch': 1.2796065260063518,
 'epoch': 50,
 'test_acc': 0.6627142857142857,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.008571428571428572,
 'train_acc': 0.9043941145092461,
 'train_acc_clean_only': 0.9290183766897263,
 'train_asr_bd_only': 0.682771650043064,
 'train_epoch_loss_avg_over_batch': 0.2561919739069801,
 'train_ra_bd_only': 0.49042869446836884}
2024-11-18:00:01:27 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03040460500580428,
 'clean_test_loss_avg_over_batch': 1.2796065260063518,
 'epoch': 50,
 'test_acc': 0.6627142857142857,
 'test_asr': 0.9878571428571429,
 'test_ra': 0.008571428571428572,
 'train_acc': 0.9043941145092461,
 'train_acc_clean_only': 0.9290183766897263,
 'train_asr_bd_only': 0.682771650043064,
 'train_epoch_loss_avg_over_batch': 0.2561919739069801,
 'train_ra_bd_only': 0.49042869446836884}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.0101225376129 s
2024-11-18:00:05:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.0101225376129 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007150299263726497,
 'clean_test_loss_avg_over_batch': 1.188133968277411,
 'epoch': 51,
 'test_acc': 0.6788571428571428,
 'test_asr': 0.9983928571428572,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9051581392247511,
 'train_acc_clean_only': 0.929620334441553,
 'train_asr_bd_only': 0.6849943044480872,
 'train_epoch_loss_avg_over_batch': 0.25498549863802084,
 'train_ra_bd_only': 0.4927624815936432}
2024-11-18:00:05:51 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007150299263726497,
 'clean_test_loss_avg_over_batch': 1.188133968277411,
 'epoch': 51,
 'test_acc': 0.6788571428571428,
 'test_asr': 0.9983928571428572,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9051581392247511,
 'train_acc_clean_only': 0.929620334441553,
 'train_asr_bd_only': 0.6849943044480872,
 'train_epoch_loss_avg_over_batch': 0.25498549863802084,
 'train_ra_bd_only': 0.4927624815936432}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.5913529396057 s
2024-11-18:00:10:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.5913529396057 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0048535575326902535,
 'clean_test_loss_avg_over_batch': 1.477314506335692,
 'epoch': 52,
 'test_acc': 0.644,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0008928571428571428,
 'train_acc': 0.9057026804765291,
 'train_acc_clean_only': 0.9304659476079051,
 'train_asr_bd_only': 0.6828360282269267,
 'train_epoch_loss_avg_over_batch': 0.2537013614155447,
 'train_ra_bd_only': 0.493498916486081}
2024-11-18:00:10:15 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0048535575326902535,
 'clean_test_loss_avg_over_batch': 1.477314506335692,
 'epoch': 52,
 'test_acc': 0.644,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0008928571428571428,
 'train_acc': 0.9057026804765291,
 'train_acc_clean_only': 0.9304659476079051,
 'train_asr_bd_only': 0.6828360282269267,
 'train_epoch_loss_avg_over_batch': 0.2537013614155447,
 'train_ra_bd_only': 0.493498916486081}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.83553814888 s
2024-11-18:00:14:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.83553814888 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007556100929584566,
 'clean_test_loss_avg_over_batch': 1.343236942453818,
 'epoch': 53,
 'test_acc': 0.6642857142857143,
 'test_asr': 0.9975,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9074140958392604,
 'train_acc_clean_only': 0.9322469215073115,
 'train_asr_bd_only': 0.6839283233782469,
 'train_epoch_loss_avg_over_batch': 0.24945771400611397,
 'train_ra_bd_only': 0.4949854146409223}
2024-11-18:00:14:38 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007556100929584566,
 'clean_test_loss_avg_over_batch': 1.343236942453818,
 'epoch': 53,
 'test_acc': 0.6642857142857143,
 'test_asr': 0.9975,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9074140958392604,
 'train_acc_clean_only': 0.9322469215073115,
 'train_asr_bd_only': 0.6839283233782469,
 'train_epoch_loss_avg_over_batch': 0.24945771400611397,
 'train_ra_bd_only': 0.4949854146409223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.9361033439636 s
2024-11-18:00:18:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.9361033439636 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03426162297414108,
 'clean_test_loss_avg_over_batch': 1.3220816639336672,
 'epoch': 54,
 'test_acc': 0.6554285714285715,
 'test_asr': 0.9876785714285714,
 'test_ra': 0.01,
 'train_acc': 0.9095978173897582,
 'train_acc_clean_only': 0.9343835180880588,
 'train_asr_bd_only': 0.6865223793515406,
 'train_epoch_loss_avg_over_batch': 0.2448173994079211,
 'train_ra_bd_only': 0.48992859722723864}
2024-11-18:00:19:00 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03426162297414108,
 'clean_test_loss_avg_over_batch': 1.3220816639336672,
 'epoch': 54,
 'test_acc': 0.6554285714285715,
 'test_asr': 0.9876785714285714,
 'test_ra': 0.01,
 'train_acc': 0.9095978173897582,
 'train_acc_clean_only': 0.9343835180880588,
 'train_asr_bd_only': 0.6865223793515406,
 'train_epoch_loss_avg_over_batch': 0.2448173994079211,
 'train_ra_bd_only': 0.48992859722723864}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.1722023487091 s
2024-11-18:00:23:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.1722023487091 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.034845817848690785,
 'clean_test_loss_avg_over_batch': 1.3189340090209787,
 'epoch': 55,
 'test_acc': 0.6752857142857143,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.911106418918919,
 'train_acc_clean_only': 0.9362227573007347,
 'train_asr_bd_only': 0.685076119568841,
 'train_epoch_loss_avg_over_batch': 0.24231918268488617,
 'train_ra_bd_only': 0.49405489498833205}
2024-11-18:00:23:25 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.034845817848690785,
 'clean_test_loss_avg_over_batch': 1.3189340090209787,
 'epoch': 55,
 'test_acc': 0.6752857142857143,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.01107142857142857,
 'train_acc': 0.911106418918919,
 'train_acc_clean_only': 0.9362227573007347,
 'train_asr_bd_only': 0.685076119568841,
 'train_epoch_loss_avg_over_batch': 0.24231918268488617,
 'train_ra_bd_only': 0.49405489498833205}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.1717667579651 s
2024-11-18:00:27:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.1717667579651 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0307966950862134,
 'clean_test_loss_avg_over_batch': 1.2349090549078854,
 'epoch': 56,
 'test_acc': 0.6695714285714286,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.009464285714285715,
 'train_acc': 0.9120232485775249,
 'train_acc_clean_only': 0.9373097653283613,
 'train_asr_bd_only': 0.6844474079013169,
 'train_epoch_loss_avg_over_batch': 0.23955109783025674,
 'train_ra_bd_only': 0.4941656942823804}
2024-11-18:00:27:48 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0307966950862134,
 'clean_test_loss_avg_over_batch': 1.2349090549078854,
 'epoch': 56,
 'test_acc': 0.6695714285714286,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.009464285714285715,
 'train_acc': 0.9120232485775249,
 'train_acc_clean_only': 0.9373097653283613,
 'train_asr_bd_only': 0.6844474079013169,
 'train_epoch_loss_avg_over_batch': 0.23955109783025674,
 'train_ra_bd_only': 0.4941656942823804}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.62380027770996 s
2024-11-18:00:32:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.62380027770996 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03258474825799402,
 'clean_test_loss_avg_over_batch': 1.2511858885938472,
 'epoch': 57,
 'test_acc': 0.6745714285714286,
 'test_asr': 0.9853571428571428,
 'test_ra': 0.012142857142857143,
 'train_acc': 0.9129206303342816,
 'train_acc_clean_only': 0.9385875823066546,
 'train_asr_bd_only': 0.6819280455618836,
 'train_epoch_loss_avg_over_batch': 0.2359838575697047,
 'train_ra_bd_only': 0.49592999027642726}
2024-11-18:00:32:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.03258474825799402,
 'clean_test_loss_avg_over_batch': 1.2511858885938472,
 'epoch': 57,
 'test_acc': 0.6745714285714286,
 'test_asr': 0.9853571428571428,
 'test_ra': 0.012142857142857143,
 'train_acc': 0.9129206303342816,
 'train_acc_clean_only': 0.9385875823066546,
 'train_asr_bd_only': 0.6819280455618836,
 'train_epoch_loss_avg_over_batch': 0.2359838575697047,
 'train_ra_bd_only': 0.49592999027642726}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.30033016204834 s
2024-11-18:00:36:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.30033016204834 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013599583215016703,
 'clean_test_loss_avg_over_batch': 1.320570997758345,
 'epoch': 58,
 'test_acc': 0.6748571428571428,
 'test_asr': 0.9944642857142857,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.9138902471550497,
 'train_acc_clean_only': 0.9394800937201915,
 'train_asr_bd_only': 0.6835773622648849,
 'train_epoch_loss_avg_over_batch': 0.234701299883563,
 'train_ra_bd_only': 0.4955963659600478}
2024-11-18:00:36:34 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013599583215016703,
 'clean_test_loss_avg_over_batch': 1.320570997758345,
 'epoch': 58,
 'test_acc': 0.6748571428571428,
 'test_asr': 0.9944642857142857,
 'test_ra': 0.004821428571428571,
 'train_acc': 0.9138902471550497,
 'train_acc_clean_only': 0.9394800937201915,
 'train_asr_bd_only': 0.6835773622648849,
 'train_epoch_loss_avg_over_batch': 0.234701299883563,
 'train_ra_bd_only': 0.4955963659600478}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.42782378196716 s
2024-11-18:00:40:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.42782378196716 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01157563067946202,
 'clean_test_loss_avg_over_batch': 1.246899941292676,
 'epoch': 59,
 'test_acc': 0.6772857142857143,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004464285714285714,
 'train_acc': 0.9161712082147937,
 'train_acc_clean_only': 0.9420825821746969,
 'train_asr_bd_only': 0.6829573238497444,
 'train_epoch_loss_avg_over_batch': 0.22987722674620525,
 'train_ra_bd_only': 0.49799955545676816}
2024-11-18:00:40:58 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01157563067946202,
 'clean_test_loss_avg_over_batch': 1.246899941292676,
 'epoch': 59,
 'test_acc': 0.6772857142857143,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004464285714285714,
 'train_acc': 0.9161712082147937,
 'train_acc_clean_only': 0.9420825821746969,
 'train_asr_bd_only': 0.6829573238497444,
 'train_epoch_loss_avg_over_batch': 0.22987722674620525,
 'train_ra_bd_only': 0.49799955545676816}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.93117690086365 s
2024-11-18:00:45:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.93117690086365 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0042757602396622215,
 'clean_test_loss_avg_over_batch': 1.2388480338183316,
 'epoch': 60,
 'test_acc': 0.6732857142857143,
 'test_asr': 0.99875,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9171602729374111,
 'train_acc_clean_only': 0.9429865314980197,
 'train_asr_bd_only': 0.68473399083206,
 'train_epoch_loss_avg_over_batch': 0.22685481904400445,
 'train_ra_bd_only': 0.4964856230031949}
2024-11-18:00:45:21 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0042757602396622215,
 'clean_test_loss_avg_over_batch': 1.2388480338183316,
 'epoch': 60,
 'test_acc': 0.6732857142857143,
 'test_asr': 0.99875,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9171602729374111,
 'train_acc_clean_only': 0.9429865314980197,
 'train_asr_bd_only': 0.68473399083206,
 'train_epoch_loss_avg_over_batch': 0.22685481904400445,
 'train_ra_bd_only': 0.4964856230031949}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.8687970638275 s
2024-11-18:00:49:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.8687970638275 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025106333272891457,
 'clean_test_loss_avg_over_batch': 1.3818625330924987,
 'epoch': 61,
 'test_acc': 0.6687142857142857,
 'test_asr': 0.9917857142857143,
 'test_ra': 0.005892857142857143,
 'train_acc': 0.9187049919985776,
 'train_acc_clean_only': 0.9449683738705505,
 'train_asr_bd_only': 0.6823447701069593,
 'train_epoch_loss_avg_over_batch': 0.22416284293529828,
 'train_ra_bd_only': 0.49837477427420473}
2024-11-18:00:49:43 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025106333272891457,
 'clean_test_loss_avg_over_batch': 1.3818625330924987,
 'epoch': 61,
 'test_acc': 0.6687142857142857,
 'test_asr': 0.9917857142857143,
 'test_ra': 0.005892857142857143,
 'train_acc': 0.9187049919985776,
 'train_acc_clean_only': 0.9449683738705505,
 'train_asr_bd_only': 0.6823447701069593,
 'train_epoch_loss_avg_over_batch': 0.22416284293529828,
 'train_ra_bd_only': 0.49837477427420473}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.78704810142517 s
2024-11-18:00:54:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.78704810142517 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.040861958668260326,
 'clean_test_loss_avg_over_batch': 1.4273922887715427,
 'epoch': 62,
 'test_acc': 0.6648571428571428,
 'test_asr': 0.9855357142857143,
 'test_ra': 0.0125,
 'train_acc': 0.9196468261024182,
 'train_acc_clean_only': 0.9456140567505494,
 'train_asr_bd_only': 0.6859302067126029,
 'train_epoch_loss_avg_over_batch': 0.22090636896682245,
 'train_ra_bd_only': 0.4946932651700378}
2024-11-18:00:54:07 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.040861958668260326,
 'clean_test_loss_avg_over_batch': 1.4273922887715427,
 'epoch': 62,
 'test_acc': 0.6648571428571428,
 'test_asr': 0.9855357142857143,
 'test_ra': 0.0125,
 'train_acc': 0.9196468261024182,
 'train_acc_clean_only': 0.9456140567505494,
 'train_asr_bd_only': 0.6859302067126029,
 'train_epoch_loss_avg_over_batch': 0.22090636896682245,
 'train_ra_bd_only': 0.4946932651700378}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.64509415626526 s
2024-11-18:00:58:26 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.64509415626526 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04982936111363498,
 'clean_test_loss_avg_over_batch': 1.3467810815030878,
 'epoch': 63,
 'test_acc': 0.6817142857142857,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.9205608774893315,
 'train_acc_clean_only': 0.9470840999172707,
 'train_asr_bd_only': 0.6818106035345115,
 'train_epoch_loss_avg_over_batch': 0.21849125805463254,
 'train_ra_bd_only': 0.4997221295987551}
2024-11-18:00:58:30 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04982936111363498,
 'clean_test_loss_avg_over_batch': 1.3467810815030878,
 'epoch': 63,
 'test_acc': 0.6817142857142857,
 'test_asr': 0.9841071428571428,
 'test_ra': 0.013928571428571429,
 'train_acc': 0.9205608774893315,
 'train_acc_clean_only': 0.9470840999172707,
 'train_asr_bd_only': 0.6818106035345115,
 'train_epoch_loss_avg_over_batch': 0.21849125805463254,
 'train_ra_bd_only': 0.4997221295987551}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.00683641433716 s
2024-11-18:01:02:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.00683641433716 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04388476906950183,
 'clean_test_loss_avg_over_batch': 1.419353055412119,
 'epoch': 64,
 'test_acc': 0.6657142857142857,
 'test_asr': 0.9858928571428571,
 'test_ra': 0.01125,
 'train_acc': 0.922288962482219,
 'train_acc_clean_only': 0.9488644607230284,
 'train_asr_bd_only': 0.6831050482038175,
 'train_epoch_loss_avg_over_batch': 0.21556452867094095,
 'train_ra_bd_only': 0.49901369710777094}
2024-11-18:01:02:53 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04388476906950183,
 'clean_test_loss_avg_over_batch': 1.419353055412119,
 'epoch': 64,
 'test_acc': 0.6657142857142857,
 'test_asr': 0.9858928571428571,
 'test_ra': 0.01125,
 'train_acc': 0.922288962482219,
 'train_acc_clean_only': 0.9488644607230284,
 'train_asr_bd_only': 0.6831050482038175,
 'train_epoch_loss_avg_over_batch': 0.21556452867094095,
 'train_ra_bd_only': 0.49901369710777094}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 260.29756450653076 s
2024-11-18:01:07:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 260.29756450653076 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005528833125440128,
 'clean_test_loss_avg_over_batch': 1.4962964762340893,
 'epoch': 65,
 'test_acc': 0.6561428571428571,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9236253111664295,
 'train_acc_clean_only': 0.9503398756567534,
 'train_asr_bd_only': 0.6831971995332555,
 'train_epoch_loss_avg_over_batch': 0.21242841825970207,
 'train_ra_bd_only': 0.501583597266211}
2024-11-18:01:07:18 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005528833125440128,
 'clean_test_loss_avg_over_batch': 1.4962964762340893,
 'epoch': 65,
 'test_acc': 0.6561428571428571,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9236253111664295,
 'train_acc_clean_only': 0.9503398756567534,
 'train_asr_bd_only': 0.6831971995332555,
 'train_epoch_loss_avg_over_batch': 0.21242841825970207,
 'train_ra_bd_only': 0.501583597266211}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.21870613098145 s
2024-11-18:01:11:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.21870613098145 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0274170351119458,
 'clean_test_loss_avg_over_batch': 1.37021179524335,
 'epoch': 66,
 'test_acc': 0.6808571428571428,
 'test_asr': 0.9896428571428572,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.9252089260312945,
 'train_acc_clean_only': 0.9519511269027384,
 'train_asr_bd_only': 0.6845395193776913,
 'train_epoch_loss_avg_over_batch': 0.2087108637067154,
 'train_ra_bd_only': 0.5004028337269065}
2024-11-18:01:11:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0274170351119458,
 'clean_test_loss_avg_over_batch': 1.37021179524335,
 'epoch': 66,
 'test_acc': 0.6808571428571428,
 'test_asr': 0.9896428571428572,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.9252089260312945,
 'train_acc_clean_only': 0.9519511269027384,
 'train_asr_bd_only': 0.6845395193776913,
 'train_epoch_loss_avg_over_batch': 0.2087108637067154,
 'train_ra_bd_only': 0.5004028337269065}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 256.2271614074707 s
2024-11-18:01:15:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 256.2271614074707 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.022246286657966928,
 'clean_test_loss_avg_over_batch': 1.4045121030374006,
 'epoch': 67,
 'test_acc': 0.6721428571428572,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.00625,
 'train_acc': 0.9272037251066856,
 'train_acc_clean_only': 0.9540940591767121,
 'train_asr_bd_only': 0.6851712928232058,
 'train_epoch_loss_avg_over_batch': 0.20445051510019457,
 'train_ra_bd_only': 0.4987913645077936}
2024-11-18:01:16:02 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.022246286657966928,
 'clean_test_loss_avg_over_batch': 1.4045121030374006,
 'epoch': 67,
 'test_acc': 0.6721428571428572,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.00625,
 'train_acc': 0.9272037251066856,
 'train_acc_clean_only': 0.9540940591767121,
 'train_asr_bd_only': 0.6851712928232058,
 'train_epoch_loss_avg_over_batch': 0.20445051510019457,
 'train_ra_bd_only': 0.4987913645077936}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.7979803085327 s
2024-11-18:01:20:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.7979803085327 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007170520979508927,
 'clean_test_loss_avg_over_batch': 1.3359940722584724,
 'epoch': 68,
 'test_acc': 0.6841428571428572,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9276315789473685,
 'train_acc_clean_only': 0.9549644382979774,
 'train_asr_bd_only': 0.6816236941542565,
 'train_epoch_loss_avg_over_batch': 0.20237793696045367,
 'train_ra_bd_only': 0.5038619693265171}
2024-11-18:01:20:26 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007170520979508927,
 'clean_test_loss_avg_over_batch': 1.3359940722584724,
 'epoch': 68,
 'test_acc': 0.6841428571428572,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9276315789473685,
 'train_acc_clean_only': 0.9549644382979774,
 'train_asr_bd_only': 0.6816236941542565,
 'train_epoch_loss_avg_over_batch': 0.20237793696045367,
 'train_ra_bd_only': 0.5038619693265171}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.74817299842834 s
2024-11-18:01:24:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.74817299842834 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013845373164671897,
 'clean_test_loss_avg_over_batch': 1.4373107064854016,
 'epoch': 69,
 'test_acc': 0.6784285714285714,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9293624422119487,
 'train_acc_clean_only': 0.9565264366680661,
 'train_asr_bd_only': 0.6848744165370082,
 'train_epoch_loss_avg_over_batch': 0.19851022739636356,
 'train_ra_bd_only': 0.50041675927984}
2024-11-18:01:24:49 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013845373164671897,
 'clean_test_loss_avg_over_batch': 1.4373107064854016,
 'epoch': 69,
 'test_acc': 0.6784285714285714,
 'test_asr': 0.9951785714285715,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9293624422119487,
 'train_acc_clean_only': 0.9565264366680661,
 'train_asr_bd_only': 0.6848744165370082,
 'train_epoch_loss_avg_over_batch': 0.19851022739636356,
 'train_ra_bd_only': 0.50041675927984}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.0007529258728 s
2024-11-18:01:29:08 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.0007529258728 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005341949620659844,
 'clean_test_loss_avg_over_batch': 1.444847309589386,
 'epoch': 70,
 'test_acc': 0.6671428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9309460570768137,
 'train_acc_clean_only': 0.9580174351122416,
 'train_asr_bd_only': 0.6872916203600801,
 'train_epoch_loss_avg_over_batch': 0.19469588987561073,
 'train_ra_bd_only': 0.4967770615692376}
2024-11-18:01:29:12 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005341949620659844,
 'clean_test_loss_avg_over_batch': 1.444847309589386,
 'epoch': 70,
 'test_acc': 0.6671428571428571,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9309460570768137,
 'train_acc_clean_only': 0.9580174351122416,
 'train_asr_bd_only': 0.6872916203600801,
 'train_epoch_loss_avg_over_batch': 0.19469588987561073,
 'train_ra_bd_only': 0.4967770615692376}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.5377049446106 s
2024-11-18:01:33:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.5377049446106 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04979842101139101,
 'clean_test_loss_avg_over_batch': 1.45478684685447,
 'epoch': 71,
 'test_acc': 0.6767142857142857,
 'test_asr': 0.985,
 'test_ra': 0.0125,
 'train_acc': 0.9317517558677099,
 'train_acc_clean_only': 0.9593549641766811,
 'train_asr_bd_only': 0.6832569126024732,
 'train_epoch_loss_avg_over_batch': 0.19299580236820035,
 'train_ra_bd_only': 0.5027094622759483}
2024-11-18:01:33:35 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.04979842101139101,
 'clean_test_loss_avg_over_batch': 1.45478684685447,
 'epoch': 71,
 'test_acc': 0.6767142857142857,
 'test_asr': 0.985,
 'test_ra': 0.0125,
 'train_acc': 0.9317517558677099,
 'train_acc_clean_only': 0.9593549641766811,
 'train_asr_bd_only': 0.6832569126024732,
 'train_epoch_loss_avg_over_batch': 0.19299580236820035,
 'train_ra_bd_only': 0.5027094622759483}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.5136694908142 s
2024-11-18:01:37:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.5136694908142 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.055896732227252374,
 'clean_test_loss_avg_over_batch': 1.40997616648674,
 'epoch': 72,
 'test_acc': 0.6835714285714286,
 'test_asr': 0.98375,
 'test_ra': 0.013571428571428571,
 'train_acc': 0.9337771159317212,
 'train_acc_clean_only': 0.9612617034478288,
 'train_asr_bd_only': 0.6864112466312894,
 'train_epoch_loss_avg_over_batch': 0.18897664858025642,
 'train_ra_bd_only': 0.5004028561109105}
2024-11-18:01:37:57 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.055896732227252374,
 'clean_test_loss_avg_over_batch': 1.40997616648674,
 'epoch': 72,
 'test_acc': 0.6835714285714286,
 'test_asr': 0.98375,
 'test_ra': 0.013571428571428571,
 'train_acc': 0.9337771159317212,
 'train_acc_clean_only': 0.9612617034478288,
 'train_asr_bd_only': 0.6864112466312894,
 'train_epoch_loss_avg_over_batch': 0.18897664858025642,
 'train_ra_bd_only': 0.5004028561109105}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.2304413318634 s
2024-11-18:01:42:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.2304413318634 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015154500301419334,
 'clean_test_loss_avg_over_batch': 1.4457129976966165,
 'epoch': 73,
 'test_acc': 0.6772857142857143,
 'test_asr': 0.9941071428571429,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.9345800364509246,
 'train_acc_clean_only': 0.9625773272253572,
 'train_asr_bd_only': 0.6825608536178727,
 'train_epoch_loss_avg_over_batch': 0.18655953095804576,
 'train_ra_bd_only': 0.5040291208180505}
2024-11-18:01:42:20 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.015154500301419334,
 'clean_test_loss_avg_over_batch': 1.4457129976966165,
 'epoch': 73,
 'test_acc': 0.6772857142857143,
 'test_asr': 0.9941071428571429,
 'test_ra': 0.004285714285714286,
 'train_acc': 0.9345800364509246,
 'train_acc_clean_only': 0.9625773272253572,
 'train_asr_bd_only': 0.6825608536178727,
 'train_epoch_loss_avg_over_batch': 0.18655953095804576,
 'train_ra_bd_only': 0.5040291208180505}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.75657868385315 s
2024-11-18:01:46:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.75657868385315 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005560807138945992,
 'clean_test_loss_avg_over_batch': 1.5189206957817079,
 'epoch': 74,
 'test_acc': 0.6748571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9363025649004267,
 'train_acc_clean_only': 0.9643484461676664,
 'train_asr_bd_only': 0.6839005417419086,
 'train_epoch_loss_avg_over_batch': 0.1825919116517346,
 'train_ra_bd_only': 0.5024308931796083}
2024-11-18:01:46:43 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005560807138945992,
 'clean_test_loss_avg_over_batch': 1.5189206957817079,
 'epoch': 74,
 'test_acc': 0.6748571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0016071428571428571,
 'train_acc': 0.9363025649004267,
 'train_acc_clean_only': 0.9643484461676664,
 'train_asr_bd_only': 0.6839005417419086,
 'train_epoch_loss_avg_over_batch': 0.1825919116517346,
 'train_ra_bd_only': 0.5024308931796083}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.5190734863281 s
2024-11-18:01:51:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.5190734863281 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01018915735767223,
 'clean_test_loss_avg_over_batch': 1.430295225165107,
 'epoch': 75,
 'test_acc': 0.6842857142857143,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0030357142857142857,
 'train_acc': 0.9382223506401138,
 'train_acc_clean_only': 0.9666236548517945,
 'train_asr_bd_only': 0.6826137689614936,
 'train_epoch_loss_avg_over_batch': 0.17854509897302215,
 'train_ra_bd_only': 0.5065844307384564}
2024-11-18:01:51:07 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.01018915735767223,
 'clean_test_loss_avg_over_batch': 1.430295225165107,
 'epoch': 75,
 'test_acc': 0.6842857142857143,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0030357142857142857,
 'train_acc': 0.9382223506401138,
 'train_acc_clean_only': 0.9666236548517945,
 'train_asr_bd_only': 0.6826137689614936,
 'train_epoch_loss_avg_over_batch': 0.17854509897302215,
 'train_ra_bd_only': 0.5065844307384564}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.2807586193085 s
2024-11-18:01:55:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.2807586193085 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.017962747904345055,
 'clean_test_loss_avg_over_batch': 1.4181302775036204,
 'epoch': 76,
 'test_acc': 0.68,
 'test_asr': 0.9933928571428572,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9390280494310099,
 'train_acc_clean_only': 0.9677629466821426,
 'train_asr_bd_only': 0.6804012002667259,
 'train_epoch_loss_avg_over_batch': 0.17621235970466015,
 'train_ra_bd_only': 0.5076683707490554}
2024-11-18:01:55:30 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.017962747904345055,
 'clean_test_loss_avg_over_batch': 1.4181302775036204,
 'epoch': 76,
 'test_acc': 0.68,
 'test_asr': 0.9933928571428572,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9390280494310099,
 'train_acc_clean_only': 0.9677629466821426,
 'train_asr_bd_only': 0.6804012002667259,
 'train_epoch_loss_avg_over_batch': 0.17621235970466015,
 'train_ra_bd_only': 0.5076683707490554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.15541315078735 s
2024-11-18:01:59:48 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.15541315078735 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013184209921746515,
 'clean_test_loss_avg_over_batch': 1.3854517297311262,
 'epoch': 77,
 'test_acc': 0.687,
 'test_asr': 0.99375,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9403866242887624,
 'train_acc_clean_only': 0.9689946410490702,
 'train_asr_bd_only': 0.6829017559457657,
 'train_epoch_loss_avg_over_batch': 0.17277320072447,
 'train_ra_bd_only': 0.5066125805734608}
2024-11-18:01:59:53 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.013184209921746515,
 'clean_test_loss_avg_over_batch': 1.3854517297311262,
 'epoch': 77,
 'test_acc': 0.687,
 'test_asr': 0.99375,
 'test_ra': 0.005357142857142857,
 'train_acc': 0.9403866242887624,
 'train_acc_clean_only': 0.9689946410490702,
 'train_asr_bd_only': 0.6829017559457657,
 'train_epoch_loss_avg_over_batch': 0.17277320072447,
 'train_ra_bd_only': 0.5066125805734608}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 256.65995168685913 s
2024-11-18:02:04:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 256.65995168685913 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0037016277849695393,
 'clean_test_loss_avg_over_batch': 1.4118886839259754,
 'epoch': 78,
 'test_acc': 0.6831428571428572,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9413534628378378,
 'train_acc_clean_only': 0.970479009937056,
 'train_asr_bd_only': 0.6792510486985026,
 'train_epoch_loss_avg_over_batch': 0.17004989757392008,
 'train_ra_bd_only': 0.5099313831708198}
2024-11-18:02:04:14 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0037016277849695393,
 'clean_test_loss_avg_over_batch': 1.4118886839259754,
 'epoch': 78,
 'test_acc': 0.6831428571428572,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9413534628378378,
 'train_acc_clean_only': 0.970479009937056,
 'train_asr_bd_only': 0.6792510486985026,
 'train_epoch_loss_avg_over_batch': 0.17004989757392008,
 'train_ra_bd_only': 0.5099313831708198}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.11915159225464 s
2024-11-18:02:08:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.11915159225464 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007146789211467628,
 'clean_test_loss_avg_over_batch': 1.3915956155820326,
 'epoch': 79,
 'test_acc': 0.6911428571428572,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0026785714285714286,
 'train_acc': 0.9432538006756757,
 'train_acc_clean_only': 0.9721244674939804,
 'train_asr_bd_only': 0.6834370485609512,
 'train_epoch_loss_avg_over_batch': 0.16654092314021177,
 'train_ra_bd_only': 0.5086120680075564}
2024-11-18:02:08:36 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007146789211467628,
 'clean_test_loss_avg_over_batch': 1.3915956155820326,
 'epoch': 79,
 'test_acc': 0.6911428571428572,
 'test_asr': 0.9969642857142857,
 'test_ra': 0.0026785714285714286,
 'train_acc': 0.9432538006756757,
 'train_acc_clean_only': 0.9721244674939804,
 'train_asr_bd_only': 0.6834370485609512,
 'train_epoch_loss_avg_over_batch': 0.16654092314021177,
 'train_ra_bd_only': 0.5086120680075564}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 256.25332283973694 s
2024-11-18:02:12:53 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 256.25332283973694 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.030954912019131534,
 'clean_test_loss_avg_over_batch': 1.5179429411888123,
 'epoch': 80,
 'test_acc': 0.6815714285714286,
 'test_asr': 0.9891071428571429,
 'test_ra': 0.00875,
 'train_acc': 0.9449235419630156,
 'train_acc_clean_only': 0.9738161387911342,
 'train_asr_bd_only': 0.6849094343815979,
 'train_epoch_loss_avg_over_batch': 0.16199909270890747,
 'train_ra_bd_only': 0.5063062562506945}
2024-11-18:02:12:57 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.030954912019131534,
 'clean_test_loss_avg_over_batch': 1.5179429411888123,
 'epoch': 80,
 'test_acc': 0.6815714285714286,
 'test_asr': 0.9891071428571429,
 'test_ra': 0.00875,
 'train_acc': 0.9449235419630156,
 'train_acc_clean_only': 0.9738161387911342,
 'train_asr_bd_only': 0.6849094343815979,
 'train_epoch_loss_avg_over_batch': 0.16199909270890747,
 'train_ra_bd_only': 0.5063062562506945}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 256.805650472641 s
2024-11-18:02:17:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 256.805650472641 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007211355181590823,
 'clean_test_loss_avg_over_batch': 1.4945620769804173,
 'epoch': 81,
 'test_acc': 0.6825714285714286,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9464377000355618,
 'train_acc_clean_only': 0.975662309919677,
 'train_asr_bd_only': 0.6834194587986887,
 'train_epoch_loss_avg_over_batch': 0.1589845797023173,
 'train_ra_bd_only': 0.5081402455964883}
2024-11-18:02:17:19 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.007211355181590823,
 'clean_test_loss_avg_over_batch': 1.4945620769804173,
 'epoch': 81,
 'test_acc': 0.6825714285714286,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9464377000355618,
 'train_acc_clean_only': 0.975662309919677,
 'train_asr_bd_only': 0.6834194587986887,
 'train_epoch_loss_avg_over_batch': 0.1589845797023173,
 'train_ra_bd_only': 0.5081402455964883}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.6826946735382 s
2024-11-18:02:21:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.6826946735382 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010672646990728523,
 'clean_test_loss_avg_over_batch': 1.482089962200685,
 'epoch': 82,
 'test_acc': 0.6925714285714286,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.003928571428571429,
 'train_acc': 0.9477490442745377,
 'train_acc_clean_only': 0.9769123199120822,
 'train_asr_bd_only': 0.6853071089257438,
 'train_epoch_loss_avg_over_batch': 0.1560417407869254,
 'train_ra_bd_only': 0.5080423368614051}
2024-11-18:02:21:41 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010672646990728523,
 'clean_test_loss_avg_over_batch': 1.482089962200685,
 'epoch': 82,
 'test_acc': 0.6925714285714286,
 'test_asr': 0.9955357142857143,
 'test_ra': 0.003928571428571429,
 'train_acc': 0.9477490442745377,
 'train_acc_clean_only': 0.9769123199120822,
 'train_asr_bd_only': 0.6853071089257438,
 'train_epoch_loss_avg_over_batch': 0.1560417407869254,
 'train_ra_bd_only': 0.5080423368614051}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.1987466812134 s
2024-11-18:02:26:00 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.1987466812134 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00499374274328478,
 'clean_test_loss_avg_over_batch': 1.5177468825470317,
 'epoch': 83,
 'test_acc': 0.6897142857142857,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9488409050497866,
 'train_acc_clean_only': 0.9782952293340084,
 'train_asr_bd_only': 0.6837879882215678,
 'train_epoch_loss_avg_over_batch': 0.15256803798201796,
 'train_ra_bd_only': 0.5096949830546141}
2024-11-18:02:26:04 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00499374274328478,
 'clean_test_loss_avg_over_batch': 1.5177468825470317,
 'epoch': 83,
 'test_acc': 0.6897142857142857,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9488409050497866,
 'train_acc_clean_only': 0.9782952293340084,
 'train_asr_bd_only': 0.6837879882215678,
 'train_epoch_loss_avg_over_batch': 0.15256803798201796,
 'train_ra_bd_only': 0.5096949830546141}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.61247181892395 s
2024-11-18:02:30:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.61247181892395 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00418434381770732,
 'clean_test_loss_avg_over_batch': 1.4761791689829393,
 'epoch': 84,
 'test_acc': 0.6938571428571428,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9495965949502134,
 'train_acc_clean_only': 0.9792588248005063,
 'train_asr_bd_only': 0.6826150982189992,
 'train_epoch_loss_avg_over_batch': 0.15056542177839605,
 'train_ra_bd_only': 0.5096551915756717}
2024-11-18:02:30:27 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00418434381770732,
 'clean_test_loss_avg_over_batch': 1.4761791689829393,
 'epoch': 84,
 'test_acc': 0.6938571428571428,
 'test_asr': 0.9991071428571429,
 'test_ra': 0.0007142857142857143,
 'train_acc': 0.9495965949502134,
 'train_acc_clean_only': 0.9792588248005063,
 'train_asr_bd_only': 0.6826150982189992,
 'train_epoch_loss_avg_over_batch': 0.15056542177839605,
 'train_ra_bd_only': 0.5096551915756717}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.3208978176117 s
2024-11-18:02:34:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.3208978176117 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025116856500972062,
 'clean_test_loss_avg_over_batch': 1.4963945722038097,
 'epoch': 85,
 'test_acc': 0.6937142857142857,
 'test_asr': 0.9903571428571428,
 'test_ra': 0.0075,
 'train_acc': 0.9511440922830725,
 'train_acc_clean_only': 0.9808668862539783,
 'train_asr_bd_only': 0.6836505070148632,
 'train_epoch_loss_avg_over_batch': 0.14736333333756008,
 'train_ra_bd_only': 0.5097652451729406}
2024-11-18:02:34:50 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.025116856500972062,
 'clean_test_loss_avg_over_batch': 1.4963945722038097,
 'epoch': 85,
 'test_acc': 0.6937142857142857,
 'test_asr': 0.9903571428571428,
 'test_ra': 0.0075,
 'train_acc': 0.9511440922830725,
 'train_acc_clean_only': 0.9808668862539783,
 'train_asr_bd_only': 0.6836505070148632,
 'train_epoch_loss_avg_over_batch': 0.14736333333756008,
 'train_ra_bd_only': 0.5097652451729406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.9222023487091 s
2024-11-18:02:39:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.9222023487091 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0032297336219926365,
 'clean_test_loss_avg_over_batch': 1.5117702681909908,
 'epoch': 86,
 'test_acc': 0.6834285714285714,
 'test_asr': 0.9996428571428572,
 'test_ra': 0.00035714285714285714,
 'train_acc': 0.9521581614509246,
 'train_acc_clean_only': 0.9819938013977725,
 'train_asr_bd_only': 0.6836241386974883,
 'train_epoch_loss_avg_over_batch': 0.14470343353759343,
 'train_ra_bd_only': 0.5104745498999778}
2024-11-18:02:39:13 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0032297336219926365,
 'clean_test_loss_avg_over_batch': 1.5117702681909908,
 'epoch': 86,
 'test_acc': 0.6834285714285714,
 'test_asr': 0.9996428571428572,
 'test_ra': 0.00035714285714285714,
 'train_acc': 0.9521581614509246,
 'train_acc_clean_only': 0.9819938013977725,
 'train_asr_bd_only': 0.6836241386974883,
 'train_epoch_loss_avg_over_batch': 0.14470343353759343,
 'train_ra_bd_only': 0.5104745498999778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.56850004196167 s
2024-11-18:02:43:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.56850004196167 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005082859530706297,
 'clean_test_loss_avg_over_batch': 1.5071678394621069,
 'epoch': 87,
 'test_acc': 0.6904285714285714,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9533917140825036,
 'train_acc_clean_only': 0.9833242782703183,
 'train_asr_bd_only': 0.6839853300733496,
 'train_epoch_loss_avg_over_batch': 0.1418375257325821,
 'train_ra_bd_only': 0.5109468770837964}
2024-11-18:02:43:38 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005082859530706297,
 'clean_test_loss_avg_over_batch': 1.5071678394621069,
 'epoch': 87,
 'test_acc': 0.6904285714285714,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9533917140825036,
 'train_acc_clean_only': 0.9833242782703183,
 'train_asr_bd_only': 0.6839853300733496,
 'train_epoch_loss_avg_over_batch': 0.1418375257325821,
 'train_ra_bd_only': 0.5109468770837964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.97326278686523 s
2024-11-18:02:47:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.97326278686523 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.003371532217980447,
 'clean_test_loss_avg_over_batch': 1.5083545690233058,
 'epoch': 88,
 'test_acc': 0.6917142857142857,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.9544113397937412,
 'train_acc_clean_only': 0.9845839455715115,
 'train_asr_bd_only': 0.682810936978993,
 'train_epoch_loss_avg_over_batch': 0.13914323386843522,
 'train_ra_bd_only': 0.5132822051795043}
2024-11-18:02:48:05 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.003371532217980447,
 'clean_test_loss_avg_over_batch': 1.5083545690233058,
 'epoch': 88,
 'test_acc': 0.6917142857142857,
 'test_asr': 0.9998214285714285,
 'test_ra': 0.00017857142857142857,
 'train_acc': 0.9544113397937412,
 'train_acc_clean_only': 0.9845839455715115,
 'train_asr_bd_only': 0.682810936978993,
 'train_epoch_loss_avg_over_batch': 0.13914323386843522,
 'train_ra_bd_only': 0.5132822051795043}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 262.1893501281738 s
2024-11-18:02:52:27 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 262.1893501281738 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005141392691505395,
 'clean_test_loss_avg_over_batch': 1.5153538758104497,
 'epoch': 89,
 'test_acc': 0.6952857142857143,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9550031116642959,
 'train_acc_clean_only': 0.9851671436024239,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.13709980041546427,
 'train_ra_bd_only': 0.5125996721584752}
2024-11-18:02:52:31 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005141392691505395,
 'clean_test_loss_avg_over_batch': 1.5153538758104497,
 'epoch': 89,
 'test_acc': 0.6952857142857143,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9550031116642959,
 'train_acc_clean_only': 0.9851671436024239,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.13709980041546427,
 'train_ra_bd_only': 0.5125996721584752}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.05055952072144 s
2024-11-18:02:56:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.05055952072144 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0046287892460399735,
 'clean_test_loss_avg_over_batch': 1.5422791109843688,
 'epoch': 90,
 'test_acc': 0.6898571428571428,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9562033250355618,
 'train_acc_clean_only': 0.9863833649233504,
 'train_asr_bd_only': 0.6845863199422126,
 'train_epoch_loss_avg_over_batch': 0.13493659703132524,
 'train_ra_bd_only': 0.5117241762515975}
2024-11-18:02:56:55 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.0046287892460399735,
 'clean_test_loss_avg_over_batch': 1.5422791109843688,
 'epoch': 90,
 'test_acc': 0.6898571428571428,
 'test_asr': 0.99875,
 'test_ra': 0.00125,
 'train_acc': 0.9562033250355618,
 'train_acc_clean_only': 0.9863833649233504,
 'train_asr_bd_only': 0.6845863199422126,
 'train_epoch_loss_avg_over_batch': 0.13493659703132524,
 'train_ra_bd_only': 0.5117241762515975}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.5144090652466 s
2024-11-18:03:01:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.5144090652466 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00880769268736582,
 'clean_test_loss_avg_over_batch': 1.571345576914874,
 'epoch': 91,
 'test_acc': 0.688,
 'test_asr': 0.9964285714285714,
 'test_ra': 0.002857142857142857,
 'train_acc': 0.9572618465504978,
 'train_acc_clean_only': 0.987288083272624,
 'train_asr_bd_only': 0.6869789929976658,
 'train_epoch_loss_avg_over_batch': 0.13180643217810356,
 'train_ra_bd_only': 0.5082805379570968}
2024-11-18:03:01:18 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00880769268736582,
 'clean_test_loss_avg_over_batch': 1.571345576914874,
 'epoch': 91,
 'test_acc': 0.688,
 'test_asr': 0.9964285714285714,
 'test_ra': 0.002857142857142857,
 'train_acc': 0.9572618465504978,
 'train_acc_clean_only': 0.987288083272624,
 'train_asr_bd_only': 0.6869789929976658,
 'train_epoch_loss_avg_over_batch': 0.13180643217810356,
 'train_ra_bd_only': 0.5082805379570968}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.35240268707275 s
2024-11-18:03:05:35 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.35240268707275 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00576904332410777,
 'clean_test_loss_avg_over_batch': 1.564117845621976,
 'epoch': 92,
 'test_acc': 0.6898571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9569034495021337,
 'train_acc_clean_only': 0.9877910243191682,
 'train_asr_bd_only': 0.6789187086736679,
 'train_epoch_loss_avg_over_batch': 0.13270713460193165,
 'train_ra_bd_only': 0.5181974773573373}
2024-11-18:03:05:40 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.00576904332410777,
 'clean_test_loss_avg_over_batch': 1.564117845621976,
 'epoch': 92,
 'test_acc': 0.6898571428571428,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9569034495021337,
 'train_acc_clean_only': 0.9877910243191682,
 'train_asr_bd_only': 0.6789187086736679,
 'train_epoch_loss_avg_over_batch': 0.13270713460193165,
 'train_ra_bd_only': 0.5181974773573373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.3473334312439 s
2024-11-18:03:09:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.3473334312439 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005723064847354015,
 'clean_test_loss_avg_over_batch': 1.578278913823041,
 'epoch': 93,
 'test_acc': 0.6924285714285714,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9581897892958748,
 'train_acc_clean_only': 0.9887604377286268,
 'train_asr_bd_only': 0.6830318690783808,
 'train_epoch_loss_avg_over_batch': 0.12995564364887785,
 'train_ra_bd_only': 0.5138506848934455}
2024-11-18:03:10:03 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005723064847354015,
 'clean_test_loss_avg_over_batch': 1.578278913823041,
 'epoch': 93,
 'test_acc': 0.6924285714285714,
 'test_asr': 0.9980357142857142,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9581897892958748,
 'train_acc_clean_only': 0.9887604377286268,
 'train_asr_bd_only': 0.6830318690783808,
 'train_epoch_loss_avg_over_batch': 0.12995564364887785,
 'train_ra_bd_only': 0.5138506848934455}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.3324773311615 s
2024-11-18:03:14:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.3324773311615 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.012714090557313863,
 'clean_test_loss_avg_over_batch': 1.5786212146282197,
 'epoch': 94,
 'test_acc': 0.6908571428571428,
 'test_asr': 0.9948214285714285,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9582703591749644,
 'train_acc_clean_only': 0.9892172055491415,
 'train_asr_bd_only': 0.6797521809190421,
 'train_epoch_loss_avg_over_batch': 0.12954547878481967,
 'train_ra_bd_only': 0.5166416624993054}
2024-11-18:03:14:25 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.012714090557313863,
 'clean_test_loss_avg_over_batch': 1.5786212146282197,
 'epoch': 94,
 'test_acc': 0.6908571428571428,
 'test_asr': 0.9948214285714285,
 'test_ra': 0.004107142857142857,
 'train_acc': 0.9582703591749644,
 'train_acc_clean_only': 0.9892172055491415,
 'train_asr_bd_only': 0.6797521809190421,
 'train_epoch_loss_avg_over_batch': 0.12954547878481967,
 'train_ra_bd_only': 0.5166416624993054}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 257.9574568271637 s
2024-11-18:03:18:43 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 257.9574568271637 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010330577804283663,
 'clean_test_loss_avg_over_batch': 1.5546601975506003,
 'epoch': 95,
 'test_acc': 0.6922857142857143,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0032142857142857142,
 'train_acc': 0.9591482930298719,
 'train_acc_clean_only': 0.989652564478538,
 'train_asr_bd_only': 0.6845878136200717,
 'train_epoch_loss_avg_over_batch': 0.12756514586084344,
 'train_ra_bd_only': 0.5124614486955072}
2024-11-18:03:18:48 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.010330577804283663,
 'clean_test_loss_avg_over_batch': 1.5546601975506003,
 'epoch': 95,
 'test_acc': 0.6922857142857143,
 'test_asr': 0.9960714285714286,
 'test_ra': 0.0032142857142857142,
 'train_acc': 0.9591482930298719,
 'train_acc_clean_only': 0.989652564478538,
 'train_asr_bd_only': 0.6845878136200717,
 'train_epoch_loss_avg_over_batch': 0.12756514586084344,
 'train_ra_bd_only': 0.5124614486955072}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.17707228660583 s
2024-11-18:03:23:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.17707228660583 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005820373642067848,
 'clean_test_loss_avg_over_batch': 1.5736727611585097,
 'epoch': 96,
 'test_acc': 0.69,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9598373044096729,
 'train_acc_clean_only': 0.9901371233121978,
 'train_asr_bd_only': 0.6871423014946936,
 'train_epoch_loss_avg_over_batch': 0.12597708243831654,
 'train_ra_bd_only': 0.5097516252708785}
2024-11-18:03:23:11 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.005820373642067848,
 'clean_test_loss_avg_over_batch': 1.5736727611585097,
 'epoch': 96,
 'test_acc': 0.69,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.0019642857142857144,
 'train_acc': 0.9598373044096729,
 'train_acc_clean_only': 0.9901371233121978,
 'train_asr_bd_only': 0.6871423014946936,
 'train_epoch_loss_avg_over_batch': 0.12597708243831654,
 'train_ra_bd_only': 0.5097516252708785}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 259.65176939964294 s
2024-11-18:03:27:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 259.65176939964294 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008034496516550214,
 'clean_test_loss_avg_over_batch': 1.5905301508578387,
 'epoch': 97,
 'test_acc': 0.691,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9599484352773826,
 'train_acc_clean_only': 0.9903779071562193,
 'train_asr_bd_only': 0.6860865699838862,
 'train_epoch_loss_avg_over_batch': 0.12548278215716183,
 'train_ra_bd_only': 0.5106684447407901}
2024-11-18:03:27:35 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008034496516550214,
 'clean_test_loss_avg_over_batch': 1.5905301508578387,
 'epoch': 97,
 'test_acc': 0.691,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0025,
 'train_acc': 0.9599484352773826,
 'train_acc_clean_only': 0.9903779071562193,
 'train_asr_bd_only': 0.6860865699838862,
 'train_epoch_loss_avg_over_batch': 0.12548278215716183,
 'train_ra_bd_only': 0.5106684447407901}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 258.74935126304626 s
2024-11-18:03:31:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 258.74935126304626 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008340558530604043,
 'clean_test_loss_avg_over_batch': 1.5791023164987563,
 'epoch': 98,
 'test_acc': 0.6904285714285714,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9598734219416786,
 'train_acc_clean_only': 0.9905785894432045,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.12568315631970975,
 'train_ra_bd_only': 0.5139332648014892}
2024-11-18:03:31:58 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.008340558530604043,
 'clean_test_loss_avg_over_batch': 1.5791023164987563,
 'epoch': 98,
 'test_acc': 0.6904285714285714,
 'test_asr': 0.9973214285714286,
 'test_ra': 0.0023214285714285715,
 'train_acc': 0.9598734219416786,
 'train_acc_clean_only': 0.9905785894432045,
 'train_asr_bd_only': 0.6835217959047593,
 'train_epoch_loss_avg_over_batch': 0.12568315631970975,
 'train_ra_bd_only': 0.5139332648014892}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 256.5709183216095 s
2024-11-18:03:36:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 256.5709183216095 s
INFO:root:{'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.004301056841954546,
 'clean_test_loss_avg_over_batch': 1.567738943479278,
 'epoch': 99,
 'test_acc': 0.6895714285714286,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9601429142958748,
 'train_acc_clean_only': 0.9906372706393698,
 'train_asr_bd_only': 0.6856801511446988,
 'train_epoch_loss_avg_over_batch': 0.12500884285617944,
 'train_ra_bd_only': 0.511419204267615}
2024-11-18:03:36:20 [INFO    ] [trainer_cls.py:65] {'batch': 2812,
 'bd_test_loss_avg_over_batch': 0.004301056841954546,
 'clean_test_loss_avg_over_batch': 1.567738943479278,
 'epoch': 99,
 'test_acc': 0.6895714285714286,
 'test_asr': 0.9989285714285714,
 'test_ra': 0.0010714285714285715,
 'train_acc': 0.9601429142958748,
 'train_acc_clean_only': 0.9906372706393698,
 'train_asr_bd_only': 0.6856801511446988,
 'train_epoch_loss_avg_over_batch': 0.12500884285617944,
 'train_ra_bd_only': 0.511419204267615}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2024-11-18:03:36:20 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/badnet_attack_efficientnet_ffpp_5classes/attack_result.pt
INFO:root:Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_5classes
2024-11-18:03:36:21 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_5classes
