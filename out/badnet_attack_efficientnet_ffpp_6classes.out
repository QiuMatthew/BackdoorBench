/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_6classes',
 'save_path': './record/badnet_attack_efficientnet_ffpp_6classes',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_6classes'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2025-02-26:12:53:02 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'badnet_attack_efficientnet_ffpp_6classes',
 'save_path': './record/badnet_attack_efficientnet_ffpp_6classes',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'badnet_attack_efficientnet_ffpp_6classes'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': None,
 'last 3 log': 'commit 961607dd40bf8c5d1b91c6ea6e56ad823c0be6cd\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Wed Feb 26 12:51:43 2025 +0900\n'
               '\n'
               '    fix typo\n'
               '\n'
               'commit a2a643175098b4b1e4c3dbe256f2dac990a93f94\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Wed Feb 26 12:48:40 2025 +0900\n'
               '\n'
               '    fix typo\n'
               '\n'
               'commit ffdc826b20f9bcd6c1ccfa09298defc7226be7ed\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Wed Feb 26 12:46:36 2025 +0900\n'
               '\n'
               '    support ffpp dadaset and ignore .DS_Store',
 'status': 'On branch nad\n'
           "Your branch is up to date with 'origin/nad'.\n"
           '\n'
           'Changes not staged for commit:\n'
           '  (use "git add <file>..." to update what will be committed)\n'
           '  (use "git restore <file>..." to discard changes in working '
           'directory)\n'
           '\tmodified:   out/badnet_attack_efficientnet_ffpp_6classes.out\n'
           '\n'
           'no changes added to commit (use "git add" and/or "git commit -a")'}
INFO:root:stage1 start
2025-02-26:12:53:02 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2025-02-26:12:53:02 [WARNING ] [dataset_and_transform_generate.py:356] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:43200.0,real pratio:0.1
2025-02-26:12:56:29 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:43200.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2025-02-26:12:56:30 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/432000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 386/432000 [00:00<01:53, 3818.14it/s]prepro_backdoor:   0%|          | 1031/432000 [00:00<01:21, 5312.98it/s]prepro_backdoor:   0%|          | 1570/432000 [00:00<01:20, 5339.13it/s]prepro_backdoor:   1%|          | 2253/432000 [00:00<01:12, 5888.71it/s]prepro_backdoor:   1%|          | 2842/432000 [00:00<01:15, 5678.79it/s]prepro_backdoor:   1%|          | 3415/432000 [00:00<01:15, 5672.67it/s]prepro_backdoor:   1%|          | 4056/432000 [00:00<01:12, 5889.23it/s]prepro_backdoor:   1%|          | 4670/432000 [00:00<01:11, 5948.79it/s]prepro_backdoor:   1%|          | 5267/432000 [00:00<01:11, 5927.97it/s]prepro_backdoor:   1%|▏         | 5878/432000 [00:01<01:11, 5981.14it/s]prepro_backdoor:   2%|▏         | 6526/432000 [00:01<01:09, 6117.42it/s]prepro_backdoor:   2%|▏         | 7139/432000 [00:01<01:12, 5822.64it/s]prepro_backdoor:   2%|▏         | 7725/432000 [00:01<01:14, 5703.00it/s]prepro_backdoor:   2%|▏         | 8298/432000 [00:01<01:16, 5551.00it/s]prepro_backdoor:   2%|▏         | 8856/432000 [00:01<01:16, 5554.20it/s]prepro_backdoor:   2%|▏         | 9515/432000 [00:01<01:12, 5832.83it/s]prepro_backdoor:   2%|▏         | 10208/432000 [00:01<01:08, 6148.65it/s]prepro_backdoor:   3%|▎         | 10827/432000 [00:01<01:08, 6127.56it/s]prepro_backdoor:   3%|▎         | 11462/432000 [00:01<01:08, 6178.73it/s]prepro_backdoor:   3%|▎         | 12100/432000 [00:02<01:07, 6209.39it/s]prepro_backdoor:   3%|▎         | 12832/432000 [00:02<01:04, 6509.87it/s]prepro_backdoor:   3%|▎         | 13484/432000 [00:02<01:06, 6311.38it/s]prepro_backdoor:   3%|▎         | 14211/432000 [00:02<01:03, 6569.71it/s]prepro_backdoor:   3%|▎         | 14905/432000 [00:02<01:02, 6670.27it/s]prepro_backdoor:   4%|▎         | 15574/432000 [00:02<01:03, 6513.34it/s]prepro_backdoor:   4%|▍         | 16227/432000 [00:02<01:07, 6132.33it/s]prepro_backdoor:   4%|▍         | 16915/432000 [00:02<01:05, 6311.83it/s]prepro_backdoor:   4%|▍         | 17551/432000 [00:02<01:09, 5953.20it/s]prepro_backdoor:   4%|▍         | 18153/432000 [00:03<01:11, 5770.62it/s]prepro_backdoor:   4%|▍         | 18842/432000 [00:03<01:08, 6056.03it/s]prepro_backdoor:   5%|▍         | 19544/432000 [00:03<01:05, 6323.11it/s]prepro_backdoor:   5%|▍         | 20182/432000 [00:03<01:05, 6246.99it/s]prepro_backdoor:   5%|▍         | 20811/432000 [00:03<01:09, 5955.75it/s]prepro_backdoor:   5%|▍         | 21412/432000 [00:03<01:10, 5792.68it/s]prepro_backdoor:   5%|▌         | 22071/432000 [00:03<01:08, 6012.21it/s]prepro_backdoor:   5%|▌         | 22679/432000 [00:03<01:08, 5962.21it/s]prepro_backdoor:   5%|▌         | 23278/432000 [00:03<01:10, 5766.83it/s]prepro_backdoor:   6%|▌         | 23996/432000 [00:03<01:06, 6149.23it/s]prepro_backdoor:   6%|▌         | 24664/432000 [00:04<01:04, 6278.46it/s]prepro_backdoor:   6%|▌         | 25295/432000 [00:04<01:07, 6026.04it/s]prepro_backdoor:   6%|▌         | 26036/432000 [00:04<01:04, 6280.21it/s]prepro_backdoor:   6%|▌         | 26679/432000 [00:04<01:04, 6322.18it/s]prepro_backdoor:   6%|▋         | 27314/432000 [00:04<01:04, 6296.92it/s]prepro_backdoor:   6%|▋         | 27962/432000 [00:04<01:03, 6348.66it/s]prepro_backdoor:   7%|▋         | 28598/432000 [00:04<01:09, 5802.35it/s]prepro_backdoor:   7%|▋         | 29251/432000 [00:04<01:07, 5981.86it/s]prepro_backdoor:   7%|▋         | 29862/432000 [00:04<01:07, 5991.42it/s]prepro_backdoor:   7%|▋         | 30467/432000 [00:05<01:08, 5834.80it/s]prepro_backdoor:   7%|▋         | 31114/432000 [00:05<01:06, 5989.14it/s]prepro_backdoor:   7%|▋         | 31717/432000 [00:05<01:07, 5940.78it/s]prepro_backdoor:   7%|▋         | 32314/432000 [00:05<01:09, 5787.19it/s]prepro_backdoor:   8%|▊         | 32895/432000 [00:05<01:12, 5487.98it/s]prepro_backdoor:   8%|▊         | 33531/432000 [00:05<01:09, 5715.58it/s]prepro_backdoor:   8%|▊         | 34107/432000 [00:05<01:12, 5501.47it/s]prepro_backdoor:   8%|▊         | 34753/432000 [00:05<01:09, 5750.69it/s]prepro_backdoor:   8%|▊         | 35333/432000 [00:05<01:09, 5720.17it/s]prepro_backdoor:   8%|▊         | 35919/432000 [00:06<01:08, 5747.07it/s]prepro_backdoor:   8%|▊         | 36528/432000 [00:06<01:07, 5842.65it/s]prepro_backdoor:   9%|▊         | 37114/432000 [00:06<01:10, 5608.08it/s]prepro_backdoor:   9%|▊         | 37678/432000 [00:06<01:13, 5366.57it/s]prepro_backdoor:   9%|▉         | 38219/432000 [00:06<01:16, 5173.68it/s]prepro_backdoor:   9%|▉         | 38751/432000 [00:06<01:15, 5190.99it/s]prepro_backdoor:   9%|▉         | 39385/432000 [00:06<01:11, 5511.06it/s]prepro_backdoor:   9%|▉         | 40005/432000 [00:06<01:13, 5328.54it/s]prepro_backdoor:   9%|▉         | 40719/432000 [00:06<01:07, 5813.61it/s]prepro_backdoor:  10%|▉         | 41321/432000 [00:06<01:06, 5848.01it/s]prepro_backdoor:  10%|▉         | 41994/432000 [00:07<01:04, 6076.84it/s]prepro_backdoor:  10%|▉         | 42674/432000 [00:07<01:02, 6260.46it/s]prepro_backdoor:  10%|█         | 43304/432000 [00:07<01:03, 6124.18it/s]prepro_backdoor:  10%|█         | 43920/432000 [00:07<01:06, 5822.02it/s]prepro_backdoor:  10%|█         | 44541/432000 [00:07<01:05, 5906.15it/s]prepro_backdoor:  10%|█         | 45136/432000 [00:07<01:09, 5547.03it/s]prepro_backdoor:  11%|█         | 45697/432000 [00:07<01:12, 5320.08it/s]prepro_backdoor:  11%|█         | 46245/432000 [00:07<01:11, 5361.65it/s]prepro_backdoor:  11%|█         | 46956/432000 [00:07<01:05, 5843.29it/s]prepro_backdoor:  11%|█         | 47546/432000 [00:08<01:08, 5649.10it/s]prepro_backdoor:  11%|█         | 48128/432000 [00:08<01:07, 5686.68it/s]prepro_backdoor:  11%|█▏        | 48701/432000 [00:08<01:08, 5582.28it/s]prepro_backdoor:  11%|█▏        | 49262/432000 [00:08<01:13, 5216.54it/s]prepro_backdoor:  12%|█▏        | 49898/432000 [00:08<01:09, 5520.04it/s]prepro_backdoor:  12%|█▏        | 50457/432000 [00:08<01:09, 5483.58it/s]prepro_backdoor:  12%|█▏        | 51039/432000 [00:08<01:08, 5562.31it/s]prepro_backdoor:  12%|█▏        | 51740/432000 [00:08<01:03, 5968.39it/s]prepro_backdoor:  12%|█▏        | 52341/432000 [00:08<01:07, 5595.96it/s]prepro_backdoor:  12%|█▏        | 52970/432000 [00:09<01:05, 5783.89it/s]prepro_backdoor:  12%|█▏        | 53599/432000 [00:09<01:03, 5914.80it/s]prepro_backdoor:  13%|█▎        | 54231/432000 [00:09<01:02, 6005.58it/s]prepro_backdoor:  13%|█▎        | 54953/432000 [00:09<00:59, 6341.50it/s]prepro_backdoor:  13%|█▎        | 55591/432000 [00:09<00:59, 6351.42it/s]prepro_backdoor:  13%|█▎        | 56301/432000 [00:09<00:57, 6558.46it/s]prepro_backdoor:  13%|█▎        | 56959/432000 [00:09<00:57, 6503.35it/s]prepro_backdoor:  13%|█▎        | 57611/432000 [00:09<01:01, 6127.19it/s]prepro_backdoor:  13%|█▎        | 58229/432000 [00:09<01:03, 5875.01it/s]prepro_backdoor:  14%|█▎        | 58904/432000 [00:09<01:01, 6094.35it/s]prepro_backdoor:  14%|█▍        | 59583/432000 [00:10<00:59, 6280.34it/s]prepro_backdoor:  14%|█▍        | 60216/432000 [00:10<01:00, 6193.09it/s]prepro_backdoor:  14%|█▍        | 60839/432000 [00:10<01:01, 6006.93it/s]prepro_backdoor:  14%|█▍        | 61528/432000 [00:10<00:59, 6240.99it/s]prepro_backdoor:  14%|█▍        | 62194/432000 [00:10<00:58, 6336.82it/s]prepro_backdoor:  15%|█▍        | 62830/432000 [00:10<00:59, 6160.42it/s]prepro_backdoor:  15%|█▍        | 63449/432000 [00:10<01:02, 5891.50it/s]prepro_backdoor:  15%|█▍        | 64042/432000 [00:10<01:02, 5888.83it/s]prepro_backdoor:  15%|█▍        | 64634/432000 [00:10<01:02, 5852.93it/s]prepro_backdoor:  15%|█▌        | 65221/432000 [00:11<01:14, 4942.36it/s]prepro_backdoor:  15%|█▌        | 65814/432000 [00:11<01:10, 5188.43it/s]prepro_backdoor:  15%|█▌        | 66387/432000 [00:11<01:08, 5329.83it/s]prepro_backdoor:  15%|█▌        | 66936/432000 [00:11<01:08, 5346.58it/s]prepro_backdoor:  16%|█▌        | 67527/432000 [00:11<01:06, 5501.57it/s]prepro_backdoor:  16%|█▌        | 68182/432000 [00:11<01:02, 5802.06it/s]prepro_backdoor:  16%|█▌        | 68770/432000 [00:11<01:03, 5722.63it/s]prepro_backdoor:  16%|█▌        | 69366/432000 [00:11<01:02, 5775.99it/s]prepro_backdoor:  16%|█▌        | 69975/432000 [00:11<01:01, 5865.45it/s]prepro_backdoor:  16%|█▋        | 70573/432000 [00:12<01:01, 5892.41it/s]prepro_backdoor:  16%|█▋        | 71244/432000 [00:12<00:58, 6119.01it/s]prepro_backdoor:  17%|█▋        | 71971/432000 [00:12<00:55, 6447.04it/s]prepro_backdoor:  17%|█▋        | 72641/432000 [00:12<00:55, 6513.90it/s]prepro_backdoor:  17%|█▋        | 73294/432000 [00:12<00:55, 6516.11it/s]prepro_backdoor:  17%|█▋        | 73947/432000 [00:12<00:55, 6408.84it/s]prepro_backdoor:  17%|█▋        | 74589/432000 [00:12<00:57, 6210.56it/s]prepro_backdoor:  17%|█▋        | 75212/432000 [00:12<01:01, 5829.46it/s]prepro_backdoor:  18%|█▊        | 75816/432000 [00:12<01:00, 5884.36it/s]prepro_backdoor:  18%|█▊        | 76427/432000 [00:12<00:59, 5936.73it/s]prepro_backdoor:  18%|█▊        | 77024/432000 [00:13<01:02, 5675.19it/s]prepro_backdoor:  18%|█▊        | 77730/432000 [00:13<00:58, 6044.03it/s]prepro_backdoor:  18%|█▊        | 78339/432000 [00:13<01:01, 5742.41it/s]prepro_backdoor:  18%|█▊        | 79024/432000 [00:13<00:58, 6045.51it/s]prepro_backdoor:  18%|█▊        | 79635/432000 [00:13<00:59, 5874.39it/s]prepro_backdoor:  19%|█▊        | 80227/432000 [00:13<01:00, 5780.17it/s]prepro_backdoor:  19%|█▊        | 80809/432000 [00:13<01:01, 5739.31it/s]prepro_backdoor:  19%|█▉        | 81385/432000 [00:13<01:01, 5723.89it/s]prepro_backdoor:  19%|█▉        | 81983/432000 [00:13<01:00, 5776.86it/s]prepro_backdoor:  19%|█▉        | 82577/432000 [00:14<01:00, 5803.54it/s]prepro_backdoor:  19%|█▉        | 83256/432000 [00:14<00:57, 6067.74it/s]prepro_backdoor:  19%|█▉        | 83864/432000 [00:14<01:00, 5785.58it/s]prepro_backdoor:  20%|█▉        | 84517/432000 [00:14<00:58, 5977.25it/s]prepro_backdoor:  20%|█▉        | 85278/432000 [00:14<00:53, 6422.44it/s]prepro_backdoor:  20%|█▉        | 85924/432000 [00:14<00:54, 6398.65it/s]prepro_backdoor:  20%|██        | 86567/432000 [00:14<00:55, 6274.29it/s]prepro_backdoor:  20%|██        | 87228/432000 [00:14<00:54, 6350.71it/s]prepro_backdoor:  20%|██        | 87865/432000 [00:14<00:54, 6349.07it/s]prepro_backdoor:  21%|██        | 88571/432000 [00:14<00:52, 6550.07it/s]prepro_backdoor:  21%|██        | 89228/432000 [00:15<01:00, 5626.64it/s]prepro_backdoor:  21%|██        | 89922/432000 [00:15<00:57, 5973.93it/s]prepro_backdoor:  21%|██        | 90540/432000 [00:15<00:58, 5882.50it/s]prepro_backdoor:  21%|██        | 91143/432000 [00:15<01:00, 5659.79it/s]prepro_backdoor:  21%|██▏       | 91916/432000 [00:15<00:54, 6207.59it/s]prepro_backdoor:  21%|██▏       | 92549/432000 [00:15<00:57, 5882.48it/s]prepro_backdoor:  22%|██▏       | 93148/432000 [00:15<00:57, 5842.98it/s]prepro_backdoor:  22%|██▏       | 93828/432000 [00:15<00:55, 6107.35it/s]prepro_backdoor:  22%|██▏       | 94452/432000 [00:15<00:55, 6120.73it/s]prepro_backdoor:  22%|██▏       | 95070/432000 [00:16<00:56, 5928.76it/s]prepro_backdoor:  22%|██▏       | 95668/432000 [00:16<00:57, 5840.08it/s]prepro_backdoor:  22%|██▏       | 96255/432000 [00:16<00:58, 5769.14it/s]prepro_backdoor:  22%|██▏       | 96941/432000 [00:16<00:55, 6077.08it/s]prepro_backdoor:  23%|██▎       | 97552/432000 [00:16<00:55, 5976.72it/s]prepro_backdoor:  23%|██▎       | 98246/432000 [00:16<00:53, 6243.28it/s]prepro_backdoor:  23%|██▎       | 98874/432000 [00:16<00:53, 6243.87it/s]prepro_backdoor:  23%|██▎       | 99500/432000 [00:16<00:53, 6196.34it/s]prepro_backdoor:  23%|██▎       | 100121/432000 [00:16<00:54, 6126.10it/s]prepro_backdoor:  23%|██▎       | 100735/432000 [00:17<00:54, 6116.69it/s]prepro_backdoor:  23%|██▎       | 101348/432000 [00:17<00:54, 6042.63it/s]prepro_backdoor:  24%|██▎       | 102056/432000 [00:17<00:52, 6340.96it/s]prepro_backdoor:  24%|██▍       | 102691/432000 [00:17<00:52, 6237.74it/s]prepro_backdoor:  24%|██▍       | 103316/432000 [00:17<00:52, 6239.01it/s]prepro_backdoor:  24%|██▍       | 103941/432000 [00:17<00:52, 6198.73it/s]prepro_backdoor:  24%|██▍       | 104611/432000 [00:17<00:51, 6322.07it/s]prepro_backdoor:  24%|██▍       | 105330/432000 [00:17<00:49, 6553.03it/s]prepro_backdoor:  25%|██▍       | 105994/432000 [00:17<00:49, 6566.42it/s]prepro_backdoor:  25%|██▍       | 106651/432000 [00:17<00:51, 6275.33it/s]prepro_backdoor:  25%|██▍       | 107313/432000 [00:18<00:51, 6362.40it/s]prepro_backdoor:  25%|██▍       | 107952/432000 [00:18<00:52, 6206.14it/s]prepro_backdoor:  25%|██▌       | 108655/432000 [00:18<00:50, 6425.15it/s]prepro_backdoor:  25%|██▌       | 109300/432000 [00:18<00:50, 6363.80it/s]prepro_backdoor:  25%|██▌       | 109973/432000 [00:18<00:49, 6462.41it/s]prepro_backdoor:  26%|██▌       | 110621/432000 [00:18<00:50, 6423.62it/s]prepro_backdoor:  26%|██▌       | 111265/432000 [00:18<00:50, 6346.49it/s]prepro_backdoor:  26%|██▌       | 111901/432000 [00:18<00:52, 6050.76it/s]prepro_backdoor:  26%|██▌       | 112561/432000 [00:18<00:51, 6196.64it/s]prepro_backdoor:  26%|██▌       | 113184/432000 [00:18<00:52, 6038.73it/s]prepro_backdoor:  26%|██▋       | 113841/432000 [00:19<00:51, 6180.07it/s]prepro_backdoor:  26%|██▋       | 114462/432000 [00:19<00:51, 6160.72it/s]prepro_backdoor:  27%|██▋       | 115080/432000 [00:19<00:52, 6007.02it/s]prepro_backdoor:  27%|██▋       | 115738/432000 [00:19<00:51, 6162.26it/s]prepro_backdoor:  27%|██▋       | 116436/432000 [00:19<00:49, 6377.21it/s]prepro_backdoor:  27%|██▋       | 117136/432000 [00:19<00:48, 6557.62it/s]prepro_backdoor:  27%|██▋       | 117881/432000 [00:19<00:46, 6788.36it/s]prepro_backdoor:  27%|██▋       | 118561/432000 [00:19<00:50, 6244.83it/s]prepro_backdoor:  28%|██▊       | 119268/432000 [00:19<00:48, 6461.10it/s]prepro_backdoor:  28%|██▊       | 119973/432000 [00:20<00:47, 6605.67it/s]prepro_backdoor:  28%|██▊       | 120640/432000 [00:20<00:48, 6385.55it/s]prepro_backdoor:  28%|██▊       | 121284/432000 [00:20<00:50, 6101.21it/s]prepro_backdoor:  28%|██▊       | 121900/432000 [00:20<00:52, 5938.76it/s]prepro_backdoor:  28%|██▊       | 122582/432000 [00:20<00:50, 6179.56it/s]prepro_backdoor:  29%|██▊       | 123205/432000 [00:20<00:49, 6182.35it/s]prepro_backdoor:  29%|██▊       | 123827/432000 [00:20<00:49, 6164.15it/s]prepro_backdoor:  29%|██▉       | 124446/432000 [00:20<00:51, 5954.81it/s]prepro_backdoor:  29%|██▉       | 125044/432000 [00:20<00:51, 5940.84it/s]prepro_backdoor:  29%|██▉       | 125746/432000 [00:20<00:48, 6250.86it/s]prepro_backdoor:  29%|██▉       | 126416/432000 [00:21<00:47, 6376.30it/s]prepro_backdoor:  29%|██▉       | 127056/432000 [00:21<00:50, 6002.23it/s]prepro_backdoor:  30%|██▉       | 127662/432000 [00:21<00:51, 5932.31it/s]prepro_backdoor:  30%|██▉       | 128259/432000 [00:21<00:53, 5687.26it/s]prepro_backdoor:  30%|██▉       | 128832/432000 [00:21<00:55, 5475.22it/s]prepro_backdoor:  30%|██▉       | 129391/432000 [00:21<00:55, 5488.20it/s]prepro_backdoor:  30%|███       | 129996/432000 [00:21<00:53, 5621.66it/s]prepro_backdoor:  30%|███       | 130561/432000 [00:21<00:55, 5439.30it/s]prepro_backdoor:  30%|███       | 131132/432000 [00:21<00:54, 5490.77it/s]prepro_backdoor:  30%|███       | 131683/432000 [00:22<00:56, 5301.45it/s]prepro_backdoor:  31%|███       | 132270/432000 [00:22<00:55, 5443.75it/s]prepro_backdoor:  31%|███       | 132857/432000 [00:22<00:53, 5561.45it/s]prepro_backdoor:  31%|███       | 133416/432000 [00:22<00:54, 5502.61it/s]prepro_backdoor:  31%|███       | 134067/432000 [00:22<00:51, 5789.59it/s]prepro_backdoor:  31%|███       | 134648/432000 [00:22<00:53, 5556.00it/s]prepro_backdoor:  31%|███▏      | 135207/432000 [00:22<00:54, 5485.94it/s]prepro_backdoor:  31%|███▏      | 135758/432000 [00:22<00:54, 5431.62it/s]prepro_backdoor:  32%|███▏      | 136413/432000 [00:22<00:51, 5743.41it/s]prepro_backdoor:  32%|███▏      | 137068/432000 [00:23<00:49, 5961.01it/s]prepro_backdoor:  32%|███▏      | 137684/432000 [00:23<00:49, 6000.20it/s]prepro_backdoor:  32%|███▏      | 138286/432000 [00:23<00:49, 5939.02it/s]prepro_backdoor:  32%|███▏      | 138997/432000 [00:23<00:46, 6261.32it/s]prepro_backdoor:  32%|███▏      | 139625/432000 [00:23<00:48, 6056.93it/s]prepro_backdoor:  32%|███▏      | 140322/432000 [00:23<00:46, 6290.53it/s]prepro_backdoor:  33%|███▎      | 140953/432000 [00:23<00:48, 5941.04it/s]prepro_backdoor:  33%|███▎      | 141672/432000 [00:23<00:46, 6268.39it/s]prepro_backdoor:  33%|███▎      | 142304/432000 [00:23<00:46, 6198.20it/s]prepro_backdoor:  33%|███▎      | 143030/432000 [00:23<00:44, 6503.24it/s]prepro_backdoor:  33%|███▎      | 143685/432000 [00:24<00:46, 6171.43it/s]prepro_backdoor:  33%|███▎      | 144431/432000 [00:24<00:44, 6516.08it/s]prepro_backdoor:  34%|███▎      | 145089/432000 [00:24<00:45, 6315.69it/s]prepro_backdoor:  34%|███▎      | 145726/432000 [00:24<00:47, 6068.96it/s]prepro_backdoor:  34%|███▍      | 146338/432000 [00:24<00:48, 5891.45it/s]prepro_backdoor:  34%|███▍      | 146931/432000 [00:24<00:48, 5849.37it/s]prepro_backdoor:  34%|███▍      | 147518/432000 [00:24<00:48, 5836.81it/s]prepro_backdoor:  34%|███▍      | 148188/432000 [00:24<00:46, 6083.78it/s]prepro_backdoor:  34%|███▍      | 148799/432000 [00:24<00:48, 5794.71it/s]prepro_backdoor:  35%|███▍      | 149383/432000 [00:25<00:50, 5619.60it/s]prepro_backdoor:  35%|███▍      | 149979/432000 [00:25<00:49, 5706.80it/s]prepro_backdoor:  35%|███▍      | 150566/432000 [00:25<00:49, 5735.56it/s]prepro_backdoor:  35%|███▍      | 151142/432000 [00:25<00:49, 5672.17it/s]prepro_backdoor:  35%|███▌      | 151739/432000 [00:25<00:48, 5744.38it/s]prepro_backdoor:  35%|███▌      | 152389/432000 [00:25<00:47, 5942.21it/s]prepro_backdoor:  35%|███▌      | 152985/432000 [00:25<00:47, 5847.86it/s]prepro_backdoor:  36%|███▌      | 153571/432000 [00:25<00:48, 5716.84it/s]prepro_backdoor:  36%|███▌      | 154144/432000 [00:25<00:49, 5586.00it/s]prepro_backdoor:  36%|███▌      | 154934/432000 [00:25<00:44, 6228.08it/s]prepro_backdoor:  36%|███▌      | 155560/432000 [00:26<00:45, 6049.24it/s]prepro_backdoor:  36%|███▌      | 156168/432000 [00:26<00:49, 5538.48it/s]prepro_backdoor:  36%|███▋      | 156755/432000 [00:26<00:49, 5616.28it/s]prepro_backdoor:  36%|███▋      | 157324/432000 [00:26<00:49, 5577.25it/s]prepro_backdoor:  37%|███▋      | 157976/432000 [00:26<00:46, 5839.61it/s]prepro_backdoor:  37%|███▋      | 158733/432000 [00:26<00:43, 6316.91it/s]prepro_backdoor:  37%|███▋      | 159370/432000 [00:26<00:44, 6100.07it/s]prepro_backdoor:  37%|███▋      | 159992/432000 [00:26<00:44, 6130.93it/s]prepro_backdoor:  37%|███▋      | 160609/432000 [00:26<00:44, 6033.87it/s]prepro_backdoor:  37%|███▋      | 161215/432000 [00:27<00:46, 5828.01it/s]prepro_backdoor:  37%|███▋      | 161810/432000 [00:27<00:46, 5841.70it/s]prepro_backdoor:  38%|███▊      | 162467/432000 [00:27<00:44, 6051.82it/s]prepro_backdoor:  38%|███▊      | 163105/432000 [00:27<00:43, 6146.71it/s]prepro_backdoor:  38%|███▊      | 163722/432000 [00:27<00:45, 5960.61it/s]prepro_backdoor:  38%|███▊      | 164321/432000 [00:27<00:45, 5824.45it/s]prepro_backdoor:  38%|███▊      | 165020/432000 [00:27<00:43, 6135.39it/s]prepro_backdoor:  38%|███▊      | 165665/432000 [00:27<00:42, 6199.34it/s]prepro_backdoor:  38%|███▊      | 166287/432000 [00:27<00:44, 5920.39it/s]prepro_backdoor:  39%|███▊      | 166929/432000 [00:27<00:43, 6052.94it/s]prepro_backdoor:  39%|███▉      | 167538/432000 [00:28<00:45, 5856.47it/s]prepro_backdoor:  39%|███▉      | 168127/432000 [00:28<00:45, 5850.68it/s]prepro_backdoor:  39%|███▉      | 168788/432000 [00:28<00:43, 6064.76it/s]prepro_backdoor:  39%|███▉      | 169418/432000 [00:28<00:42, 6112.65it/s]prepro_backdoor:  39%|███▉      | 170141/432000 [00:28<00:40, 6414.40it/s]prepro_backdoor:  40%|███▉      | 170784/432000 [00:28<00:42, 6091.45it/s]prepro_backdoor:  40%|███▉      | 171398/432000 [00:28<00:42, 6088.41it/s]prepro_backdoor:  40%|███▉      | 172032/432000 [00:28<00:42, 6142.45it/s]prepro_backdoor:  40%|███▉      | 172649/432000 [00:28<00:42, 6045.08it/s]prepro_backdoor:  40%|████      | 173256/432000 [00:29<00:46, 5514.12it/s]prepro_backdoor:  40%|████      | 173873/432000 [00:29<00:45, 5678.66it/s]prepro_backdoor:  40%|████      | 174499/432000 [00:29<00:44, 5827.86it/s]prepro_backdoor:  41%|████      | 175093/432000 [00:29<00:43, 5852.37it/s]prepro_backdoor:  41%|████      | 175827/432000 [00:29<00:40, 6257.73it/s]prepro_backdoor:  41%|████      | 176458/432000 [00:29<00:40, 6261.00it/s]prepro_backdoor:  41%|████      | 177088/432000 [00:29<00:42, 5961.66it/s]prepro_backdoor:  41%|████      | 177689/432000 [00:29<00:43, 5895.75it/s]prepro_backdoor:  41%|████▏     | 178282/432000 [00:29<00:44, 5690.67it/s]prepro_backdoor:  41%|████▏     | 178855/432000 [00:30<00:46, 5442.57it/s]prepro_backdoor:  42%|████▏     | 179488/432000 [00:30<00:44, 5670.86it/s]prepro_backdoor:  42%|████▏     | 180116/432000 [00:30<00:43, 5818.84it/s]prepro_backdoor:  42%|████▏     | 180749/432000 [00:30<00:42, 5944.69it/s]prepro_backdoor:  42%|████▏     | 181354/432000 [00:30<00:42, 5967.56it/s]prepro_backdoor:  42%|████▏     | 181953/432000 [00:30<00:43, 5788.81it/s]prepro_backdoor:  42%|████▏     | 182535/432000 [00:30<00:44, 5592.60it/s]prepro_backdoor:  42%|████▏     | 183100/432000 [00:30<00:44, 5596.19it/s]prepro_backdoor:  43%|████▎     | 183735/432000 [00:30<00:42, 5788.99it/s]prepro_backdoor:  43%|████▎     | 184500/432000 [00:30<00:39, 6320.09it/s]prepro_backdoor:  43%|████▎     | 185152/432000 [00:31<00:38, 6363.90it/s]prepro_backdoor:  43%|████▎     | 185791/432000 [00:31<00:40, 6083.02it/s]prepro_backdoor:  43%|████▎     | 186462/432000 [00:31<00:39, 6251.02it/s]prepro_backdoor:  43%|████▎     | 187091/432000 [00:31<00:41, 5925.60it/s]prepro_backdoor:  43%|████▎     | 187774/432000 [00:31<00:39, 6157.52it/s]prepro_backdoor:  44%|████▎     | 188395/432000 [00:31<00:40, 6069.60it/s]prepro_backdoor:  44%|████▍     | 189006/432000 [00:31<00:42, 5674.81it/s]prepro_backdoor:  44%|████▍     | 189737/432000 [00:31<00:39, 6114.33it/s]prepro_backdoor:  44%|████▍     | 190357/432000 [00:31<00:40, 6036.69it/s]prepro_backdoor:  44%|████▍     | 190967/432000 [00:32<00:40, 5936.94it/s]prepro_backdoor:  44%|████▍     | 191565/432000 [00:32<00:44, 5357.12it/s]prepro_backdoor:  44%|████▍     | 192113/432000 [00:32<00:44, 5374.95it/s]prepro_backdoor:  45%|████▍     | 192692/432000 [00:32<00:43, 5483.49it/s]prepro_backdoor:  45%|████▍     | 193248/432000 [00:32<00:45, 5274.83it/s]prepro_backdoor:  45%|████▍     | 193999/432000 [00:32<00:40, 5892.34it/s]prepro_backdoor:  45%|████▌     | 194597/432000 [00:32<00:42, 5531.48it/s]prepro_backdoor:  45%|████▌     | 195330/432000 [00:32<00:39, 6009.43it/s]prepro_backdoor:  45%|████▌     | 195942/432000 [00:32<00:40, 5811.58it/s]prepro_backdoor:  45%|████▌     | 196531/432000 [00:33<00:41, 5662.12it/s]prepro_backdoor:  46%|████▌     | 197103/432000 [00:33<00:42, 5480.42it/s]prepro_backdoor:  46%|████▌     | 197656/432000 [00:33<00:42, 5467.82it/s]prepro_backdoor:  46%|████▌     | 198206/432000 [00:33<00:42, 5454.60it/s]prepro_backdoor:  46%|████▌     | 198773/432000 [00:33<00:42, 5506.26it/s]prepro_backdoor:  46%|████▌     | 199409/432000 [00:33<00:40, 5733.75it/s]prepro_backdoor:  46%|████▋     | 200021/432000 [00:33<00:39, 5832.81it/s]prepro_backdoor:  46%|████▋     | 200606/432000 [00:33<00:39, 5820.65it/s]prepro_backdoor:  47%|████▋     | 201189/432000 [00:33<00:43, 5364.61it/s]prepro_backdoor:  47%|████▋     | 201926/432000 [00:33<00:38, 5923.77it/s]prepro_backdoor:  47%|████▋     | 202624/432000 [00:34<00:36, 6205.62it/s]prepro_backdoor:  47%|████▋     | 203253/432000 [00:34<00:36, 6199.05it/s]prepro_backdoor:  47%|████▋     | 203954/432000 [00:34<00:35, 6409.45it/s]prepro_backdoor:  47%|████▋     | 204600/432000 [00:34<00:35, 6411.82it/s]prepro_backdoor:  48%|████▊     | 205245/432000 [00:34<00:37, 5969.05it/s]prepro_backdoor:  48%|████▊     | 205850/432000 [00:34<00:41, 5487.14it/s]prepro_backdoor:  48%|████▊     | 206539/432000 [00:34<00:38, 5844.44it/s]prepro_backdoor:  48%|████▊     | 207158/432000 [00:34<00:37, 5923.22it/s]prepro_backdoor:  48%|████▊     | 207760/432000 [00:34<00:39, 5735.64it/s]prepro_backdoor:  48%|████▊     | 208341/432000 [00:35<00:41, 5332.40it/s]prepro_backdoor:  48%|████▊     | 208934/432000 [00:35<00:40, 5479.61it/s]prepro_backdoor:  48%|████▊     | 209490/432000 [00:35<00:41, 5306.24it/s]prepro_backdoor:  49%|████▊     | 210105/432000 [00:35<00:40, 5525.27it/s]prepro_backdoor:  49%|████▉     | 210761/432000 [00:35<00:38, 5795.93it/s]prepro_backdoor:  49%|████▉     | 211346/432000 [00:35<00:38, 5764.64it/s]prepro_backdoor:  49%|████▉     | 212003/432000 [00:35<00:36, 5984.80it/s]prepro_backdoor:  49%|████▉     | 212605/432000 [00:35<00:36, 5980.12it/s]prepro_backdoor:  49%|████▉     | 213206/432000 [00:35<00:37, 5904.04it/s]prepro_backdoor:  49%|████▉     | 213799/432000 [00:36<00:37, 5775.66it/s]prepro_backdoor:  50%|████▉     | 214460/432000 [00:36<00:36, 6008.87it/s]prepro_backdoor:  50%|████▉     | 215086/432000 [00:36<00:35, 6055.37it/s]prepro_backdoor:  50%|████▉     | 215693/432000 [00:36<00:36, 5930.93it/s]prepro_backdoor:  50%|█████     | 216302/432000 [00:36<00:36, 5959.62it/s]prepro_backdoor:  50%|█████     | 216942/432000 [00:36<00:35, 6088.01it/s]prepro_backdoor:  50%|█████     | 217599/432000 [00:36<00:34, 6214.90it/s]prepro_backdoor:  51%|█████     | 218222/432000 [00:36<00:35, 5950.92it/s]prepro_backdoor:  51%|█████     | 218820/432000 [00:36<00:38, 5566.24it/s]prepro_backdoor:  51%|█████     | 219449/432000 [00:36<00:36, 5761.66it/s]prepro_backdoor:  51%|█████     | 220154/432000 [00:37<00:34, 6118.56it/s]prepro_backdoor:  51%|█████     | 220772/432000 [00:37<00:35, 5986.10it/s]prepro_backdoor:  51%|█████     | 221395/432000 [00:37<00:34, 6055.54it/s]prepro_backdoor:  51%|█████▏    | 222004/432000 [00:37<00:35, 5844.49it/s]prepro_backdoor:  52%|█████▏    | 222654/432000 [00:37<00:34, 6019.80it/s]prepro_backdoor:  52%|█████▏    | 223260/432000 [00:37<00:34, 5965.34it/s]prepro_backdoor:  52%|█████▏    | 223859/432000 [00:37<00:35, 5783.57it/s]prepro_backdoor:  52%|█████▏    | 224440/432000 [00:37<00:35, 5784.48it/s]prepro_backdoor:  52%|█████▏    | 225135/432000 [00:37<00:33, 6105.41it/s]prepro_backdoor:  52%|█████▏    | 225748/432000 [00:38<00:37, 5490.61it/s]prepro_backdoor:  52%|█████▏    | 226312/432000 [00:38<00:37, 5528.26it/s]prepro_backdoor:  53%|█████▎    | 226947/432000 [00:38<00:35, 5756.19it/s]prepro_backdoor:  53%|█████▎    | 227766/432000 [00:38<00:31, 6449.62it/s]prepro_backdoor:  53%|█████▎    | 228442/432000 [00:38<00:31, 6535.91it/s]prepro_backdoor:  53%|█████▎    | 229103/432000 [00:38<00:31, 6519.44it/s]prepro_backdoor:  53%|█████▎    | 229760/432000 [00:38<00:31, 6361.79it/s]prepro_backdoor:  53%|█████▎    | 230400/432000 [00:38<00:33, 6050.03it/s]prepro_backdoor:  53%|█████▎    | 231042/432000 [00:38<00:32, 6139.52it/s]prepro_backdoor:  54%|█████▎    | 231687/432000 [00:39<00:32, 6224.15it/s]prepro_backdoor:  54%|█████▍    | 232313/432000 [00:39<00:32, 6122.28it/s]prepro_backdoor:  54%|█████▍    | 232968/432000 [00:39<00:32, 6219.72it/s]prepro_backdoor:  54%|█████▍    | 233614/432000 [00:39<00:31, 6280.90it/s]prepro_backdoor:  54%|█████▍    | 234244/432000 [00:39<00:35, 5632.00it/s]prepro_backdoor:  54%|█████▍    | 234821/432000 [00:39<00:35, 5598.97it/s]prepro_backdoor:  54%|█████▍    | 235390/432000 [00:39<00:37, 5240.27it/s]prepro_backdoor:  55%|█████▍    | 236087/432000 [00:39<00:34, 5682.99it/s]prepro_backdoor:  55%|█████▍    | 236676/432000 [00:39<00:34, 5717.52it/s]prepro_backdoor:  55%|█████▍    | 237262/432000 [00:39<00:33, 5749.81it/s]prepro_backdoor:  55%|█████▌    | 237866/432000 [00:40<00:33, 5824.16it/s]prepro_backdoor:  55%|█████▌    | 238453/432000 [00:40<00:33, 5703.41it/s]prepro_backdoor:  55%|█████▌    | 239086/432000 [00:40<00:32, 5880.05it/s]prepro_backdoor:  55%|█████▌    | 239705/432000 [00:40<00:32, 5952.03it/s]prepro_backdoor:  56%|█████▌    | 240480/432000 [00:40<00:29, 6468.26it/s]prepro_backdoor:  56%|█████▌    | 241130/432000 [00:40<00:30, 6205.75it/s]prepro_backdoor:  56%|█████▌    | 241755/432000 [00:40<00:31, 6065.04it/s]prepro_backdoor:  56%|█████▌    | 242472/432000 [00:40<00:29, 6371.66it/s]prepro_backdoor:  56%|█████▋    | 243113/432000 [00:40<00:30, 6111.16it/s]prepro_backdoor:  56%|█████▋    | 243819/432000 [00:41<00:29, 6374.22it/s]prepro_backdoor:  57%|█████▋    | 244461/432000 [00:41<00:29, 6369.56it/s]prepro_backdoor:  57%|█████▋    | 245153/432000 [00:41<00:28, 6513.25it/s]prepro_backdoor:  57%|█████▋    | 245807/432000 [00:41<00:30, 6059.56it/s]prepro_backdoor:  57%|█████▋    | 246492/432000 [00:41<00:29, 6259.29it/s]prepro_backdoor:  57%|█████▋    | 247125/432000 [00:41<00:29, 6170.85it/s]prepro_backdoor:  57%|█████▋    | 247747/432000 [00:41<00:31, 5776.69it/s]prepro_backdoor:  57%|█████▋    | 248332/432000 [00:41<00:32, 5724.93it/s]prepro_backdoor:  58%|█████▊    | 248910/432000 [00:41<00:32, 5671.97it/s]prepro_backdoor:  58%|█████▊    | 249526/432000 [00:42<00:31, 5787.62it/s]prepro_backdoor:  58%|█████▊    | 250113/432000 [00:42<00:31, 5805.97it/s]prepro_backdoor:  58%|█████▊    | 250696/432000 [00:42<00:32, 5559.92it/s]prepro_backdoor:  58%|█████▊    | 251355/432000 [00:42<00:30, 5830.63it/s]prepro_backdoor:  58%|█████▊    | 251942/432000 [00:42<00:31, 5685.37it/s]prepro_backdoor:  58%|█████▊    | 252514/432000 [00:42<00:31, 5650.84it/s]prepro_backdoor:  59%|█████▊    | 253237/432000 [00:42<00:29, 6088.87it/s]prepro_backdoor:  59%|█████▉    | 253866/432000 [00:42<00:29, 6118.92it/s]prepro_backdoor:  59%|█████▉    | 254526/432000 [00:42<00:28, 6231.26it/s]prepro_backdoor:  59%|█████▉    | 255151/432000 [00:42<00:29, 6011.86it/s]prepro_backdoor:  59%|█████▉    | 255816/432000 [00:43<00:29, 6039.05it/s]prepro_backdoor:  59%|█████▉    | 256436/432000 [00:43<00:28, 6071.98it/s]prepro_backdoor:  60%|█████▉    | 257045/432000 [00:43<00:29, 5845.17it/s]prepro_backdoor:  60%|█████▉    | 257632/432000 [00:43<00:30, 5762.57it/s]prepro_backdoor:  60%|█████▉    | 258383/432000 [00:43<00:27, 6262.20it/s]prepro_backdoor:  60%|█████▉    | 259039/432000 [00:43<00:27, 6347.09it/s]prepro_backdoor:  60%|██████    | 259703/432000 [00:43<00:26, 6430.84it/s]prepro_backdoor:  60%|██████    | 260349/432000 [00:43<00:27, 6161.53it/s]prepro_backdoor:  60%|██████    | 260976/432000 [00:43<00:27, 6165.49it/s]prepro_backdoor:  61%|██████    | 261608/432000 [00:43<00:27, 6210.08it/s]prepro_backdoor:  61%|██████    | 262307/432000 [00:44<00:26, 6411.65it/s]prepro_backdoor:  61%|██████    | 262950/432000 [00:44<00:26, 6393.74it/s]prepro_backdoor:  61%|██████    | 263745/432000 [00:44<00:24, 6833.65it/s]prepro_backdoor:  61%|██████    | 264430/432000 [00:44<00:26, 6299.93it/s]prepro_backdoor:  61%|██████▏   | 265069/432000 [00:44<00:27, 6113.69it/s]prepro_backdoor:  62%|██████▏   | 265687/432000 [00:44<00:28, 5931.27it/s]prepro_backdoor:  62%|██████▏   | 266314/432000 [00:44<00:27, 6015.83it/s]prepro_backdoor:  62%|██████▏   | 266920/432000 [00:44<00:30, 5484.36it/s]prepro_backdoor:  62%|██████▏   | 267479/432000 [00:45<00:31, 5264.89it/s]prepro_backdoor:  62%|██████▏   | 268219/432000 [00:45<00:28, 5814.60it/s]prepro_backdoor:  62%|██████▏   | 268896/432000 [00:45<00:26, 6052.37it/s]prepro_backdoor:  62%|██████▏   | 269511/432000 [00:45<00:28, 5783.79it/s]prepro_backdoor:  63%|██████▎   | 270234/432000 [00:45<00:26, 6166.00it/s]prepro_backdoor:  63%|██████▎   | 270859/432000 [00:45<00:26, 5997.51it/s]prepro_backdoor:  63%|██████▎   | 271465/432000 [00:45<00:28, 5711.65it/s]prepro_backdoor:  63%|██████▎   | 272059/432000 [00:45<00:28, 5550.09it/s]prepro_backdoor:  63%|██████▎   | 272768/432000 [00:45<00:26, 5947.93it/s]prepro_backdoor:  63%|██████▎   | 273421/432000 [00:45<00:26, 6090.11it/s]prepro_backdoor:  63%|██████▎   | 274119/432000 [00:46<00:24, 6316.72it/s]prepro_backdoor:  64%|██████▎   | 274756/432000 [00:46<00:24, 6292.67it/s]prepro_backdoor:  64%|██████▍   | 275540/432000 [00:46<00:23, 6735.27it/s]prepro_backdoor:  64%|██████▍   | 276289/432000 [00:46<00:22, 6935.79it/s]prepro_backdoor:  64%|██████▍   | 276987/432000 [00:46<00:22, 6917.00it/s]prepro_backdoor:  64%|██████▍   | 277681/432000 [00:46<00:23, 6475.65it/s]prepro_backdoor:  64%|██████▍   | 278336/432000 [00:46<00:23, 6421.66it/s]prepro_backdoor:  65%|██████▍   | 279054/432000 [00:46<00:23, 6629.58it/s]prepro_backdoor:  65%|██████▍   | 279722/432000 [00:46<00:23, 6596.27it/s]prepro_backdoor:  65%|██████▍   | 280385/432000 [00:47<00:24, 6144.45it/s]prepro_backdoor:  65%|██████▌   | 281007/432000 [00:47<00:24, 6116.11it/s]prepro_backdoor:  65%|██████▌   | 281682/432000 [00:47<00:23, 6290.65it/s]prepro_backdoor:  65%|██████▌   | 282416/432000 [00:47<00:22, 6589.02it/s]prepro_backdoor:  66%|██████▌   | 283080/432000 [00:47<00:23, 6352.02it/s]prepro_backdoor:  66%|██████▌   | 283720/432000 [00:47<00:23, 6288.32it/s]prepro_backdoor:  66%|██████▌   | 284375/432000 [00:47<00:23, 6354.39it/s]prepro_backdoor:  66%|██████▌   | 285013/432000 [00:47<00:23, 6185.97it/s]prepro_backdoor:  66%|██████▌   | 285634/432000 [00:47<00:23, 6186.32it/s]prepro_backdoor:  66%|██████▋   | 286308/432000 [00:47<00:23, 6321.27it/s]prepro_backdoor:  66%|██████▋   | 286942/432000 [00:48<00:23, 6174.98it/s]prepro_backdoor:  67%|██████▋   | 287561/432000 [00:48<00:23, 6167.17it/s]prepro_backdoor:  67%|██████▋   | 288179/432000 [00:48<00:24, 5917.50it/s]prepro_backdoor:  67%|██████▋   | 288847/432000 [00:48<00:23, 6114.44it/s]prepro_backdoor:  67%|██████▋   | 289461/432000 [00:48<00:24, 5702.46it/s]prepro_backdoor:  67%|██████▋   | 290126/432000 [00:48<00:23, 5946.47it/s]prepro_backdoor:  67%|██████▋   | 290839/432000 [00:48<00:22, 6258.36it/s]prepro_backdoor:  67%|██████▋   | 291483/432000 [00:48<00:22, 6290.29it/s]prepro_backdoor:  68%|██████▊   | 292257/432000 [00:48<00:20, 6698.32it/s]prepro_backdoor:  68%|██████▊   | 292967/432000 [00:49<00:20, 6806.28it/s]prepro_backdoor:  68%|██████▊   | 293651/432000 [00:49<00:20, 6815.05it/s]prepro_backdoor:  68%|██████▊   | 294335/432000 [00:49<00:21, 6380.54it/s]prepro_backdoor:  68%|██████▊   | 294980/432000 [00:49<00:21, 6257.02it/s]prepro_backdoor:  68%|██████▊   | 295611/432000 [00:49<00:21, 6240.60it/s]prepro_backdoor:  69%|██████▊   | 296239/432000 [00:49<00:22, 6027.40it/s]prepro_backdoor:  69%|██████▊   | 296874/432000 [00:49<00:22, 6090.69it/s]prepro_backdoor:  69%|██████▉   | 297541/432000 [00:49<00:21, 6242.14it/s]prepro_backdoor:  69%|██████▉   | 298208/432000 [00:49<00:21, 6351.58it/s]prepro_backdoor:  69%|██████▉   | 298846/432000 [00:50<00:24, 5438.42it/s]prepro_backdoor:  69%|██████▉   | 299490/432000 [00:50<00:23, 5686.83it/s]prepro_backdoor:  69%|██████▉   | 300114/432000 [00:50<00:22, 5816.48it/s]prepro_backdoor:  70%|██████▉   | 300751/432000 [00:50<00:22, 5946.16it/s]prepro_backdoor:  70%|██████▉   | 301386/432000 [00:50<00:21, 6057.05it/s]prepro_backdoor:  70%|██████▉   | 302001/432000 [00:50<00:21, 5927.61it/s]prepro_backdoor:  70%|███████   | 302600/432000 [00:50<00:22, 5687.09it/s]prepro_backdoor:  70%|███████   | 303250/432000 [00:50<00:21, 5900.14it/s]prepro_backdoor:  70%|███████   | 303914/432000 [00:50<00:20, 6102.96it/s]prepro_backdoor:  70%|███████   | 304529/432000 [00:50<00:20, 6102.89it/s]prepro_backdoor:  71%|███████   | 305184/432000 [00:51<00:20, 6217.87it/s]prepro_backdoor:  71%|███████   | 305918/432000 [00:51<00:19, 6520.28it/s]prepro_backdoor:  71%|███████   | 306652/432000 [00:51<00:18, 6735.43it/s]prepro_backdoor:  71%|███████   | 307328/432000 [00:51<00:19, 6346.03it/s]prepro_backdoor:  71%|███████▏  | 307968/432000 [00:51<00:20, 6190.54it/s]prepro_backdoor:  71%|███████▏  | 308693/432000 [00:51<00:19, 6472.87it/s]prepro_backdoor:  72%|███████▏  | 309359/432000 [00:51<00:18, 6504.60it/s]prepro_backdoor:  72%|███████▏  | 310013/432000 [00:51<00:18, 6499.81it/s]prepro_backdoor:  72%|███████▏  | 310666/432000 [00:51<00:19, 6233.01it/s]prepro_backdoor:  72%|███████▏  | 311312/432000 [00:52<00:19, 6269.94it/s]prepro_backdoor:  72%|███████▏  | 311942/432000 [00:52<00:19, 6016.99it/s]prepro_backdoor:  72%|███████▏  | 312547/432000 [00:52<00:20, 5798.64it/s]prepro_backdoor:  72%|███████▏  | 313130/432000 [00:52<00:20, 5781.26it/s]prepro_backdoor:  73%|███████▎  | 313744/432000 [00:52<00:20, 5879.44it/s]prepro_backdoor:  73%|███████▎  | 314334/432000 [00:52<00:21, 5575.19it/s]prepro_backdoor:  73%|███████▎  | 314905/432000 [00:52<00:20, 5598.58it/s]prepro_backdoor:  73%|███████▎  | 315519/432000 [00:52<00:20, 5742.03it/s]prepro_backdoor:  73%|███████▎  | 316096/432000 [00:52<00:22, 5209.33it/s]prepro_backdoor:  73%|███████▎  | 316659/432000 [00:53<00:21, 5310.81it/s]prepro_backdoor:  73%|███████▎  | 317252/432000 [00:53<00:20, 5470.66it/s]prepro_backdoor:  74%|███████▎  | 317932/432000 [00:53<00:19, 5833.36it/s]prepro_backdoor:  74%|███████▍  | 318643/432000 [00:53<00:18, 6195.91it/s]prepro_backdoor:  74%|███████▍  | 319269/432000 [00:53<00:18, 6190.16it/s]prepro_backdoor:  74%|███████▍  | 319893/432000 [00:53<00:18, 6037.76it/s]prepro_backdoor:  74%|███████▍  | 320501/432000 [00:53<00:19, 5857.61it/s]prepro_backdoor:  74%|███████▍  | 321153/432000 [00:53<00:18, 6022.16it/s]prepro_backdoor:  74%|███████▍  | 321759/432000 [00:53<00:18, 6007.92it/s]prepro_backdoor:  75%|███████▍  | 322362/432000 [00:53<00:18, 5790.28it/s]prepro_backdoor:  75%|███████▍  | 323083/432000 [00:54<00:17, 6173.40it/s]prepro_backdoor:  75%|███████▍  | 323756/432000 [00:54<00:17, 6308.79it/s]prepro_backdoor:  75%|███████▌  | 324500/432000 [00:54<00:16, 6609.29it/s]prepro_backdoor:  75%|███████▌  | 325164/432000 [00:54<00:16, 6411.63it/s]prepro_backdoor:  75%|███████▌  | 325808/432000 [00:54<00:16, 6275.97it/s]prepro_backdoor:  76%|███████▌  | 326438/432000 [00:54<00:16, 6224.81it/s]prepro_backdoor:  76%|███████▌  | 327102/432000 [00:54<00:16, 6341.45it/s]prepro_backdoor:  76%|███████▌  | 327916/432000 [00:54<00:15, 6841.53it/s]prepro_backdoor:  76%|███████▌  | 328602/432000 [00:54<00:15, 6630.51it/s]prepro_backdoor:  76%|███████▌  | 329268/432000 [00:55<00:16, 6149.90it/s]prepro_backdoor:  76%|███████▋  | 329891/432000 [00:55<00:16, 6008.24it/s]prepro_backdoor:  77%|███████▋  | 330568/432000 [00:55<00:16, 6216.90it/s]prepro_backdoor:  77%|███████▋  | 331234/432000 [00:55<00:15, 6319.96it/s]prepro_backdoor:  77%|███████▋  | 331871/432000 [00:55<00:15, 6302.89it/s]prepro_backdoor:  77%|███████▋  | 332509/432000 [00:55<00:15, 6300.08it/s]prepro_backdoor:  77%|███████▋  | 333141/432000 [00:55<00:16, 6072.94it/s]prepro_backdoor:  77%|███████▋  | 333855/432000 [00:55<00:15, 6355.98it/s]prepro_backdoor:  77%|███████▋  | 334494/432000 [00:55<00:15, 6176.60it/s]prepro_backdoor:  78%|███████▊  | 335293/432000 [00:55<00:14, 6686.73it/s]prepro_backdoor:  78%|███████▊  | 335966/432000 [00:56<00:15, 6303.63it/s]prepro_backdoor:  78%|███████▊  | 336603/432000 [00:56<00:15, 6263.19it/s]prepro_backdoor:  78%|███████▊  | 337234/432000 [00:56<00:15, 5930.09it/s]prepro_backdoor:  78%|███████▊  | 337974/432000 [00:56<00:14, 6317.40it/s]prepro_backdoor:  78%|███████▊  | 338613/432000 [00:56<00:15, 6152.15it/s]prepro_backdoor:  79%|███████▊  | 339240/432000 [00:56<00:15, 6169.89it/s]prepro_backdoor:  79%|███████▊  | 339861/432000 [00:56<00:15, 5964.69it/s]prepro_backdoor:  79%|███████▉  | 340461/432000 [00:56<00:15, 5818.93it/s]prepro_backdoor:  79%|███████▉  | 341085/432000 [00:56<00:15, 5927.60it/s]prepro_backdoor:  79%|███████▉  | 341990/432000 [00:57<00:13, 6792.36it/s]prepro_backdoor:  79%|███████▉  | 342674/432000 [00:57<00:13, 6713.92it/s]prepro_backdoor:  79%|███████▉  | 343349/432000 [00:57<00:13, 6722.92it/s]prepro_backdoor:  80%|███████▉  | 344024/432000 [00:57<00:13, 6684.13it/s]prepro_backdoor:  80%|███████▉  | 344696/432000 [00:57<00:13, 6675.72it/s]prepro_backdoor:  80%|███████▉  | 345407/432000 [00:57<00:12, 6780.67it/s]prepro_backdoor:  80%|████████  | 346086/432000 [00:57<00:12, 6662.43it/s]prepro_backdoor:  80%|████████  | 346754/432000 [00:57<00:14, 6010.58it/s]prepro_backdoor:  80%|████████  | 347441/432000 [00:57<00:13, 6227.17it/s]prepro_backdoor:  81%|████████  | 348074/432000 [00:57<00:13, 6155.95it/s]prepro_backdoor:  81%|████████  | 348697/432000 [00:58<00:13, 5999.53it/s]prepro_backdoor:  81%|████████  | 349372/432000 [00:58<00:13, 6194.67it/s]prepro_backdoor:  81%|████████  | 349997/432000 [00:58<00:13, 6182.41it/s]prepro_backdoor:  81%|████████  | 350654/432000 [00:58<00:12, 6279.06it/s]prepro_backdoor:  81%|████████▏ | 351285/432000 [00:58<00:13, 6074.43it/s]prepro_backdoor:  81%|████████▏ | 351896/432000 [00:58<00:13, 5749.19it/s]prepro_backdoor:  82%|████████▏ | 352641/432000 [00:58<00:12, 6201.55it/s]prepro_backdoor:  82%|████████▏ | 353268/432000 [00:58<00:13, 6040.84it/s]prepro_backdoor:  82%|████████▏ | 353980/432000 [00:58<00:12, 6343.47it/s]prepro_backdoor:  82%|████████▏ | 354681/432000 [00:59<00:11, 6519.92it/s]prepro_backdoor:  82%|████████▏ | 355338/432000 [00:59<00:11, 6448.89it/s]prepro_backdoor:  82%|████████▏ | 355986/432000 [00:59<00:12, 5893.61it/s]prepro_backdoor:  83%|████████▎ | 356586/432000 [00:59<00:13, 5730.46it/s]prepro_backdoor:  83%|████████▎ | 357335/432000 [00:59<00:12, 6202.64it/s]prepro_backdoor:  83%|████████▎ | 357965/432000 [00:59<00:12, 5729.37it/s]prepro_backdoor:  83%|████████▎ | 358628/432000 [00:59<00:12, 5968.26it/s]prepro_backdoor:  83%|████████▎ | 359236/432000 [00:59<00:12, 5912.11it/s]prepro_backdoor:  83%|████████▎ | 359835/432000 [00:59<00:12, 5699.91it/s]prepro_backdoor:  83%|████████▎ | 360411/432000 [01:00<00:13, 5434.47it/s]prepro_backdoor:  84%|████████▎ | 361113/432000 [01:00<00:12, 5864.22it/s]prepro_backdoor:  84%|████████▎ | 361745/432000 [01:00<00:11, 5971.87it/s]prepro_backdoor:  84%|████████▍ | 362349/432000 [01:00<00:11, 5812.79it/s]prepro_backdoor:  84%|████████▍ | 362959/432000 [01:00<00:11, 5876.00it/s]prepro_backdoor:  84%|████████▍ | 363551/432000 [01:00<00:11, 5829.99it/s]prepro_backdoor:  84%|████████▍ | 364137/432000 [01:00<00:11, 5779.69it/s]prepro_backdoor:  84%|████████▍ | 364732/432000 [01:00<00:11, 5821.27it/s]prepro_backdoor:  85%|████████▍ | 365332/432000 [01:00<00:11, 5849.91it/s]prepro_backdoor:  85%|████████▍ | 366002/432000 [01:01<00:10, 6089.56it/s]prepro_backdoor:  85%|████████▍ | 366743/432000 [01:01<00:10, 6457.29it/s]prepro_backdoor:  85%|████████▌ | 367390/432000 [01:01<00:10, 6219.36it/s]prepro_backdoor:  85%|████████▌ | 368015/432000 [01:01<00:10, 5938.29it/s]prepro_backdoor:  85%|████████▌ | 368639/432000 [01:01<00:10, 6018.16it/s]prepro_backdoor:  85%|████████▌ | 369244/432000 [01:01<00:10, 5912.88it/s]prepro_backdoor:  86%|████████▌ | 369873/432000 [01:01<00:10, 6004.17it/s]prepro_backdoor:  86%|████████▌ | 370551/432000 [01:01<00:09, 6228.57it/s]prepro_backdoor:  86%|████████▌ | 371192/432000 [01:01<00:09, 6251.96it/s]prepro_backdoor:  86%|████████▌ | 371819/432000 [01:01<00:09, 6132.17it/s]prepro_backdoor:  86%|████████▌ | 372541/432000 [01:02<00:09, 6440.56it/s]prepro_backdoor:  86%|████████▋ | 373187/432000 [01:02<00:09, 6223.40it/s]prepro_backdoor:  87%|████████▋ | 373812/432000 [01:02<00:09, 6092.48it/s]prepro_backdoor:  87%|████████▋ | 374575/432000 [01:02<00:08, 6512.84it/s]prepro_backdoor:  87%|████████▋ | 375230/432000 [01:02<00:08, 6383.74it/s]prepro_backdoor:  87%|████████▋ | 375871/432000 [01:02<00:09, 6215.93it/s]prepro_backdoor:  87%|████████▋ | 376495/432000 [01:02<00:09, 6037.19it/s]prepro_backdoor:  87%|████████▋ | 377115/432000 [01:02<00:09, 6075.92it/s]prepro_backdoor:  87%|████████▋ | 377781/432000 [01:02<00:08, 6224.64it/s]prepro_backdoor:  88%|████████▊ | 378405/432000 [01:03<00:09, 5941.32it/s]prepro_backdoor:  88%|████████▊ | 379003/432000 [01:03<00:09, 5411.01it/s]prepro_backdoor:  88%|████████▊ | 379834/432000 [01:03<00:08, 6176.12it/s]prepro_backdoor:  88%|████████▊ | 380467/432000 [01:03<00:08, 5872.88it/s]prepro_backdoor:  88%|████████▊ | 381067/432000 [01:03<00:08, 5672.31it/s]prepro_backdoor:  88%|████████▊ | 381737/432000 [01:03<00:08, 5941.53it/s]prepro_backdoor:  89%|████████▊ | 382340/432000 [01:03<00:08, 5676.91it/s]prepro_backdoor:  89%|████████▊ | 382915/432000 [01:03<00:09, 5283.56it/s]prepro_backdoor:  89%|████████▉ | 383452/432000 [01:03<00:09, 5301.38it/s]prepro_backdoor:  89%|████████▉ | 384065/432000 [01:04<00:08, 5506.25it/s]prepro_backdoor:  89%|████████▉ | 384719/432000 [01:04<00:08, 5784.84it/s]prepro_backdoor:  89%|████████▉ | 385308/432000 [01:04<00:08, 5807.41it/s]prepro_backdoor:  89%|████████▉ | 385893/432000 [01:04<00:08, 5639.72it/s]prepro_backdoor:  89%|████████▉ | 386461/432000 [01:04<00:08, 5145.55it/s]prepro_backdoor:  90%|████████▉ | 387105/432000 [01:04<00:08, 5495.32it/s]prepro_backdoor:  90%|████████▉ | 387811/432000 [01:04<00:07, 5927.96it/s]prepro_backdoor:  90%|████████▉ | 388415/432000 [01:04<00:07, 5763.41it/s]prepro_backdoor:  90%|█████████ | 389054/432000 [01:04<00:07, 5916.65it/s]prepro_backdoor:  90%|█████████ | 389669/432000 [01:05<00:07, 5885.52it/s]prepro_backdoor:  90%|█████████ | 390332/432000 [01:05<00:06, 6098.93it/s]prepro_backdoor:  90%|█████████ | 390946/432000 [01:05<00:07, 5824.89it/s]prepro_backdoor:  91%|█████████ | 391552/432000 [01:05<00:06, 5885.70it/s]prepro_backdoor:  91%|█████████ | 392251/432000 [01:05<00:06, 6188.46it/s]prepro_backdoor:  91%|█████████ | 392874/432000 [01:05<00:06, 5925.45it/s]prepro_backdoor:  91%|█████████ | 393474/432000 [01:05<00:06, 5937.82it/s]prepro_backdoor:  91%|█████████ | 394071/432000 [01:05<00:06, 5785.44it/s]prepro_backdoor:  91%|█████████▏| 394653/432000 [01:05<00:06, 5647.92it/s]prepro_backdoor:  91%|█████████▏| 395220/432000 [01:05<00:06, 5593.85it/s]prepro_backdoor:  92%|█████████▏| 395848/432000 [01:06<00:06, 5776.23it/s]prepro_backdoor:  92%|█████████▏| 396535/432000 [01:06<00:05, 6076.39it/s]prepro_backdoor:  92%|█████████▏| 397321/432000 [01:06<00:05, 6594.94it/s]prepro_backdoor:  92%|█████████▏| 397984/432000 [01:06<00:05, 6311.34it/s]prepro_backdoor:  92%|█████████▏| 398620/432000 [01:06<00:05, 6167.83it/s]prepro_backdoor:  92%|█████████▏| 399240/432000 [01:06<00:05, 5940.37it/s]prepro_backdoor:  93%|█████████▎| 399897/432000 [01:06<00:05, 6098.23it/s]prepro_backdoor:  93%|█████████▎| 400544/432000 [01:06<00:05, 6196.98it/s]prepro_backdoor:  93%|█████████▎| 401207/432000 [01:06<00:04, 6312.99it/s]prepro_backdoor:  93%|█████████▎| 401947/432000 [01:07<00:04, 6621.59it/s]prepro_backdoor:  93%|█████████▎| 402612/432000 [01:07<00:04, 6337.94it/s]prepro_backdoor:  93%|█████████▎| 403250/432000 [01:07<00:04, 5891.67it/s]prepro_backdoor:  93%|█████████▎| 403875/432000 [01:07<00:04, 5982.92it/s]prepro_backdoor:  94%|█████████▎| 404544/432000 [01:07<00:04, 6160.01it/s]prepro_backdoor:  94%|█████████▍| 405166/432000 [01:07<00:04, 6030.13it/s]prepro_backdoor:  94%|█████████▍| 405848/432000 [01:07<00:04, 6234.39it/s]prepro_backdoor:  94%|█████████▍| 406475/432000 [01:07<00:04, 6235.07it/s]prepro_backdoor:  94%|█████████▍| 407101/432000 [01:07<00:04, 6158.05it/s]prepro_backdoor:  94%|█████████▍| 407723/432000 [01:07<00:03, 6152.63it/s]prepro_backdoor:  95%|█████████▍| 408440/432000 [01:08<00:03, 6448.69it/s]prepro_backdoor:  95%|█████████▍| 409138/432000 [01:08<00:03, 6588.06it/s]prepro_backdoor:  95%|█████████▍| 409799/432000 [01:08<00:03, 6404.11it/s]prepro_backdoor:  95%|█████████▌| 410442/432000 [01:08<00:03, 5901.45it/s]prepro_backdoor:  95%|█████████▌| 411041/432000 [01:08<00:03, 5560.15it/s]prepro_backdoor:  95%|█████████▌| 411745/432000 [01:08<00:03, 5939.06it/s]prepro_backdoor:  95%|█████████▌| 412375/432000 [01:08<00:03, 6017.18it/s]prepro_backdoor:  96%|█████████▌| 412984/432000 [01:08<00:03, 5810.40it/s]prepro_backdoor:  96%|█████████▌| 413571/432000 [01:08<00:03, 5606.47it/s]prepro_backdoor:  96%|█████████▌| 414301/432000 [01:09<00:02, 6056.08it/s]prepro_backdoor:  96%|█████████▌| 414964/432000 [01:09<00:02, 6210.98it/s]prepro_backdoor:  96%|█████████▌| 415591/432000 [01:09<00:02, 6067.48it/s]prepro_backdoor:  96%|█████████▋| 416202/432000 [01:09<00:02, 5919.20it/s]prepro_backdoor:  96%|█████████▋| 416797/432000 [01:09<00:02, 5890.18it/s]prepro_backdoor:  97%|█████████▋| 417389/432000 [01:09<00:02, 5734.92it/s]prepro_backdoor:  97%|█████████▋| 417967/432000 [01:09<00:02, 5725.12it/s]prepro_backdoor:  97%|█████████▋| 418557/432000 [01:09<00:02, 5761.56it/s]prepro_backdoor:  97%|█████████▋| 419135/432000 [01:09<00:02, 5551.01it/s]prepro_backdoor:  97%|█████████▋| 419764/432000 [01:10<00:02, 5754.84it/s]prepro_backdoor:  97%|█████████▋| 420342/432000 [01:10<00:02, 5751.50it/s]prepro_backdoor:  97%|█████████▋| 420919/432000 [01:10<00:01, 5561.34it/s]prepro_backdoor:  98%|█████████▊| 421478/432000 [01:10<00:01, 5514.60it/s]prepro_backdoor:  98%|█████████▊| 422075/432000 [01:10<00:01, 5639.62it/s]prepro_backdoor:  98%|█████████▊| 422678/432000 [01:10<00:01, 5740.99it/s]prepro_backdoor:  98%|█████████▊| 423409/432000 [01:10<00:01, 6187.84it/s]prepro_backdoor:  98%|█████████▊| 424030/432000 [01:10<00:01, 6141.97it/s]prepro_backdoor:  98%|█████████▊| 424646/432000 [01:10<00:01, 6106.14it/s]prepro_backdoor:  98%|█████████▊| 425258/432000 [01:10<00:01, 5963.73it/s]prepro_backdoor:  99%|█████████▊| 425906/432000 [01:11<00:01, 6093.41it/s]prepro_backdoor:  99%|█████████▊| 426576/432000 [01:11<00:00, 6256.80it/s]prepro_backdoor:  99%|█████████▉| 427203/432000 [01:11<00:00, 6172.02it/s]prepro_backdoor:  99%|█████████▉| 427822/432000 [01:11<00:00, 5897.60it/s]prepro_backdoor:  99%|█████████▉| 428489/432000 [01:11<00:00, 6100.05it/s]prepro_backdoor:  99%|█████████▉| 429310/432000 [01:11<00:00, 6708.18it/s]prepro_backdoor: 100%|█████████▉| 429985/432000 [01:11<00:00, 6102.49it/s]prepro_backdoor: 100%|█████████▉| 430608/432000 [01:11<00:00, 6101.78it/s]prepro_backdoor: 100%|█████████▉| 431310/432000 [01:11<00:00, 6333.34it/s]prepro_backdoor: 100%|█████████▉| 431951/432000 [01:12<00:00, 6053.95it/s]prepro_backdoor: 100%|██████████| 432000/432000 [01:12<00:00, 5997.83it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:7000.0,real pratio:0.8333333333333334
2025-02-26:12:57:42 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:7000.0,real pratio:0.8333333333333334
INFO:root:save file format is .png
2025-02-26:12:57:42 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/8400 [00:00<?, ?it/s]prepro_backdoor:  17%|█▋        | 1461/8400 [00:00<00:00, 14449.51it/s]prepro_backdoor:  35%|███▍      | 2906/8400 [00:02<00:05, 1054.54it/s] prepro_backdoor:  42%|████▏     | 3539/8400 [00:03<00:05, 870.83it/s] prepro_backdoor:  47%|████▋     | 3910/8400 [00:04<00:05, 810.98it/s]prepro_backdoor:  50%|████▉     | 4159/8400 [00:04<00:05, 776.55it/s]prepro_backdoor:  52%|█████▏    | 4341/8400 [00:04<00:05, 746.68it/s]prepro_backdoor:  53%|█████▎    | 4482/8400 [00:04<00:05, 729.45it/s]prepro_backdoor:  55%|█████▍    | 4598/8400 [00:05<00:05, 717.31it/s]prepro_backdoor:  56%|█████▌    | 4698/8400 [00:05<00:05, 704.94it/s]prepro_backdoor:  57%|█████▋    | 4786/8400 [00:05<00:05, 693.65it/s]prepro_backdoor:  58%|█████▊    | 4867/8400 [00:05<00:05, 662.79it/s]prepro_backdoor:  59%|█████▉    | 4940/8400 [00:05<00:05, 658.38it/s]prepro_backdoor:  60%|█████▉    | 5010/8400 [00:05<00:05, 654.41it/s]prepro_backdoor:  60%|██████    | 5078/8400 [00:05<00:05, 653.26it/s]prepro_backdoor:  61%|██████▏   | 5146/8400 [00:06<00:05, 645.61it/s]prepro_backdoor:  62%|██████▏   | 5212/8400 [00:06<00:04, 644.44it/s]prepro_backdoor:  63%|██████▎   | 5278/8400 [00:06<00:04, 641.17it/s]prepro_backdoor:  64%|██████▎   | 5343/8400 [00:06<00:04, 641.12it/s]prepro_backdoor:  64%|██████▍   | 5408/8400 [00:06<00:04, 638.17it/s]prepro_backdoor:  65%|██████▌   | 5473/8400 [00:06<00:04, 639.61it/s]prepro_backdoor:  66%|██████▌   | 5538/8400 [00:06<00:04, 635.44it/s]prepro_backdoor:  67%|██████▋   | 5603/8400 [00:06<00:04, 637.31it/s]prepro_backdoor:  67%|██████▋   | 5668/8400 [00:06<00:04, 640.33it/s]prepro_backdoor:  68%|██████▊   | 5733/8400 [00:06<00:04, 641.19it/s]prepro_backdoor:  69%|██████▉   | 5798/8400 [00:07<00:04, 640.36it/s]prepro_backdoor:  70%|██████▉   | 5863/8400 [00:07<00:03, 639.45it/s]prepro_backdoor:  71%|███████   | 5928/8400 [00:07<00:03, 641.05it/s]prepro_backdoor:  71%|███████▏  | 5993/8400 [00:07<00:03, 641.10it/s]prepro_backdoor:  72%|███████▏  | 6058/8400 [00:07<00:03, 639.09it/s]prepro_backdoor:  73%|███████▎  | 6124/8400 [00:07<00:03, 642.54it/s]prepro_backdoor:  74%|███████▎  | 6192/8400 [00:07<00:03, 651.95it/s]prepro_backdoor:  74%|███████▍  | 6258/8400 [00:07<00:03, 648.96it/s]prepro_backdoor:  75%|███████▌  | 6323/8400 [00:07<00:03, 646.08it/s]prepro_backdoor:  76%|███████▌  | 6388/8400 [00:07<00:03, 621.87it/s]prepro_backdoor:  77%|███████▋  | 6455/8400 [00:08<00:03, 634.30it/s]prepro_backdoor:  78%|███████▊  | 6520/8400 [00:08<00:02, 637.27it/s]prepro_backdoor:  78%|███████▊  | 6585/8400 [00:08<00:02, 640.72it/s]prepro_backdoor:  79%|███████▉  | 6650/8400 [00:08<00:02, 634.48it/s]prepro_backdoor:  80%|███████▉  | 6714/8400 [00:08<00:02, 633.69it/s]prepro_backdoor:  81%|████████  | 6778/8400 [00:08<00:02, 631.85it/s]prepro_backdoor:  81%|████████▏ | 6843/8400 [00:08<00:02, 636.22it/s]prepro_backdoor:  82%|████████▏ | 6909/8400 [00:08<00:02, 642.69it/s]prepro_backdoor:  83%|████████▎ | 6974/8400 [00:08<00:02, 639.81it/s]prepro_backdoor:  84%|████████▍ | 7039/8400 [00:08<00:02, 639.13it/s]prepro_backdoor:  85%|████████▍ | 7103/8400 [00:09<00:02, 637.31it/s]prepro_backdoor:  85%|████████▌ | 7167/8400 [00:09<00:01, 635.18it/s]prepro_backdoor:  86%|████████▌ | 7233/8400 [00:09<00:01, 639.96it/s]prepro_backdoor:  87%|████████▋ | 7298/8400 [00:09<00:01, 639.19it/s]prepro_backdoor:  88%|████████▊ | 7363/8400 [00:09<00:01, 641.64it/s]prepro_backdoor:  88%|████████▊ | 7428/8400 [00:09<00:01, 640.15it/s]prepro_backdoor:  89%|████████▉ | 7493/8400 [00:09<00:01, 636.02it/s]prepro_backdoor:  90%|████████▉ | 7558/8400 [00:09<00:01, 638.98it/s]prepro_backdoor:  91%|█████████ | 7624/8400 [00:09<00:01, 643.14it/s]prepro_backdoor:  92%|█████████▏| 7689/8400 [00:10<00:01, 643.16it/s]prepro_backdoor:  92%|█████████▏| 7754/8400 [00:10<00:01, 637.95it/s]prepro_backdoor:  93%|█████████▎| 7818/8400 [00:10<00:00, 637.74it/s]prepro_backdoor:  94%|█████████▍| 7883/8400 [00:10<00:00, 641.07it/s]prepro_backdoor:  95%|█████████▍| 7948/8400 [00:10<00:00, 641.96it/s]prepro_backdoor:  95%|█████████▌| 8013/8400 [00:10<00:00, 639.12it/s]prepro_backdoor:  96%|█████████▌| 8077/8400 [00:10<00:00, 636.69it/s]prepro_backdoor:  97%|█████████▋| 8143/8400 [00:10<00:00, 640.75it/s]prepro_backdoor:  98%|█████████▊| 8208/8400 [00:10<00:00, 636.99it/s]prepro_backdoor:  98%|█████████▊| 8273/8400 [00:10<00:00, 639.35it/s]prepro_backdoor:  99%|█████████▉| 8338/8400 [00:11<00:00, 642.05it/s]prepro_backdoor: 100%|██████████| 8400/8400 [00:11<00:00, 755.32it/s]
INFO:root:stage2 start
2025-02-26:12:57:54 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2025-02-26:12:57:54 [INFO    ] [trainer_cls.py:972] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2025-02-26:12:57:54 [INFO    ] [trainer_cls.py:1030] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 329.5514302253723 s
2025-02-26:13:03:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 329.5514302253723 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
2025-02-26:13:03:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.8419463634491 s
2025-02-26:13:08:40 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.8419463634491 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
2025-02-26:13:08:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.62388134002686 s
2025-02-26:13:13:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.62388134002686 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
2025-02-26:13:14:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.2120463848114 s
2025-02-26:13:19:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.2120463848114 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
2025-02-26:13:19:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.87355399131775 s
2025-02-26:13:24:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.87355399131775 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
2025-02-26:13:24:37 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.5843050479889 s
2025-02-26:13:29:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.5843050479889 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
2025-02-26:13:29:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.395231962204 s
2025-02-26:13:35:00 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.395231962204 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
2025-02-26:13:35:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 314.43735575675964 s
2025-02-26:13:40:19 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 314.43735575675964 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
2025-02-26:13:40:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.24587965011597 s
2025-02-26:13:45:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.24587965011597 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
2025-02-26:13:45:38 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.479798078537 s
2025-02-26:13:50:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.479798078537 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
2025-02-26:13:50:48 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.35217475891113 s
2025-02-26:13:55:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.35217475891113 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
2025-02-26:13:56:02 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 290.33105516433716 s
2025-02-26:14:00:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 290.33105516433716 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
2025-02-26:14:00:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.6151692867279 s
2025-02-26:14:05:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.6151692867279 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
2025-02-26:14:06:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.59158515930176 s
2025-02-26:14:11:08 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.59158515930176 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
2025-02-26:14:11:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 292.98965406417847 s
2025-02-26:14:16:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 292.98965406417847 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
2025-02-26:14:16:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 285.7442970275879 s
2025-02-26:14:20:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 285.7442970275879 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
2025-02-26:14:21:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.0066318511963 s
2025-02-26:14:26:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.0066318511963 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
2025-02-26:14:26:13 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.0782096385956 s
2025-02-26:14:31:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.0782096385956 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
2025-02-26:14:31:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 315.48675084114075 s
2025-02-26:14:36:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 315.48675084114075 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
2025-02-26:14:36:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 289.07276940345764 s
2025-02-26:14:41:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 289.07276940345764 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
2025-02-26:14:41:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.5060086250305 s
2025-02-26:14:46:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.5060086250305 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
2025-02-26:14:46:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 287.24049735069275 s
2025-02-26:14:51:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 287.24049735069275 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
2025-02-26:14:51:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.75418996810913 s
2025-02-26:14:56:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.75418996810913 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
2025-02-26:14:57:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.47199869155884 s
2025-02-26:15:02:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.47199869155884 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
2025-02-26:15:02:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.22707414627075 s
2025-02-26:15:07:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.22707414627075 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
2025-02-26:15:07:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.48495268821716 s
2025-02-26:15:12:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.48495268821716 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
2025-02-26:15:12:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.83463072776794 s
2025-02-26:15:17:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.83463072776794 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
2025-02-26:15:17:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.31593680381775 s
2025-02-26:15:22:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.31593680381775 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
2025-02-26:15:23:02 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.6518805027008 s
2025-02-26:15:28:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.6518805027008 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
2025-02-26:15:28:16 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.751296043396 s
2025-02-26:15:33:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.751296043396 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
2025-02-26:15:33:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.10214948654175 s
2025-02-26:15:38:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.10214948654175 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
2025-02-26:15:38:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.39636969566345 s
2025-02-26:15:43:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.39636969566345 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
2025-02-26:15:43:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.85215520858765 s
2025-02-26:15:48:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.85215520858765 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
2025-02-26:15:49:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.6129295825958 s
2025-02-26:15:54:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.6129295825958 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
2025-02-26:15:54:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.37588357925415 s
2025-02-26:15:59:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.37588357925415 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
2025-02-26:15:59:20 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.24707078933716 s
2025-02-26:16:04:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.24707078933716 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
2025-02-26:16:04:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.05853295326233 s
2025-02-26:16:09:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.05853295326233 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
2025-02-26:16:09:38 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 301.03523874282837 s
2025-02-26:16:14:40 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 301.03523874282837 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
2025-02-26:16:14:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.4365212917328 s
2025-02-26:16:19:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.4365212917328 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
2025-02-26:16:19:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.83065128326416 s
2025-02-26:16:24:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.83065128326416 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
2025-02-26:16:24:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.7742328643799 s
2025-02-26:16:29:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.7742328643799 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
2025-02-26:16:30:02 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 301.00764298439026 s
2025-02-26:16:35:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 301.00764298439026 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
2025-02-26:16:35:08 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.2209475040436 s
2025-02-26:16:40:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.2209475040436 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
2025-02-26:16:40:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.69898080825806 s
2025-02-26:16:45:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.69898080825806 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
2025-02-26:16:45:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.38914918899536 s
2025-02-26:16:50:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.38914918899536 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
2025-02-26:16:50:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.2153146266937 s
2025-02-26:16:55:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.2153146266937 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
2025-02-26:16:55:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.0981056690216 s
2025-02-26:17:00:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.0981056690216 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
2025-02-26:17:00:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.7219281196594 s
2025-02-26:17:06:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.7219281196594 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
2025-02-26:17:06:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.22238945961 s
2025-02-26:17:11:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.22238945961 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
2025-02-26:17:11:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 299.03640723228455 s
2025-02-26:17:16:19 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 299.03640723228455 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
2025-02-26:17:16:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.1946904659271 s
2025-02-26:17:21:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.1946904659271 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
2025-02-26:17:21:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.1535379886627 s
2025-02-26:17:26:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.1535379886627 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
2025-02-26:17:26:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.1581349372864 s
2025-02-26:17:31:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.1581349372864 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
2025-02-26:17:31:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.3979308605194 s
2025-02-26:17:36:58 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.3979308605194 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
2025-02-26:17:37:02 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.041255235672 s
2025-02-26:17:42:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.041255235672 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
2025-02-26:17:42:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.055623292923 s
2025-02-26:17:47:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.055623292923 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
2025-02-26:17:47:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.71022176742554 s
2025-02-26:17:52:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.71022176742554 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
2025-02-26:17:52:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.47133350372314 s
2025-02-26:17:57:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.47133350372314 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
2025-02-26:17:57:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.0928614139557 s
2025-02-26:18:03:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.0928614139557 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
2025-02-26:18:03:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.62787771224976 s
2025-02-26:18:08:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.62787771224976 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
2025-02-26:18:08:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.99217796325684 s
2025-02-26:18:13:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.99217796325684 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
2025-02-26:18:13:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.07967162132263 s
2025-02-26:18:18:23 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.07967162132263 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
2025-02-26:18:18:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.00194811820984 s
2025-02-26:18:23:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.00194811820984 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
2025-02-26:18:23:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.91261076927185 s
2025-02-26:18:28:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.91261076927185 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
2025-02-26:18:28:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.6925208568573 s
2025-02-26:18:33:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.6925208568573 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
2025-02-26:18:34:00 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.0831162929535 s
2025-02-26:18:39:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.0831162929535 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
2025-02-26:18:39:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 296.14801812171936 s
2025-02-26:18:44:08 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 296.14801812171936 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
2025-02-26:18:44:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.02846908569336 s
2025-02-26:18:49:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.02846908569336 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
2025-02-26:18:49:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 296.9954466819763 s
2025-02-26:18:54:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 296.9954466819763 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
2025-02-26:18:54:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.6057720184326 s
2025-02-26:18:59:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.6057720184326 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
2025-02-26:18:59:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.2181541919708 s
2025-02-26:19:04:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.2181541919708 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
2025-02-26:19:04:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 287.9321038722992 s
2025-02-26:19:09:42 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 287.9321038722992 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
2025-02-26:19:09:47 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.2559061050415 s
2025-02-26:19:14:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.2559061050415 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
2025-02-26:19:15:00 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 281.89067101478577 s
2025-02-26:19:19:43 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 281.89067101478577 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
2025-02-26:19:19:47 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 279.5128803253174 s
2025-02-26:19:24:27 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 279.5128803253174 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
2025-02-26:19:24:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.74429059028625 s
2025-02-26:19:29:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.74429059028625 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
2025-02-26:19:29:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.0629868507385 s
2025-02-26:19:34:53 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.0629868507385 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
2025-02-26:19:34:57 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.9263710975647 s
2025-02-26:19:39:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.9263710975647 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
2025-02-26:19:40:00 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.48042249679565 s
2025-02-26:19:45:11 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.48042249679565 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
2025-02-26:19:45:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 310.34923005104065 s
2025-02-26:19:50:26 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 310.34923005104065 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
2025-02-26:19:50:31 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.8624622821808 s
2025-02-26:19:55:30 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.8624622821808 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
2025-02-26:19:55:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 293.3631491661072 s
2025-02-26:20:00:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 293.3631491661072 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
2025-02-26:20:00:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.0505928993225 s
2025-02-26:20:05:42 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.0505928993225 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
2025-02-26:20:05:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.34645771980286 s
2025-02-26:20:10:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.34645771980286 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
2025-02-26:20:10:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.8932263851166 s
2025-02-26:20:16:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.8932263851166 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
2025-02-26:20:16:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.1012637615204 s
2025-02-26:20:21:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.1012637615204 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
2025-02-26:20:21:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 289.71555352211 s
2025-02-26:20:26:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 289.71555352211 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
2025-02-26:20:26:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.63604283332825 s
2025-02-26:20:31:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.63604283332825 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
2025-02-26:20:31:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 326.87449312210083 s
2025-02-26:20:36:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 326.87449312210083 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
2025-02-26:20:36:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.5751066207886 s
2025-02-26:20:42:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.5751066207886 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
2025-02-26:20:42:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.592236995697 s
2025-02-26:20:47:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.592236995697 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
2025-02-26:20:47:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.04024744033813 s
2025-02-26:20:52:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.04024744033813 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
2025-02-26:20:52:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.3494131565094 s
2025-02-26:20:57:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.3494131565094 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
2025-02-26:20:57:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 290.9726974964142 s
2025-02-26:21:02:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 290.9726974964142 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
2025-02-26:21:02:37 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 282.26047921180725 s
2025-02-26:21:07:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 282.26047921180725 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
2025-02-26:21:07:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.5828802585602 s
2025-02-26:21:12:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.5828802585602 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
2025-02-26:21:12:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.9080250263214 s
2025-02-26:21:17:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.9080250263214 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
2025-02-26:21:17:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 296.685400724411 s
2025-02-26:21:22:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 296.685400724411 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
2025-02-26:21:22:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 317.87656903266907 s
2025-02-26:21:28:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 317.87656903266907 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
2025-02-26:21:28:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.3872971534729 s
2025-02-26:21:33:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.3872971534729 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
2025-02-26:21:33:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2025-02-26:21:33:11 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/badnet_attack_efficientnet_ffpp_6classes/attack_result.pt
INFO:root:Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_6classes
2025-02-26:21:33:12 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/badnet_attack_efficientnet_ffpp_6classes
