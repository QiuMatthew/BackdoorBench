/home/fmg/yuran/miniconda3/envs/backdoorbenchv2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libc10_hip.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
INFO:root:{'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'nad_badnet_attack_efficientnet_ffpp_multiclass',
 'save_path': './record/nad_badnet_attack_efficientnet_ffpp_multiclass',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'nad_badnet_attack_efficientnet_ffpp_multiclass'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
2025-03-09:18:41:13 [INFO    ] [prototype.py:124] {'amp': False,
 'attack': 'badnet',
 'attack_label_trans': 'all2one',
 'attack_target': 0,
 'batch_size': 128,
 'bd_yaml_path': './config/attack/badnet/default.yaml',
 'client_optimizer': 'sgd',
 'dataset': 'ffpp_multiclass',
 'dataset_path': './data/ffpp_multiclass',
 'device': 'cuda:0',
 'epochs': 100,
 'frequency_save': 0,
 'img_size': (64, 64, 3),
 'input_channel': 3,
 'input_height': 64,
 'input_width': 64,
 'lr': 0.01,
 'lr_scheduler': 'CosineAnnealingLR',
 'model': 'efficientnet_b3',
 'non_blocking': True,
 'num_classes': 6,
 'num_workers': 4,
 'patch_mask_path': './resource/badnet/trigger_image.png',
 'pin_memory': True,
 'pratio': 0.1,
 'prefetch': False,
 'random_seed': 0,
 'save_folder_name': 'nad_badnet_attack_efficientnet_ffpp_multiclass',
 'save_path': './record/nad_badnet_attack_efficientnet_ffpp_multiclass',
 'sgd_momentum': 0.9,
 'terminal_info': ['./attack/badnet.py',
                   '--yaml_path',
                   './config/attack/prototype/cifar10.yaml',
                   '--model',
                   'efficientnet_b3',
                   '--dataset',
                   'ffpp_multiclass',
                   '--patch_mask_path',
                   './resource/badnet/trigger_image.png',
                   '--save_folder_name',
                   'nad_badnet_attack_efficientnet_ffpp_multiclass'],
 'wd': 0.0005,
 'yaml_path': './config/attack/prototype/cifar10.yaml'}
DEBUG:root:Only INFO or above level log will show in cmd. DEBUG level log only will show in log file.
DEBUG:root:{'git hash': '--git_hash 93c010236cd5097975442a3536e583b4a158ed70',
 'last 3 log': 'commit 93c010236cd5097975442a3536e583b4a158ed70\n'
               'Author: QiuMatthew <uzenkyu@gmail.com>\n'
               'Date:   Sun Mar 9 18:40:02 2025 +0900\n'
               '\n'
               '    new script: badnet attack multiclass, will use nad defense '
               'later\n'
               '\n'
               'commit 4edf940e5ff7b72cfeb82a61bfcc05ff0016913c\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Wed Mar 5 16:30:14 2025 +0900\n'
               '\n'
               '    update gitignroe\n'
               '\n'
               'commit 2f4576fc48ceb3f440b34a15c730a9ae83a22140\n'
               'Author: QiuMatthew <q_masio@outlook.com>\n'
               'Date:   Wed Mar 5 16:09:03 2025 +0900\n'
               '\n'
               '    add prefix for script filenames',
 'status': 'On branch nad\n'
           "Your branch is up to date with 'origin/nad'.\n"
           '\n'
           'Untracked files:\n'
           '  (use "git add <file>..." to include in what will be committed)\n'
           '\tout/nad_badnet_attack_efficientnet_ffpp_multiclass.out\n'
           '\n'
           'nothing added to commit but untracked files present (use "git add" '
           'to track)'}
INFO:root:stage1 start
2025-03-09:18:41:14 [INFO    ] [badnet.py:111] stage1 start
WARNING:root:For ImageNet, this script need large size of RAM to load the whole dataset.
2025-03-09:18:41:14 [WARNING ] [dataset_and_transform_generate.py:356] For ImageNet, this script need large size of RAM to load the whole dataset.
DEBUG:root:We will provide a different script later to handle this problem for backdoor ImageNet.
DEBUG:root:dataset_and_transform_generate done
DEBUG:root:get .targets
DEBUG:root:get .targets
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:43200.0,real pratio:0.1
2025-03-09:18:51:16 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:43200.0,real pratio:0.1
DEBUG:root:poison train idx is saved
INFO:root:save file format is .png
2025-03-09:18:51:17 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/432000 [00:00<?, ?it/s]prepro_backdoor:   0%|          | 226/432000 [00:00<03:12, 2247.65it/s]prepro_backdoor:   0%|          | 646/432000 [00:00<02:08, 3347.69it/s]prepro_backdoor:   0%|          | 1031/432000 [00:00<02:01, 3535.02it/s]prepro_backdoor:   0%|          | 1384/432000 [00:00<02:03, 3477.02it/s]prepro_backdoor:   0%|          | 1799/432000 [00:00<01:56, 3691.10it/s]prepro_backdoor:   1%|          | 2211/432000 [00:00<01:52, 3822.76it/s]prepro_backdoor:   1%|          | 2594/432000 [00:00<01:55, 3721.14it/s]prepro_backdoor:   1%|          | 3019/432000 [00:00<01:50, 3868.34it/s]prepro_backdoor:   1%|          | 3407/432000 [00:00<01:51, 3832.72it/s]prepro_backdoor:   1%|          | 3791/432000 [00:01<02:04, 3433.41it/s]prepro_backdoor:   1%|          | 4165/432000 [00:01<02:02, 3501.88it/s]prepro_backdoor:   1%|          | 4546/432000 [00:01<01:59, 3576.08it/s]prepro_backdoor:   1%|          | 4909/432000 [00:01<02:13, 3206.57it/s]prepro_backdoor:   1%|          | 5263/432000 [00:01<02:10, 3268.68it/s]prepro_backdoor:   1%|▏         | 5597/432000 [00:01<02:14, 3180.96it/s]prepro_backdoor:   1%|▏         | 6014/432000 [00:01<02:03, 3445.57it/s]prepro_backdoor:   1%|▏         | 6390/432000 [00:01<02:01, 3506.16it/s]prepro_backdoor:   2%|▏         | 6745/432000 [00:01<02:11, 3241.27it/s]prepro_backdoor:   2%|▏         | 7076/432000 [00:02<02:13, 3194.39it/s]prepro_backdoor:   2%|▏         | 7400/432000 [00:02<02:15, 3126.79it/s]prepro_backdoor:   2%|▏         | 7716/432000 [00:02<02:19, 3038.29it/s]prepro_backdoor:   2%|▏         | 8022/432000 [00:02<02:19, 3034.28it/s]prepro_backdoor:   2%|▏         | 8327/432000 [00:02<02:21, 3001.69it/s]prepro_backdoor:   2%|▏         | 8655/432000 [00:02<02:18, 3056.29it/s]prepro_backdoor:   2%|▏         | 8991/432000 [00:02<02:14, 3139.28it/s]prepro_backdoor:   2%|▏         | 9373/432000 [00:02<02:07, 3324.33it/s]prepro_backdoor:   2%|▏         | 9707/432000 [00:02<02:10, 3228.82it/s]prepro_backdoor:   2%|▏         | 10032/432000 [00:03<02:11, 3217.12it/s]prepro_backdoor:   2%|▏         | 10355/432000 [00:03<02:13, 3157.71it/s]prepro_backdoor:   3%|▎         | 10811/432000 [00:03<01:58, 3559.68it/s]prepro_backdoor:   3%|▎         | 11169/432000 [00:03<02:09, 3242.78it/s]prepro_backdoor:   3%|▎         | 11535/432000 [00:03<02:05, 3353.34it/s]prepro_backdoor:   3%|▎         | 11876/432000 [00:03<02:08, 3277.09it/s]prepro_backdoor:   3%|▎         | 12240/432000 [00:03<02:04, 3374.05it/s]prepro_backdoor:   3%|▎         | 12643/432000 [00:03<01:58, 3539.82it/s]prepro_backdoor:   3%|▎         | 13000/432000 [00:03<02:04, 3373.04it/s]prepro_backdoor:   3%|▎         | 13360/432000 [00:03<02:02, 3413.11it/s]prepro_backdoor:   3%|▎         | 13704/432000 [00:04<02:04, 3347.41it/s]prepro_backdoor:   3%|▎         | 14067/432000 [00:04<02:01, 3426.03it/s]prepro_backdoor:   3%|▎         | 14444/432000 [00:04<01:59, 3502.98it/s]prepro_backdoor:   3%|▎         | 14796/432000 [00:04<02:02, 3406.30it/s]prepro_backdoor:   4%|▎         | 15147/432000 [00:04<02:02, 3412.38it/s]prepro_backdoor:   4%|▎         | 15490/432000 [00:04<02:06, 3291.58it/s]prepro_backdoor:   4%|▎         | 15821/432000 [00:04<02:13, 3111.04it/s]prepro_backdoor:   4%|▎         | 16135/432000 [00:04<02:16, 3039.47it/s]prepro_backdoor:   4%|▍         | 16465/432000 [00:04<02:13, 3110.33it/s]prepro_backdoor:   4%|▍         | 16832/432000 [00:05<02:07, 3256.69it/s]prepro_backdoor:   4%|▍         | 17160/432000 [00:05<02:16, 3037.56it/s]prepro_backdoor:   4%|▍         | 17468/432000 [00:05<02:22, 2913.36it/s]prepro_backdoor:   4%|▍         | 17767/432000 [00:05<02:21, 2927.99it/s]prepro_backdoor:   4%|▍         | 18062/432000 [00:05<02:21, 2924.93it/s]prepro_backdoor:   4%|▍         | 18431/432000 [00:05<02:12, 3118.61it/s]prepro_backdoor:   4%|▍         | 18833/432000 [00:05<02:02, 3376.74it/s]prepro_backdoor:   4%|▍         | 19219/432000 [00:05<01:57, 3509.83it/s]prepro_backdoor:   5%|▍         | 19595/432000 [00:05<01:55, 3570.03it/s]prepro_backdoor:   5%|▍         | 19954/432000 [00:06<02:01, 3379.52it/s]prepro_backdoor:   5%|▍         | 20316/432000 [00:06<02:00, 3428.37it/s]prepro_backdoor:   5%|▍         | 20671/432000 [00:06<02:04, 3295.03it/s]prepro_backdoor:   5%|▍         | 21017/432000 [00:06<02:03, 3321.54it/s]prepro_backdoor:   5%|▍         | 21352/432000 [00:06<02:11, 3120.09it/s]prepro_backdoor:   5%|▌         | 21821/432000 [00:06<01:56, 3532.96it/s]prepro_backdoor:   5%|▌         | 22180/432000 [00:06<02:16, 3010.37it/s]prepro_backdoor:   5%|▌         | 22509/432000 [00:06<02:13, 3064.82it/s]prepro_backdoor:   5%|▌         | 22873/432000 [00:06<02:08, 3192.78it/s]prepro_backdoor:   5%|▌         | 23202/432000 [00:07<02:16, 3003.28it/s]prepro_backdoor:   5%|▌         | 23556/432000 [00:07<02:10, 3131.40it/s]prepro_backdoor:   6%|▌         | 23964/432000 [00:07<02:00, 3388.97it/s]prepro_backdoor:   6%|▌         | 24311/432000 [00:07<02:03, 3294.54it/s]prepro_backdoor:   6%|▌         | 24665/432000 [00:07<02:01, 3358.50it/s]prepro_backdoor:   6%|▌         | 25005/432000 [00:07<02:04, 3277.93it/s]prepro_backdoor:   6%|▌         | 25336/432000 [00:07<02:07, 3182.55it/s]prepro_backdoor:   6%|▌         | 25679/432000 [00:07<02:05, 3245.11it/s]prepro_backdoor:   6%|▌         | 26119/432000 [00:07<01:54, 3550.50it/s]prepro_backdoor:   6%|▌         | 26477/432000 [00:08<02:06, 3206.93it/s]prepro_backdoor:   6%|▌         | 26890/432000 [00:08<01:57, 3436.16it/s]prepro_backdoor:   6%|▋         | 27241/432000 [00:08<02:01, 3317.83it/s]prepro_backdoor:   6%|▋         | 27624/432000 [00:08<01:57, 3444.55it/s]prepro_backdoor:   6%|▋         | 27974/432000 [00:08<02:03, 3280.65it/s]prepro_backdoor:   7%|▋         | 28307/432000 [00:08<02:18, 2921.19it/s]prepro_backdoor:   7%|▋         | 28608/432000 [00:08<02:32, 2646.99it/s]prepro_backdoor:   7%|▋         | 28882/432000 [00:08<02:45, 2438.78it/s]prepro_backdoor:   7%|▋         | 29329/432000 [00:09<02:17, 2933.52it/s]prepro_backdoor:   7%|▋         | 29650/432000 [00:09<02:15, 2977.41it/s]prepro_backdoor:   7%|▋         | 30056/432000 [00:09<02:03, 3254.36it/s]prepro_backdoor:   7%|▋         | 30393/432000 [00:09<02:09, 3102.69it/s]prepro_backdoor:   7%|▋         | 30838/432000 [00:09<01:56, 3445.60it/s]prepro_backdoor:   7%|▋         | 31192/432000 [00:09<02:04, 3214.26it/s]prepro_backdoor:   7%|▋         | 31541/432000 [00:09<02:02, 3264.79it/s]prepro_backdoor:   7%|▋         | 31916/432000 [00:09<01:57, 3391.96it/s]prepro_backdoor:   7%|▋         | 32261/432000 [00:09<02:10, 3062.84it/s]prepro_backdoor:   8%|▊         | 32596/432000 [00:10<02:07, 3126.52it/s]prepro_backdoor:   8%|▊         | 32916/432000 [00:10<02:18, 2873.72it/s]prepro_backdoor:   8%|▊         | 33226/432000 [00:10<02:16, 2920.11it/s]prepro_backdoor:   8%|▊         | 33576/432000 [00:10<02:10, 3054.98it/s]prepro_backdoor:   8%|▊         | 33887/432000 [00:10<02:10, 3054.54it/s]prepro_backdoor:   8%|▊         | 34197/432000 [00:10<02:11, 3025.24it/s]prepro_backdoor:   8%|▊         | 34511/432000 [00:10<02:10, 3049.95it/s]prepro_backdoor:   8%|▊         | 34822/432000 [00:10<02:09, 3058.42it/s]prepro_backdoor:   8%|▊         | 35130/432000 [00:10<02:14, 2949.06it/s]prepro_backdoor:   8%|▊         | 35427/432000 [00:10<02:17, 2892.57it/s]prepro_backdoor:   8%|▊         | 35798/432000 [00:11<02:06, 3124.55it/s]prepro_backdoor:   8%|▊         | 36145/432000 [00:11<02:02, 3219.28it/s]prepro_backdoor:   8%|▊         | 36469/432000 [00:11<02:02, 3219.25it/s]prepro_backdoor:   9%|▊         | 36793/432000 [00:11<02:06, 3126.28it/s]prepro_backdoor:   9%|▊         | 37107/432000 [00:11<02:10, 3018.67it/s]prepro_backdoor:   9%|▊         | 37411/432000 [00:11<02:23, 2754.66it/s]prepro_backdoor:   9%|▊         | 37700/432000 [00:11<02:21, 2790.43it/s]prepro_backdoor:   9%|▉         | 37992/432000 [00:11<02:20, 2804.37it/s]prepro_backdoor:   9%|▉         | 38276/432000 [00:11<02:26, 2691.70it/s]prepro_backdoor:   9%|▉         | 38548/432000 [00:12<02:27, 2664.65it/s]prepro_backdoor:   9%|▉         | 38929/432000 [00:12<02:12, 2962.47it/s]prepro_backdoor:   9%|▉         | 39323/432000 [00:12<02:02, 3217.12it/s]prepro_backdoor:   9%|▉         | 39648/432000 [00:12<02:10, 3016.59it/s]prepro_backdoor:   9%|▉         | 40059/432000 [00:12<01:58, 3297.89it/s]prepro_backdoor:   9%|▉         | 40394/432000 [00:12<02:02, 3184.87it/s]prepro_backdoor:   9%|▉         | 40906/432000 [00:12<01:45, 3703.25it/s]prepro_backdoor:  10%|▉         | 41282/432000 [00:12<01:49, 3580.13it/s]prepro_backdoor:  10%|▉         | 41645/432000 [00:12<01:50, 3536.22it/s]prepro_backdoor:  10%|▉         | 42002/432000 [00:13<02:01, 3213.03it/s]prepro_backdoor:  10%|▉         | 42330/432000 [00:13<02:10, 2976.15it/s]prepro_backdoor:  10%|▉         | 42635/432000 [00:13<02:12, 2949.40it/s]prepro_backdoor:  10%|▉         | 42935/432000 [00:13<02:21, 2753.73it/s]prepro_backdoor:  10%|█         | 43223/432000 [00:13<02:20, 2758.87it/s]prepro_backdoor:  10%|█         | 43502/432000 [00:13<02:34, 2512.38it/s]prepro_backdoor:  10%|█         | 43759/432000 [00:13<02:44, 2363.70it/s]prepro_backdoor:  10%|█         | 44018/432000 [00:13<02:41, 2401.42it/s]prepro_backdoor:  10%|█         | 44262/432000 [00:14<02:46, 2334.44it/s]prepro_backdoor:  10%|█         | 44546/432000 [00:14<02:37, 2458.63it/s]prepro_backdoor:  10%|█         | 44795/432000 [00:14<02:51, 2251.92it/s]prepro_backdoor:  10%|█         | 45025/432000 [00:14<03:00, 2140.44it/s]prepro_backdoor:  10%|█         | 45243/432000 [00:14<03:09, 2039.63it/s]prepro_backdoor:  11%|█         | 45450/432000 [00:14<03:12, 2007.26it/s]prepro_backdoor:  11%|█         | 45653/432000 [00:14<03:15, 1972.84it/s]prepro_backdoor:  11%|█         | 45866/432000 [00:14<03:11, 2015.75it/s]prepro_backdoor:  11%|█         | 46088/432000 [00:14<03:07, 2058.27it/s]prepro_backdoor:  11%|█         | 46421/432000 [00:15<02:40, 2394.91it/s]prepro_backdoor:  11%|█         | 46696/432000 [00:15<02:34, 2495.77it/s]prepro_backdoor:  11%|█         | 46963/432000 [00:15<02:32, 2522.99it/s]prepro_backdoor:  11%|█         | 47217/432000 [00:15<02:44, 2334.97it/s]prepro_backdoor:  11%|█         | 47454/432000 [00:15<02:46, 2316.18it/s]prepro_backdoor:  11%|█         | 47712/432000 [00:15<02:41, 2380.31it/s]prepro_backdoor:  11%|█         | 47952/432000 [00:15<02:56, 2172.78it/s]prepro_backdoor:  11%|█         | 48184/432000 [00:15<02:54, 2197.98it/s]prepro_backdoor:  11%|█         | 48407/432000 [00:15<03:11, 2002.34it/s]prepro_backdoor:  11%|█▏        | 48649/432000 [00:16<03:03, 2089.04it/s]prepro_backdoor:  11%|█▏        | 48863/432000 [00:16<03:05, 2068.53it/s]prepro_backdoor:  11%|█▏        | 49073/432000 [00:16<03:19, 1915.36it/s]prepro_backdoor:  11%|█▏        | 49283/432000 [00:16<03:16, 1948.98it/s]prepro_backdoor:  11%|█▏        | 49557/432000 [00:16<02:57, 2157.42it/s]prepro_backdoor:  12%|█▏        | 49844/432000 [00:16<02:42, 2350.68it/s]prepro_backdoor:  12%|█▏        | 50083/432000 [00:16<02:55, 2173.70it/s]prepro_backdoor:  12%|█▏        | 50306/432000 [00:16<02:59, 2122.11it/s]prepro_backdoor:  12%|█▏        | 50599/432000 [00:16<02:43, 2327.57it/s]prepro_backdoor:  12%|█▏        | 50836/432000 [00:17<02:47, 2273.34it/s]prepro_backdoor:  12%|█▏        | 51067/432000 [00:17<02:50, 2236.29it/s]prepro_backdoor:  12%|█▏        | 51361/432000 [00:17<02:37, 2413.26it/s]prepro_backdoor:  12%|█▏        | 51648/432000 [00:17<02:29, 2540.62it/s]prepro_backdoor:  12%|█▏        | 51905/432000 [00:17<02:47, 2264.23it/s]prepro_backdoor:  12%|█▏        | 52153/432000 [00:17<02:45, 2300.56it/s]prepro_backdoor:  12%|█▏        | 52392/432000 [00:17<02:43, 2319.47it/s]prepro_backdoor:  12%|█▏        | 52628/432000 [00:17<02:44, 2304.79it/s]prepro_backdoor:  12%|█▏        | 52909/432000 [00:17<02:36, 2421.58it/s]prepro_backdoor:  12%|█▏        | 53154/432000 [00:18<02:44, 2303.81it/s]prepro_backdoor:  12%|█▏        | 53444/432000 [00:18<02:34, 2449.64it/s]prepro_backdoor:  12%|█▏        | 53692/432000 [00:18<02:35, 2438.50it/s]prepro_backdoor:  12%|█▏        | 53951/432000 [00:18<02:33, 2455.41it/s]prepro_backdoor:  13%|█▎        | 54207/432000 [00:18<02:32, 2483.10it/s]prepro_backdoor:  13%|█▎        | 54467/432000 [00:18<02:30, 2515.82it/s]prepro_backdoor:  13%|█▎        | 54823/432000 [00:18<02:13, 2821.12it/s]prepro_backdoor:  13%|█▎        | 55107/432000 [00:18<02:17, 2738.05it/s]prepro_backdoor:  13%|█▎        | 55383/432000 [00:18<02:18, 2719.48it/s]prepro_backdoor:  13%|█▎        | 55656/432000 [00:18<02:20, 2687.20it/s]prepro_backdoor:  13%|█▎        | 55995/432000 [00:19<02:10, 2889.10it/s]prepro_backdoor:  13%|█▎        | 56286/432000 [00:19<02:10, 2883.99it/s]prepro_backdoor:  13%|█▎        | 56576/432000 [00:19<02:19, 2688.28it/s]prepro_backdoor:  13%|█▎        | 56848/432000 [00:19<02:19, 2686.31it/s]prepro_backdoor:  13%|█▎        | 57119/432000 [00:19<02:23, 2607.49it/s]prepro_backdoor:  13%|█▎        | 57382/432000 [00:19<02:29, 2501.44it/s]prepro_backdoor:  13%|█▎        | 57634/432000 [00:19<02:29, 2496.92it/s]prepro_backdoor:  13%|█▎        | 57885/432000 [00:19<02:37, 2369.29it/s]prepro_backdoor:  13%|█▎        | 58124/432000 [00:19<02:39, 2349.80it/s]prepro_backdoor:  14%|█▎        | 58361/432000 [00:20<02:44, 2276.79it/s]prepro_backdoor:  14%|█▎        | 58683/432000 [00:20<02:27, 2534.80it/s]prepro_backdoor:  14%|█▎        | 58939/432000 [00:20<02:29, 2501.59it/s]prepro_backdoor:  14%|█▎        | 59195/432000 [00:20<02:29, 2499.55it/s]prepro_backdoor:  14%|█▍        | 59506/432000 [00:20<02:19, 2663.18it/s]prepro_backdoor:  14%|█▍        | 59774/432000 [00:20<02:27, 2530.47it/s]prepro_backdoor:  14%|█▍        | 60051/432000 [00:20<02:24, 2573.16it/s]prepro_backdoor:  14%|█▍        | 60310/432000 [00:20<02:33, 2416.35it/s]prepro_backdoor:  14%|█▍        | 60563/432000 [00:20<02:33, 2423.84it/s]prepro_backdoor:  14%|█▍        | 60808/432000 [00:21<02:40, 2316.16it/s]prepro_backdoor:  14%|█▍        | 61082/432000 [00:21<02:33, 2419.85it/s]prepro_backdoor:  14%|█▍        | 61326/432000 [00:21<02:36, 2369.86it/s]prepro_backdoor:  14%|█▍        | 61651/432000 [00:21<02:22, 2595.79it/s]prepro_backdoor:  14%|█▍        | 61931/432000 [00:21<02:20, 2626.30it/s]prepro_backdoor:  14%|█▍        | 62195/432000 [00:21<02:24, 2551.71it/s]prepro_backdoor:  14%|█▍        | 62477/432000 [00:21<02:21, 2619.90it/s]prepro_backdoor:  15%|█▍        | 62761/432000 [00:21<02:18, 2668.56it/s]prepro_backdoor:  15%|█▍        | 63029/432000 [00:21<02:29, 2469.09it/s]prepro_backdoor:  15%|█▍        | 63280/432000 [00:22<02:39, 2307.59it/s]prepro_backdoor:  15%|█▍        | 63571/432000 [00:22<02:30, 2451.10it/s]prepro_backdoor:  15%|█▍        | 63820/432000 [00:22<02:36, 2351.57it/s]prepro_backdoor:  15%|█▍        | 64061/432000 [00:22<02:35, 2365.05it/s]prepro_backdoor:  15%|█▍        | 64300/432000 [00:22<02:37, 2328.95it/s]prepro_backdoor:  15%|█▍        | 64583/432000 [00:22<02:29, 2451.54it/s]prepro_backdoor:  15%|█▌        | 64830/432000 [00:22<02:59, 2048.25it/s]prepro_backdoor:  15%|█▌        | 65297/432000 [00:22<02:15, 2700.33it/s]prepro_backdoor:  15%|█▌        | 65672/432000 [00:22<02:02, 2978.77it/s]prepro_backdoor:  15%|█▌        | 66099/432000 [00:23<01:50, 3326.35it/s]prepro_backdoor:  15%|█▌        | 66458/432000 [00:23<01:47, 3391.97it/s]prepro_backdoor:  15%|█▌        | 66808/432000 [00:23<01:46, 3416.73it/s]prepro_backdoor:  16%|█▌        | 67233/432000 [00:23<01:40, 3640.42it/s]prepro_backdoor:  16%|█▌        | 67603/432000 [00:23<01:43, 3503.86it/s]prepro_backdoor:  16%|█▌        | 68007/432000 [00:23<01:40, 3637.54it/s]prepro_backdoor:  16%|█▌        | 68477/432000 [00:23<01:32, 3931.72it/s]prepro_backdoor:  16%|█▌        | 68874/432000 [00:23<01:33, 3893.83it/s]prepro_backdoor:  16%|█▌        | 69294/432000 [00:23<01:31, 3959.76it/s]prepro_backdoor:  16%|█▌        | 69715/432000 [00:23<01:29, 4025.62it/s]prepro_backdoor:  16%|█▌        | 70120/432000 [00:24<01:33, 3891.15it/s]prepro_backdoor:  16%|█▋        | 70511/432000 [00:24<01:51, 3248.01it/s]prepro_backdoor:  16%|█▋        | 70855/432000 [00:24<01:51, 3247.00it/s]prepro_backdoor:  16%|█▋        | 71232/432000 [00:24<01:46, 3375.23it/s]prepro_backdoor:  17%|█▋        | 71632/432000 [00:24<01:41, 3537.86it/s]prepro_backdoor:  17%|█▋        | 71995/432000 [00:24<01:41, 3537.32it/s]prepro_backdoor:  17%|█▋        | 72355/432000 [00:24<01:42, 3524.76it/s]prepro_backdoor:  17%|█▋        | 72782/432000 [00:24<01:36, 3730.45it/s]prepro_backdoor:  17%|█▋        | 73159/432000 [00:24<01:38, 3655.42it/s]prepro_backdoor:  17%|█▋        | 73528/432000 [00:25<01:38, 3623.04it/s]prepro_backdoor:  17%|█▋        | 73893/432000 [00:25<01:42, 3482.99it/s]prepro_backdoor:  17%|█▋        | 74252/432000 [00:25<01:42, 3485.09it/s]prepro_backdoor:  17%|█▋        | 74603/432000 [00:25<01:55, 3086.21it/s]prepro_backdoor:  17%|█▋        | 74921/432000 [00:25<01:55, 3080.32it/s]prepro_backdoor:  17%|█▋        | 75235/432000 [00:25<02:01, 2945.60it/s]prepro_backdoor:  17%|█▋        | 75544/432000 [00:25<01:59, 2975.39it/s]prepro_backdoor:  18%|█▊        | 75855/432000 [00:25<01:59, 2991.62it/s]prepro_backdoor:  18%|█▊        | 76239/432000 [00:25<01:50, 3212.33it/s]prepro_backdoor:  18%|█▊        | 76563/432000 [00:26<01:53, 3126.34it/s]prepro_backdoor:  18%|█▊        | 76878/432000 [00:26<01:58, 3004.80it/s]prepro_backdoor:  18%|█▊        | 77199/432000 [00:26<01:55, 3060.59it/s]prepro_backdoor:  18%|█▊        | 77551/432000 [00:26<01:51, 3189.21it/s]prepro_backdoor:  18%|█▊        | 77924/432000 [00:26<01:46, 3326.69it/s]prepro_backdoor:  18%|█▊        | 78259/432000 [00:26<01:52, 3135.60it/s]prepro_backdoor:  18%|█▊        | 78576/432000 [00:26<01:56, 3043.21it/s]prepro_backdoor:  18%|█▊        | 78916/432000 [00:26<01:52, 3126.25it/s]prepro_backdoor:  18%|█▊        | 79297/432000 [00:26<01:46, 3305.89it/s]prepro_backdoor:  18%|█▊        | 79630/432000 [00:27<01:55, 3062.24it/s]prepro_backdoor:  19%|█▊        | 79986/432000 [00:27<01:50, 3182.98it/s]prepro_backdoor:  19%|█▊        | 80309/432000 [00:27<01:52, 3122.57it/s]prepro_backdoor:  19%|█▊        | 80625/432000 [00:27<01:55, 3041.50it/s]prepro_backdoor:  19%|█▊        | 80932/432000 [00:27<01:57, 2979.47it/s]prepro_backdoor:  19%|█▉        | 81271/432000 [00:27<01:53, 3081.92it/s]prepro_backdoor:  19%|█▉        | 81581/432000 [00:27<01:56, 2996.35it/s]prepro_backdoor:  19%|█▉        | 81911/432000 [00:27<01:53, 3075.46it/s]prepro_backdoor:  19%|█▉        | 82220/432000 [00:27<02:02, 2857.50it/s]prepro_backdoor:  19%|█▉        | 82510/432000 [00:27<02:02, 2858.50it/s]prepro_backdoor:  19%|█▉        | 82952/432000 [00:28<01:46, 3282.86it/s]prepro_backdoor:  19%|█▉        | 83289/432000 [00:28<01:45, 3295.54it/s]prepro_backdoor:  19%|█▉        | 83622/432000 [00:28<01:50, 3158.19it/s]prepro_backdoor:  19%|█▉        | 83941/432000 [00:28<01:55, 3001.35it/s]prepro_backdoor:  20%|█▉        | 84245/432000 [00:28<01:56, 2979.40it/s]prepro_backdoor:  20%|█▉        | 84652/432000 [00:28<01:45, 3278.11it/s]prepro_backdoor:  20%|█▉        | 85044/432000 [00:28<01:40, 3456.34it/s]prepro_backdoor:  20%|█▉        | 85393/432000 [00:28<01:40, 3460.33it/s]prepro_backdoor:  20%|█▉        | 85782/432000 [00:28<01:37, 3555.78it/s]prepro_backdoor:  20%|█▉        | 86140/432000 [00:29<01:38, 3497.40it/s]prepro_backdoor:  20%|██        | 86491/432000 [00:29<01:42, 3361.35it/s]prepro_backdoor:  20%|██        | 86873/432000 [00:29<01:39, 3467.96it/s]prepro_backdoor:  20%|██        | 87240/432000 [00:29<01:38, 3517.30it/s]prepro_backdoor:  20%|██        | 87593/432000 [00:29<01:38, 3504.26it/s]prepro_backdoor:  20%|██        | 87967/432000 [00:29<01:36, 3566.15it/s]prepro_backdoor:  20%|██        | 88360/432000 [00:29<01:34, 3642.78it/s]prepro_backdoor:  21%|██        | 88725/432000 [00:29<01:45, 3252.30it/s]prepro_backdoor:  21%|██        | 89075/432000 [00:29<01:43, 3311.80it/s]prepro_backdoor:  21%|██        | 89493/432000 [00:30<01:36, 3551.94it/s]prepro_backdoor:  21%|██        | 89855/432000 [00:30<01:37, 3518.91it/s]prepro_backdoor:  21%|██        | 90211/432000 [00:30<01:44, 3269.78it/s]prepro_backdoor:  21%|██        | 90565/432000 [00:30<01:42, 3325.59it/s]prepro_backdoor:  21%|██        | 90902/432000 [00:30<01:44, 3264.86it/s]prepro_backdoor:  21%|██        | 91232/432000 [00:30<01:46, 3198.23it/s]prepro_backdoor:  21%|██        | 91638/432000 [00:30<01:39, 3421.01it/s]prepro_backdoor:  21%|██▏       | 92003/432000 [00:30<01:38, 3469.11it/s]prepro_backdoor:  21%|██▏       | 92352/432000 [00:30<01:39, 3410.73it/s]prepro_backdoor:  21%|██▏       | 92695/432000 [00:31<01:47, 3165.20it/s]prepro_backdoor:  22%|██▏       | 93017/432000 [00:31<01:46, 3172.48it/s]prepro_backdoor:  22%|██▏       | 93338/432000 [00:31<01:47, 3161.54it/s]prepro_backdoor:  22%|██▏       | 93718/432000 [00:31<01:41, 3319.25it/s]prepro_backdoor:  22%|██▏       | 94116/432000 [00:31<01:36, 3498.63it/s]prepro_backdoor:  22%|██▏       | 94468/432000 [00:31<01:41, 3314.54it/s]prepro_backdoor:  22%|██▏       | 94803/432000 [00:31<01:45, 3188.60it/s]prepro_backdoor:  22%|██▏       | 95145/432000 [00:31<01:44, 3238.98it/s]prepro_backdoor:  22%|██▏       | 95471/432000 [00:31<01:51, 3030.83it/s]prepro_backdoor:  22%|██▏       | 95796/432000 [00:31<01:49, 3067.50it/s]prepro_backdoor:  22%|██▏       | 96106/432000 [00:32<01:52, 2990.47it/s]prepro_backdoor:  22%|██▏       | 96487/432000 [00:32<01:44, 3202.67it/s]prepro_backdoor:  22%|██▏       | 96839/432000 [00:32<01:41, 3291.85it/s]prepro_backdoor:  22%|██▏       | 97178/432000 [00:32<01:41, 3303.41it/s]prepro_backdoor:  23%|██▎       | 97510/432000 [00:32<01:42, 3253.49it/s]prepro_backdoor:  23%|██▎       | 97950/432000 [00:32<01:33, 3558.20it/s]prepro_backdoor:  23%|██▎       | 98338/432000 [00:32<01:31, 3627.61it/s]prepro_backdoor:  23%|██▎       | 98702/432000 [00:32<01:32, 3620.81it/s]prepro_backdoor:  23%|██▎       | 99065/432000 [00:32<01:38, 3381.92it/s]prepro_backdoor:  23%|██▎       | 99407/432000 [00:33<01:47, 3085.20it/s]prepro_backdoor:  23%|██▎       | 99774/432000 [00:33<01:42, 3233.12it/s]prepro_backdoor:  23%|██▎       | 100104/432000 [00:33<01:45, 3149.50it/s]prepro_backdoor:  23%|██▎       | 100497/432000 [00:33<01:38, 3355.82it/s]prepro_backdoor:  23%|██▎       | 100838/432000 [00:33<01:45, 3135.74it/s]prepro_backdoor:  23%|██▎       | 101164/432000 [00:33<01:44, 3166.12it/s]prepro_backdoor:  23%|██▎       | 101519/432000 [00:33<01:41, 3248.76it/s]prepro_backdoor:  24%|██▎       | 101967/432000 [00:33<01:31, 3596.33it/s]prepro_backdoor:  24%|██▎       | 102331/432000 [00:33<01:35, 3441.66it/s]prepro_backdoor:  24%|██▍       | 102680/432000 [00:34<01:37, 3370.09it/s]prepro_backdoor:  24%|██▍       | 103061/432000 [00:34<01:34, 3469.33it/s]prepro_backdoor:  24%|██▍       | 103411/432000 [00:34<01:39, 3314.51it/s]prepro_backdoor:  24%|██▍       | 103778/432000 [00:34<01:36, 3390.25it/s]prepro_backdoor:  24%|██▍       | 104154/432000 [00:34<01:34, 3468.02it/s]prepro_backdoor:  24%|██▍       | 104519/432000 [00:34<01:33, 3503.30it/s]prepro_backdoor:  24%|██▍       | 104871/432000 [00:34<01:34, 3451.23it/s]prepro_backdoor:  24%|██▍       | 105220/432000 [00:34<01:34, 3440.93it/s]prepro_backdoor:  24%|██▍       | 105635/432000 [00:34<01:29, 3627.01it/s]prepro_backdoor:  25%|██▍       | 105999/432000 [00:34<01:34, 3444.29it/s]prepro_backdoor:  25%|██▍       | 106346/432000 [00:35<01:41, 3213.75it/s]prepro_backdoor:  25%|██▍       | 106689/432000 [00:35<01:40, 3250.45it/s]prepro_backdoor:  25%|██▍       | 107058/432000 [00:35<01:36, 3362.59it/s]prepro_backdoor:  25%|██▍       | 107422/432000 [00:35<01:34, 3434.75it/s]prepro_backdoor:  25%|██▍       | 107768/432000 [00:35<01:40, 3240.82it/s]prepro_backdoor:  25%|██▌       | 108144/432000 [00:35<01:36, 3369.94it/s]prepro_backdoor:  25%|██▌       | 108554/432000 [00:35<01:31, 3547.83it/s]prepro_backdoor:  25%|██▌       | 108921/432000 [00:35<01:30, 3562.81it/s]prepro_backdoor:  25%|██▌       | 109280/432000 [00:35<01:35, 3369.42it/s]prepro_backdoor:  25%|██▌       | 109731/432000 [00:36<01:27, 3687.82it/s]prepro_backdoor:  25%|██▌       | 110105/432000 [00:36<01:30, 3548.01it/s]prepro_backdoor:  26%|██▌       | 110464/432000 [00:36<01:32, 3478.99it/s]prepro_backdoor:  26%|██▌       | 110815/432000 [00:36<01:39, 3241.85it/s]prepro_backdoor:  26%|██▌       | 111183/432000 [00:36<01:35, 3355.48it/s]prepro_backdoor:  26%|██▌       | 111523/432000 [00:36<01:36, 3323.05it/s]prepro_backdoor:  26%|██▌       | 111858/432000 [00:36<01:43, 3081.18it/s]prepro_backdoor:  26%|██▌       | 112283/432000 [00:36<01:34, 3380.27it/s]prepro_backdoor:  26%|██▌       | 112627/432000 [00:36<01:41, 3153.29it/s]prepro_backdoor:  26%|██▌       | 112960/432000 [00:37<01:40, 3178.62it/s]prepro_backdoor:  26%|██▌       | 113323/432000 [00:37<01:37, 3280.61it/s]prepro_backdoor:  26%|██▋       | 113655/432000 [00:37<01:37, 3270.70it/s]prepro_backdoor:  26%|██▋       | 114010/432000 [00:37<01:35, 3326.54it/s]prepro_backdoor:  26%|██▋       | 114345/432000 [00:37<01:38, 3239.74it/s]prepro_backdoor:  27%|██▋       | 114686/432000 [00:37<01:37, 3268.75it/s]prepro_backdoor:  27%|██▋       | 115015/432000 [00:37<01:43, 3070.87it/s]prepro_backdoor:  27%|██▋       | 115454/432000 [00:37<01:32, 3424.62it/s]prepro_backdoor:  27%|██▋       | 115801/432000 [00:37<01:37, 3230.63it/s]prepro_backdoor:  27%|██▋       | 116129/432000 [00:38<01:39, 3162.56it/s]prepro_backdoor:  27%|██▋       | 116524/432000 [00:38<01:33, 3381.24it/s]prepro_backdoor:  27%|██▋       | 116893/432000 [00:38<01:31, 3459.16it/s]prepro_backdoor:  27%|██▋       | 117243/432000 [00:38<01:31, 3456.48it/s]prepro_backdoor:  27%|██▋       | 117641/432000 [00:38<01:27, 3584.53it/s]prepro_backdoor:  27%|██▋       | 118002/432000 [00:38<01:29, 3502.46it/s]prepro_backdoor:  27%|██▋       | 118354/432000 [00:38<01:35, 3269.49it/s]prepro_backdoor:  27%|██▋       | 118708/432000 [00:38<01:33, 3334.57it/s]prepro_backdoor:  28%|██▊       | 119051/432000 [00:38<01:33, 3344.22it/s]prepro_backdoor:  28%|██▊       | 119454/432000 [00:39<01:28, 3540.31it/s]prepro_backdoor:  28%|██▊       | 119838/432000 [00:39<01:26, 3616.80it/s]prepro_backdoor:  28%|██▊       | 120202/432000 [00:39<01:31, 3392.82it/s]prepro_backdoor:  28%|██▊       | 120546/432000 [00:39<01:35, 3256.72it/s]prepro_backdoor:  28%|██▊       | 120875/432000 [00:39<01:40, 3089.80it/s]prepro_backdoor:  28%|██▊       | 121188/432000 [00:39<01:41, 3066.67it/s]prepro_backdoor:  28%|██▊       | 121525/432000 [00:39<01:39, 3125.05it/s]prepro_backdoor:  28%|██▊       | 121840/432000 [00:39<01:41, 3062.63it/s]prepro_backdoor:  28%|██▊       | 122251/432000 [00:39<01:32, 3339.47it/s]prepro_backdoor:  28%|██▊       | 122611/432000 [00:39<01:31, 3396.08it/s]prepro_backdoor:  28%|██▊       | 123037/432000 [00:40<01:25, 3629.27it/s]prepro_backdoor:  29%|██▊       | 123402/432000 [00:40<01:30, 3402.13it/s]prepro_backdoor:  29%|██▊       | 123746/432000 [00:40<01:32, 3323.32it/s]prepro_backdoor:  29%|██▊       | 124081/432000 [00:40<01:35, 3209.29it/s]prepro_backdoor:  29%|██▉       | 124404/432000 [00:40<01:36, 3195.47it/s]prepro_backdoor:  29%|██▉       | 124725/432000 [00:40<01:37, 3141.36it/s]prepro_backdoor:  29%|██▉       | 125172/432000 [00:40<01:27, 3499.63it/s]prepro_backdoor:  29%|██▉       | 125525/432000 [00:40<01:27, 3506.56it/s]prepro_backdoor:  29%|██▉       | 125936/432000 [00:40<01:23, 3679.83it/s]prepro_backdoor:  29%|██▉       | 126323/432000 [00:41<01:22, 3724.35it/s]prepro_backdoor:  29%|██▉       | 126697/432000 [00:41<01:28, 3456.21it/s]prepro_backdoor:  29%|██▉       | 127048/432000 [00:41<01:34, 3241.27it/s]prepro_backdoor:  29%|██▉       | 127378/432000 [00:41<01:34, 3234.39it/s]prepro_backdoor:  30%|██▉       | 127711/432000 [00:41<01:33, 3242.18it/s]prepro_backdoor:  30%|██▉       | 128038/432000 [00:41<01:38, 3093.94it/s]prepro_backdoor:  30%|██▉       | 128350/432000 [00:41<01:47, 2831.46it/s]prepro_backdoor:  30%|██▉       | 128639/432000 [00:41<01:53, 2667.18it/s]prepro_backdoor:  30%|██▉       | 129021/432000 [00:41<01:42, 2951.42it/s]prepro_backdoor:  30%|██▉       | 129323/432000 [00:42<01:43, 2920.78it/s]prepro_backdoor:  30%|███       | 129674/432000 [00:42<01:38, 3067.78it/s]prepro_backdoor:  30%|███       | 129996/432000 [00:42<01:37, 3095.30it/s]prepro_backdoor:  30%|███       | 130309/432000 [00:42<01:39, 3047.26it/s]prepro_backdoor:  30%|███       | 130616/432000 [00:42<01:40, 3012.65it/s]prepro_backdoor:  30%|███       | 130927/432000 [00:42<01:39, 3029.29it/s]prepro_backdoor:  30%|███       | 131266/432000 [00:42<01:36, 3110.04it/s]prepro_backdoor:  30%|███       | 131578/432000 [00:42<01:45, 2841.64it/s]prepro_backdoor:  31%|███       | 131909/432000 [00:42<01:41, 2957.31it/s]prepro_backdoor:  31%|███       | 132209/432000 [00:43<01:44, 2867.55it/s]prepro_backdoor:  31%|███       | 132499/432000 [00:43<01:45, 2847.55it/s]prepro_backdoor:  31%|███       | 132857/432000 [00:43<01:37, 3054.23it/s]prepro_backdoor:  31%|███       | 133166/432000 [00:43<01:38, 3032.90it/s]prepro_backdoor:  31%|███       | 133491/432000 [00:43<01:37, 3071.82it/s]prepro_backdoor:  31%|███       | 133833/432000 [00:43<01:34, 3149.38it/s]prepro_backdoor:  31%|███       | 134196/432000 [00:43<01:30, 3284.24it/s]prepro_backdoor:  31%|███       | 134622/432000 [00:43<01:23, 3544.67it/s]prepro_backdoor:  31%|███▏      | 135014/432000 [00:43<01:21, 3637.62it/s]prepro_backdoor:  31%|███▏      | 135379/432000 [00:43<01:23, 3532.24it/s]prepro_backdoor:  31%|███▏      | 135734/432000 [00:44<01:27, 3388.09it/s]prepro_backdoor:  32%|███▏      | 136095/432000 [00:44<01:26, 3435.44it/s]prepro_backdoor:  32%|███▏      | 136440/432000 [00:44<01:25, 3439.30it/s]prepro_backdoor:  32%|███▏      | 136843/432000 [00:44<01:21, 3609.12it/s]prepro_backdoor:  32%|███▏      | 137206/432000 [00:44<01:27, 3380.88it/s]prepro_backdoor:  32%|███▏      | 137606/432000 [00:44<01:23, 3532.14it/s]prepro_backdoor:  32%|███▏      | 137963/432000 [00:44<01:33, 3160.37it/s]prepro_backdoor:  32%|███▏      | 138311/432000 [00:44<01:30, 3229.82it/s]prepro_backdoor:  32%|███▏      | 138692/432000 [00:44<01:26, 3378.16it/s]prepro_backdoor:  32%|███▏      | 139123/432000 [00:45<01:20, 3627.10it/s]prepro_backdoor:  32%|███▏      | 139492/432000 [00:45<01:31, 3186.54it/s]prepro_backdoor:  32%|███▏      | 139824/432000 [00:45<01:32, 3155.06it/s]prepro_backdoor:  32%|███▏      | 140322/432000 [00:45<01:20, 3624.39it/s]prepro_backdoor:  33%|███▎      | 140696/432000 [00:45<01:23, 3473.75it/s]prepro_backdoor:  33%|███▎      | 141052/432000 [00:45<01:31, 3166.51it/s]prepro_backdoor:  33%|███▎      | 141422/432000 [00:45<01:28, 3280.64it/s]prepro_backdoor:  33%|███▎      | 141759/432000 [00:45<01:32, 3129.63it/s]prepro_backdoor:  33%|███▎      | 142088/432000 [00:46<01:32, 3146.64it/s]prepro_backdoor:  33%|███▎      | 142408/432000 [00:46<01:45, 2742.06it/s]prepro_backdoor:  33%|███▎      | 142694/432000 [00:46<01:45, 2736.19it/s]prepro_backdoor:  33%|███▎      | 142982/432000 [00:46<01:44, 2757.54it/s]prepro_backdoor:  33%|███▎      | 143264/432000 [00:46<01:51, 2585.15it/s]prepro_backdoor:  33%|███▎      | 143562/432000 [00:46<01:48, 2651.66it/s]prepro_backdoor:  33%|███▎      | 143832/432000 [00:46<01:54, 2525.95it/s]prepro_backdoor:  33%|███▎      | 144088/432000 [00:46<01:57, 2450.97it/s]prepro_backdoor:  33%|███▎      | 144338/432000 [00:46<01:57, 2452.42it/s]prepro_backdoor:  33%|███▎      | 144671/432000 [00:47<01:46, 2688.57it/s]prepro_backdoor:  34%|███▎      | 144943/432000 [00:47<01:49, 2624.48it/s]prepro_backdoor:  34%|███▎      | 145208/432000 [00:47<02:04, 2305.04it/s]prepro_backdoor:  34%|███▎      | 145447/432000 [00:47<02:06, 2263.36it/s]prepro_backdoor:  34%|███▎      | 145688/432000 [00:47<02:04, 2299.02it/s]prepro_backdoor:  34%|███▍      | 145953/432000 [00:47<02:00, 2374.59it/s]prepro_backdoor:  34%|███▍      | 146194/432000 [00:47<02:07, 2236.34it/s]prepro_backdoor:  34%|███▍      | 146439/432000 [00:47<02:04, 2292.95it/s]prepro_backdoor:  34%|███▍      | 146723/432000 [00:47<01:57, 2431.35it/s]prepro_backdoor:  34%|███▍      | 146969/432000 [00:48<02:10, 2188.69it/s]prepro_backdoor:  34%|███▍      | 147222/432000 [00:48<02:05, 2266.41it/s]prepro_backdoor:  34%|███▍      | 147454/432000 [00:48<02:08, 2207.42it/s]prepro_backdoor:  34%|███▍      | 147714/432000 [00:48<02:03, 2301.36it/s]prepro_backdoor:  34%|███▍      | 148012/432000 [00:48<01:54, 2483.85it/s]prepro_backdoor:  34%|███▍      | 148264/432000 [00:48<01:57, 2415.79it/s]prepro_backdoor:  34%|███▍      | 148508/432000 [00:48<02:04, 2282.66it/s]prepro_backdoor:  34%|███▍      | 148739/432000 [00:48<02:08, 2207.45it/s]prepro_backdoor:  35%|███▍      | 149058/432000 [00:48<01:54, 2461.61it/s]prepro_backdoor:  35%|███▍      | 149308/432000 [00:49<02:07, 2208.60it/s]prepro_backdoor:  35%|███▍      | 149536/432000 [00:49<02:09, 2189.16it/s]prepro_backdoor:  35%|███▍      | 149765/432000 [00:49<02:08, 2203.78it/s]prepro_backdoor:  35%|███▍      | 149995/432000 [00:49<02:06, 2224.20it/s]prepro_backdoor:  35%|███▍      | 150282/432000 [00:49<01:58, 2381.16it/s]prepro_backdoor:  35%|███▍      | 150523/432000 [00:49<02:00, 2336.70it/s]prepro_backdoor:  35%|███▍      | 150759/432000 [00:49<02:02, 2296.34it/s]prepro_backdoor:  35%|███▍      | 151023/432000 [00:49<01:58, 2371.94it/s]prepro_backdoor:  35%|███▌      | 151262/432000 [00:49<02:01, 2305.50it/s]prepro_backdoor:  35%|███▌      | 151545/432000 [00:50<01:55, 2433.44it/s]prepro_backdoor:  35%|███▌      | 151796/432000 [00:50<01:54, 2442.46it/s]prepro_backdoor:  35%|███▌      | 152041/432000 [00:50<01:56, 2411.63it/s]prepro_backdoor:  35%|███▌      | 152321/432000 [00:50<01:52, 2493.26it/s]prepro_backdoor:  35%|███▌      | 152585/432000 [00:50<01:50, 2522.38it/s]prepro_backdoor:  35%|███▌      | 152838/432000 [00:50<01:59, 2326.54it/s]prepro_backdoor:  35%|███▌      | 153080/432000 [00:50<01:59, 2329.97it/s]prepro_backdoor:  35%|███▌      | 153318/432000 [00:50<02:00, 2311.71it/s]prepro_backdoor:  36%|███▌      | 153551/432000 [00:50<02:06, 2204.74it/s]prepro_backdoor:  36%|███▌      | 153796/432000 [00:51<02:02, 2265.36it/s]prepro_backdoor:  36%|███▌      | 154025/432000 [00:51<02:03, 2245.58it/s]prepro_backdoor:  36%|███▌      | 154251/432000 [00:51<02:10, 2125.82it/s]prepro_backdoor:  36%|███▌      | 154523/432000 [00:51<02:02, 2273.00it/s]prepro_backdoor:  36%|███▌      | 154934/432000 [00:51<01:39, 2783.94it/s]prepro_backdoor:  36%|███▌      | 155217/432000 [00:51<01:45, 2620.96it/s]prepro_backdoor:  36%|███▌      | 155484/432000 [00:51<01:53, 2433.30it/s]prepro_backdoor:  36%|███▌      | 155750/432000 [00:51<01:50, 2489.06it/s]prepro_backdoor:  36%|███▌      | 156003/432000 [00:51<02:10, 2111.98it/s]prepro_backdoor:  36%|███▌      | 156226/432000 [00:52<02:15, 2034.14it/s]prepro_backdoor:  36%|███▌      | 156459/432000 [00:52<02:10, 2105.18it/s]prepro_backdoor:  36%|███▋      | 156738/432000 [00:52<02:01, 2274.62it/s]prepro_backdoor:  36%|███▋      | 156973/432000 [00:52<02:04, 2202.48it/s]prepro_backdoor:  36%|███▋      | 157198/432000 [00:52<02:04, 2211.06it/s]prepro_backdoor:  36%|███▋      | 157477/432000 [00:52<01:56, 2360.88it/s]prepro_backdoor:  37%|███▋      | 157744/432000 [00:52<01:52, 2438.56it/s]prepro_backdoor:  37%|███▋      | 158032/432000 [00:52<01:47, 2554.25it/s]prepro_backdoor:  37%|███▋      | 158291/432000 [00:52<01:47, 2543.97it/s]prepro_backdoor:  37%|███▋      | 158555/432000 [00:53<01:47, 2555.50it/s]prepro_backdoor:  37%|███▋      | 158860/432000 [00:53<01:41, 2691.40it/s]prepro_backdoor:  37%|███▋      | 159165/432000 [00:53<01:38, 2782.71it/s]prepro_backdoor:  37%|███▋      | 159445/432000 [00:53<01:54, 2370.28it/s]prepro_backdoor:  37%|███▋      | 159693/432000 [00:53<01:57, 2313.28it/s]prepro_backdoor:  37%|███▋      | 159974/432000 [00:53<01:51, 2431.80it/s]prepro_backdoor:  37%|███▋      | 160243/432000 [00:53<01:49, 2483.14it/s]prepro_backdoor:  37%|███▋      | 160536/432000 [00:53<01:45, 2579.23it/s]prepro_backdoor:  37%|███▋      | 160798/432000 [00:53<01:55, 2349.99it/s]prepro_backdoor:  37%|███▋      | 161039/432000 [00:54<02:00, 2253.59it/s]prepro_backdoor:  37%|███▋      | 161337/432000 [00:54<01:50, 2446.96it/s]prepro_backdoor:  37%|███▋      | 161601/432000 [00:54<01:48, 2495.53it/s]prepro_backdoor:  37%|███▋      | 161855/432000 [00:54<01:51, 2421.18it/s]prepro_backdoor:  38%|███▊      | 162134/432000 [00:54<01:48, 2498.41it/s]prepro_backdoor:  38%|███▊      | 162387/432000 [00:54<01:50, 2434.52it/s]prepro_backdoor:  38%|███▊      | 162686/432000 [00:54<01:44, 2585.28it/s]prepro_backdoor:  38%|███▊      | 162947/432000 [00:54<01:44, 2583.43it/s]prepro_backdoor:  38%|███▊      | 163207/432000 [00:54<01:47, 2492.94it/s]prepro_backdoor:  38%|███▊      | 163458/432000 [00:55<01:53, 2371.74it/s]prepro_backdoor:  38%|███▊      | 163705/432000 [00:55<01:53, 2360.94it/s]prepro_backdoor:  38%|███▊      | 163948/432000 [00:55<01:52, 2376.77it/s]prepro_backdoor:  38%|███▊      | 164187/432000 [00:55<01:55, 2310.22it/s]prepro_backdoor:  38%|███▊      | 164462/432000 [00:55<01:49, 2433.83it/s]prepro_backdoor:  38%|███▊      | 164771/432000 [00:55<01:42, 2610.69it/s]prepro_backdoor:  38%|███▊      | 165034/432000 [00:55<01:47, 2478.87it/s]prepro_backdoor:  38%|███▊      | 165333/432000 [00:55<01:42, 2606.77it/s]prepro_backdoor:  38%|███▊      | 165596/432000 [00:55<01:44, 2552.52it/s]prepro_backdoor:  38%|███▊      | 165853/432000 [00:55<01:53, 2343.46it/s]prepro_backdoor:  38%|███▊      | 166092/432000 [00:56<01:58, 2243.54it/s]prepro_backdoor:  39%|███▊      | 166367/432000 [00:56<01:52, 2355.63it/s]prepro_backdoor:  39%|███▊      | 166664/432000 [00:56<01:45, 2516.81it/s]prepro_backdoor:  39%|███▊      | 166919/432000 [00:56<01:45, 2524.06it/s]prepro_backdoor:  39%|███▊      | 167174/432000 [00:56<01:49, 2423.14it/s]prepro_backdoor:  39%|███▉      | 167419/432000 [00:56<01:52, 2351.52it/s]prepro_backdoor:  39%|███▉      | 167656/432000 [00:56<01:53, 2333.05it/s]prepro_backdoor:  39%|███▉      | 167891/432000 [00:56<02:02, 2161.44it/s]prepro_backdoor:  39%|███▉      | 168152/432000 [00:56<01:55, 2276.55it/s]prepro_backdoor:  39%|███▉      | 168404/432000 [00:57<01:52, 2344.32it/s]prepro_backdoor:  39%|███▉      | 168724/432000 [00:57<01:42, 2578.30it/s]prepro_backdoor:  39%|███▉      | 169009/432000 [00:57<01:39, 2655.03it/s]prepro_backdoor:  39%|███▉      | 169277/432000 [00:57<01:38, 2655.53it/s]prepro_backdoor:  39%|███▉      | 169545/432000 [00:57<01:44, 2515.68it/s]prepro_backdoor:  39%|███▉      | 169885/432000 [00:57<01:35, 2746.82it/s]prepro_backdoor:  39%|███▉      | 170163/432000 [00:57<01:36, 2715.97it/s]prepro_backdoor:  39%|███▉      | 170437/432000 [00:57<01:45, 2486.63it/s]prepro_backdoor:  40%|███▉      | 170691/432000 [00:57<01:50, 2364.91it/s]prepro_backdoor:  40%|███▉      | 170932/432000 [00:58<01:50, 2369.53it/s]prepro_backdoor:  40%|███▉      | 171172/432000 [00:58<01:52, 2322.56it/s]prepro_backdoor:  40%|███▉      | 171457/432000 [00:58<01:45, 2466.43it/s]prepro_backdoor:  40%|███▉      | 171730/432000 [00:58<01:42, 2540.33it/s]prepro_backdoor:  40%|███▉      | 171986/432000 [00:58<01:44, 2492.38it/s]prepro_backdoor:  40%|███▉      | 172237/432000 [00:58<01:44, 2476.11it/s]prepro_backdoor:  40%|███▉      | 172486/432000 [00:58<01:50, 2348.45it/s]prepro_backdoor:  40%|███▉      | 172754/432000 [00:58<01:46, 2425.82it/s]prepro_backdoor:  40%|████      | 173027/432000 [00:58<01:43, 2494.84it/s]prepro_backdoor:  40%|████      | 173278/432000 [00:59<01:59, 2170.54it/s]prepro_backdoor:  40%|████      | 173556/432000 [00:59<01:51, 2325.48it/s]prepro_backdoor:  40%|████      | 173828/432000 [00:59<01:46, 2414.97it/s]prepro_backdoor:  40%|████      | 174076/432000 [00:59<01:50, 2332.53it/s]prepro_backdoor:  40%|████      | 174314/432000 [00:59<01:51, 2318.38it/s]prepro_backdoor:  40%|████      | 174638/432000 [00:59<01:40, 2563.29it/s]prepro_backdoor:  40%|████      | 174898/432000 [00:59<01:43, 2484.97it/s]prepro_backdoor:  41%|████      | 175150/432000 [00:59<01:51, 2297.84it/s]prepro_backdoor:  41%|████      | 175471/432000 [00:59<01:41, 2522.47it/s]prepro_backdoor:  41%|████      | 175734/432000 [01:00<01:41, 2528.56it/s]prepro_backdoor:  41%|████      | 175991/432000 [01:00<01:42, 2492.80it/s]prepro_backdoor:  41%|████      | 176293/432000 [01:00<01:36, 2640.49it/s]prepro_backdoor:  41%|████      | 176560/432000 [01:00<01:40, 2543.66it/s]prepro_backdoor:  41%|████      | 176817/432000 [01:00<01:43, 2463.09it/s]prepro_backdoor:  41%|████      | 177066/432000 [01:00<01:47, 2378.32it/s]prepro_backdoor:  41%|████      | 177306/432000 [01:00<01:51, 2292.95it/s]prepro_backdoor:  41%|████      | 177578/432000 [01:00<01:45, 2402.87it/s]prepro_backdoor:  41%|████      | 177834/432000 [01:00<01:44, 2428.65it/s]prepro_backdoor:  41%|████      | 178079/432000 [01:01<01:45, 2408.72it/s]prepro_backdoor:  41%|████▏     | 178321/432000 [01:01<01:52, 2263.27it/s]prepro_backdoor:  41%|████▏     | 178550/432000 [01:01<01:56, 2180.18it/s]prepro_backdoor:  41%|████▏     | 178790/432000 [01:01<01:53, 2225.78it/s]prepro_backdoor:  41%|████▏     | 179014/432000 [01:01<01:53, 2223.49it/s]prepro_backdoor:  42%|████▏     | 179288/432000 [01:01<01:47, 2358.39it/s]prepro_backdoor:  42%|████▏     | 179534/432000 [01:01<01:46, 2372.92it/s]prepro_backdoor:  42%|████▏     | 179842/432000 [01:01<01:38, 2570.32it/s]prepro_backdoor:  42%|████▏     | 180101/432000 [01:01<01:42, 2467.48it/s]prepro_backdoor:  42%|████▏     | 180374/432000 [01:01<01:39, 2518.67it/s]prepro_backdoor:  42%|████▏     | 180656/432000 [01:02<01:36, 2599.77it/s]prepro_backdoor:  42%|████▏     | 180918/432000 [01:02<01:48, 2321.46it/s]prepro_backdoor:  42%|████▏     | 181203/432000 [01:02<01:42, 2442.17it/s]prepro_backdoor:  42%|████▏     | 181501/432000 [01:02<01:37, 2570.98it/s]prepro_backdoor:  42%|████▏     | 181763/432000 [01:02<01:39, 2522.04it/s]prepro_backdoor:  42%|████▏     | 182033/432000 [01:02<01:37, 2563.29it/s]prepro_backdoor:  42%|████▏     | 182292/432000 [01:02<01:43, 2404.01it/s]prepro_backdoor:  42%|████▏     | 182537/432000 [01:02<01:44, 2397.09it/s]prepro_backdoor:  42%|████▏     | 182824/432000 [01:02<01:38, 2523.21it/s]prepro_backdoor:  42%|████▏     | 183079/432000 [01:03<01:52, 2210.47it/s]prepro_backdoor:  42%|████▏     | 183309/432000 [01:03<01:53, 2189.36it/s]prepro_backdoor:  43%|████▎     | 183605/432000 [01:03<01:44, 2386.76it/s]prepro_backdoor:  43%|████▎     | 183871/432000 [01:03<01:40, 2460.98it/s]prepro_backdoor:  43%|████▎     | 184195/432000 [01:03<01:33, 2654.35it/s]prepro_backdoor:  43%|████▎     | 184507/432000 [01:03<01:29, 2763.30it/s]prepro_backdoor:  43%|████▎     | 184833/432000 [01:03<01:25, 2899.74it/s]prepro_backdoor:  43%|████▎     | 185126/432000 [01:03<01:32, 2656.81it/s]prepro_backdoor:  43%|████▎     | 185398/432000 [01:03<01:42, 2410.69it/s]prepro_backdoor:  43%|████▎     | 185670/432000 [01:04<01:39, 2479.06it/s]prepro_backdoor:  43%|████▎     | 185924/432000 [01:04<01:47, 2285.35it/s]prepro_backdoor:  43%|████▎     | 186238/432000 [01:04<01:38, 2507.74it/s]prepro_backdoor:  43%|████▎     | 186532/432000 [01:04<01:34, 2606.13it/s]prepro_backdoor:  43%|████▎     | 186805/432000 [01:04<01:33, 2625.61it/s]prepro_backdoor:  43%|████▎     | 187072/432000 [01:04<01:40, 2425.36it/s]prepro_backdoor:  43%|████▎     | 187372/432000 [01:04<01:35, 2560.64it/s]prepro_backdoor:  43%|████▎     | 187641/432000 [01:04<01:34, 2585.29it/s]prepro_backdoor:  44%|████▎     | 187996/432000 [01:04<01:26, 2830.10it/s]prepro_backdoor:  44%|████▎     | 188283/432000 [01:05<01:37, 2487.23it/s]prepro_backdoor:  44%|████▎     | 188541/432000 [01:05<01:42, 2366.33it/s]prepro_backdoor:  44%|████▎     | 188785/432000 [01:05<01:48, 2234.86it/s]prepro_backdoor:  44%|████▍     | 189014/432000 [01:05<01:51, 2171.63it/s]prepro_backdoor:  44%|████▍     | 189246/432000 [01:05<01:50, 2190.78it/s]prepro_backdoor:  44%|████▍     | 189599/432000 [01:05<01:35, 2535.48it/s]prepro_backdoor:  44%|████▍     | 189919/432000 [01:05<01:30, 2675.02it/s]prepro_backdoor:  44%|████▍     | 190191/432000 [01:05<01:32, 2613.61it/s]prepro_backdoor:  44%|████▍     | 190455/432000 [01:06<01:32, 2602.94it/s]prepro_backdoor:  44%|████▍     | 190718/432000 [01:06<01:39, 2426.78it/s]prepro_backdoor:  44%|████▍     | 190964/432000 [01:06<01:43, 2336.49it/s]prepro_backdoor:  44%|████▍     | 191200/432000 [01:06<01:45, 2272.83it/s]prepro_backdoor:  44%|████▍     | 191429/432000 [01:06<01:56, 2068.78it/s]prepro_backdoor:  44%|████▍     | 191665/432000 [01:06<01:52, 2129.54it/s]prepro_backdoor:  44%|████▍     | 191882/432000 [01:06<01:57, 2045.82it/s]prepro_backdoor:  44%|████▍     | 192110/432000 [01:06<01:53, 2107.07it/s]prepro_backdoor:  45%|████▍     | 192355/432000 [01:06<01:49, 2192.11it/s]prepro_backdoor:  45%|████▍     | 192577/432000 [01:07<01:48, 2198.58it/s]prepro_backdoor:  45%|████▍     | 192799/432000 [01:07<01:50, 2170.74it/s]prepro_backdoor:  45%|████▍     | 193018/432000 [01:07<01:54, 2092.72it/s]prepro_backdoor:  45%|████▍     | 193236/432000 [01:07<01:52, 2116.30it/s]prepro_backdoor:  45%|████▍     | 193449/432000 [01:07<01:53, 2094.38it/s]prepro_backdoor:  45%|████▍     | 193749/432000 [01:07<01:41, 2344.94it/s]prepro_backdoor:  45%|████▍     | 194088/432000 [01:07<01:29, 2644.80it/s]prepro_backdoor:  45%|████▍     | 194354/432000 [01:07<01:43, 2297.25it/s]prepro_backdoor:  45%|████▌     | 194593/432000 [01:07<01:42, 2313.02it/s]prepro_backdoor:  45%|████▌     | 194848/432000 [01:08<01:40, 2359.40it/s]prepro_backdoor:  45%|████▌     | 195106/432000 [01:08<01:38, 2414.07it/s]prepro_backdoor:  45%|████▌     | 195377/432000 [01:08<01:35, 2471.96it/s]prepro_backdoor:  45%|████▌     | 195641/432000 [01:08<01:33, 2520.17it/s]prepro_backdoor:  45%|████▌     | 195920/432000 [01:08<01:31, 2592.82it/s]prepro_backdoor:  45%|████▌     | 196181/432000 [01:08<01:33, 2523.05it/s]prepro_backdoor:  45%|████▌     | 196435/432000 [01:08<01:38, 2385.11it/s]prepro_backdoor:  46%|████▌     | 196676/432000 [01:08<01:59, 1963.04it/s]prepro_backdoor:  46%|████▌     | 196979/432000 [01:08<01:45, 2217.80it/s]prepro_backdoor:  46%|████▌     | 197215/432000 [01:09<01:50, 2130.08it/s]prepro_backdoor:  46%|████▌     | 197461/432000 [01:09<01:46, 2197.98it/s]prepro_backdoor:  46%|████▌     | 197689/432000 [01:09<01:46, 2199.96it/s]prepro_backdoor:  46%|████▌     | 197958/432000 [01:09<01:41, 2310.73it/s]prepro_backdoor:  46%|████▌     | 198201/432000 [01:09<01:40, 2334.81it/s]prepro_backdoor:  46%|████▌     | 198438/432000 [01:09<01:42, 2284.94it/s]prepro_backdoor:  46%|████▌     | 198669/432000 [01:09<01:43, 2247.75it/s]prepro_backdoor:  46%|████▌     | 198947/432000 [01:09<01:37, 2383.37it/s]prepro_backdoor:  46%|████▌     | 199187/432000 [01:09<01:41, 2304.78it/s]prepro_backdoor:  46%|████▌     | 199544/432000 [01:09<01:27, 2656.94it/s]prepro_backdoor:  46%|████▋     | 199813/432000 [01:10<01:31, 2535.92it/s]prepro_backdoor:  46%|████▋     | 200070/432000 [01:10<01:34, 2452.89it/s]prepro_backdoor:  46%|████▋     | 200409/432000 [01:10<01:25, 2700.32it/s]prepro_backdoor:  46%|████▋     | 200683/432000 [01:10<01:43, 2233.98it/s]prepro_backdoor:  47%|████▋     | 200922/432000 [01:10<01:43, 2227.08it/s]prepro_backdoor:  47%|████▋     | 201155/432000 [01:10<01:43, 2228.22it/s]prepro_backdoor:  47%|████▋     | 201415/432000 [01:10<01:39, 2319.06it/s]prepro_backdoor:  47%|████▋     | 201771/432000 [01:10<01:26, 2660.45it/s]prepro_backdoor:  47%|████▋     | 202045/432000 [01:11<01:27, 2614.78it/s]prepro_backdoor:  47%|████▋     | 202352/432000 [01:11<01:23, 2742.58it/s]prepro_backdoor:  47%|████▋     | 202642/432000 [01:11<01:22, 2787.81it/s]prepro_backdoor:  47%|████▋     | 202924/432000 [01:11<01:26, 2647.26it/s]prepro_backdoor:  47%|████▋     | 203193/432000 [01:11<01:28, 2579.10it/s]prepro_backdoor:  47%|████▋     | 203534/432000 [01:11<01:21, 2796.85it/s]prepro_backdoor:  47%|████▋     | 203817/432000 [01:11<01:23, 2721.64it/s]prepro_backdoor:  47%|████▋     | 204092/432000 [01:11<01:27, 2590.00it/s]prepro_backdoor:  47%|████▋     | 204398/432000 [01:11<01:23, 2712.45it/s]prepro_backdoor:  47%|████▋     | 204672/432000 [01:12<01:37, 2328.82it/s]prepro_backdoor:  47%|████▋     | 204916/432000 [01:12<01:42, 2221.40it/s]prepro_backdoor:  48%|████▊     | 205215/432000 [01:12<01:34, 2401.93it/s]prepro_backdoor:  48%|████▊     | 205463/432000 [01:12<01:42, 2211.76it/s]prepro_backdoor:  48%|████▊     | 205692/432000 [01:12<01:45, 2137.47it/s]prepro_backdoor:  48%|████▊     | 205911/432000 [01:12<01:46, 2127.76it/s]prepro_backdoor:  48%|████▊     | 206191/432000 [01:12<01:38, 2301.66it/s]prepro_backdoor:  48%|████▊     | 206523/432000 [01:12<01:28, 2561.58it/s]prepro_backdoor:  48%|████▊     | 206784/432000 [01:12<01:28, 2535.19it/s]prepro_backdoor:  48%|████▊     | 207041/432000 [01:13<01:33, 2398.15it/s]prepro_backdoor:  48%|████▊     | 207284/432000 [01:13<01:34, 2388.57it/s]prepro_backdoor:  48%|████▊     | 207552/432000 [01:13<01:31, 2449.90it/s]prepro_backdoor:  48%|████▊     | 207848/432000 [01:13<01:26, 2589.32it/s]prepro_backdoor:  48%|████▊     | 208109/432000 [01:13<01:30, 2476.23it/s]prepro_backdoor:  48%|████▊     | 208359/432000 [01:13<01:32, 2412.51it/s]prepro_backdoor:  48%|████▊     | 208609/432000 [01:13<01:31, 2432.96it/s]prepro_backdoor:  48%|████▊     | 208854/432000 [01:13<01:35, 2335.23it/s]prepro_backdoor:  48%|████▊     | 209089/432000 [01:13<01:38, 2272.24it/s]prepro_backdoor:  48%|████▊     | 209320/432000 [01:14<01:37, 2273.13it/s]prepro_backdoor:  49%|████▊     | 209578/432000 [01:14<01:35, 2328.30it/s]prepro_backdoor:  49%|████▊     | 209812/432000 [01:14<01:39, 2226.50it/s]prepro_backdoor:  49%|████▊     | 210129/432000 [01:14<01:29, 2468.34it/s]prepro_backdoor:  49%|████▊     | 210378/432000 [01:14<01:33, 2364.69it/s]prepro_backdoor:  49%|████▉     | 210645/432000 [01:14<01:30, 2433.84it/s]prepro_backdoor:  49%|████▉     | 210909/432000 [01:14<01:29, 2476.79it/s]prepro_backdoor:  49%|████▉     | 211158/432000 [01:14<01:29, 2456.57it/s]prepro_backdoor:  49%|████▉     | 211438/432000 [01:14<01:27, 2531.91it/s]prepro_backdoor:  49%|████▉     | 211692/432000 [01:14<01:27, 2518.05it/s]prepro_backdoor:  49%|████▉     | 211974/432000 [01:15<01:25, 2577.14it/s]prepro_backdoor:  49%|████▉     | 212233/432000 [01:15<01:35, 2306.84it/s]prepro_backdoor:  49%|████▉     | 212587/432000 [01:15<01:23, 2621.29it/s]prepro_backdoor:  49%|████▉     | 212872/432000 [01:15<01:22, 2659.82it/s]prepro_backdoor:  49%|████▉     | 213143/432000 [01:15<01:25, 2545.36it/s]prepro_backdoor:  49%|████▉     | 213402/432000 [01:15<01:26, 2540.69it/s]prepro_backdoor:  49%|████▉     | 213659/432000 [01:15<01:30, 2413.51it/s]prepro_backdoor:  50%|████▉     | 213904/432000 [01:15<01:31, 2379.60it/s]prepro_backdoor:  50%|████▉     | 214146/432000 [01:15<01:31, 2382.15it/s]prepro_backdoor:  50%|████▉     | 214394/432000 [01:16<01:31, 2368.02it/s]prepro_backdoor:  50%|████▉     | 214632/432000 [01:16<01:33, 2318.77it/s]prepro_backdoor:  50%|████▉     | 214912/432000 [01:16<01:29, 2431.41it/s]prepro_backdoor:  50%|████▉     | 215156/432000 [01:16<01:36, 2253.52it/s]prepro_backdoor:  50%|████▉     | 215459/432000 [01:16<01:28, 2440.96it/s]prepro_backdoor:  50%|████▉     | 215707/432000 [01:16<01:32, 2350.54it/s]prepro_backdoor:  50%|████▉     | 215974/432000 [01:16<01:29, 2422.43it/s]prepro_backdoor:  50%|█████     | 216244/432000 [01:16<01:26, 2494.46it/s]prepro_backdoor:  50%|█████     | 216496/432000 [01:16<01:31, 2359.55it/s]prepro_backdoor:  50%|█████     | 216778/432000 [01:17<01:26, 2487.30it/s]prepro_backdoor:  50%|█████     | 217030/432000 [01:17<01:26, 2486.00it/s]prepro_backdoor:  50%|█████     | 217281/432000 [01:17<01:35, 2255.26it/s]prepro_backdoor:  50%|█████     | 217591/432000 [01:17<01:26, 2478.95it/s]prepro_backdoor:  50%|█████     | 217845/432000 [01:17<01:31, 2352.85it/s]prepro_backdoor:  50%|█████     | 218089/432000 [01:17<01:30, 2365.62it/s]prepro_backdoor:  51%|█████     | 218330/432000 [01:17<01:35, 2242.94it/s]prepro_backdoor:  51%|█████     | 218558/432000 [01:17<01:35, 2233.95it/s]prepro_backdoor:  51%|█████     | 218803/432000 [01:17<01:33, 2270.45it/s]prepro_backdoor:  51%|█████     | 219083/432000 [01:18<01:28, 2398.21it/s]prepro_backdoor:  51%|█████     | 219346/432000 [01:18<01:26, 2454.37it/s]prepro_backdoor:  51%|█████     | 219620/432000 [01:18<01:23, 2536.03it/s]prepro_backdoor:  51%|█████     | 219875/432000 [01:18<01:24, 2516.30it/s]prepro_backdoor:  51%|█████     | 220169/432000 [01:18<01:20, 2633.31it/s]prepro_backdoor:  51%|█████     | 220467/432000 [01:18<01:17, 2717.14it/s]prepro_backdoor:  51%|█████     | 220740/432000 [01:18<01:28, 2390.24it/s]prepro_backdoor:  51%|█████     | 220998/432000 [01:18<01:26, 2430.35it/s]prepro_backdoor:  51%|█████     | 221251/432000 [01:18<01:26, 2449.65it/s]prepro_backdoor:  51%|█████▏    | 221500/432000 [01:19<01:31, 2304.66it/s]prepro_backdoor:  51%|█████▏    | 221735/432000 [01:19<01:33, 2256.68it/s]prepro_backdoor:  51%|█████▏    | 221964/432000 [01:19<01:36, 2183.23it/s]prepro_backdoor:  51%|█████▏    | 222193/432000 [01:19<01:35, 2204.30it/s]prepro_backdoor:  52%|█████▏    | 222480/432000 [01:19<01:28, 2369.30it/s]prepro_backdoor:  52%|█████▏    | 222734/432000 [01:19<01:27, 2394.68it/s]prepro_backdoor:  52%|█████▏    | 222999/432000 [01:19<01:25, 2449.73it/s]prepro_backdoor:  52%|█████▏    | 223246/432000 [01:19<01:35, 2183.57it/s]prepro_backdoor:  52%|█████▏    | 223517/432000 [01:19<01:30, 2307.67it/s]prepro_backdoor:  52%|█████▏    | 223753/432000 [01:20<01:30, 2302.73it/s]prepro_backdoor:  52%|█████▏    | 224007/432000 [01:20<01:27, 2366.38it/s]prepro_backdoor:  52%|█████▏    | 224247/432000 [01:20<01:30, 2307.14it/s]prepro_backdoor:  52%|█████▏    | 224490/432000 [01:20<01:29, 2324.04it/s]prepro_backdoor:  52%|█████▏    | 224791/432000 [01:20<01:22, 2505.96it/s]prepro_backdoor:  52%|█████▏    | 225081/432000 [01:20<01:19, 2610.50it/s]prepro_backdoor:  52%|█████▏    | 225344/432000 [01:20<01:27, 2366.38it/s]prepro_backdoor:  52%|█████▏    | 225586/432000 [01:20<01:34, 2178.17it/s]prepro_backdoor:  52%|█████▏    | 225810/432000 [01:20<01:39, 2065.19it/s]prepro_backdoor:  52%|█████▏    | 226067/432000 [01:21<01:34, 2188.77it/s]prepro_backdoor:  52%|█████▏    | 226291/432000 [01:21<01:34, 2166.01it/s]prepro_backdoor:  52%|█████▏    | 226642/432000 [01:21<01:21, 2517.65it/s]prepro_backdoor:  53%|█████▎    | 226899/432000 [01:21<01:26, 2376.10it/s]prepro_backdoor:  53%|█████▎    | 227141/432000 [01:21<01:34, 2161.76it/s]prepro_backdoor:  53%|█████▎    | 227489/432000 [01:21<01:21, 2494.93it/s]prepro_backdoor:  53%|█████▎    | 227849/432000 [01:21<01:13, 2780.27it/s]prepro_backdoor:  53%|█████▎    | 228136/432000 [01:21<01:16, 2680.74it/s]prepro_backdoor:  53%|█████▎    | 228411/432000 [01:21<01:16, 2650.37it/s]prepro_backdoor:  53%|█████▎    | 228708/432000 [01:22<01:14, 2731.19it/s]prepro_backdoor:  53%|█████▎    | 228985/432000 [01:22<01:18, 2581.70it/s]prepro_backdoor:  53%|█████▎    | 229264/432000 [01:22<01:17, 2611.17it/s]prepro_backdoor:  53%|█████▎    | 229528/432000 [01:22<01:24, 2384.24it/s]prepro_backdoor:  53%|█████▎    | 229781/432000 [01:22<01:23, 2420.85it/s]prepro_backdoor:  53%|█████▎    | 230027/432000 [01:22<01:26, 2324.31it/s]prepro_backdoor:  53%|█████▎    | 230263/432000 [01:22<01:30, 2221.45it/s]prepro_backdoor:  53%|█████▎    | 230569/432000 [01:22<01:22, 2430.71it/s]prepro_backdoor:  53%|█████▎    | 230843/432000 [01:22<01:20, 2499.56it/s]prepro_backdoor:  53%|█████▎    | 231096/432000 [01:23<01:25, 2337.49it/s]prepro_backdoor:  54%|█████▎    | 231423/432000 [01:23<01:17, 2586.58it/s]prepro_backdoor:  54%|█████▎    | 231687/432000 [01:23<01:25, 2346.82it/s]prepro_backdoor:  54%|█████▎    | 231929/432000 [01:23<01:25, 2333.22it/s]prepro_backdoor:  54%|█████▎    | 232168/432000 [01:23<01:25, 2331.59it/s]prepro_backdoor:  54%|█████▍    | 232408/432000 [01:23<01:25, 2346.65it/s]prepro_backdoor:  54%|█████▍    | 232646/432000 [01:23<01:24, 2345.73it/s]prepro_backdoor:  54%|█████▍    | 232900/432000 [01:23<01:23, 2381.83it/s]prepro_backdoor:  54%|█████▍    | 233159/432000 [01:23<01:21, 2428.28it/s]prepro_backdoor:  54%|█████▍    | 233403/432000 [01:24<01:22, 2414.49it/s]prepro_backdoor:  54%|█████▍    | 233646/432000 [01:24<01:22, 2411.45it/s]prepro_backdoor:  54%|█████▍    | 233888/432000 [01:24<01:23, 2378.93it/s]prepro_backdoor:  54%|█████▍    | 234127/432000 [01:24<01:30, 2178.34it/s]prepro_backdoor:  54%|█████▍    | 234349/432000 [01:24<01:43, 1904.22it/s]prepro_backdoor:  54%|█████▍    | 234559/432000 [01:24<01:41, 1954.01it/s]prepro_backdoor:  54%|█████▍    | 234792/432000 [01:24<01:37, 2030.84it/s]prepro_backdoor:  54%|█████▍    | 235001/432000 [01:24<01:37, 2026.69it/s]prepro_backdoor:  54%|█████▍    | 235208/432000 [01:24<01:37, 2025.94it/s]prepro_backdoor:  54%|█████▍    | 235428/432000 [01:25<01:34, 2074.98it/s]prepro_backdoor:  55%|█████▍    | 235739/432000 [01:25<01:22, 2373.08it/s]prepro_backdoor:  55%|█████▍    | 235979/432000 [01:25<01:22, 2376.89it/s]prepro_backdoor:  55%|█████▍    | 236219/432000 [01:25<01:24, 2325.32it/s]prepro_backdoor:  55%|█████▍    | 236456/432000 [01:25<01:24, 2319.68it/s]prepro_backdoor:  55%|█████▍    | 236716/432000 [01:25<01:21, 2395.52it/s]prepro_backdoor:  55%|█████▍    | 236972/432000 [01:25<01:20, 2417.29it/s]prepro_backdoor:  55%|█████▍    | 237215/432000 [01:25<01:23, 2337.18it/s]prepro_backdoor:  55%|█████▍    | 237506/432000 [01:25<01:18, 2479.36it/s]prepro_backdoor:  55%|█████▌    | 237755/432000 [01:25<01:20, 2417.40it/s]prepro_backdoor:  55%|█████▌    | 237998/432000 [01:26<01:20, 2395.58it/s]prepro_backdoor:  55%|█████▌    | 238239/432000 [01:26<01:23, 2319.58it/s]prepro_backdoor:  55%|█████▌    | 238472/432000 [01:26<01:24, 2284.95it/s]prepro_backdoor:  55%|█████▌    | 238725/432000 [01:26<01:22, 2329.27it/s]prepro_backdoor:  55%|█████▌    | 238969/432000 [01:26<01:22, 2336.55it/s]prepro_backdoor:  55%|█████▌    | 239269/432000 [01:26<01:16, 2507.00it/s]prepro_backdoor:  55%|█████▌    | 239521/432000 [01:26<01:19, 2426.77it/s]prepro_backdoor:  56%|█████▌    | 239765/432000 [01:26<01:25, 2249.71it/s]prepro_backdoor:  56%|█████▌    | 240004/432000 [01:26<01:24, 2281.15it/s]prepro_backdoor:  56%|█████▌    | 240369/432000 [01:27<01:12, 2639.58it/s]prepro_backdoor:  56%|█████▌    | 240679/432000 [01:27<01:09, 2740.29it/s]prepro_backdoor:  56%|█████▌    | 240956/432000 [01:27<01:17, 2480.41it/s]prepro_backdoor:  56%|█████▌    | 241210/432000 [01:27<01:19, 2406.19it/s]prepro_backdoor:  56%|█████▌    | 241455/432000 [01:27<01:20, 2363.34it/s]prepro_backdoor:  56%|█████▌    | 241694/432000 [01:27<01:21, 2334.64it/s]prepro_backdoor:  56%|█████▌    | 241946/432000 [01:27<01:20, 2369.34it/s]prepro_backdoor:  56%|█████▌    | 242192/432000 [01:27<01:19, 2377.41it/s]prepro_backdoor:  56%|█████▌    | 242557/432000 [01:27<01:09, 2730.36it/s]prepro_backdoor:  56%|█████▌    | 242832/432000 [01:28<01:12, 2592.10it/s]prepro_backdoor:  56%|█████▋    | 243094/432000 [01:28<01:21, 2305.48it/s]prepro_backdoor:  56%|█████▋    | 243390/432000 [01:28<01:16, 2470.75it/s]prepro_backdoor:  56%|█████▋    | 243644/432000 [01:28<01:19, 2356.79it/s]prepro_backdoor:  56%|█████▋    | 243973/432000 [01:28<01:12, 2585.28it/s]prepro_backdoor:  57%|█████▋    | 244238/432000 [01:28<01:14, 2530.27it/s]prepro_backdoor:  57%|█████▋    | 244511/432000 [01:28<01:13, 2563.43it/s]prepro_backdoor:  57%|█████▋    | 244912/432000 [01:28<01:03, 2941.81it/s]prepro_backdoor:  57%|█████▋    | 245210/432000 [01:28<01:14, 2518.39it/s]prepro_backdoor:  57%|█████▋    | 245479/432000 [01:29<01:13, 2539.49it/s]prepro_backdoor:  57%|█████▋    | 245742/432000 [01:29<01:19, 2346.92it/s]prepro_backdoor:  57%|█████▋    | 245985/432000 [01:29<01:21, 2271.68it/s]prepro_backdoor:  57%|█████▋    | 246341/432000 [01:29<01:11, 2603.42it/s]prepro_backdoor:  57%|█████▋    | 246610/432000 [01:29<01:14, 2495.63it/s]prepro_backdoor:  57%|█████▋    | 246884/432000 [01:29<01:12, 2551.07it/s]prepro_backdoor:  57%|█████▋    | 247144/432000 [01:29<01:13, 2511.16it/s]prepro_backdoor:  57%|█████▋    | 247399/432000 [01:29<01:25, 2150.04it/s]prepro_backdoor:  57%|█████▋    | 247687/432000 [01:30<01:19, 2314.09it/s]prepro_backdoor:  57%|█████▋    | 247934/432000 [01:30<01:18, 2353.40it/s]prepro_backdoor:  57%|█████▋    | 248177/432000 [01:30<01:21, 2263.26it/s]prepro_backdoor:  58%|█████▊    | 248409/432000 [01:30<01:21, 2263.21it/s]prepro_backdoor:  58%|█████▊    | 248647/432000 [01:30<01:20, 2270.87it/s]prepro_backdoor:  58%|█████▊    | 248877/432000 [01:30<01:21, 2247.03it/s]prepro_backdoor:  58%|█████▊    | 249219/432000 [01:30<01:11, 2573.17it/s]prepro_backdoor:  58%|█████▊    | 249480/432000 [01:30<01:18, 2339.59it/s]prepro_backdoor:  58%|█████▊    | 249720/432000 [01:30<01:17, 2344.62it/s]prepro_backdoor:  58%|█████▊    | 249959/432000 [01:31<01:18, 2330.85it/s]prepro_backdoor:  58%|█████▊    | 250195/432000 [01:31<01:20, 2262.52it/s]prepro_backdoor:  58%|█████▊    | 250424/432000 [01:31<01:23, 2174.07it/s]prepro_backdoor:  58%|█████▊    | 250656/432000 [01:31<01:22, 2199.43it/s]prepro_backdoor:  58%|█████▊    | 250896/432000 [01:31<01:20, 2244.44it/s]prepro_backdoor:  58%|█████▊    | 251210/432000 [01:31<01:12, 2488.76it/s]prepro_backdoor:  58%|█████▊    | 251499/432000 [01:31<01:09, 2579.95it/s]prepro_backdoor:  58%|█████▊    | 251759/432000 [01:31<01:15, 2384.21it/s]prepro_backdoor:  58%|█████▊    | 252016/432000 [01:31<01:14, 2416.11it/s]prepro_backdoor:  58%|█████▊    | 252261/432000 [01:31<01:16, 2348.69it/s]prepro_backdoor:  58%|█████▊    | 252498/432000 [01:32<01:17, 2307.16it/s]prepro_backdoor:  59%|█████▊    | 252781/432000 [01:32<01:13, 2449.02it/s]prepro_backdoor:  59%|█████▊    | 253037/432000 [01:32<01:12, 2454.09it/s]prepro_backdoor:  59%|█████▊    | 253371/432000 [01:32<01:06, 2703.96it/s]prepro_backdoor:  59%|█████▊    | 253644/432000 [01:32<01:06, 2674.49it/s]prepro_backdoor:  59%|█████▉    | 253913/432000 [01:32<01:13, 2416.84it/s]prepro_backdoor:  59%|█████▉    | 254202/432000 [01:32<01:09, 2541.52it/s]prepro_backdoor:  59%|█████▉    | 254495/432000 [01:32<01:07, 2631.62it/s]prepro_backdoor:  59%|█████▉    | 254762/432000 [01:32<01:14, 2383.16it/s]prepro_backdoor:  59%|█████▉    | 255007/432000 [01:33<01:22, 2152.50it/s]prepro_backdoor:  59%|█████▉    | 255266/432000 [01:33<01:18, 2259.77it/s]prepro_backdoor:  59%|█████▉    | 255578/432000 [01:33<01:11, 2465.15it/s]prepro_backdoor:  59%|█████▉    | 255835/432000 [01:33<01:11, 2475.91it/s]prepro_backdoor:  59%|█████▉    | 256114/432000 [01:33<01:09, 2544.10it/s]prepro_backdoor:  59%|█████▉    | 256373/432000 [01:33<01:10, 2505.25it/s]prepro_backdoor:  59%|█████▉    | 256627/432000 [01:33<01:17, 2263.58it/s]prepro_backdoor:  59%|█████▉    | 256859/432000 [01:33<01:17, 2248.73it/s]prepro_backdoor:  60%|█████▉    | 257163/432000 [01:33<01:11, 2453.17it/s]prepro_backdoor:  60%|█████▉    | 257413/432000 [01:34<01:18, 2227.20it/s]prepro_backdoor:  60%|█████▉    | 257682/432000 [01:34<01:14, 2348.12it/s]prepro_backdoor:  60%|█████▉    | 257989/432000 [01:34<01:09, 2519.88it/s]prepro_backdoor:  60%|█████▉    | 258324/432000 [01:34<01:03, 2738.12it/s]prepro_backdoor:  60%|█████▉    | 258603/432000 [01:34<01:09, 2493.21it/s]prepro_backdoor:  60%|█████▉    | 258894/432000 [01:34<01:06, 2602.52it/s]prepro_backdoor:  60%|█████▉    | 259187/432000 [01:34<01:04, 2685.06it/s]prepro_backdoor:  60%|██████    | 259461/432000 [01:34<01:04, 2691.16it/s]prepro_backdoor:  60%|██████    | 259734/432000 [01:34<01:07, 2569.98it/s]prepro_backdoor:  60%|██████    | 259995/432000 [01:35<01:09, 2466.80it/s]prepro_backdoor:  60%|██████    | 260245/432000 [01:35<01:15, 2281.63it/s]prepro_backdoor:  60%|██████    | 260530/432000 [01:35<01:10, 2432.27it/s]prepro_backdoor:  60%|██████    | 260800/432000 [01:35<01:08, 2483.12it/s]prepro_backdoor:  60%|██████    | 261052/432000 [01:35<01:11, 2383.43it/s]prepro_backdoor:  60%|██████    | 261302/432000 [01:35<01:11, 2390.51it/s]prepro_backdoor:  61%|██████    | 261608/432000 [01:35<01:06, 2577.39it/s]prepro_backdoor:  61%|██████    | 261869/432000 [01:35<01:06, 2570.27it/s]prepro_backdoor:  61%|██████    | 262174/432000 [01:35<01:02, 2700.43it/s]prepro_backdoor:  61%|██████    | 262446/432000 [01:36<01:05, 2598.64it/s]prepro_backdoor:  61%|██████    | 262794/432000 [01:36<00:59, 2822.80it/s]prepro_backdoor:  61%|██████    | 263079/432000 [01:36<01:03, 2639.62it/s]prepro_backdoor:  61%|██████    | 263415/432000 [01:36<00:59, 2814.39it/s]prepro_backdoor:  61%|██████    | 263723/432000 [01:36<00:58, 2867.52it/s]prepro_backdoor:  61%|██████    | 264013/432000 [01:36<01:02, 2704.43it/s]prepro_backdoor:  61%|██████    | 264287/432000 [01:36<01:06, 2538.30it/s]prepro_backdoor:  61%|██████    | 264545/432000 [01:36<01:15, 2210.95it/s]prepro_backdoor:  61%|██████▏   | 264800/432000 [01:37<01:12, 2291.54it/s]prepro_backdoor:  61%|██████▏   | 265043/432000 [01:37<01:12, 2316.55it/s]prepro_backdoor:  61%|██████▏   | 265305/432000 [01:37<01:09, 2394.12it/s]prepro_backdoor:  61%|██████▏   | 265549/432000 [01:37<01:11, 2319.63it/s]prepro_backdoor:  62%|██████▏   | 265791/432000 [01:37<01:11, 2328.69it/s]prepro_backdoor:  62%|██████▏   | 266060/432000 [01:37<01:08, 2424.81it/s]prepro_backdoor:  62%|██████▏   | 266327/432000 [01:37<01:07, 2470.78it/s]prepro_backdoor:  62%|██████▏   | 266576/432000 [01:37<01:09, 2395.66it/s]prepro_backdoor:  62%|██████▏   | 266825/432000 [01:37<01:08, 2416.11it/s]prepro_backdoor:  62%|██████▏   | 267068/432000 [01:37<01:12, 2286.66it/s]prepro_backdoor:  62%|██████▏   | 267299/432000 [01:38<01:14, 2217.10it/s]prepro_backdoor:  62%|██████▏   | 267523/432000 [01:38<01:19, 2057.93it/s]prepro_backdoor:  62%|██████▏   | 267754/432000 [01:38<01:17, 2123.71it/s]prepro_backdoor:  62%|██████▏   | 268129/432000 [01:38<01:04, 2558.14it/s]prepro_backdoor:  62%|██████▏   | 268414/432000 [01:38<01:01, 2639.43it/s]prepro_backdoor:  62%|██████▏   | 268695/432000 [01:38<01:01, 2660.21it/s]prepro_backdoor:  62%|██████▏   | 268964/432000 [01:38<01:03, 2551.90it/s]prepro_backdoor:  62%|██████▏   | 269222/432000 [01:38<01:03, 2555.19it/s]prepro_backdoor:  62%|██████▏   | 269480/432000 [01:38<01:07, 2390.29it/s]prepro_backdoor:  62%|██████▏   | 269722/432000 [01:39<01:09, 2343.47it/s]prepro_backdoor:  62%|██████▏   | 269959/432000 [01:39<01:11, 2263.95it/s]prepro_backdoor:  63%|██████▎   | 270297/432000 [01:39<01:02, 2568.76it/s]prepro_backdoor:  63%|██████▎   | 270558/432000 [01:39<01:07, 2400.61it/s]prepro_backdoor:  63%|██████▎   | 270837/432000 [01:39<01:04, 2487.62it/s]prepro_backdoor:  63%|██████▎   | 271090/432000 [01:39<01:11, 2262.52it/s]prepro_backdoor:  63%|██████▎   | 271322/432000 [01:39<01:14, 2161.29it/s]prepro_backdoor:  63%|██████▎   | 271582/432000 [01:39<01:11, 2255.53it/s]prepro_backdoor:  63%|██████▎   | 271860/432000 [01:39<01:07, 2380.34it/s]prepro_backdoor:  63%|██████▎   | 272135/432000 [01:40<01:04, 2464.07it/s]prepro_backdoor:  63%|██████▎   | 272385/432000 [01:40<01:04, 2462.95it/s]prepro_backdoor:  63%|██████▎   | 272634/432000 [01:40<01:04, 2459.27it/s]prepro_backdoor:  63%|██████▎   | 272928/432000 [01:40<01:01, 2579.57it/s]prepro_backdoor:  63%|██████▎   | 273188/432000 [01:40<01:02, 2522.61it/s]prepro_backdoor:  63%|██████▎   | 273463/432000 [01:40<01:01, 2570.63it/s]prepro_backdoor:  63%|██████▎   | 273831/432000 [01:40<00:54, 2890.03it/s]prepro_backdoor:  63%|██████▎   | 274122/432000 [01:40<01:00, 2627.55it/s]prepro_backdoor:  64%|██████▎   | 274391/432000 [01:40<01:02, 2530.80it/s]prepro_backdoor:  64%|██████▎   | 274649/432000 [01:41<01:02, 2502.45it/s]prepro_backdoor:  64%|██████▎   | 274919/432000 [01:41<01:01, 2543.04it/s]prepro_backdoor:  64%|██████▎   | 275221/432000 [01:41<00:59, 2646.48it/s]prepro_backdoor:  64%|██████▍   | 275578/432000 [01:41<00:54, 2890.68it/s]prepro_backdoor:  64%|██████▍   | 275887/432000 [01:41<00:53, 2924.92it/s]prepro_backdoor:  64%|██████▍   | 276229/432000 [01:41<00:50, 3059.61it/s]prepro_backdoor:  64%|██████▍   | 276537/432000 [01:41<00:55, 2785.93it/s]prepro_backdoor:  64%|██████▍   | 276821/432000 [01:41<00:55, 2799.92it/s]prepro_backdoor:  64%|██████▍   | 277105/432000 [01:41<00:57, 2682.89it/s]prepro_backdoor:  64%|██████▍   | 277377/432000 [01:42<00:58, 2657.92it/s]prepro_backdoor:  64%|██████▍   | 277645/432000 [01:42<01:03, 2429.90it/s]prepro_backdoor:  64%|██████▍   | 277893/432000 [01:42<01:07, 2279.80it/s]prepro_backdoor:  64%|██████▍   | 278140/432000 [01:42<01:06, 2305.49it/s]prepro_backdoor:  64%|██████▍   | 278377/432000 [01:42<01:06, 2320.70it/s]prepro_backdoor:  65%|██████▍   | 278671/432000 [01:42<01:02, 2467.96it/s]prepro_backdoor:  65%|██████▍   | 278950/432000 [01:42<00:59, 2556.45it/s]prepro_backdoor:  65%|██████▍   | 279237/432000 [01:42<00:57, 2633.85it/s]prepro_backdoor:  65%|██████▍   | 279503/432000 [01:42<00:59, 2544.35it/s]prepro_backdoor:  65%|██████▍   | 279760/432000 [01:43<01:01, 2470.54it/s]prepro_backdoor:  65%|██████▍   | 280009/432000 [01:43<01:03, 2397.17it/s]prepro_backdoor:  65%|██████▍   | 280269/432000 [01:43<01:02, 2433.71it/s]prepro_backdoor:  65%|██████▍   | 280514/432000 [01:43<01:05, 2319.68it/s]prepro_backdoor:  65%|██████▍   | 280748/432000 [01:43<01:06, 2276.17it/s]prepro_backdoor:  65%|██████▌   | 281062/432000 [01:43<01:00, 2505.31it/s]prepro_backdoor:  65%|██████▌   | 281375/432000 [01:43<00:56, 2653.89it/s]prepro_backdoor:  65%|██████▌   | 281643/432000 [01:43<00:57, 2602.14it/s]prepro_backdoor:  65%|██████▌   | 281932/432000 [01:43<00:56, 2679.60it/s]prepro_backdoor:  65%|██████▌   | 282202/432000 [01:43<00:57, 2627.60it/s]prepro_backdoor:  65%|██████▌   | 282524/432000 [01:44<00:53, 2793.83it/s]prepro_backdoor:  65%|██████▌   | 282805/432000 [01:44<00:54, 2719.17it/s]prepro_backdoor:  66%|██████▌   | 283079/432000 [01:44<00:59, 2493.65it/s]prepro_backdoor:  66%|██████▌   | 283333/432000 [01:44<01:01, 2422.95it/s]prepro_backdoor:  66%|██████▌   | 283578/432000 [01:44<01:02, 2374.79it/s]prepro_backdoor:  66%|██████▌   | 283846/432000 [01:44<01:00, 2453.53it/s]prepro_backdoor:  66%|██████▌   | 284094/432000 [01:44<01:03, 2344.23it/s]prepro_backdoor:  66%|██████▌   | 284412/432000 [01:44<00:57, 2558.71it/s]prepro_backdoor:  66%|██████▌   | 284671/432000 [01:44<01:02, 2370.96it/s]prepro_backdoor:  66%|██████▌   | 284913/432000 [01:45<01:02, 2350.08it/s]prepro_backdoor:  66%|██████▌   | 285194/432000 [01:45<00:59, 2453.21it/s]prepro_backdoor:  66%|██████▌   | 285442/432000 [01:45<01:01, 2372.93it/s]prepro_backdoor:  66%|██████▌   | 285738/432000 [01:45<00:57, 2535.33it/s]prepro_backdoor:  66%|██████▌   | 286011/432000 [01:45<00:56, 2585.11it/s]prepro_backdoor:  66%|██████▋   | 286295/432000 [01:45<00:54, 2649.27it/s]prepro_backdoor:  66%|██████▋   | 286562/432000 [01:45<01:01, 2350.02it/s]prepro_backdoor:  66%|██████▋   | 286804/432000 [01:45<01:01, 2357.04it/s]prepro_backdoor:  66%|██████▋   | 287050/432000 [01:45<01:01, 2370.73it/s]prepro_backdoor:  67%|██████▋   | 287292/432000 [01:46<01:01, 2361.66it/s]prepro_backdoor:  67%|██████▋   | 287549/432000 [01:46<00:59, 2412.27it/s]prepro_backdoor:  67%|██████▋   | 287793/432000 [01:46<01:02, 2324.81it/s]prepro_backdoor:  67%|██████▋   | 288028/432000 [01:46<01:05, 2201.97it/s]prepro_backdoor:  67%|██████▋   | 288297/432000 [01:46<01:02, 2315.53it/s]prepro_backdoor:  67%|██████▋   | 288531/432000 [01:46<01:03, 2263.99it/s]prepro_backdoor:  67%|██████▋   | 288851/432000 [01:46<00:57, 2503.98it/s]prepro_backdoor:  67%|██████▋   | 289104/432000 [01:46<01:04, 2208.31it/s]prepro_backdoor:  67%|██████▋   | 289332/432000 [01:46<01:04, 2204.06it/s]prepro_backdoor:  67%|██████▋   | 289558/432000 [01:47<01:14, 1916.08it/s]prepro_backdoor:  67%|██████▋   | 289844/432000 [01:47<01:06, 2149.76it/s]prepro_backdoor:  67%|██████▋   | 290126/432000 [01:47<01:01, 2311.89it/s]prepro_backdoor:  67%|██████▋   | 290367/432000 [01:47<01:02, 2265.92it/s]prepro_backdoor:  67%|██████▋   | 290719/432000 [01:47<00:54, 2587.52it/s]prepro_backdoor:  67%|██████▋   | 290993/432000 [01:47<00:53, 2620.13it/s]prepro_backdoor:  67%|██████▋   | 291261/432000 [01:47<00:56, 2481.97it/s]prepro_backdoor:  67%|██████▋   | 291565/432000 [01:47<00:53, 2621.17it/s]prepro_backdoor:  68%|██████▊   | 291832/432000 [01:47<00:53, 2612.73it/s]prepro_backdoor:  68%|██████▊   | 292105/432000 [01:48<00:53, 2617.85it/s]prepro_backdoor:  68%|██████▊   | 292369/432000 [01:48<00:53, 2598.98it/s]prepro_backdoor:  68%|██████▊   | 292713/432000 [01:48<00:49, 2834.49it/s]prepro_backdoor:  68%|██████▊   | 292999/432000 [01:48<00:53, 2615.59it/s]prepro_backdoor:  68%|██████▊   | 293265/432000 [01:48<00:54, 2569.10it/s]prepro_backdoor:  68%|██████▊   | 293573/432000 [01:48<00:51, 2704.66it/s]prepro_backdoor:  68%|██████▊   | 293895/432000 [01:48<00:48, 2833.26it/s]prepro_backdoor:  68%|██████▊   | 294181/432000 [01:48<00:54, 2519.65it/s]prepro_backdoor:  68%|██████▊   | 294441/432000 [01:48<00:56, 2422.67it/s]prepro_backdoor:  68%|██████▊   | 294689/432000 [01:49<00:58, 2350.23it/s]prepro_backdoor:  68%|██████▊   | 294928/432000 [01:49<00:58, 2342.95it/s]prepro_backdoor:  68%|██████▊   | 295165/432000 [01:49<00:58, 2340.77it/s]prepro_backdoor:  68%|██████▊   | 295452/432000 [01:49<00:55, 2471.44it/s]prepro_backdoor:  68%|██████▊   | 295701/432000 [01:49<00:56, 2425.03it/s]prepro_backdoor:  69%|██████▊   | 295945/432000 [01:49<00:57, 2364.78it/s]prepro_backdoor:  69%|██████▊   | 296183/432000 [01:49<01:01, 2203.70it/s]prepro_backdoor:  69%|██████▊   | 296437/432000 [01:49<00:59, 2278.96it/s]prepro_backdoor:  69%|██████▊   | 296694/432000 [01:49<00:57, 2335.13it/s]prepro_backdoor:  69%|██████▉   | 297036/432000 [01:50<00:51, 2630.47it/s]prepro_backdoor:  69%|██████▉   | 297317/432000 [01:50<00:50, 2662.05it/s]prepro_backdoor:  69%|██████▉   | 297586/432000 [01:50<00:52, 2577.77it/s]prepro_backdoor:  69%|██████▉   | 297846/432000 [01:50<00:53, 2502.88it/s]prepro_backdoor:  69%|██████▉   | 298134/432000 [01:50<00:52, 2574.27it/s]prepro_backdoor:  69%|██████▉   | 298393/432000 [01:50<00:53, 2496.26it/s]prepro_backdoor:  69%|██████▉   | 298644/432000 [01:50<01:02, 2148.62it/s]prepro_backdoor:  69%|██████▉   | 298868/432000 [01:50<01:04, 2079.81it/s]prepro_backdoor:  69%|██████▉   | 299145/432000 [01:50<00:58, 2254.01it/s]prepro_backdoor:  69%|██████▉   | 299377/432000 [01:51<01:02, 2113.17it/s]prepro_backdoor:  69%|██████▉   | 299594/432000 [01:51<01:03, 2091.78it/s]prepro_backdoor:  69%|██████▉   | 299863/432000 [01:51<00:59, 2232.48it/s]prepro_backdoor:  69%|██████▉   | 300161/432000 [01:51<00:54, 2423.07it/s]prepro_backdoor:  70%|██████▉   | 300410/432000 [01:51<00:54, 2417.96it/s]prepro_backdoor:  70%|██████▉   | 300655/432000 [01:51<00:54, 2411.03it/s]prepro_backdoor:  70%|██████▉   | 300944/432000 [01:51<00:51, 2530.81it/s]prepro_backdoor:  70%|██████▉   | 301214/432000 [01:51<00:51, 2555.67it/s]prepro_backdoor:  70%|██████▉   | 301471/432000 [01:51<00:56, 2310.86it/s]prepro_backdoor:  70%|██████▉   | 301734/432000 [01:52<00:54, 2394.53it/s]prepro_backdoor:  70%|██████▉   | 301978/432000 [01:52<01:01, 2124.33it/s]prepro_backdoor:  70%|██████▉   | 302247/432000 [01:52<00:57, 2255.71it/s]prepro_backdoor:  70%|███████   | 302480/432000 [01:52<01:00, 2150.11it/s]prepro_backdoor:  70%|███████   | 302701/432000 [01:52<01:00, 2147.06it/s]prepro_backdoor:  70%|███████   | 303018/432000 [01:52<00:53, 2414.72it/s]prepro_backdoor:  70%|███████   | 303265/432000 [01:52<00:53, 2418.80it/s]prepro_backdoor:  70%|███████   | 303515/432000 [01:52<00:52, 2434.25it/s]prepro_backdoor:  70%|███████   | 303761/432000 [01:52<00:54, 2373.26it/s]prepro_backdoor:  70%|███████   | 304001/432000 [01:53<00:57, 2245.10it/s]prepro_backdoor:  70%|███████   | 304228/432000 [01:53<00:57, 2234.87it/s]prepro_backdoor:  70%|███████   | 304501/432000 [01:53<00:53, 2365.99it/s]prepro_backdoor:  71%|███████   | 304755/432000 [01:53<00:53, 2390.09it/s]prepro_backdoor:  71%|███████   | 305014/432000 [01:53<00:51, 2446.18it/s]prepro_backdoor:  71%|███████   | 305298/432000 [01:53<00:49, 2553.49it/s]prepro_backdoor:  71%|███████   | 305616/432000 [01:53<00:46, 2732.46it/s]prepro_backdoor:  71%|███████   | 305891/432000 [01:53<00:47, 2636.17it/s]prepro_backdoor:  71%|███████   | 306224/432000 [01:53<00:44, 2824.77it/s]prepro_backdoor:  71%|███████   | 306508/432000 [01:54<00:44, 2821.63it/s]prepro_backdoor:  71%|███████   | 306792/432000 [01:54<00:51, 2437.29it/s]prepro_backdoor:  71%|███████   | 307046/432000 [01:54<00:54, 2298.16it/s]prepro_backdoor:  71%|███████   | 307284/432000 [01:54<00:54, 2295.70it/s]prepro_backdoor:  71%|███████   | 307519/432000 [01:54<00:54, 2286.30it/s]prepro_backdoor:  71%|███████▏  | 307806/432000 [01:54<00:51, 2431.33it/s]prepro_backdoor:  71%|███████▏  | 308053/432000 [01:54<00:52, 2350.65it/s]prepro_backdoor:  71%|███████▏  | 308377/432000 [01:54<00:47, 2597.51it/s]prepro_backdoor:  71%|███████▏  | 308669/432000 [01:54<00:45, 2685.11it/s]prepro_backdoor:  72%|███████▏  | 308972/432000 [01:55<00:44, 2777.07it/s]prepro_backdoor:  72%|███████▏  | 309273/432000 [01:55<00:43, 2831.01it/s]prepro_backdoor:  72%|███████▏  | 309558/432000 [01:55<00:51, 2399.41it/s]prepro_backdoor:  72%|███████▏  | 309820/432000 [01:55<00:49, 2447.25it/s]prepro_backdoor:  72%|███████▏  | 310087/432000 [01:55<00:48, 2504.19it/s]prepro_backdoor:  72%|███████▏  | 310345/432000 [01:55<00:52, 2315.09it/s]prepro_backdoor:  72%|███████▏  | 310591/432000 [01:55<00:51, 2350.57it/s]prepro_backdoor:  72%|███████▏  | 310841/432000 [01:55<00:50, 2382.78it/s]prepro_backdoor:  72%|███████▏  | 311100/432000 [01:55<00:49, 2437.20it/s]prepro_backdoor:  72%|███████▏  | 311356/432000 [01:56<00:48, 2470.44it/s]prepro_backdoor:  72%|███████▏  | 311609/432000 [01:56<00:48, 2460.09it/s]prepro_backdoor:  72%|███████▏  | 311857/432000 [01:56<00:51, 2319.89it/s]prepro_backdoor:  72%|███████▏  | 312095/432000 [01:56<00:51, 2333.26it/s]prepro_backdoor:  72%|███████▏  | 312331/432000 [01:56<00:52, 2279.79it/s]prepro_backdoor:  72%|███████▏  | 312571/432000 [01:56<00:51, 2304.24it/s]prepro_backdoor:  72%|███████▏  | 312816/432000 [01:56<00:51, 2327.61it/s]prepro_backdoor:  72%|███████▏  | 313102/432000 [01:56<00:48, 2457.90it/s]prepro_backdoor:  73%|███████▎  | 313349/432000 [01:56<00:48, 2439.14it/s]prepro_backdoor:  73%|███████▎  | 313594/432000 [01:56<00:49, 2370.71it/s]prepro_backdoor:  73%|███████▎  | 313832/432000 [01:57<00:54, 2150.30it/s]prepro_backdoor:  73%|███████▎  | 314052/432000 [01:57<00:55, 2141.45it/s]prepro_backdoor:  73%|███████▎  | 314281/432000 [01:57<00:54, 2178.39it/s]prepro_backdoor:  73%|███████▎  | 314501/432000 [01:57<00:54, 2157.60it/s]prepro_backdoor:  73%|███████▎  | 314742/432000 [01:57<00:52, 2228.14it/s]prepro_backdoor:  73%|███████▎  | 314970/432000 [01:57<00:52, 2241.84it/s]prepro_backdoor:  73%|███████▎  | 315223/432000 [01:57<00:50, 2299.00it/s]prepro_backdoor:  73%|███████▎  | 315519/432000 [01:57<00:47, 2472.07it/s]prepro_backdoor:  73%|███████▎  | 315767/432000 [01:57<00:49, 2329.83it/s]prepro_backdoor:  73%|███████▎  | 316002/432000 [01:58<00:57, 2014.63it/s]prepro_backdoor:  73%|███████▎  | 316233/432000 [01:58<00:55, 2074.69it/s]prepro_backdoor:  73%|███████▎  | 316447/432000 [01:58<00:58, 1977.50it/s]prepro_backdoor:  73%|███████▎  | 316690/432000 [01:58<00:55, 2086.68it/s]prepro_backdoor:  73%|███████▎  | 316940/432000 [01:58<00:52, 2196.69it/s]prepro_backdoor:  73%|███████▎  | 317199/432000 [01:58<00:49, 2301.37it/s]prepro_backdoor:  73%|███████▎  | 317453/432000 [01:58<00:48, 2355.70it/s]prepro_backdoor:  74%|███████▎  | 317742/432000 [01:58<00:46, 2482.16it/s]prepro_backdoor:  74%|███████▎  | 317993/432000 [01:58<00:45, 2482.99it/s]prepro_backdoor:  74%|███████▎  | 318285/432000 [01:59<00:43, 2587.81it/s]prepro_backdoor:  74%|███████▎  | 318596/432000 [01:59<00:41, 2720.80it/s]prepro_backdoor:  74%|███████▍  | 318869/432000 [01:59<00:41, 2712.52it/s]prepro_backdoor:  74%|███████▍  | 319141/432000 [01:59<00:43, 2599.32it/s]prepro_backdoor:  74%|███████▍  | 319403/432000 [01:59<00:46, 2440.53it/s]prepro_backdoor:  74%|███████▍  | 319650/432000 [01:59<00:48, 2337.77it/s]prepro_backdoor:  74%|███████▍  | 319896/432000 [01:59<00:47, 2359.77it/s]prepro_backdoor:  74%|███████▍  | 320134/432000 [01:59<00:49, 2271.78it/s]prepro_backdoor:  74%|███████▍  | 320363/432000 [01:59<00:49, 2270.80it/s]prepro_backdoor:  74%|███████▍  | 320592/432000 [02:00<00:50, 2200.23it/s]prepro_backdoor:  74%|███████▍  | 320857/432000 [02:00<00:48, 2300.58it/s]prepro_backdoor:  74%|███████▍  | 321100/432000 [02:00<00:47, 2319.10it/s]prepro_backdoor:  74%|███████▍  | 321333/432000 [02:00<00:48, 2297.85it/s]prepro_backdoor:  74%|███████▍  | 321564/432000 [02:00<00:49, 2238.54it/s]prepro_backdoor:  74%|███████▍  | 321832/432000 [02:00<00:46, 2362.54it/s]prepro_backdoor:  75%|███████▍  | 322112/432000 [02:00<00:44, 2469.84it/s]prepro_backdoor:  75%|███████▍  | 322360/432000 [02:00<00:45, 2410.07it/s]prepro_backdoor:  75%|███████▍  | 322604/432000 [02:00<00:45, 2399.08it/s]prepro_backdoor:  75%|███████▍  | 322882/432000 [02:00<00:43, 2501.50it/s]prepro_backdoor:  75%|███████▍  | 323143/432000 [02:01<00:43, 2523.34it/s]prepro_backdoor:  75%|███████▍  | 323433/432000 [02:01<00:41, 2616.20it/s]prepro_backdoor:  75%|███████▍  | 323695/432000 [02:01<00:44, 2439.33it/s]prepro_backdoor:  75%|███████▌  | 324047/432000 [02:01<00:39, 2721.00it/s]prepro_backdoor:  75%|███████▌  | 324405/432000 [02:01<00:36, 2958.97it/s]prepro_backdoor:  75%|███████▌  | 324705/432000 [02:01<00:39, 2695.09it/s]prepro_backdoor:  75%|███████▌  | 324981/432000 [02:01<00:41, 2574.70it/s]prepro_backdoor:  75%|███████▌  | 325244/432000 [02:01<00:41, 2582.93it/s]prepro_backdoor:  75%|███████▌  | 325539/432000 [02:01<00:39, 2671.94it/s]prepro_backdoor:  75%|███████▌  | 325810/432000 [02:02<00:41, 2552.90it/s]prepro_backdoor:  75%|███████▌  | 326069/432000 [02:02<00:43, 2454.79it/s]prepro_backdoor:  76%|███████▌  | 326317/432000 [02:02<00:43, 2440.31it/s]prepro_backdoor:  76%|███████▌  | 326594/432000 [02:02<00:42, 2506.34it/s]prepro_backdoor:  76%|███████▌  | 326863/432000 [02:02<00:41, 2536.76it/s]prepro_backdoor:  76%|███████▌  | 327156/432000 [02:02<00:39, 2621.78it/s]prepro_backdoor:  76%|███████▌  | 327521/432000 [02:02<00:36, 2901.20it/s]prepro_backdoor:  76%|███████▌  | 327813/432000 [02:02<00:36, 2836.90it/s]prepro_backdoor:  76%|███████▌  | 328177/432000 [02:02<00:33, 3063.35it/s]prepro_backdoor:  76%|███████▌  | 328485/432000 [02:03<00:40, 2555.21it/s]prepro_backdoor:  76%|███████▌  | 328756/432000 [02:03<00:40, 2521.14it/s]prepro_backdoor:  76%|███████▌  | 329031/432000 [02:03<00:39, 2574.53it/s]prepro_backdoor:  76%|███████▌  | 329297/432000 [02:03<00:42, 2404.08it/s]prepro_backdoor:  76%|███████▋  | 329545/432000 [02:03<00:43, 2367.68it/s]prepro_backdoor:  76%|███████▋  | 329787/432000 [02:03<00:45, 2269.76it/s]prepro_backdoor:  76%|███████▋  | 330063/432000 [02:03<00:42, 2389.23it/s]prepro_backdoor:  76%|███████▋  | 330377/432000 [02:03<00:39, 2579.10it/s]prepro_backdoor:  77%|███████▋  | 330639/432000 [02:03<00:39, 2556.29it/s]prepro_backdoor:  77%|███████▋  | 330898/432000 [02:04<00:40, 2519.76it/s]prepro_backdoor:  77%|███████▋  | 331152/432000 [02:04<00:41, 2434.31it/s]prepro_backdoor:  77%|███████▋  | 331397/432000 [02:04<00:41, 2410.19it/s]prepro_backdoor:  77%|███████▋  | 331725/432000 [02:04<00:38, 2624.54it/s]prepro_backdoor:  77%|███████▋  | 331989/432000 [02:04<00:38, 2581.71it/s]prepro_backdoor:  77%|███████▋  | 332248/432000 [02:04<00:40, 2458.78it/s]prepro_backdoor:  77%|███████▋  | 332509/432000 [02:04<00:40, 2479.00it/s]prepro_backdoor:  77%|███████▋  | 332758/432000 [02:04<00:41, 2365.10it/s]prepro_backdoor:  77%|███████▋  | 333016/432000 [02:04<00:40, 2415.56it/s]prepro_backdoor:  77%|███████▋  | 333259/432000 [02:05<00:42, 2336.00it/s]prepro_backdoor:  77%|███████▋  | 333543/432000 [02:05<00:39, 2474.78it/s]prepro_backdoor:  77%|███████▋  | 333805/432000 [02:05<00:39, 2507.91it/s]prepro_backdoor:  77%|███████▋  | 334060/432000 [02:05<00:39, 2504.55it/s]prepro_backdoor:  77%|███████▋  | 334312/432000 [02:05<00:41, 2348.77it/s]prepro_backdoor:  77%|███████▋  | 334572/432000 [02:05<00:40, 2410.05it/s]prepro_backdoor:  78%|███████▊  | 334863/432000 [02:05<00:38, 2546.54it/s]prepro_backdoor:  78%|███████▊  | 335255/432000 [02:05<00:33, 2931.48it/s]prepro_backdoor:  78%|███████▊  | 335551/432000 [02:05<00:34, 2775.44it/s]prepro_backdoor:  78%|███████▊  | 335832/432000 [02:06<00:36, 2654.44it/s]prepro_backdoor:  78%|███████▊  | 336101/432000 [02:06<00:37, 2549.90it/s]prepro_backdoor:  78%|███████▊  | 336413/432000 [02:06<00:35, 2698.28it/s]prepro_backdoor:  78%|███████▊  | 336686/432000 [02:06<00:39, 2388.30it/s]prepro_backdoor:  78%|███████▊  | 336933/432000 [02:06<00:41, 2318.60it/s]prepro_backdoor:  78%|███████▊  | 337170/432000 [02:06<00:41, 2310.07it/s]prepro_backdoor:  78%|███████▊  | 337481/432000 [02:06<00:37, 2523.01it/s]prepro_backdoor:  78%|███████▊  | 337777/432000 [02:06<00:36, 2616.83it/s]prepro_backdoor:  78%|███████▊  | 338043/432000 [02:06<00:37, 2506.98it/s]prepro_backdoor:  78%|███████▊  | 338297/432000 [02:07<00:39, 2388.46it/s]prepro_backdoor:  78%|███████▊  | 338573/432000 [02:07<00:37, 2481.52it/s]prepro_backdoor:  78%|███████▊  | 338837/432000 [02:07<00:37, 2504.91it/s]prepro_backdoor:  78%|███████▊  | 339098/432000 [02:07<00:36, 2516.03it/s]prepro_backdoor:  79%|███████▊  | 339352/432000 [02:07<00:37, 2462.13it/s]prepro_backdoor:  79%|███████▊  | 339631/432000 [02:07<00:36, 2529.42it/s]prepro_backdoor:  79%|███████▊  | 339885/432000 [02:07<00:42, 2180.48it/s]prepro_backdoor:  79%|███████▊  | 340112/432000 [02:07<00:42, 2165.63it/s]prepro_backdoor:  79%|███████▉  | 340335/432000 [02:07<00:42, 2180.76it/s]prepro_backdoor:  79%|███████▉  | 340581/432000 [02:08<00:40, 2233.49it/s]prepro_backdoor:  79%|███████▉  | 340828/432000 [02:08<00:39, 2288.89it/s]prepro_backdoor:  79%|███████▉  | 341060/432000 [02:08<00:41, 2212.80it/s]prepro_backdoor:  79%|███████▉  | 341356/432000 [02:08<00:37, 2415.98it/s]prepro_backdoor:  79%|███████▉  | 341671/432000 [02:08<00:34, 2620.51it/s]prepro_backdoor:  79%|███████▉  | 342028/432000 [02:08<00:31, 2880.09it/s]prepro_backdoor:  79%|███████▉  | 342319/432000 [02:08<00:33, 2707.86it/s]prepro_backdoor:  79%|███████▉  | 342602/432000 [02:08<00:32, 2719.28it/s]prepro_backdoor:  79%|███████▉  | 342877/432000 [02:08<00:33, 2684.66it/s]prepro_backdoor:  79%|███████▉  | 343193/432000 [02:08<00:31, 2787.08it/s]prepro_backdoor:  80%|███████▉  | 343474/432000 [02:09<00:33, 2656.99it/s]prepro_backdoor:  80%|███████▉  | 343742/432000 [02:09<00:35, 2501.76it/s]prepro_backdoor:  80%|███████▉  | 344031/432000 [02:09<00:33, 2598.22it/s]prepro_backdoor:  80%|███████▉  | 344294/432000 [02:09<00:34, 2572.06it/s]prepro_backdoor:  80%|███████▉  | 344559/432000 [02:09<00:34, 2568.12it/s]prepro_backdoor:  80%|███████▉  | 344823/432000 [02:09<00:33, 2588.10it/s]prepro_backdoor:  80%|███████▉  | 345088/432000 [02:09<00:33, 2595.58it/s]prepro_backdoor:  80%|███████▉  | 345381/432000 [02:09<00:32, 2670.03it/s]prepro_backdoor:  80%|████████  | 345649/432000 [02:09<00:32, 2619.02it/s]prepro_backdoor:  80%|████████  | 345923/432000 [02:10<00:32, 2648.09it/s]prepro_backdoor:  80%|████████  | 346189/432000 [02:10<00:35, 2385.16it/s]prepro_backdoor:  80%|████████  | 346516/432000 [02:10<00:32, 2619.62it/s]prepro_backdoor:  80%|████████  | 346836/432000 [02:10<00:30, 2766.18it/s]prepro_backdoor:  80%|████████  | 347269/432000 [02:10<00:26, 3193.17it/s]prepro_backdoor:  80%|████████  | 347601/432000 [02:10<00:26, 3213.85it/s]prepro_backdoor:  81%|████████  | 347926/432000 [02:10<00:26, 3145.69it/s]prepro_backdoor:  81%|████████  | 348310/432000 [02:10<00:25, 3343.77it/s]prepro_backdoor:  81%|████████  | 348647/432000 [02:10<00:24, 3346.05it/s]prepro_backdoor:  81%|████████  | 349063/432000 [02:11<00:23, 3565.34it/s]prepro_backdoor:  81%|████████  | 349443/432000 [02:11<00:22, 3606.35it/s]prepro_backdoor:  81%|████████  | 349808/432000 [02:11<00:22, 3600.39it/s]prepro_backdoor:  81%|████████  | 350248/432000 [02:11<00:21, 3829.67it/s]prepro_backdoor:  81%|████████  | 350654/432000 [02:11<00:20, 3884.72it/s]prepro_backdoor:  81%|████████▏ | 351044/432000 [02:11<00:21, 3699.58it/s]prepro_backdoor:  81%|████████▏ | 351417/432000 [02:11<00:22, 3518.71it/s]prepro_backdoor:  81%|████████▏ | 351772/432000 [02:11<00:24, 3314.51it/s]prepro_backdoor:  82%|████████▏ | 352134/432000 [02:11<00:23, 3389.50it/s]prepro_backdoor:  82%|████████▏ | 352661/432000 [02:11<00:20, 3908.56it/s]prepro_backdoor:  82%|████████▏ | 353058/432000 [02:12<00:20, 3809.46it/s]prepro_backdoor:  82%|████████▏ | 353444/432000 [02:12<00:20, 3766.89it/s]prepro_backdoor:  82%|████████▏ | 353875/432000 [02:12<00:20, 3898.44it/s]prepro_backdoor:  82%|████████▏ | 354408/432000 [02:12<00:18, 4298.05it/s]prepro_backdoor:  82%|████████▏ | 354841/432000 [02:12<00:19, 3908.99it/s]prepro_backdoor:  82%|████████▏ | 355241/432000 [02:12<00:20, 3749.96it/s]prepro_backdoor:  82%|████████▏ | 355623/432000 [02:12<00:22, 3453.23it/s]prepro_backdoor:  82%|████████▏ | 355976/432000 [02:12<00:23, 3225.99it/s]prepro_backdoor:  82%|████████▏ | 356305/432000 [02:13<00:24, 3108.84it/s]prepro_backdoor:  83%|████████▎ | 356830/432000 [02:13<00:20, 3648.15it/s]prepro_backdoor:  83%|████████▎ | 357297/432000 [02:13<00:19, 3918.64it/s]prepro_backdoor:  83%|████████▎ | 357699/432000 [02:13<00:21, 3515.68it/s]prepro_backdoor:  83%|████████▎ | 358064/432000 [02:13<00:21, 3457.82it/s]prepro_backdoor:  83%|████████▎ | 358484/432000 [02:13<00:20, 3651.47it/s]prepro_backdoor:  83%|████████▎ | 358901/432000 [02:13<00:19, 3782.49it/s]prepro_backdoor:  83%|████████▎ | 359287/432000 [02:13<00:19, 3638.20it/s]prepro_backdoor:  83%|████████▎ | 359657/432000 [02:13<00:19, 3640.37it/s]prepro_backdoor:  83%|████████▎ | 360025/432000 [02:14<00:20, 3546.77it/s]prepro_backdoor:  83%|████████▎ | 360387/432000 [02:14<00:20, 3557.80it/s]prepro_backdoor:  84%|████████▎ | 360842/432000 [02:14<00:18, 3820.53it/s]prepro_backdoor:  84%|████████▎ | 361257/432000 [02:14<00:18, 3901.64it/s]prepro_backdoor:  84%|████████▎ | 361680/432000 [02:14<00:17, 3997.10it/s]prepro_backdoor:  84%|████████▍ | 362082/432000 [02:14<00:19, 3623.59it/s]prepro_backdoor:  84%|████████▍ | 362452/432000 [02:14<00:20, 3408.50it/s]prepro_backdoor:  84%|████████▍ | 362800/432000 [02:14<00:20, 3368.40it/s]prepro_backdoor:  84%|████████▍ | 363165/432000 [02:14<00:20, 3422.78it/s]prepro_backdoor:  84%|████████▍ | 363580/432000 [02:14<00:18, 3618.16it/s]prepro_backdoor:  84%|████████▍ | 363946/432000 [02:15<00:19, 3517.61it/s]prepro_backdoor:  84%|████████▍ | 364356/432000 [02:15<00:18, 3665.14it/s]prepro_backdoor:  84%|████████▍ | 364733/432000 [02:15<00:18, 3686.11it/s]prepro_backdoor:  85%|████████▍ | 365104/432000 [02:15<00:18, 3638.83it/s]prepro_backdoor:  85%|████████▍ | 365548/432000 [02:15<00:17, 3853.47it/s]prepro_backdoor:  85%|████████▍ | 365935/432000 [02:15<00:17, 3816.72it/s]prepro_backdoor:  85%|████████▍ | 366369/432000 [02:15<00:16, 3961.25it/s]prepro_backdoor:  85%|████████▍ | 366858/432000 [02:15<00:15, 4227.22it/s]prepro_backdoor:  85%|████████▌ | 367282/432000 [02:15<00:17, 3746.47it/s]prepro_backdoor:  85%|████████▌ | 367668/432000 [02:16<00:18, 3412.08it/s]prepro_backdoor:  85%|████████▌ | 368021/432000 [02:16<00:19, 3355.95it/s]prepro_backdoor:  85%|████████▌ | 368411/432000 [02:16<00:18, 3490.65it/s]prepro_backdoor:  85%|████████▌ | 368768/432000 [02:16<00:19, 3248.38it/s]prepro_backdoor:  85%|████████▌ | 369155/432000 [02:16<00:18, 3394.37it/s]prepro_backdoor:  86%|████████▌ | 369501/432000 [02:16<00:18, 3371.04it/s]prepro_backdoor:  86%|████████▌ | 369853/432000 [02:16<00:18, 3405.56it/s]prepro_backdoor:  86%|████████▌ | 370324/432000 [02:16<00:16, 3767.15it/s]prepro_backdoor:  86%|████████▌ | 370707/432000 [02:16<00:16, 3781.41it/s]prepro_backdoor:  86%|████████▌ | 371095/432000 [02:17<00:16, 3798.54it/s]prepro_backdoor:  86%|████████▌ | 371493/432000 [02:17<00:15, 3832.51it/s]prepro_backdoor:  86%|████████▌ | 371883/432000 [02:17<00:15, 3823.10it/s]prepro_backdoor:  86%|████████▌ | 372272/432000 [02:17<00:15, 3826.31it/s]prepro_backdoor:  86%|████████▋ | 372656/432000 [02:17<00:16, 3539.66it/s]prepro_backdoor:  86%|████████▋ | 373022/432000 [02:17<00:16, 3570.03it/s]prepro_backdoor:  86%|████████▋ | 373388/432000 [02:17<00:16, 3572.70it/s]prepro_backdoor:  87%|████████▋ | 373748/432000 [02:17<00:17, 3359.32it/s]prepro_backdoor:  87%|████████▋ | 374108/432000 [02:17<00:16, 3415.99it/s]prepro_backdoor:  87%|████████▋ | 374601/432000 [02:18<00:15, 3807.86it/s]prepro_backdoor:  87%|████████▋ | 375023/432000 [02:18<00:14, 3918.80it/s]prepro_backdoor:  87%|████████▋ | 375472/432000 [02:18<00:13, 4082.48it/s]prepro_backdoor:  87%|████████▋ | 375883/432000 [02:18<00:14, 3891.94it/s]prepro_backdoor:  87%|████████▋ | 376283/432000 [02:18<00:14, 3897.67it/s]prepro_backdoor:  87%|████████▋ | 376676/432000 [02:18<00:14, 3697.74it/s]prepro_backdoor:  87%|████████▋ | 377050/432000 [02:18<00:14, 3685.94it/s]prepro_backdoor:  87%|████████▋ | 377448/432000 [02:18<00:14, 3748.16it/s]prepro_backdoor:  87%|████████▋ | 377856/432000 [02:18<00:14, 3819.93it/s]prepro_backdoor:  88%|████████▊ | 378245/432000 [02:18<00:14, 3826.25it/s]prepro_backdoor:  88%|████████▊ | 378629/432000 [02:19<00:14, 3743.01it/s]prepro_backdoor:  88%|████████▊ | 379005/432000 [02:19<00:16, 3209.44it/s]prepro_backdoor:  88%|████████▊ | 379547/432000 [02:19<00:13, 3772.14it/s]prepro_backdoor:  88%|████████▊ | 379970/432000 [02:19<00:13, 3872.65it/s]prepro_backdoor:  88%|████████▊ | 380370/432000 [02:19<00:14, 3539.82it/s]prepro_backdoor:  88%|████████▊ | 380781/432000 [02:19<00:13, 3675.59it/s]prepro_backdoor:  88%|████████▊ | 381162/432000 [02:19<00:13, 3709.79it/s]prepro_backdoor:  88%|████████▊ | 381541/432000 [02:19<00:13, 3608.27it/s]prepro_backdoor:  88%|████████▊ | 381908/432000 [02:19<00:14, 3447.53it/s]prepro_backdoor:  88%|████████▊ | 382258/432000 [02:20<00:14, 3436.47it/s]prepro_backdoor:  89%|████████▊ | 382605/432000 [02:20<00:14, 3303.08it/s]prepro_backdoor:  89%|████████▊ | 382968/432000 [02:20<00:14, 3387.11it/s]prepro_backdoor:  89%|████████▊ | 383310/432000 [02:20<00:14, 3309.12it/s]prepro_backdoor:  89%|████████▉ | 383682/432000 [02:20<00:14, 3403.78it/s]prepro_backdoor:  89%|████████▉ | 384067/432000 [02:20<00:13, 3513.54it/s]prepro_backdoor:  89%|████████▉ | 384478/432000 [02:20<00:12, 3685.14it/s]prepro_backdoor:  89%|████████▉ | 384867/432000 [02:20<00:12, 3740.62it/s]prepro_backdoor:  89%|████████▉ | 385261/432000 [02:20<00:12, 3767.68it/s]prepro_backdoor:  89%|████████▉ | 385639/432000 [02:21<00:12, 3680.08it/s]prepro_backdoor:  89%|████████▉ | 386008/432000 [02:21<00:13, 3401.44it/s]prepro_backdoor:  89%|████████▉ | 386353/432000 [02:21<00:14, 3071.15it/s]prepro_backdoor:  90%|████████▉ | 386739/432000 [02:21<00:13, 3264.04it/s]prepro_backdoor:  90%|████████▉ | 387138/432000 [02:21<00:12, 3455.26it/s]prepro_backdoor:  90%|████████▉ | 387583/432000 [02:21<00:11, 3712.10it/s]prepro_backdoor:  90%|████████▉ | 387978/432000 [02:21<00:11, 3769.75it/s]prepro_backdoor:  90%|████████▉ | 388360/432000 [02:21<00:11, 3664.49it/s]prepro_backdoor:  90%|████████▉ | 388731/432000 [02:21<00:12, 3532.92it/s]prepro_backdoor:  90%|█████████ | 389151/432000 [02:22<00:11, 3713.04it/s]prepro_backdoor:  90%|█████████ | 389588/432000 [02:22<00:10, 3893.27it/s]prepro_backdoor:  90%|█████████ | 389981/432000 [02:22<00:11, 3621.44it/s]prepro_backdoor:  90%|█████████ | 390387/432000 [02:22<00:11, 3738.35it/s]prepro_backdoor:  90%|█████████ | 390766/432000 [02:22<00:11, 3615.97it/s]prepro_backdoor:  91%|█████████ | 391132/432000 [02:22<00:12, 3303.88it/s]prepro_backdoor:  91%|█████████ | 391520/432000 [02:22<00:11, 3444.35it/s]prepro_backdoor:  91%|█████████ | 391927/432000 [02:22<00:11, 3601.15it/s]prepro_backdoor:  91%|█████████ | 392367/432000 [02:22<00:10, 3813.34it/s]prepro_backdoor:  91%|█████████ | 392754/432000 [02:23<00:10, 3639.59it/s]prepro_backdoor:  91%|█████████ | 393161/432000 [02:23<00:10, 3747.74it/s]prepro_backdoor:  91%|█████████ | 393540/432000 [02:23<00:11, 3487.29it/s]prepro_backdoor:  91%|█████████ | 393908/432000 [02:23<00:10, 3539.26it/s]prepro_backdoor:  91%|█████████▏| 394274/432000 [02:23<00:10, 3556.47it/s]prepro_backdoor:  91%|█████████▏| 394633/432000 [02:23<00:10, 3506.95it/s]prepro_backdoor:  91%|█████████▏| 394986/432000 [02:23<00:11, 3262.77it/s]prepro_backdoor:  92%|█████████▏| 395363/432000 [02:23<00:10, 3383.33it/s]prepro_backdoor:  92%|█████████▏| 395749/432000 [02:23<00:10, 3502.00it/s]prepro_backdoor:  92%|█████████▏| 396220/432000 [02:24<00:09, 3835.14it/s]prepro_backdoor:  92%|█████████▏| 396608/432000 [02:24<00:09, 3803.69it/s]prepro_backdoor:  92%|█████████▏| 397141/432000 [02:24<00:08, 4238.16it/s]prepro_backdoor:  92%|█████████▏| 397569/432000 [02:24<00:08, 4230.37it/s]prepro_backdoor:  92%|█████████▏| 397995/432000 [02:24<00:08, 4114.48it/s]prepro_backdoor:  92%|█████████▏| 398409/432000 [02:24<00:08, 3773.83it/s]prepro_backdoor:  92%|█████████▏| 398793/432000 [02:24<00:09, 3633.45it/s]prepro_backdoor:  92%|█████████▏| 399161/432000 [02:24<00:09, 3445.32it/s]prepro_backdoor:  92%|█████████▏| 399511/432000 [02:24<00:09, 3442.66it/s]prepro_backdoor:  93%|█████████▎| 399914/432000 [02:24<00:08, 3590.85it/s]prepro_backdoor:  93%|█████████▎| 400277/432000 [02:25<00:08, 3581.91it/s]prepro_backdoor:  93%|█████████▎| 400645/432000 [02:25<00:08, 3609.84it/s]prepro_backdoor:  93%|█████████▎| 401012/432000 [02:25<00:08, 3611.60it/s]prepro_backdoor:  93%|█████████▎| 401389/432000 [02:25<00:08, 3656.30it/s]prepro_backdoor:  93%|█████████▎| 401825/432000 [02:25<00:07, 3857.03it/s]prepro_backdoor:  93%|█████████▎| 402237/432000 [02:25<00:07, 3930.05it/s]prepro_backdoor:  93%|█████████▎| 402631/432000 [02:25<00:07, 3771.40it/s]prepro_backdoor:  93%|█████████▎| 403010/432000 [02:25<00:08, 3501.61it/s]prepro_backdoor:  93%|█████████▎| 403365/432000 [02:25<00:08, 3484.12it/s]prepro_backdoor:  93%|█████████▎| 403717/432000 [02:26<00:08, 3461.08it/s]prepro_backdoor:  94%|█████████▎| 404149/432000 [02:26<00:07, 3678.96it/s]prepro_backdoor:  94%|█████████▎| 404555/432000 [02:26<00:07, 3772.42it/s]prepro_backdoor:  94%|█████████▎| 404935/432000 [02:26<00:07, 3529.65it/s]prepro_backdoor:  94%|█████████▍| 405292/432000 [02:26<00:07, 3442.53it/s]prepro_backdoor:  94%|█████████▍| 405640/432000 [02:26<00:07, 3419.04it/s]prepro_backdoor:  94%|█████████▍| 405984/432000 [02:26<00:07, 3414.59it/s]prepro_backdoor:  94%|█████████▍| 406327/432000 [02:26<00:07, 3414.46it/s]prepro_backdoor:  94%|█████████▍| 406685/432000 [02:26<00:07, 3436.62it/s]prepro_backdoor:  94%|█████████▍| 407049/432000 [02:26<00:07, 3479.64it/s]prepro_backdoor:  94%|█████████▍| 407416/432000 [02:27<00:06, 3524.25it/s]prepro_backdoor:  94%|█████████▍| 407847/432000 [02:27<00:06, 3743.22it/s]prepro_backdoor:  95%|█████████▍| 408281/432000 [02:27<00:06, 3897.14it/s]prepro_backdoor:  95%|█████████▍| 408766/432000 [02:27<00:05, 4162.65it/s]prepro_backdoor:  95%|█████████▍| 409183/432000 [02:27<00:05, 3828.86it/s]prepro_backdoor:  95%|█████████▍| 409572/432000 [02:27<00:06, 3640.70it/s]prepro_backdoor:  95%|█████████▍| 409941/432000 [02:27<00:06, 3487.07it/s]prepro_backdoor:  95%|█████████▍| 410294/432000 [02:27<00:06, 3480.13it/s]prepro_backdoor:  95%|█████████▌| 410645/432000 [02:27<00:06, 3358.78it/s]prepro_backdoor:  95%|█████████▌| 410983/432000 [02:28<00:06, 3100.68it/s]prepro_backdoor:  95%|█████████▌| 411367/432000 [02:28<00:06, 3285.67it/s]prepro_backdoor:  95%|█████████▌| 411851/432000 [02:28<00:05, 3712.07it/s]prepro_backdoor:  95%|█████████▌| 412240/432000 [02:28<00:05, 3735.26it/s]prepro_backdoor:  96%|█████████▌| 412619/432000 [02:28<00:05, 3667.57it/s]prepro_backdoor:  96%|█████████▌| 412990/432000 [02:28<00:05, 3555.56it/s]prepro_backdoor:  96%|█████████▌| 413349/432000 [02:28<00:05, 3321.16it/s]prepro_backdoor:  96%|█████████▌| 413725/432000 [02:28<00:05, 3428.73it/s]prepro_backdoor:  96%|█████████▌| 414147/432000 [02:28<00:04, 3628.87it/s]prepro_backdoor:  96%|█████████▌| 414514/432000 [02:29<00:04, 3597.63it/s]prepro_backdoor:  96%|█████████▌| 414881/432000 [02:29<00:04, 3599.64it/s]prepro_backdoor:  96%|█████████▌| 415243/432000 [02:29<00:04, 3380.88it/s]prepro_backdoor:  96%|█████████▌| 415604/432000 [02:29<00:04, 3427.13it/s]prepro_backdoor:  96%|█████████▋| 415950/432000 [02:29<00:04, 3275.36it/s]prepro_backdoor:  96%|█████████▋| 416349/432000 [02:29<00:04, 3471.82it/s]prepro_backdoor:  96%|█████████▋| 416700/432000 [02:29<00:04, 3398.49it/s]prepro_backdoor:  97%|█████████▋| 417043/432000 [02:29<00:04, 3348.01it/s]prepro_backdoor:  97%|█████████▋| 417380/432000 [02:29<00:04, 3336.29it/s]prepro_backdoor:  97%|█████████▋| 417757/432000 [02:30<00:04, 3437.88it/s]prepro_backdoor:  97%|█████████▋| 418128/432000 [02:30<00:03, 3498.25it/s]prepro_backdoor:  97%|█████████▋| 418565/432000 [02:30<00:03, 3746.99it/s]prepro_backdoor:  97%|█████████▋| 418941/432000 [02:30<00:03, 3417.43it/s]prepro_backdoor:  97%|█████████▋| 419330/432000 [02:30<00:03, 3542.31it/s]prepro_backdoor:  97%|█████████▋| 419862/432000 [02:30<00:03, 4016.88it/s]prepro_backdoor:  97%|█████████▋| 420270/432000 [02:30<00:03, 3747.78it/s]prepro_backdoor:  97%|█████████▋| 420652/432000 [02:30<00:03, 3636.71it/s]prepro_backdoor:  97%|█████████▋| 421021/432000 [02:30<00:03, 3646.86it/s]prepro_backdoor:  98%|█████████▊| 421390/432000 [02:31<00:03, 3478.22it/s]prepro_backdoor:  98%|█████████▊| 421764/432000 [02:31<00:02, 3529.81it/s]prepro_backdoor:  98%|█████████▊| 422142/432000 [02:31<00:02, 3587.93it/s]prepro_backdoor:  98%|█████████▊| 422568/432000 [02:31<00:02, 3767.35it/s]prepro_backdoor:  98%|█████████▊| 423004/432000 [02:31<00:02, 3911.01it/s]prepro_backdoor:  98%|█████████▊| 423454/432000 [02:31<00:02, 4080.08it/s]prepro_backdoor:  98%|█████████▊| 423884/432000 [02:31<00:01, 4136.61it/s]prepro_backdoor:  98%|█████████▊| 424299/432000 [02:31<00:01, 4066.63it/s]prepro_backdoor:  98%|█████████▊| 424707/432000 [02:31<00:01, 3936.90it/s]prepro_backdoor:  98%|█████████▊| 425141/432000 [02:31<00:01, 4042.16it/s]prepro_backdoor:  99%|█████████▊| 425547/432000 [02:32<00:01, 3988.90it/s]prepro_backdoor:  99%|█████████▊| 425947/432000 [02:32<00:01, 3784.91it/s]prepro_backdoor:  99%|█████████▊| 426341/432000 [02:32<00:01, 3814.06it/s]prepro_backdoor:  99%|█████████▉| 426725/432000 [02:32<00:01, 3814.63it/s]prepro_backdoor:  99%|█████████▉| 427108/432000 [02:32<00:01, 3554.28it/s]prepro_backdoor:  99%|█████████▉| 427468/432000 [02:32<00:01, 3467.20it/s]prepro_backdoor:  99%|█████████▉| 427818/432000 [02:32<00:01, 3239.94it/s]prepro_backdoor:  99%|█████████▉| 428196/432000 [02:32<00:01, 3371.88it/s]prepro_backdoor:  99%|█████████▉| 428717/432000 [02:32<00:00, 3836.64it/s]prepro_backdoor:  99%|█████████▉| 429106/432000 [02:33<00:00, 3624.72it/s]prepro_backdoor:  99%|█████████▉| 429537/432000 [02:33<00:00, 3483.42it/s]prepro_backdoor: 100%|█████████▉| 429891/432000 [02:33<00:00, 3292.14it/s]prepro_backdoor: 100%|█████████▉| 430302/432000 [02:33<00:00, 3486.72it/s]prepro_backdoor: 100%|█████████▉| 430716/432000 [02:33<00:00, 3641.57it/s]prepro_backdoor: 100%|█████████▉| 431118/432000 [02:33<00:00, 3728.80it/s]prepro_backdoor: 100%|█████████▉| 431507/432000 [02:33<00:00, 3752.78it/s]prepro_backdoor: 100%|█████████▉| 431886/432000 [02:33<00:00, 3601.10it/s]prepro_backdoor: 100%|██████████| 432000/432000 [02:33<00:00, 2807.31it/s]
DEBUG:root:Reminder: plz note that if p_num or pratio exceed the number of possible candidate samples
 then only maximum number of samples will be applied
DEBUG:root:Reminder: priority p_num > pratio, and choosing fix number of sample is prefered if possible 
INFO:root:poison num:7000.0,real pratio:0.8333333333333334
2025-03-09:18:53:51 [INFO    ] [backdoor_generate_poison_index.py:61] poison num:7000.0,real pratio:0.8333333333333334
INFO:root:save file format is .png
2025-03-09:18:53:51 [INFO    ] [bd_dataset_v2.py:133] save file format is .png
prepro_backdoor:   0%|          | 0/8400 [00:00<?, ?it/s]prepro_backdoor:  17%|█▋        | 1433/8400 [00:00<00:00, 14071.09it/s]prepro_backdoor:  34%|███▍      | 2841/8400 [00:03<00:09, 614.59it/s]  prepro_backdoor:  41%|████      | 3442/8400 [00:05<00:09, 511.03it/s]prepro_backdoor:  45%|████▌     | 3785/8400 [00:06<00:09, 480.75it/s]prepro_backdoor:  48%|████▊     | 4008/8400 [00:07<00:09, 465.77it/s]prepro_backdoor:  50%|████▉     | 4165/8400 [00:07<00:09, 450.01it/s]prepro_backdoor:  51%|█████     | 4281/8400 [00:07<00:09, 439.49it/s]prepro_backdoor:  52%|█████▏    | 4371/8400 [00:08<00:09, 434.71it/s]prepro_backdoor:  53%|█████▎    | 4445/8400 [00:08<00:09, 431.55it/s]prepro_backdoor:  54%|█████▎    | 4509/8400 [00:08<00:09, 428.17it/s]prepro_backdoor:  54%|█████▍    | 4566/8400 [00:08<00:09, 420.85it/s]prepro_backdoor:  55%|█████▍    | 4617/8400 [00:08<00:09, 409.31it/s]prepro_backdoor:  56%|█████▌    | 4664/8400 [00:08<00:09, 400.62it/s]prepro_backdoor:  56%|█████▌    | 4708/8400 [00:09<00:09, 391.48it/s]prepro_backdoor:  57%|█████▋    | 4749/8400 [00:09<00:09, 368.81it/s]prepro_backdoor:  57%|█████▋    | 4787/8400 [00:09<00:09, 363.45it/s]prepro_backdoor:  57%|█████▋    | 4824/8400 [00:09<00:10, 355.89it/s]prepro_backdoor:  58%|█████▊    | 4860/8400 [00:09<00:10, 341.41it/s]prepro_backdoor:  58%|█████▊    | 4894/8400 [00:09<00:10, 338.01it/s]prepro_backdoor:  59%|█████▊    | 4928/8400 [00:09<00:10, 333.34it/s]prepro_backdoor:  59%|█████▉    | 4962/8400 [00:09<00:10, 332.55it/s]prepro_backdoor:  60%|█████▉    | 4999/8400 [00:09<00:09, 341.61it/s]prepro_backdoor:  60%|██████    | 5040/8400 [00:10<00:09, 348.63it/s]prepro_backdoor:  60%|██████    | 5080/8400 [00:10<00:09, 361.14it/s]prepro_backdoor:  61%|██████    | 5120/8400 [00:10<00:08, 370.97it/s]prepro_backdoor:  61%|██████▏   | 5159/8400 [00:10<00:08, 374.26it/s]prepro_backdoor:  62%|██████▏   | 5198/8400 [00:10<00:08, 377.16it/s]prepro_backdoor:  62%|██████▏   | 5236/8400 [00:10<00:08, 374.46it/s]prepro_backdoor:  63%|██████▎   | 5274/8400 [00:10<00:08, 371.85it/s]prepro_backdoor:  63%|██████▎   | 5315/8400 [00:10<00:08, 380.65it/s]prepro_backdoor:  64%|██████▎   | 5354/8400 [00:10<00:08, 367.85it/s]prepro_backdoor:  64%|██████▍   | 5391/8400 [00:10<00:08, 348.34it/s]prepro_backdoor:  65%|██████▍   | 5427/8400 [00:11<00:08, 334.91it/s]prepro_backdoor:  65%|██████▌   | 5461/8400 [00:11<00:08, 334.88it/s]prepro_backdoor:  65%|██████▌   | 5499/8400 [00:11<00:08, 345.98it/s]prepro_backdoor:  66%|██████▌   | 5534/8400 [00:11<00:08, 336.50it/s]prepro_backdoor:  66%|██████▋   | 5571/8400 [00:11<00:08, 343.69it/s]prepro_backdoor:  67%|██████▋   | 5611/8400 [00:11<00:07, 359.80it/s]prepro_backdoor:  67%|██████▋   | 5651/8400 [00:11<00:07, 369.24it/s]prepro_backdoor:  68%|██████▊   | 5692/8400 [00:11<00:07, 380.40it/s]prepro_backdoor:  68%|██████▊   | 5731/8400 [00:11<00:07, 373.84it/s]prepro_backdoor:  69%|██████▊   | 5769/8400 [00:12<00:08, 325.55it/s]prepro_backdoor:  69%|██████▉   | 5808/8400 [00:12<00:07, 341.38it/s]prepro_backdoor:  70%|██████▉   | 5848/8400 [00:12<00:07, 352.15it/s]prepro_backdoor:  70%|███████   | 5885/8400 [00:12<00:07, 355.15it/s]prepro_backdoor:  71%|███████   | 5925/8400 [00:12<00:06, 366.60it/s]prepro_backdoor:  71%|███████   | 5963/8400 [00:12<00:06, 353.42it/s]prepro_backdoor:  71%|███████▏  | 5999/8400 [00:12<00:06, 346.62it/s]prepro_backdoor:  72%|███████▏  | 6034/8400 [00:12<00:06, 339.58it/s]prepro_backdoor:  72%|███████▏  | 6073/8400 [00:12<00:06, 351.99it/s]prepro_backdoor:  73%|███████▎  | 6112/8400 [00:13<00:06, 360.89it/s]prepro_backdoor:  73%|███████▎  | 6151/8400 [00:13<00:06, 367.44it/s]prepro_backdoor:  74%|███████▎  | 6191/8400 [00:13<00:05, 375.65it/s]prepro_backdoor:  74%|███████▍  | 6231/8400 [00:13<00:05, 382.73it/s]prepro_backdoor:  75%|███████▍  | 6270/8400 [00:13<00:05, 378.53it/s]prepro_backdoor:  75%|███████▌  | 6308/8400 [00:13<00:05, 363.96it/s]prepro_backdoor:  76%|███████▌  | 6348/8400 [00:13<00:05, 372.49it/s]prepro_backdoor:  76%|███████▌  | 6387/8400 [00:13<00:05, 377.56it/s]prepro_backdoor:  77%|███████▋  | 6428/8400 [00:13<00:05, 384.52it/s]prepro_backdoor:  77%|███████▋  | 6468/8400 [00:13<00:04, 386.54it/s]prepro_backdoor:  78%|███████▊  | 6510/8400 [00:14<00:04, 394.35it/s]prepro_backdoor:  78%|███████▊  | 6550/8400 [00:14<00:05, 369.15it/s]prepro_backdoor:  78%|███████▊  | 6590/8400 [00:14<00:04, 376.95it/s]prepro_backdoor:  79%|███████▉  | 6629/8400 [00:14<00:04, 378.30it/s]prepro_backdoor:  79%|███████▉  | 6669/8400 [00:14<00:04, 384.14it/s]prepro_backdoor:  80%|███████▉  | 6709/8400 [00:14<00:04, 387.96it/s]prepro_backdoor:  80%|████████  | 6748/8400 [00:14<00:04, 375.17it/s]prepro_backdoor:  81%|████████  | 6786/8400 [00:14<00:04, 360.49it/s]prepro_backdoor:  81%|████████  | 6823/8400 [00:14<00:04, 347.47it/s]prepro_backdoor:  82%|████████▏ | 6864/8400 [00:15<00:04, 363.69it/s]prepro_backdoor:  82%|████████▏ | 6905/8400 [00:15<00:03, 375.82it/s]prepro_backdoor:  83%|████████▎ | 6943/8400 [00:15<00:03, 375.65it/s]prepro_backdoor:  83%|████████▎ | 6983/8400 [00:15<00:03, 380.99it/s]prepro_backdoor:  84%|████████▎ | 7022/8400 [00:15<00:03, 361.11it/s]prepro_backdoor:  84%|████████▍ | 7059/8400 [00:15<00:03, 361.48it/s]prepro_backdoor:  84%|████████▍ | 7096/8400 [00:15<00:03, 354.54it/s]prepro_backdoor:  85%|████████▍ | 7135/8400 [00:15<00:03, 362.81it/s]prepro_backdoor:  85%|████████▌ | 7175/8400 [00:15<00:03, 373.45it/s]prepro_backdoor:  86%|████████▌ | 7215/8400 [00:15<00:03, 381.13it/s]prepro_backdoor:  86%|████████▋ | 7254/8400 [00:16<00:03, 378.94it/s]prepro_backdoor:  87%|████████▋ | 7294/8400 [00:16<00:02, 383.27it/s]prepro_backdoor:  87%|████████▋ | 7334/8400 [00:16<00:02, 385.90it/s]prepro_backdoor:  88%|████████▊ | 7374/8400 [00:16<00:02, 389.99it/s]prepro_backdoor:  88%|████████▊ | 7414/8400 [00:16<00:02, 391.03it/s]prepro_backdoor:  89%|████████▊ | 7454/8400 [00:16<00:02, 391.40it/s]prepro_backdoor:  89%|████████▉ | 7494/8400 [00:16<00:02, 367.82it/s]prepro_backdoor:  90%|████████▉ | 7532/8400 [00:16<00:02, 342.68it/s]prepro_backdoor:  90%|█████████ | 7567/8400 [00:16<00:02, 344.03it/s]prepro_backdoor:  90%|█████████ | 7602/8400 [00:17<00:02, 339.51it/s]prepro_backdoor:  91%|█████████ | 7637/8400 [00:17<00:02, 331.04it/s]prepro_backdoor:  91%|█████████▏| 7678/8400 [00:17<00:02, 351.53it/s]prepro_backdoor:  92%|█████████▏| 7717/8400 [00:17<00:01, 362.10it/s]prepro_backdoor:  92%|█████████▏| 7757/8400 [00:17<00:01, 371.52it/s]prepro_backdoor:  93%|█████████▎| 7797/8400 [00:17<00:01, 379.53it/s]prepro_backdoor:  93%|█████████▎| 7836/8400 [00:17<00:01, 373.65it/s]prepro_backdoor:  94%|█████████▍| 7875/8400 [00:17<00:01, 377.25it/s]prepro_backdoor:  94%|█████████▍| 7913/8400 [00:17<00:01, 359.02it/s]prepro_backdoor:  95%|█████████▍| 7950/8400 [00:17<00:01, 356.82it/s]prepro_backdoor:  95%|█████████▌| 7986/8400 [00:18<00:01, 355.83it/s]prepro_backdoor:  96%|█████████▌| 8027/8400 [00:18<00:01, 369.14it/s]prepro_backdoor:  96%|█████████▌| 8065/8400 [00:18<00:00, 358.21it/s]prepro_backdoor:  96%|█████████▋| 8101/8400 [00:18<00:00, 347.48it/s]prepro_backdoor:  97%|█████████▋| 8136/8400 [00:18<00:00, 340.41it/s]prepro_backdoor:  97%|█████████▋| 8171/8400 [00:18<00:00, 331.61it/s]prepro_backdoor:  98%|█████████▊| 8205/8400 [00:18<00:00, 329.05it/s]prepro_backdoor:  98%|█████████▊| 8239/8400 [00:18<00:00, 330.97it/s]prepro_backdoor:  98%|█████████▊| 8273/8400 [00:18<00:00, 333.43it/s]prepro_backdoor:  99%|█████████▉| 8307/8400 [00:19<00:00, 321.21it/s]prepro_backdoor:  99%|█████████▉| 8340/8400 [00:19<00:00, 287.98it/s]prepro_backdoor: 100%|█████████▉| 8372/8400 [00:19<00:00, 296.47it/s]prepro_backdoor: 100%|██████████| 8400/8400 [00:19<00:00, 433.36it/s]
INFO:root:stage2 start
2025-03-09:18:54:10 [INFO    ] [badnet.py:193] stage2 start
DEBUG:root:image_size ONLY apply for vit!!!
If you use vit make sure you set the image size!
DEBUG:root:This class REQUIRE bd dataset to implement overwrite methods. This is NOT a general class for all cls task.
INFO:root:Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
2025-03-09:18:54:10 [INFO    ] [trainer_cls.py:972] Do NOT set the settings/parameters attr manually after you start training!
You may break the relationship between them.
INFO:root:('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
2025-03-09:18:54:11 [INFO    ] [trainer_cls.py:1030] ('epoch_now:0, '
 'batch_now:0self.amp:False,self.criterion:CrossEntropyLoss(),self.optimizer:SGD '
 '(\n'
 'Parameter Group 0\n'
 '    dampening: 0\n'
 '    initial_lr: 0.01\n'
 '    lr: 0.01\n'
 '    maximize: False\n'
 '    momentum: 0.9\n'
 '    nesterov: False\n'
 '    weight_decay: 0.0005\n'
 "),self.scheduler:{'T_max': 100, 'eta_min': 0, 'base_lrs': [0.01], "
 "'last_epoch': 0, '_step_count': 1, 'verbose': False, "
 "'_get_lr_called_within_step': False, '_last_lr': [0.01]},self.scaler:{})")
INFO:root:one epoch training part done, use time = 320.0286567211151 s
2025-03-09:18:59:31 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 320.0286567211151 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
2025-03-09:18:59:36 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.457083314115351,
 'clean_test_loss_avg_over_batch': 1.8078127304712932,
 'epoch': 0,
 'test_acc': 0.1667857142857143,
 'test_asr': 0.9997142857142857,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.2414212962962963,
 'train_acc_clean_only': 0.1665380658436214,
 'train_asr_bd_only': 0.9153703703703704,
 'train_epoch_loss_avg_over_batch': 2.0341324527528553,
 'train_ra_bd_only': 0.16810185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.9097144603729 s
2025-03-09:19:04:39 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.9097144603729 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
2025-03-09:19:04:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.367158859426325,
 'clean_test_loss_avg_over_batch': 1.8095421140844172,
 'epoch': 1,
 'test_acc': 0.16666666666666666,
 'test_asr': 0.998,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.24873148148148147,
 'train_acc_clean_only': 0.1672582304526749,
 'train_asr_bd_only': 0.9819907407407408,
 'train_epoch_loss_avg_over_batch': 1.8087508404696429,
 'train_ra_bd_only': 0.16923611111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.209591627121 s
2025-03-09:19:09:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.209591627121 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
2025-03-09:19:09:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.380426287651062,
 'clean_test_loss_avg_over_batch': 1.774042339035959,
 'epoch': 2,
 'test_acc': 0.19964285714285715,
 'test_asr': 0.8692857142857143,
 'test_ra': 0.057,
 'train_acc': 0.25997453703703705,
 'train_acc_clean_only': 0.1884619341563786,
 'train_asr_bd_only': 0.903587962962963,
 'train_epoch_loss_avg_over_batch': 1.7492024630440606,
 'train_ra_bd_only': 0.1904398148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 288.09267711639404 s
2025-03-09:19:14:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 288.09267711639404 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
2025-03-09:19:14:50 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4028584783727474,
 'clean_test_loss_avg_over_batch': 1.6613002943270134,
 'epoch': 3,
 'test_acc': 0.26916666666666667,
 'test_asr': 0.7524285714285714,
 'test_ra': 0.14942857142857144,
 'train_acc': 0.3012916666666667,
 'train_acc_clean_only': 0.2495164609053498,
 'train_asr_bd_only': 0.7672685185185185,
 'train_epoch_loss_avg_over_batch': 1.6610973630481296,
 'train_ra_bd_only': 0.24824074074074073}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.6486175060272 s
2025-03-09:19:19:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.6486175060272 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
2025-03-09:19:19:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.4892562476071445,
 'clean_test_loss_avg_over_batch': 1.5218957337466152,
 'epoch': 4,
 'test_acc': 0.3701190476190476,
 'test_asr': 0.37157142857142855,
 'test_ra': 0.33514285714285713,
 'train_acc': 0.3739212962962963,
 'train_acc_clean_only': 0.35536779835390947,
 'train_asr_bd_only': 0.5409027777777777,
 'train_epoch_loss_avg_over_batch': 1.4914301489017627,
 'train_ra_bd_only': 0.3573148148148148}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 296.1790382862091 s
2025-03-09:19:24:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 296.1790382862091 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
2025-03-09:19:24:57 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.6052926410328259,
 'clean_test_loss_avg_over_batch': 1.5391769418210695,
 'epoch': 5,
 'test_acc': 0.4151190476190476,
 'test_asr': 0.3172857142857143,
 'test_ra': 0.3952857142857143,
 'train_acc': 0.4601064814814815,
 'train_acc_clean_only': 0.4686908436213992,
 'train_asr_bd_only': 0.3828472222222222,
 'train_epoch_loss_avg_over_batch': 1.2890661113173874,
 'train_ra_bd_only': 0.4669212962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.30159044265747 s
2025-03-09:19:30:05 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.30159044265747 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
2025-03-09:19:30:09 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.5284053282304244,
 'clean_test_loss_avg_over_batch': 1.9235392528952975,
 'epoch': 6,
 'test_acc': 0.4357142857142857,
 'test_asr': 0.2872857142857143,
 'test_ra': 0.42242857142857143,
 'train_acc': 0.5361666666666667,
 'train_acc_clean_only': 0.5621090534979424,
 'train_asr_bd_only': 0.30268518518518517,
 'train_epoch_loss_avg_over_batch': 1.1117281261196843,
 'train_ra_bd_only': 0.5638425925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.07555055618286 s
2025-03-09:19:35:08 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.07555055618286 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
2025-03-09:19:35:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 1.812771463394165,
 'clean_test_loss_avg_over_batch': 2.251986105333675,
 'epoch': 7,
 'test_acc': 0.4519047619047619,
 'test_asr': 0.15671428571428572,
 'test_ra': 0.48228571428571426,
 'train_acc': 0.5992083333333333,
 'train_acc_clean_only': 0.636386316872428,
 'train_asr_bd_only': 0.26460648148148147,
 'train_epoch_loss_avg_over_batch': 0.96603059330693,
 'train_ra_bd_only': 0.6345833333333334}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.77206158638 s
2025-03-09:19:40:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.77206158638 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
2025-03-09:19:40:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1169407136568969,
 'clean_test_loss_avg_over_batch': 1.7487507408315486,
 'epoch': 8,
 'test_acc': 0.46654761904761904,
 'test_asr': 0.9508571428571428,
 'test_ra': 0.037,
 'train_acc': 0.6517361111111111,
 'train_acc_clean_only': 0.6896965020576131,
 'train_asr_bd_only': 0.3100925925925926,
 'train_epoch_loss_avg_over_batch': 0.8429736332363552,
 'train_ra_bd_only': 0.6434722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.84534525871277 s
2025-03-09:19:45:29 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.84534525871277 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
2025-03-09:19:45:34 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0542414992433888,
 'clean_test_loss_avg_over_batch': 1.6499223591703358,
 'epoch': 9,
 'test_acc': 0.5047619047619047,
 'test_asr': 0.9785714285714285,
 'test_ra': 0.017142857142857144,
 'train_acc': 0.7302847222222222,
 'train_acc_clean_only': 0.7375977366255144,
 'train_asr_bd_only': 0.6644675925925926,
 'train_epoch_loss_avg_over_batch': 0.6592599251623507,
 'train_ra_bd_only': 0.41203703703703703}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.4869089126587 s
2025-03-09:19:50:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.4869089126587 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
2025-03-09:19:50:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.16352677585726436,
 'clean_test_loss_avg_over_batch': 1.5938441997224635,
 'epoch': 10,
 'test_acc': 0.5278571428571428,
 'test_asr': 0.9437142857142857,
 'test_ra': 0.04328571428571429,
 'train_acc': 0.7615625,
 'train_acc_clean_only': 0.7709104938271605,
 'train_asr_bd_only': 0.6774305555555555,
 'train_epoch_loss_avg_over_batch': 0.584826109011968,
 'train_ra_bd_only': 0.4113657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.65514945983887 s
2025-03-09:19:55:46 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.65514945983887 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
2025-03-09:19:55:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.02192082311534746,
 'clean_test_loss_avg_over_batch': 1.527603880925612,
 'epoch': 11,
 'test_acc': 0.5391666666666667,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.0054285714285714284,
 'train_acc': 0.7820324074074074,
 'train_acc_clean_only': 0.7937011316872428,
 'train_asr_bd_only': 0.6770138888888889,
 'train_epoch_loss_avg_over_batch': 0.5372788138036375,
 'train_ra_bd_only': 0.42150462962962965}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.9272952079773 s
2025-03-09:20:00:51 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.9272952079773 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
2025-03-09:20:00:55 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022986023731275715,
 'clean_test_loss_avg_over_batch': 1.5856151206023765,
 'epoch': 12,
 'test_acc': 0.5404761904761904,
 'test_asr': 0.9918571428571429,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.7958657407407408,
 'train_acc_clean_only': 0.8088940329218107,
 'train_asr_bd_only': 0.6786111111111112,
 'train_epoch_loss_avg_over_batch': 0.5049277800012518,
 'train_ra_bd_only': 0.42486111111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 291.1149606704712 s
2025-03-09:20:05:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 291.1149606704712 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
2025-03-09:20:05:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048714363868136636,
 'clean_test_loss_avg_over_batch': 1.5542189352440112,
 'epoch': 13,
 'test_acc': 0.5548809523809524,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.010714285714285714,
 'train_acc': 0.8052199074074075,
 'train_acc_clean_only': 0.819375,
 'train_asr_bd_only': 0.6778240740740741,
 'train_epoch_loss_avg_over_batch': 0.48184405120213825,
 'train_ra_bd_only': 0.4326388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 293.19580340385437 s
2025-03-09:20:10:46 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 293.19580340385437 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
2025-03-09:20:10:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020771945746806027,
 'clean_test_loss_avg_over_batch': 1.597309578097228,
 'epoch': 14,
 'test_acc': 0.5615476190476191,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.812650462962963,
 'train_acc_clean_only': 0.8278163580246913,
 'train_asr_bd_only': 0.6761574074074074,
 'train_epoch_loss_avg_over_batch': 0.46431424125918636,
 'train_ra_bd_only': 0.43462962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 273.83412170410156 s
2025-03-09:20:15:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 273.83412170410156 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
2025-03-09:20:15:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.1993169304745441,
 'clean_test_loss_avg_over_batch': 1.6308661780574105,
 'epoch': 15,
 'test_acc': 0.5580952380952381,
 'test_asr': 0.9461428571428572,
 'test_ra': 0.03842857142857143,
 'train_acc': 0.8201736111111111,
 'train_acc_clean_only': 0.835406378600823,
 'train_asr_bd_only': 0.6830787037037037,
 'train_epoch_loss_avg_over_batch': 0.44592988097226177,
 'train_ra_bd_only': 0.43243055555555554}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.7737934589386 s
2025-03-09:20:20:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.7737934589386 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
2025-03-09:20:20:44 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.14794406879439273,
 'clean_test_loss_avg_over_batch': 1.4077433916655453,
 'epoch': 16,
 'test_acc': 0.5785714285714286,
 'test_asr': 0.9544285714285714,
 'test_ra': 0.03357142857142857,
 'train_acc': 0.8250601851851852,
 'train_acc_clean_only': 0.841766975308642,
 'train_asr_bd_only': 0.674699074074074,
 'train_epoch_loss_avg_over_batch': 0.43372913916464206,
 'train_ra_bd_only': 0.4399537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.45865511894226 s
2025-03-09:20:25:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.45865511894226 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
2025-03-09:20:25:58 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.10148431418611753,
 'clean_test_loss_avg_over_batch': 1.4645728798526707,
 'epoch': 17,
 'test_acc': 0.5972619047619048,
 'test_asr': 0.9698571428571429,
 'test_ra': 0.021714285714285714,
 'train_acc': 0.8310740740740741,
 'train_acc_clean_only': 0.8479449588477366,
 'train_asr_bd_only': 0.6792361111111112,
 'train_epoch_loss_avg_over_batch': 0.42093784546410595,
 'train_ra_bd_only': 0.4380787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.6272165775299 s
2025-03-09:20:31:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.6272165775299 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
2025-03-09:20:31:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004315822089979933,
 'clean_test_loss_avg_over_batch': 1.4766560102050954,
 'epoch': 18,
 'test_acc': 0.5888095238095238,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.8363541666666666,
 'train_acc_clean_only': 0.8542001028806584,
 'train_asr_bd_only': 0.6757407407407408,
 'train_epoch_loss_avg_over_batch': 0.4090582287841373,
 'train_ra_bd_only': 0.4415972222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.790123462677 s
2025-03-09:20:36:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.790123462677 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
2025-03-09:20:36:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0027077207634812854,
 'clean_test_loss_avg_over_batch': 1.3968641773204913,
 'epoch': 19,
 'test_acc': 0.6113095238095239,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8421342592592592,
 'train_acc_clean_only': 0.8603575102880658,
 'train_asr_bd_only': 0.678125,
 'train_epoch_loss_avg_over_batch': 0.39609445425757656,
 'train_ra_bd_only': 0.4409722222222222}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.85307717323303 s
2025-03-09:20:41:26 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.85307717323303 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
2025-03-09:20:41:30 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006291943787470122,
 'clean_test_loss_avg_over_batch': 1.556162709765362,
 'epoch': 20,
 'test_acc': 0.5882142857142857,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.8446458333333333,
 'train_acc_clean_only': 0.8634079218106996,
 'train_asr_bd_only': 0.675787037037037,
 'train_epoch_loss_avg_over_batch': 0.3899841263205917,
 'train_ra_bd_only': 0.4471527777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.3964333534241 s
2025-03-09:20:46:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.3964333534241 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
2025-03-09:20:46:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06954612255477431,
 'clean_test_loss_avg_over_batch': 1.4580438595378038,
 'epoch': 21,
 'test_acc': 0.6067857142857143,
 'test_asr': 0.981,
 'test_ra': 0.013285714285714286,
 'train_acc': 0.848474537037037,
 'train_acc_clean_only': 0.867960390946502,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.38178868478315847,
 'train_ra_bd_only': 0.4496759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.0521538257599 s
2025-03-09:20:51:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.0521538257599 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
2025-03-09:20:51:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0467508667667227,
 'clean_test_loss_avg_over_batch': 1.570868639444763,
 'epoch': 22,
 'test_acc': 0.5870238095238095,
 'test_asr': 0.9872857142857143,
 'test_ra': 0.007857142857142858,
 'train_acc': 0.8522847222222222,
 'train_acc_clean_only': 0.8721373456790124,
 'train_asr_bd_only': 0.6736111111111112,
 'train_epoch_loss_avg_over_batch': 0.3734138015817713,
 'train_ra_bd_only': 0.4512731481481482}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.0264403820038 s
2025-03-09:20:56:55 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.0264403820038 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
2025-03-09:20:57:00 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.038398771080061456,
 'clean_test_loss_avg_over_batch': 1.368454790137934,
 'epoch': 23,
 'test_acc': 0.6211904761904762,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.006285714285714286,
 'train_acc': 0.8547222222222223,
 'train_acc_clean_only': 0.8745704732510288,
 'train_asr_bd_only': 0.6760879629629629,
 'train_epoch_loss_avg_over_batch': 0.36815333269702066,
 'train_ra_bd_only': 0.44710648148148147}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.37054109573364 s
2025-03-09:21:02:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.37054109573364 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
2025-03-09:21:02:08 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08977071412902494,
 'clean_test_loss_avg_over_batch': 1.3453306420282884,
 'epoch': 24,
 'test_acc': 0.6239285714285714,
 'test_asr': 0.976,
 'test_ra': 0.018,
 'train_acc': 0.8584583333333333,
 'train_acc_clean_only': 0.8788605967078189,
 'train_asr_bd_only': 0.674837962962963,
 'train_epoch_loss_avg_over_batch': 0.3612745620497951,
 'train_ra_bd_only': 0.45057870370370373}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.0063724517822 s
2025-03-09:21:07:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.0063724517822 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
2025-03-09:21:07:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.09649185939818959,
 'clean_test_loss_avg_over_batch': 1.4926294101910158,
 'epoch': 25,
 'test_acc': 0.6140476190476191,
 'test_asr': 0.9755714285714285,
 'test_ra': 0.018857142857142857,
 'train_acc': 0.8609189814814815,
 'train_acc_clean_only': 0.8820010288065844,
 'train_asr_bd_only': 0.6711805555555556,
 'train_epoch_loss_avg_over_batch': 0.35582616006445,
 'train_ra_bd_only': 0.4565046296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.5569839477539 s
2025-03-09:21:12:27 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.5569839477539 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
2025-03-09:21:12:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.028794619228309868,
 'clean_test_loss_avg_over_batch': 1.3407677876001054,
 'epoch': 26,
 'test_acc': 0.6255952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8634560185185185,
 'train_acc_clean_only': 0.8845216049382716,
 'train_asr_bd_only': 0.6738657407407408,
 'train_epoch_loss_avg_over_batch': 0.3507654040566197,
 'train_ra_bd_only': 0.4536574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.17482924461365 s
2025-03-09:21:17:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.17482924461365 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
2025-03-09:21:17:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.002187352140423503,
 'clean_test_loss_avg_over_batch': 1.4239665552635083,
 'epoch': 27,
 'test_acc': 0.6159523809523809,
 'test_asr': 1.0,
 'test_ra': 0.0,
 'train_acc': 0.8670648148148148,
 'train_acc_clean_only': 0.8885931069958848,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.34348855132968337,
 'train_ra_bd_only': 0.45532407407407405}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 290.72679352760315 s
2025-03-09:21:22:34 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 290.72679352760315 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
2025-03-09:21:22:39 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.08231341500808909,
 'clean_test_loss_avg_over_batch': 1.2747694153451559,
 'epoch': 28,
 'test_acc': 0.6463095238095238,
 'test_asr': 0.9787142857142858,
 'test_ra': 0.016142857142857143,
 'train_acc': 0.8685185185185185,
 'train_acc_clean_only': 0.8902494855967078,
 'train_asr_bd_only': 0.6729398148148148,
 'train_epoch_loss_avg_over_batch': 0.3401389447759699,
 'train_ra_bd_only': 0.45666666666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.3846137523651 s
2025-03-09:21:27:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.3846137523651 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
2025-03-09:21:27:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01960229098119519,
 'clean_test_loss_avg_over_batch': 1.42427536574277,
 'epoch': 29,
 'test_acc': 0.6130952380952381,
 'test_asr': 0.9934285714285714,
 'test_ra': 0.005285714285714286,
 'train_acc': 0.8707986111111111,
 'train_acc_clean_only': 0.8927932098765432,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.33447332851975053,
 'train_ra_bd_only': 0.4544675925925926}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 291.4141573905945 s
2025-03-09:21:32:43 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 291.4141573905945 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
2025-03-09:21:32:48 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03011732901742851,
 'clean_test_loss_avg_over_batch': 1.3721502549861642,
 'epoch': 30,
 'test_acc': 0.6382142857142857,
 'test_asr': 0.9898571428571429,
 'test_ra': 0.007571428571428572,
 'train_acc': 0.8728842592592593,
 'train_acc_clean_only': 0.895082304526749,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.33014068812794156,
 'train_ra_bd_only': 0.45766203703703706}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.5969326496124 s
2025-03-09:21:37:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.5969326496124 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
2025-03-09:21:37:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07789958600293506,
 'clean_test_loss_avg_over_batch': 1.323183678993673,
 'epoch': 31,
 'test_acc': 0.6347619047619047,
 'test_asr': 0.979,
 'test_ra': 0.018,
 'train_acc': 0.8755787037037037,
 'train_acc_clean_only': 0.8976543209876543,
 'train_asr_bd_only': 0.6768981481481482,
 'train_epoch_loss_avg_over_batch': 0.3244333667446066,
 'train_ra_bd_only': 0.4583333333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.6858048439026 s
2025-03-09:21:42:59 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.6858048439026 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
2025-03-09:21:43:04 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.052195155194071544,
 'clean_test_loss_avg_over_batch': 1.3787871314720674,
 'epoch': 32,
 'test_acc': 0.6357142857142857,
 'test_asr': 0.9834285714285714,
 'test_ra': 0.012857142857142857,
 'train_acc': 0.8761666666666666,
 'train_acc_clean_only': 0.8989094650205761,
 'train_asr_bd_only': 0.6714814814814815,
 'train_epoch_loss_avg_over_batch': 0.3228383884827296,
 'train_ra_bd_only': 0.4617824074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 301.5876667499542 s
2025-03-09:21:48:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 301.5876667499542 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
2025-03-09:21:48:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.048866495191627606,
 'clean_test_loss_avg_over_batch': 1.3417089166063252,
 'epoch': 33,
 'test_acc': 0.638095238095238,
 'test_asr': 0.9828571428571429,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.8785,
 'train_acc_clean_only': 0.901304012345679,
 'train_asr_bd_only': 0.6732638888888889,
 'train_epoch_loss_avg_over_batch': 0.3177453843222724,
 'train_ra_bd_only': 0.4576388888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.99691557884216 s
2025-03-09:21:53:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.99691557884216 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
2025-03-09:21:53:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.047728084597143935,
 'clean_test_loss_avg_over_batch': 1.32139353781487,
 'epoch': 34,
 'test_acc': 0.6478571428571429,
 'test_asr': 0.9818571428571429,
 'test_ra': 0.014714285714285714,
 'train_acc': 0.8798888888888889,
 'train_acc_clean_only': 0.9025874485596708,
 'train_asr_bd_only': 0.6756018518518518,
 'train_epoch_loss_avg_over_batch': 0.3143943744809539,
 'train_ra_bd_only': 0.45872685185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 289.4278643131256 s
2025-03-09:21:58:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 289.4278643131256 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
2025-03-09:21:58:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.044929113317365675,
 'clean_test_loss_avg_over_batch': 1.4169606612713048,
 'epoch': 35,
 'test_acc': 0.6167857142857143,
 'test_asr': 0.9815714285714285,
 'test_ra': 0.014142857142857143,
 'train_acc': 0.8815949074074074,
 'train_acc_clean_only': 0.9047196502057613,
 'train_asr_bd_only': 0.6734722222222222,
 'train_epoch_loss_avg_over_batch': 0.3103006035177796,
 'train_ra_bd_only': 0.4587962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.78582239151 s
2025-03-09:22:03:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.78582239151 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
2025-03-09:22:03:17 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.035402583048297936,
 'clean_test_loss_avg_over_batch': 1.3303868843411857,
 'epoch': 36,
 'test_acc': 0.6461904761904762,
 'test_asr': 0.9865714285714285,
 'test_ra': 0.010571428571428572,
 'train_acc': 0.8838402777777777,
 'train_acc_clean_only': 0.9072685185185185,
 'train_asr_bd_only': 0.6729861111111111,
 'train_epoch_loss_avg_over_batch': 0.30718704122525675,
 'train_ra_bd_only': 0.4625694444444444}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 292.1464776992798 s
2025-03-09:22:08:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 292.1464776992798 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
2025-03-09:22:08:15 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017409161139618268,
 'clean_test_loss_avg_over_batch': 1.459440332470518,
 'epoch': 37,
 'test_acc': 0.6295238095238095,
 'test_asr': 0.995,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.8850462962962963,
 'train_acc_clean_only': 0.9088143004115227,
 'train_asr_bd_only': 0.6711342592592593,
 'train_epoch_loss_avg_over_batch': 0.3040418815480338,
 'train_ra_bd_only': 0.4634027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 301.87930274009705 s
2025-03-09:22:13:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 301.87930274009705 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
2025-03-09:22:13:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06856068774676798,
 'clean_test_loss_avg_over_batch': 1.373660361676505,
 'epoch': 38,
 'test_acc': 0.6471428571428571,
 'test_asr': 0.975,
 'test_ra': 0.019285714285714285,
 'train_acc': 0.8861689814814815,
 'train_acc_clean_only': 0.9099742798353909,
 'train_asr_bd_only': 0.6719212962962963,
 'train_epoch_loss_avg_over_batch': 0.30136130377098364,
 'train_ra_bd_only': 0.4635416666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.325954914093 s
2025-03-09:22:18:19 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.325954914093 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
2025-03-09:22:18:24 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025575083598695612,
 'clean_test_loss_avg_over_batch': 1.3194158594265128,
 'epoch': 39,
 'test_acc': 0.6580952380952381,
 'test_asr': 0.9895714285714285,
 'test_ra': 0.008714285714285714,
 'train_acc': 0.8881851851851852,
 'train_acc_clean_only': 0.912201646090535,
 'train_asr_bd_only': 0.672037037037037,
 'train_epoch_loss_avg_over_batch': 0.29613663114662525,
 'train_ra_bd_only': 0.46511574074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.5397539138794 s
2025-03-09:22:23:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.5397539138794 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
2025-03-09:22:23:38 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0045881697807503355,
 'clean_test_loss_avg_over_batch': 1.4238321519259252,
 'epoch': 40,
 'test_acc': 0.6345238095238095,
 'test_asr': 0.9987142857142857,
 'test_ra': 0.0012857142857142856,
 'train_acc': 0.890087962962963,
 'train_acc_clean_only': 0.9146219135802469,
 'train_asr_bd_only': 0.6692824074074074,
 'train_epoch_loss_avg_over_batch': 0.29282330285619806,
 'train_ra_bd_only': 0.4671064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 311.2188415527344 s
2025-03-09:22:28:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 311.2188415527344 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
2025-03-09:22:28:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016857420627705077,
 'clean_test_loss_avg_over_batch': 1.3490805978124791,
 'epoch': 41,
 'test_acc': 0.6497619047619048,
 'test_asr': 0.9924285714285714,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.8911481481481481,
 'train_acc_clean_only': 0.9156327160493827,
 'train_asr_bd_only': 0.670787037037037,
 'train_epoch_loss_avg_over_batch': 0.2899898088817243,
 'train_ra_bd_only': 0.4655324074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 282.4765570163727 s
2025-03-09:22:33:37 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 282.4765570163727 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
2025-03-09:22:33:41 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06348228450885719,
 'clean_test_loss_avg_over_batch': 1.3827338009282495,
 'epoch': 42,
 'test_acc': 0.6377380952380952,
 'test_asr': 0.9807142857142858,
 'test_ra': 0.015428571428571429,
 'train_acc': 0.8927662037037037,
 'train_acc_clean_only': 0.9172427983539094,
 'train_asr_bd_only': 0.6724768518518518,
 'train_epoch_loss_avg_over_batch': 0.2853848528906151,
 'train_ra_bd_only': 0.46564814814814814}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.44273614883423 s
2025-03-09:22:38:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.44273614883423 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
2025-03-09:22:38:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019586144654418935,
 'clean_test_loss_avg_over_batch': 1.3294361176138574,
 'epoch': 43,
 'test_acc': 0.6570238095238096,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.008,
 'train_acc': 0.8950046296296297,
 'train_acc_clean_only': 0.9195781893004116,
 'train_asr_bd_only': 0.6738425925925926,
 'train_epoch_loss_avg_over_batch': 0.2817116515327383,
 'train_ra_bd_only': 0.4647453703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.1085500717163 s
2025-03-09:22:44:03 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.1085500717163 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
2025-03-09:22:44:08 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0025884800230745564,
 'clean_test_loss_avg_over_batch': 1.4012760686490573,
 'epoch': 44,
 'test_acc': 0.6426190476190476,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.8962199074074074,
 'train_acc_clean_only': 0.9210108024691358,
 'train_asr_bd_only': 0.6731018518518519,
 'train_epoch_loss_avg_over_batch': 0.27827018350804295,
 'train_ra_bd_only': 0.46597222222222223}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.965594291687 s
2025-03-09:22:49:13 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.965594291687 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
2025-03-09:22:49:18 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022222386965189467,
 'clean_test_loss_avg_over_batch': 1.4579006964058587,
 'epoch': 45,
 'test_acc': 0.6467857142857143,
 'test_asr': 0.9908571428571429,
 'test_ra': 0.008,
 'train_acc': 0.898125,
 'train_acc_clean_only': 0.9233796296296296,
 'train_asr_bd_only': 0.6708333333333333,
 'train_epoch_loss_avg_over_batch': 0.2744320319802673,
 'train_ra_bd_only': 0.4689351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.0780129432678 s
2025-03-09:22:54:23 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.0780129432678 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
2025-03-09:22:54:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06631568237578242,
 'clean_test_loss_avg_over_batch': 1.3901100391239831,
 'epoch': 46,
 'test_acc': 0.6483333333333333,
 'test_asr': 0.9768571428571429,
 'test_ra': 0.019142857142857142,
 'train_acc': 0.8996481481481482,
 'train_acc_clean_only': 0.9250205761316872,
 'train_asr_bd_only': 0.6712962962962963,
 'train_epoch_loss_avg_over_batch': 0.2718974446323183,
 'train_ra_bd_only': 0.46923611111111113}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.5369396209717 s
2025-03-09:22:59:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.5369396209717 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
2025-03-09:22:59:43 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010313183386196297,
 'clean_test_loss_avg_over_batch': 1.339132009582086,
 'epoch': 47,
 'test_acc': 0.6539285714285714,
 'test_asr': 0.9955714285714286,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9014722222222222,
 'train_acc_clean_only': 0.9268801440329218,
 'train_asr_bd_only': 0.6728009259259259,
 'train_epoch_loss_avg_over_batch': 0.2669714174579691,
 'train_ra_bd_only': 0.4688657407407407}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 304.2050895690918 s
2025-03-09:23:04:47 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 304.2050895690918 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
2025-03-09:23:04:52 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004392689722854728,
 'clean_test_loss_avg_over_batch': 1.3129955197712688,
 'epoch': 48,
 'test_acc': 0.6595238095238095,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.9020833333333333,
 'train_acc_clean_only': 0.9278369341563786,
 'train_asr_bd_only': 0.6703009259259259,
 'train_epoch_loss_avg_over_batch': 0.264556583362597,
 'train_ra_bd_only': 0.47280092592592593}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 660.1232922077179 s
2025-03-09:23:15:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 660.1232922077179 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
2025-03-09:23:16:16 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007327140707109886,
 'clean_test_loss_avg_over_batch': 1.4074894244020635,
 'epoch': 49,
 'test_acc': 0.6458333333333334,
 'test_asr': 0.9974285714285714,
 'test_ra': 0.002,
 'train_acc': 0.9040023148148149,
 'train_acc_clean_only': 0.9298148148148148,
 'train_asr_bd_only': 0.6716898148148148,
 'train_epoch_loss_avg_over_batch': 0.2609867473884865,
 'train_ra_bd_only': 0.4695138888888889}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 678.0175042152405 s
2025-03-09:23:27:35 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 678.0175042152405 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
2025-03-09:23:27:51 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006532525692389093,
 'clean_test_loss_avg_over_batch': 1.3667594675313344,
 'epoch': 50,
 'test_acc': 0.6454761904761904,
 'test_asr': 0.9988571428571429,
 'test_ra': 0.001142857142857143,
 'train_acc': 0.9059652777777778,
 'train_acc_clean_only': 0.9317232510288066,
 'train_asr_bd_only': 0.6741435185185185,
 'train_epoch_loss_avg_over_batch': 0.2566161019956624,
 'train_ra_bd_only': 0.4685185185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 596.7509841918945 s
2025-03-09:23:37:48 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 596.7509841918945 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
2025-03-09:23:38:12 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022201421581187538,
 'clean_test_loss_avg_over_batch': 1.3522082935228492,
 'epoch': 51,
 'test_acc': 0.6576190476190477,
 'test_asr': 0.9885714285714285,
 'test_ra': 0.009714285714285713,
 'train_acc': 0.9072037037037037,
 'train_acc_clean_only': 0.9330401234567901,
 'train_asr_bd_only': 0.674675925925926,
 'train_epoch_loss_avg_over_batch': 0.25331252843583074,
 'train_ra_bd_only': 0.4674537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 750.7797677516937 s
2025-03-09:23:50:43 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 750.7797677516937 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
2025-03-09:23:51:09 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006725884753872048,
 'clean_test_loss_avg_over_batch': 1.342279247036486,
 'epoch': 52,
 'test_acc': 0.6545238095238095,
 'test_asr': 0.9994285714285714,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9079768518518518,
 'train_acc_clean_only': 0.9343184156378601,
 'train_asr_bd_only': 0.6709027777777777,
 'train_epoch_loss_avg_over_batch': 0.2519188011067885,
 'train_ra_bd_only': 0.4728703703703704}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 682.8646173477173 s
2025-03-10:00:02:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 682.8646173477173 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
2025-03-10:00:03:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.043000884227116,
 'clean_test_loss_avg_over_batch': 1.4203936532704216,
 'epoch': 53,
 'test_acc': 0.6575,
 'test_asr': 0.9814285714285714,
 'test_ra': 0.014857142857142857,
 'train_acc': 0.9093680555555556,
 'train_acc_clean_only': 0.9360133744855967,
 'train_asr_bd_only': 0.6695601851851852,
 'train_epoch_loss_avg_over_batch': 0.24878777704415497,
 'train_ra_bd_only': 0.47368055555555555}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 665.3225314617157 s
2025-03-10:00:14:07 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 665.3225314617157 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
2025-03-10:00:14:35 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07437574062073095,
 'clean_test_loss_avg_over_batch': 1.3549162764948877,
 'epoch': 54,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9801428571428571,
 'test_ra': 0.015142857142857144,
 'train_acc': 0.9109027777777777,
 'train_acc_clean_only': 0.9373302469135802,
 'train_asr_bd_only': 0.6730555555555555,
 'train_epoch_loss_avg_over_batch': 0.2454222890911279,
 'train_ra_bd_only': 0.47208333333333335}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 670.7844941616058 s
2025-03-10:00:25:46 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 670.7844941616058 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
2025-03-10:00:26:10 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020862419010055335,
 'clean_test_loss_avg_over_batch': 1.3909398301532774,
 'epoch': 55,
 'test_acc': 0.659047619047619,
 'test_asr': 0.9905714285714285,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.912699074074074,
 'train_acc_clean_only': 0.9391898148148148,
 'train_asr_bd_only': 0.6742824074074074,
 'train_epoch_loss_avg_over_batch': 0.2415579411961414,
 'train_ra_bd_only': 0.47046296296296297}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 681.1699070930481 s
2025-03-10:00:37:32 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 681.1699070930481 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
2025-03-10:00:37:57 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.04394162977325984,
 'clean_test_loss_avg_over_batch': 1.3821922542922425,
 'epoch': 56,
 'test_acc': 0.6597619047619048,
 'test_asr': 0.9844285714285714,
 'test_ra': 0.012,
 'train_acc': 0.9135162037037037,
 'train_acc_clean_only': 0.9403420781893004,
 'train_asr_bd_only': 0.6720833333333334,
 'train_epoch_loss_avg_over_batch': 0.23860637691065117,
 'train_ra_bd_only': 0.4727546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 643.7369225025177 s
2025-03-10:00:48:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 643.7369225025177 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
2025-03-10:00:49:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.07557482782073996,
 'clean_test_loss_avg_over_batch': 1.3864752690900455,
 'epoch': 57,
 'test_acc': 0.6670238095238096,
 'test_asr': 0.9827142857142858,
 'test_ra': 0.013857142857142858,
 'train_acc': 0.9146412037037037,
 'train_acc_clean_only': 0.9417103909465021,
 'train_asr_bd_only': 0.6710185185185186,
 'train_epoch_loss_avg_over_batch': 0.23657873545311114,
 'train_ra_bd_only': 0.4764351851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 618.2160613536835 s
2025-03-10:00:59:19 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 618.2160613536835 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
2025-03-10:00:59:45 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01659586519341577,
 'clean_test_loss_avg_over_batch': 1.4046508661104422,
 'epoch': 58,
 'test_acc': 0.6476190476190476,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.0037142857142857142,
 'train_acc': 0.9158819444444445,
 'train_acc_clean_only': 0.9432844650205762,
 'train_asr_bd_only': 0.6692592592592592,
 'train_epoch_loss_avg_over_batch': 0.2330902679408038,
 'train_ra_bd_only': 0.4777777777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 778.493367433548 s
2025-03-10:01:12:44 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 778.493367433548 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
2025-03-10:01:13:03 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.015342635542831638,
 'clean_test_loss_avg_over_batch': 1.3787070976175142,
 'epoch': 59,
 'test_acc': 0.6646428571428571,
 'test_asr': 0.9967142857142857,
 'test_ra': 0.003,
 'train_acc': 0.9176435185185186,
 'train_acc_clean_only': 0.944781378600823,
 'train_asr_bd_only': 0.6734027777777778,
 'train_epoch_loss_avg_over_batch': 0.22974307157595952,
 'train_ra_bd_only': 0.47412037037037036}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 665.2815058231354 s
2025-03-10:01:24:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 665.2815058231354 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
2025-03-10:01:24:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03500813461035829,
 'clean_test_loss_avg_over_batch': 1.3722696398017984,
 'epoch': 60,
 'test_acc': 0.6695238095238095,
 'test_asr': 0.9871428571428571,
 'test_ra': 0.01,
 'train_acc': 0.9183425925925925,
 'train_acc_clean_only': 0.9459439300411523,
 'train_asr_bd_only': 0.6699305555555556,
 'train_epoch_loss_avg_over_batch': 0.22712182017829682,
 'train_ra_bd_only': 0.47935185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.4986798763275 s
2025-03-10:01:29:24 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.4986798763275 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
2025-03-10:01:29:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016552998436699537,
 'clean_test_loss_avg_over_batch': 1.3867387185155442,
 'epoch': 61,
 'test_acc': 0.6714285714285714,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.006571428571428572,
 'train_acc': 0.9199444444444445,
 'train_acc_clean_only': 0.9476337448559671,
 'train_asr_bd_only': 0.6707407407407407,
 'train_epoch_loss_avg_over_batch': 0.22397457329211412,
 'train_ra_bd_only': 0.4783101851851852}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.241082906723 s
2025-03-10:01:34:38 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.241082906723 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
2025-03-10:01:34:42 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.014192926822314886,
 'clean_test_loss_avg_over_batch': 1.4946788623364586,
 'epoch': 62,
 'test_acc': 0.6710714285714285,
 'test_asr': 0.9935714285714285,
 'test_ra': 0.006,
 'train_acc': 0.9214143518518518,
 'train_acc_clean_only': 0.9488528806584362,
 'train_asr_bd_only': 0.6744675925925926,
 'train_epoch_loss_avg_over_batch': 0.22049740755116498,
 'train_ra_bd_only': 0.4761111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.1522560119629 s
2025-03-10:01:39:50 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.1522560119629 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
2025-03-10:01:39:54 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012735241220798343,
 'clean_test_loss_avg_over_batch': 1.343238567989884,
 'epoch': 63,
 'test_acc': 0.6775,
 'test_asr': 0.9952857142857143,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9227476851851852,
 'train_acc_clean_only': 0.950270061728395,
 'train_asr_bd_only': 0.6750462962962963,
 'train_epoch_loss_avg_over_batch': 0.21673089928317954,
 'train_ra_bd_only': 0.4739583333333333}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.6522784233093 s
2025-03-10:01:44:57 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.6522784233093 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
2025-03-10:01:45:02 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011207303603772412,
 'clean_test_loss_avg_over_batch': 1.3719215720440403,
 'epoch': 64,
 'test_acc': 0.6752380952380952,
 'test_asr': 0.996,
 'test_ra': 0.0034285714285714284,
 'train_acc': 0.9240486111111111,
 'train_acc_clean_only': 0.9519701646090535,
 'train_asr_bd_only': 0.6727546296296296,
 'train_epoch_loss_avg_over_batch': 0.2141736142127602,
 'train_ra_bd_only': 0.47685185185185186}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.3246359825134 s
2025-03-10:01:50:09 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.3246359825134 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
2025-03-10:01:50:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005936301726085896,
 'clean_test_loss_avg_over_batch': 1.4637453668948375,
 'epoch': 65,
 'test_acc': 0.6419047619047619,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00028571428571428574,
 'train_acc': 0.9256412037037037,
 'train_acc_clean_only': 0.9535442386831275,
 'train_asr_bd_only': 0.6745138888888889,
 'train_epoch_loss_avg_over_batch': 0.21105881146589914,
 'train_ra_bd_only': 0.47608796296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 313.7210326194763 s
2025-03-10:01:55:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 313.7210326194763 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
2025-03-10:01:55:33 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007999686028977687,
 'clean_test_loss_avg_over_batch': 1.4315893663037005,
 'epoch': 66,
 'test_acc': 0.6628571428571428,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9265439814814814,
 'train_acc_clean_only': 0.9544135802469136,
 'train_asr_bd_only': 0.6757175925925926,
 'train_epoch_loss_avg_over_batch': 0.20760281562584418,
 'train_ra_bd_only': 0.4753935185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 283.83710765838623 s
2025-03-10:02:00:17 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 283.83710765838623 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
2025-03-10:02:00:22 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004524292362938551,
 'clean_test_loss_avg_over_batch': 1.3769899409998096,
 'epoch': 67,
 'test_acc': 0.6825,
 'test_asr': 0.9995714285714286,
 'test_ra': 0.00042857142857142855,
 'train_acc': 0.9281319444444445,
 'train_acc_clean_only': 0.9565097736625514,
 'train_asr_bd_only': 0.6727314814814814,
 'train_epoch_loss_avg_over_batch': 0.2043123322504538,
 'train_ra_bd_only': 0.47962962962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 299.63066935539246 s
2025-03-10:02:05:22 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 299.63066935539246 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
2025-03-10:02:05:27 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011337989500977776,
 'clean_test_loss_avg_over_batch': 1.4379600770630394,
 'epoch': 68,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.998,
 'test_ra': 0.0018571428571428571,
 'train_acc': 0.929162037037037,
 'train_acc_clean_only': 0.957716049382716,
 'train_asr_bd_only': 0.6721759259259259,
 'train_epoch_loss_avg_over_batch': 0.20163660510822579,
 'train_ra_bd_only': 0.48094907407407406}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.52539443969727 s
2025-03-10:02:10:33 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.52539443969727 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
2025-03-10:02:10:38 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009802682203537022,
 'clean_test_loss_avg_over_batch': 1.3754253465908044,
 'epoch': 69,
 'test_acc': 0.675952380952381,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003,
 'train_acc': 0.9299837962962964,
 'train_acc_clean_only': 0.958832304526749,
 'train_asr_bd_only': 0.6703472222222222,
 'train_epoch_loss_avg_over_batch': 0.19985233191649118,
 'train_ra_bd_only': 0.48217592592592595}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.871954202652 s
2025-03-10:02:15:49 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.871954202652 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
2025-03-10:02:15:53 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.020632247120903974,
 'clean_test_loss_avg_over_batch': 1.5935459576095596,
 'epoch': 70,
 'test_acc': 0.6627380952380952,
 'test_asr': 0.992,
 'test_ra': 0.006142857142857143,
 'train_acc': 0.9320347222222222,
 'train_acc_clean_only': 0.9608024691358025,
 'train_asr_bd_only': 0.673125,
 'train_epoch_loss_avg_over_batch': 0.19493661794839082,
 'train_ra_bd_only': 0.4796064814814815}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 312.69377422332764 s
2025-03-10:02:21:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 312.69377422332764 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
2025-03-10:02:21:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01551238457270136,
 'clean_test_loss_avg_over_batch': 1.468721118614529,
 'epoch': 71,
 'test_acc': 0.6738095238095239,
 'test_asr': 0.992,
 'test_ra': 0.007,
 'train_acc': 0.9330393518518518,
 'train_acc_clean_only': 0.9619855967078189,
 'train_asr_bd_only': 0.6725231481481482,
 'train_epoch_loss_avg_over_batch': 0.1922100729379389,
 'train_ra_bd_only': 0.48118055555555556}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.52701234817505 s
2025-03-10:02:26:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.52701234817505 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
2025-03-10:02:26:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.006779990971765735,
 'clean_test_loss_avg_over_batch': 1.394802541161577,
 'epoch': 72,
 'test_acc': 0.6764285714285714,
 'test_asr': 0.9978571428571429,
 'test_ra': 0.002,
 'train_acc': 0.9342106481481481,
 'train_acc_clean_only': 0.9636033950617284,
 'train_asr_bd_only': 0.669675925925926,
 'train_epoch_loss_avg_over_batch': 0.18959098747262249,
 'train_ra_bd_only': 0.4841435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.11002230644226 s
2025-03-10:02:31:23 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.11002230644226 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
2025-03-10:02:31:28 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012928109922954305,
 'clean_test_loss_avg_over_batch': 1.5697370109458764,
 'epoch': 73,
 'test_acc': 0.6732142857142858,
 'test_asr': 0.9945714285714286,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9356597222222223,
 'train_acc_clean_only': 0.9651568930041152,
 'train_asr_bd_only': 0.6701851851851852,
 'train_epoch_loss_avg_over_batch': 0.18641086749235788,
 'train_ra_bd_only': 0.48636574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 296.30641317367554 s
2025-03-10:02:36:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 296.30641317367554 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
2025-03-10:02:36:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.025345409396951173,
 'clean_test_loss_avg_over_batch': 1.389660489237444,
 'epoch': 74,
 'test_acc': 0.6776190476190476,
 'test_asr': 0.9897142857142858,
 'test_ra': 0.009,
 'train_acc': 0.9364675925925926,
 'train_acc_clean_only': 0.966275720164609,
 'train_asr_bd_only': 0.6681944444444444,
 'train_epoch_loss_avg_over_batch': 0.18405859482509118,
 'train_ra_bd_only': 0.48743055555555553}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 290.5109314918518 s
2025-03-10:02:41:20 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 290.5109314918518 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
2025-03-10:02:41:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.004672670882957226,
 'clean_test_loss_avg_over_batch': 1.5284713833508166,
 'epoch': 75,
 'test_acc': 0.6588095238095238,
 'test_asr': 0.9998571428571429,
 'test_ra': 0.00014285714285714287,
 'train_acc': 0.938837962962963,
 'train_acc_clean_only': 0.968341049382716,
 'train_asr_bd_only': 0.6733101851851852,
 'train_epoch_loss_avg_over_batch': 0.17815817722678184,
 'train_ra_bd_only': 0.4827546296296296}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.0405921936035 s
2025-03-10:02:46:36 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.0405921936035 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
2025-03-10:02:46:40 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.026898687646131625,
 'clean_test_loss_avg_over_batch': 1.4092125136292342,
 'epoch': 76,
 'test_acc': 0.6746428571428571,
 'test_asr': 0.989,
 'test_ra': 0.008857142857142857,
 'train_acc': 0.9401041666666666,
 'train_acc_clean_only': 0.9699202674897119,
 'train_asr_bd_only': 0.6717592592592593,
 'train_epoch_loss_avg_over_batch': 0.1754006903844851,
 'train_ra_bd_only': 0.48435185185185187}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.9755005836487 s
2025-03-10:02:51:45 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.9755005836487 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
2025-03-10:02:51:49 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010307360992936249,
 'clean_test_loss_avg_over_batch': 1.5073275027627295,
 'epoch': 77,
 'test_acc': 0.6778571428571428,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.003142857142857143,
 'train_acc': 0.9410138888888889,
 'train_acc_clean_only': 0.9708101851851851,
 'train_asr_bd_only': 0.6728472222222223,
 'train_epoch_loss_avg_over_batch': 0.17245211059848467,
 'train_ra_bd_only': 0.4849537037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.2534728050232 s
2025-03-10:02:56:53 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.2534728050232 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
2025-03-10:02:56:58 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.007354655870321122,
 'clean_test_loss_avg_over_batch': 1.438934921047114,
 'epoch': 78,
 'test_acc': 0.6783333333333333,
 'test_asr': 0.9975714285714286,
 'test_ra': 0.002285714285714286,
 'train_acc': 0.9423865740740741,
 'train_acc_clean_only': 0.9726105967078189,
 'train_asr_bd_only': 0.6703703703703704,
 'train_epoch_loss_avg_over_batch': 0.1697921015686459,
 'train_ra_bd_only': 0.4861574074074074}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 302.3408052921295 s
2025-03-10:03:02:01 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 302.3408052921295 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
2025-03-10:03:02:05 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009896277369592678,
 'clean_test_loss_avg_over_batch': 1.4915239365037642,
 'epoch': 79,
 'test_acc': 0.6722619047619047,
 'test_asr': 0.9971428571428571,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9435671296296296,
 'train_acc_clean_only': 0.9742438271604938,
 'train_asr_bd_only': 0.6674768518518519,
 'train_epoch_loss_avg_over_batch': 0.16605588497828555,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.07576513290405 s
2025-03-10:03:07:11 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.07576513290405 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
2025-03-10:03:07:16 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03601912012937564,
 'clean_test_loss_avg_over_batch': 1.4788463288410143,
 'epoch': 80,
 'test_acc': 0.6851190476190476,
 'test_asr': 0.9864285714285714,
 'test_ra': 0.011,
 'train_acc': 0.9455763888888888,
 'train_acc_clean_only': 0.9757921810699588,
 'train_asr_bd_only': 0.6736342592592592,
 'train_epoch_loss_avg_over_batch': 0.16192897494192476,
 'train_ra_bd_only': 0.48412037037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 299.9783070087433 s
2025-03-10:03:12:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 299.9783070087433 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
2025-03-10:03:12:21 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.06725657659857957,
 'clean_test_loss_avg_over_batch': 1.5965999864944906,
 'epoch': 81,
 'test_acc': 0.6698809523809524,
 'test_asr': 0.9861428571428571,
 'test_ra': 0.011,
 'train_acc': 0.9462916666666666,
 'train_acc_clean_only': 0.9769470164609053,
 'train_asr_bd_only': 0.6703935185185185,
 'train_epoch_loss_avg_over_batch': 0.1597550555964311,
 'train_ra_bd_only': 0.48824074074074075}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.29966402053833 s
2025-03-10:03:17:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.29966402053833 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
2025-03-10:03:17:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.0059559637426652694,
 'clean_test_loss_avg_over_batch': 1.5289267446055557,
 'epoch': 82,
 'test_acc': 0.6770238095238095,
 'test_asr': 0.9985714285714286,
 'test_ra': 0.0014285714285714286,
 'train_acc': 0.9479282407407408,
 'train_acc_clean_only': 0.9786085390946502,
 'train_asr_bd_only': 0.6718055555555555,
 'train_epoch_loss_avg_over_batch': 0.15620049757758778,
 'train_ra_bd_only': 0.4880787037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 294.9544486999512 s
2025-03-10:03:22:21 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 294.9544486999512 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
2025-03-10:03:22:26 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005375156946353276,
 'clean_test_loss_avg_over_batch': 1.5415214105424555,
 'epoch': 83,
 'test_acc': 0.6810714285714285,
 'test_asr': 0.999,
 'test_ra': 0.001,
 'train_acc': 0.9487384259259259,
 'train_acc_clean_only': 0.9796322016460906,
 'train_asr_bd_only': 0.6706944444444445,
 'train_epoch_loss_avg_over_batch': 0.1536300621419041,
 'train_ra_bd_only': 0.4893287037037037}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 290.0095634460449 s
2025-03-10:03:27:16 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 290.0095634460449 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
2025-03-10:03:27:21 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.03310960872860795,
 'clean_test_loss_avg_over_batch': 1.52899845999976,
 'epoch': 84,
 'test_acc': 0.690952380952381,
 'test_asr': 0.9882857142857143,
 'test_ra': 0.009428571428571429,
 'train_acc': 0.9500833333333333,
 'train_acc_clean_only': 0.9812191358024691,
 'train_asr_bd_only': 0.6698611111111111,
 'train_epoch_loss_avg_over_batch': 0.15069635959852626,
 'train_ra_bd_only': 0.4911111111111111}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 306.42680191993713 s
2025-03-10:03:32:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 306.42680191993713 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
2025-03-10:03:32:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.019290356115776706,
 'clean_test_loss_avg_over_batch': 1.5483848769782167,
 'epoch': 85,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9912857142857143,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9517453703703703,
 'train_acc_clean_only': 0.9820884773662552,
 'train_asr_bd_only': 0.6786574074074074,
 'train_epoch_loss_avg_over_batch': 0.14683206690240788,
 'train_ra_bd_only': 0.48310185185185184}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 308.9396970272064 s
2025-03-10:03:37:41 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 308.9396970272064 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
2025-03-10:03:37:46 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.00740151350195943,
 'clean_test_loss_avg_over_batch': 1.493791146655426,
 'epoch': 86,
 'test_acc': 0.6872619047619047,
 'test_asr': 0.9977142857142857,
 'test_ra': 0.002142857142857143,
 'train_acc': 0.9525717592592593,
 'train_acc_clean_only': 0.9838837448559671,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.1444773102733824,
 'train_ra_bd_only': 0.49020833333333336}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.6820960044861 s
2025-03-10:03:42:56 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.6820960044861 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
2025-03-10:03:43:01 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022033317166973244,
 'clean_test_loss_avg_over_batch': 1.516458348794417,
 'epoch': 87,
 'test_acc': 0.6869047619047619,
 'test_asr': 0.991,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.9530833333333333,
 'train_acc_clean_only': 0.9845190329218108,
 'train_asr_bd_only': 0.670162037037037,
 'train_epoch_loss_avg_over_batch': 0.14321892202783515,
 'train_ra_bd_only': 0.49212962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 300.9049961566925 s
2025-03-10:03:48:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 300.9049961566925 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
2025-03-10:03:48:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009673274257643655,
 'clean_test_loss_avg_over_batch': 1.5612710830049985,
 'epoch': 88,
 'test_acc': 0.6798809523809524,
 'test_asr': 0.9972857142857143,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.9542685185185186,
 'train_acc_clean_only': 0.9855658436213992,
 'train_asr_bd_only': 0.6725925925925926,
 'train_epoch_loss_avg_over_batch': 0.14036652793321344,
 'train_ra_bd_only': 0.48962962962962964}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 299.14527583122253 s
2025-03-10:03:53:06 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 299.14527583122253 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
2025-03-10:03:53:11 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.012378115272572772,
 'clean_test_loss_avg_over_batch': 1.529609964144501,
 'epoch': 89,
 'test_acc': 0.6889285714285714,
 'test_asr': 0.9944285714285714,
 'test_ra': 0.004571428571428572,
 'train_acc': 0.9554351851851852,
 'train_acc_clean_only': 0.9866049382716049,
 'train_asr_bd_only': 0.6749074074074074,
 'train_epoch_loss_avg_over_batch': 0.1369521625660084,
 'train_ra_bd_only': 0.4872916666666667}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 303.27807784080505 s
2025-03-10:03:58:15 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 303.27807784080505 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
2025-03-10:03:58:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.017563549179414457,
 'clean_test_loss_avg_over_batch': 1.5246969351375645,
 'epoch': 90,
 'test_acc': 0.6852380952380952,
 'test_asr': 0.9914285714285714,
 'test_ra': 0.0074285714285714285,
 'train_acc': 0.9554699074074074,
 'train_acc_clean_only': 0.9874022633744856,
 'train_asr_bd_only': 0.6680787037037037,
 'train_epoch_loss_avg_over_batch': 0.13714374175888522,
 'train_ra_bd_only': 0.49564814814814817}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 298.919949054718 s
2025-03-10:04:03:18 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 298.919949054718 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
2025-03-10:04:03:23 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.005847982516173612,
 'clean_test_loss_avg_over_batch': 1.538616587944103,
 'epoch': 91,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9981428571428571,
 'test_ra': 0.0017142857142857142,
 'train_acc': 0.956849537037037,
 'train_acc_clean_only': 0.9884670781893005,
 'train_asr_bd_only': 0.6722916666666666,
 'train_epoch_loss_avg_over_batch': 0.1334485155802082,
 'train_ra_bd_only': 0.491087962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 286.4932358264923 s
2025-03-10:04:08:10 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 286.4932358264923 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
2025-03-10:04:08:14 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01813579322770238,
 'clean_test_loss_avg_over_batch': 1.548304116522724,
 'epoch': 92,
 'test_acc': 0.6823809523809524,
 'test_asr': 0.9911428571428571,
 'test_ra': 0.007714285714285714,
 'train_acc': 0.95725,
 'train_acc_clean_only': 0.989102366255144,
 'train_asr_bd_only': 0.6705787037037036,
 'train_epoch_loss_avg_over_batch': 0.1327610031278045,
 'train_ra_bd_only': 0.4934027777777778}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.96514916419983 s
2025-03-10:04:13:25 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.96514916419983 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
2025-03-10:04:13:29 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.01649255279070613,
 'clean_test_loss_avg_over_batch': 1.5121548355303027,
 'epoch': 93,
 'test_acc': 0.6870238095238095,
 'test_asr': 0.9917142857142857,
 'test_ra': 0.007142857142857143,
 'train_acc': 0.9581435185185185,
 'train_acc_clean_only': 0.9899356995884774,
 'train_asr_bd_only': 0.6720138888888889,
 'train_epoch_loss_avg_over_batch': 0.13134542337170355,
 'train_ra_bd_only': 0.4921759259259259}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 297.96609354019165 s
2025-03-10:04:18:28 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 297.96609354019165 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
2025-03-10:04:18:32 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.022074892548632555,
 'clean_test_loss_avg_over_batch': 1.5162245985120535,
 'epoch': 94,
 'test_acc': 0.6879761904761905,
 'test_asr': 0.9907142857142858,
 'test_ra': 0.008,
 'train_acc': 0.9583634259259259,
 'train_acc_clean_only': 0.9903369341563786,
 'train_asr_bd_only': 0.6706018518518518,
 'train_epoch_loss_avg_over_batch': 0.13022465221142326,
 'train_ra_bd_only': 0.49365740740740743}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 309.3859534263611 s
2025-03-10:04:23:42 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 309.3859534263611 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
2025-03-10:04:23:47 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.008205607915508815,
 'clean_test_loss_avg_over_batch': 1.524913460185582,
 'epoch': 95,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.9968571428571429,
 'test_ra': 0.0027142857142857142,
 'train_acc': 0.959025462962963,
 'train_acc_clean_only': 0.9907510288065844,
 'train_asr_bd_only': 0.6734953703703703,
 'train_epoch_loss_avg_over_batch': 0.12864947986602784,
 'train_ra_bd_only': 0.49113425925925924}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.118093252182 s
2025-03-10:04:28:54 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.118093252182 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
2025-03-10:04:28:59 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.016573194016448477,
 'clean_test_loss_avg_over_batch': 1.5227560810180325,
 'epoch': 96,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9922857142857143,
 'test_ra': 0.006714285714285714,
 'train_acc': 0.9595046296296297,
 'train_acc_clean_only': 0.9912577160493827,
 'train_asr_bd_only': 0.6737268518518519,
 'train_epoch_loss_avg_over_batch': 0.12767759039225401,
 'train_ra_bd_only': 0.490462962962963}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 292.5231499671936 s
2025-03-10:04:33:52 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 292.5231499671936 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
2025-03-10:04:33:56 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.009885502223518085,
 'clean_test_loss_avg_over_batch': 1.5089105397011295,
 'epoch': 97,
 'test_acc': 0.6864285714285714,
 'test_asr': 0.996,
 'test_ra': 0.0035714285714285713,
 'train_acc': 0.9595231481481481,
 'train_acc_clean_only': 0.9912937242798354,
 'train_asr_bd_only': 0.673587962962963,
 'train_epoch_loss_avg_over_batch': 0.12747177377895072,
 'train_ra_bd_only': 0.49104166666666665}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 305.0433955192566 s
2025-03-10:04:39:02 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 305.0433955192566 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
2025-03-10:04:39:07 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.011209148735823956,
 'clean_test_loss_avg_over_batch': 1.516387497328899,
 'epoch': 98,
 'test_acc': 0.6854761904761905,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9599837962962963,
 'train_acc_clean_only': 0.9916332304526749,
 'train_asr_bd_only': 0.6751388888888888,
 'train_epoch_loss_avg_over_batch': 0.12646747744248973,
 'train_ra_bd_only': 0.48953703703703705}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:one epoch training part done, use time = 307.22301387786865 s
2025-03-10:04:44:14 [INFO    ] [trainer_cls.py:1800] one epoch training part done, use time = 307.22301387786865 s
INFO:root:{'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
2025-03-10:04:44:19 [INFO    ] [trainer_cls.py:65] {'batch': 3375,
 'bd_test_loss_avg_over_batch': 0.010139344971288334,
 'clean_test_loss_avg_over_batch': 1.5195792086535331,
 'epoch': 99,
 'test_acc': 0.6839285714285714,
 'test_asr': 0.9957142857142857,
 'test_ra': 0.003857142857142857,
 'train_acc': 0.9594236111111111,
 'train_acc_clean_only': 0.9914969135802469,
 'train_asr_bd_only': 0.6707638888888889,
 'train_epoch_loss_avg_over_batch': 0.12769494749274518,
 'train_ra_bd_only': 0.4941435185185185}
DEBUG:root:return df with np.nan and None converted by str()
DEBUG:root:return df with np.nan and None converted by str()
INFO:root:saving...
2025-03-10:04:44:19 [INFO    ] [save_load_attack.py:141] saving...
DEBUG:root:location : ./record/nad_badnet_attack_efficientnet_ffpp_multiclass/attack_result.pt
INFO:root:Saved, folder path: ./record/nad_badnet_attack_efficientnet_ffpp_multiclass
2025-03-10:04:44:20 [INFO    ] [save_load_attack.py:149] Saved, folder path: ./record/nad_badnet_attack_efficientnet_ffpp_multiclass
